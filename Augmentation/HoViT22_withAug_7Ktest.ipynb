{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "6e0b0f71-299a-4e24-ff91-ccab0fd67a1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=12d365a19dc14416ec41fae928b9eed0c0fa4e248244180d30f85d75d707f16c\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "bd07a7d7-d6c6-404e-a3df-3c8c499483cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-02-24 02:13:35--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.45.92, 188.185.48.194, 188.185.43.25, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.45.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-02-24 02:13:36--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  17.8MB/s    in 11m 22s \n",
            "\n",
            "2025-02-24 02:24:59 (16.3 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=2, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=2, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "df25f7dc-5a8b-4eba-8051-25d43a6be2b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "d28738bb-2727-402e-a461-269c17a5e8f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 4,909,234\n",
            "Trainable params: 4,909,234\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.82\n",
            "Params size (MB): 19.64\n",
            "Estimated Total Size (MB): 936.72\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "abdc4466-a68e-478d-a792-77ad2a59ba36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.82\n",
            "Params size (MB): 19.64\n",
            "Estimated Total Size (MB): 936.72\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.82\n",
            "Params size (MB): 19.64\n",
            "Estimated Total Size (MB): 936.72\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "52aaa8c8-a79e-4250-b712-b6a68eb4cb53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "g18xh7W1tv8W"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from glob import glob\n",
        "import cv2\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, dir, aug=False):\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.aug = aug\n",
        "        self.samples = [i for i in glob(os.path.join(dir, '**/*')) if os.path.isfile(i)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        class_name = os.path.basename(self.samples[idx]).split('-')[0]\n",
        "        label = {\n",
        "            'ADI': 0,\n",
        "            'BACK': 1,\n",
        "            'DEB': 2,\n",
        "            'LYM': 3,\n",
        "            'MUC': 4,\n",
        "            'MUS': 5,\n",
        "            'NORM': 6,\n",
        "            'STR': 7,\n",
        "            'TUM': 8,\n",
        "        }\n",
        "\n",
        "        img = cv2.imread(self.samples[idx], -1)[:, :, ::-1]\n",
        "        img = np.float32(img) / 255.0\n",
        "\n",
        "        if self.aug:\n",
        "            if random.random() < 0.5:\n",
        "                img = img[::-1]\n",
        "\n",
        "            if random.random() < 0.5:\n",
        "                img = img[:, ::-1]\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                if random.random() < 0.5:\n",
        "                    img += np.random.normal(\n",
        "                        0.0, np.random.uniform(0.01, 0.2),\n",
        "                        (img.shape[0], img.shape[1], img.shape[2])\n",
        "                    )\n",
        "                else:\n",
        "                    x = np.random.uniform(0.02, 0.15)\n",
        "                    img += np.random.uniform(\n",
        "                        -x, x,\n",
        "                        (img.shape[0], img.shape[1], img.shape[2])\n",
        "                    )\n",
        "\n",
        "            if random.random() < 0.9:\n",
        "                img += np.random.uniform(-0.15, 0.15, (1, 1, 3))\n",
        "                img *= np.random.uniform(0.85, 1.15, (1, 1, 3))\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                kX, kY = np.random.randint(0, 4, 2) * 2 + 1\n",
        "                if random.random() < 0.5:\n",
        "                    img = cv2.GaussianBlur(img, (kX, kY), 0)\n",
        "                else:\n",
        "                    img = cv2.blur(img, (kX, kY))\n",
        "\n",
        "        img = np.uint8(np.clip(img, 0, 1) * 255.0)\n",
        "        img = self.transform(Image.fromarray(img))\n",
        "\n",
        "        return img, label[class_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset(dir=train_dir, aug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "train_data = Subset(dataset, load_train_idx)\n",
        "val_data = Subset(dataset, load_val_idx)\n",
        "test_data = Subset(dataset, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "996f9141-d5a5-4ecc-8e35-c7c62b899565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    val_losses.append(epoch_loss)\n",
        "    val_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "1f7ef208-8788-4ba4-97ac-1a11f0fa19ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:04<00:00,  5.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.8917, Train Accuracy: 67.88%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.5169, Validation Accuracy: 81.79%\n",
            "Balanced Accuracy: 0.8116\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4488, Train Accuracy: 83.97%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.3839, Validation Accuracy: 86.70%\n",
            "Balanced Accuracy: 0.8651\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3283, Train Accuracy: 88.53%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.2493, Validation Accuracy: 91.28%\n",
            "Balanced Accuracy: 0.9121\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2632, Train Accuracy: 90.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.2370, Validation Accuracy: 91.99%\n",
            "Balanced Accuracy: 0.9219\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2210, Train Accuracy: 92.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.2177, Validation Accuracy: 92.69%\n",
            "Balanced Accuracy: 0.9276\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:01<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1964, Train Accuracy: 93.29%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1932, Validation Accuracy: 93.09%\n",
            "Balanced Accuracy: 0.9325\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1750, Train Accuracy: 94.07%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1481, Validation Accuracy: 95.22%\n",
            "Balanced Accuracy: 0.9523\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1594, Train Accuracy: 94.65%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1499, Validation Accuracy: 95.02%\n",
            "Balanced Accuracy: 0.9517\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1444, Train Accuracy: 95.14%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1445, Validation Accuracy: 95.27%\n",
            "Balanced Accuracy: 0.9529\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1324, Train Accuracy: 95.40%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1338, Validation Accuracy: 95.57%\n",
            "Balanced Accuracy: 0.9567\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1215, Train Accuracy: 95.90%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1285, Validation Accuracy: 95.81%\n",
            "Balanced Accuracy: 0.9590\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1155, Train Accuracy: 96.08%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1304, Validation Accuracy: 95.61%\n",
            "Balanced Accuracy: 0.9581\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1056, Train Accuracy: 96.37%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1075, Validation Accuracy: 96.55%\n",
            "Balanced Accuracy: 0.9661\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0983, Train Accuracy: 96.65%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1211, Validation Accuracy: 96.16%\n",
            "Balanced Accuracy: 0.9618\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:04<00:00,  5.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0945, Train Accuracy: 96.76%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1175, Validation Accuracy: 96.15%\n",
            "Balanced Accuracy: 0.9629\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0885, Train Accuracy: 97.01%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1323, Validation Accuracy: 95.70%\n",
            "Balanced Accuracy: 0.9590\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0826, Train Accuracy: 97.21%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1110, Validation Accuracy: 96.31%\n",
            "Balanced Accuracy: 0.9641\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0774, Train Accuracy: 97.35%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1028, Validation Accuracy: 96.67%\n",
            "Balanced Accuracy: 0.9668\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0752, Train Accuracy: 97.47%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1108, Validation Accuracy: 96.44%\n",
            "Balanced Accuracy: 0.9636\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0680, Train Accuracy: 97.68%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1028, Validation Accuracy: 96.79%\n",
            "Balanced Accuracy: 0.9685\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0674, Train Accuracy: 97.76%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1001, Validation Accuracy: 96.77%\n",
            "Balanced Accuracy: 0.9683\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0614, Train Accuracy: 97.85%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0975, Validation Accuracy: 96.98%\n",
            "Balanced Accuracy: 0.9701\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:04<00:00,  5.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0589, Train Accuracy: 98.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0999, Validation Accuracy: 96.99%\n",
            "Balanced Accuracy: 0.9707\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:08<00:00,  5.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0574, Train Accuracy: 98.04%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1134, Validation Accuracy: 96.42%\n",
            "Balanced Accuracy: 0.9653\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0549, Train Accuracy: 98.10%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1007, Validation Accuracy: 96.99%\n",
            "Balanced Accuracy: 0.9706\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0504, Train Accuracy: 98.26%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1014, Validation Accuracy: 96.97%\n",
            "Balanced Accuracy: 0.9701\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0502, Train Accuracy: 98.24%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1047, Validation Accuracy: 96.84%\n",
            "Balanced Accuracy: 0.9694\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0462, Train Accuracy: 98.40%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0946, Validation Accuracy: 97.20%\n",
            "Balanced Accuracy: 0.9724\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0446, Train Accuracy: 98.48%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1063, Validation Accuracy: 96.86%\n",
            "Balanced Accuracy: 0.9692\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:04<00:00,  5.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0455, Train Accuracy: 98.43%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0976, Validation Accuracy: 96.96%\n",
            "Balanced Accuracy: 0.9701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "c2f1fea1-2a3a-49ee-fc06-ceba6268a366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test: 100%|██████████| 469/469 [01:23<00:00,  5.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0979, Test Accuracy: 97.13%\n",
            "Balanced Accuracy: 0.9720\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "67688ac4-d0bd-41d9-fb13-2cf1cb6dd12c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 6.40 ms\n",
            "Standard Deviation: 0.42 ms\n",
            "Maximum Time: 9.87 ms\n",
            "Minimum Time: 6.07 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "bc646755-d3f6-4e29-a6e0-b3f636c9ae2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         1.95%     209.228us        21.28%       2.285ms      95.195us       0.000us         0.00%       2.528ms     105.314us            24  \n",
            "                                           aten::linear         0.91%      97.273us        13.89%       1.491ms      82.837us       0.000us         0.00%       1.820ms     101.114us            18  \n",
            "                                               aten::mm         6.95%     746.568us         9.65%       1.036ms      64.751us       1.796ms        32.13%       1.796ms     112.261us            16  \n",
            "                                       aten::batch_norm         1.20%     129.031us        27.38%       2.940ms     127.834us       0.000us         0.00%       1.384ms      60.168us            23  \n",
            "                           aten::_batch_norm_impl_index         2.06%     221.725us        26.18%       2.811ms     122.224us       0.000us         0.00%       1.384ms      60.168us            23  \n",
            "                                           aten::conv2d         0.53%      56.683us        16.79%       1.803ms     300.523us       0.000us         0.00%     722.050us     120.342us             6  \n",
            "                                      aten::convolution         0.51%      54.495us        16.26%       1.746ms     291.076us       0.000us         0.00%     722.050us     120.342us             6  \n",
            "                                     aten::_convolution         0.85%      91.183us        15.76%       1.692ms     281.994us       0.000us         0.00%     722.050us     120.342us             6  \n",
            "                                aten::cudnn_convolution        12.04%       1.293ms        14.42%       1.548ms     258.061us     707.203us        12.65%     707.203us     117.867us             6  \n",
            "                                aten::native_batch_norm         5.62%     603.153us        16.17%       1.736ms      96.458us     678.298us        12.13%     692.664us      38.481us            18  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 10.739ms\n",
            "Self CUDA time total: 5.591ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbSpMMWGk3bf",
        "outputId": "f9902407-a19f-4292-dc4a-9f75779e397e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-24 14:56:19--  https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.43.25, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 800276929 (763M) [application/octet-stream]\n",
            "Saving to: ‘CRC-VAL-HE-7K.zip’\n",
            "\n",
            "CRC-VAL-HE-7K.zip     5%[>                   ]  45.57M  16.8MB/s               ^C\n",
            "[CRC-VAL-HE-7K.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of CRC-VAL-HE-7K.zip or\n",
            "        CRC-VAL-HE-7K.zip.zip, and cannot find CRC-VAL-HE-7K.zip.ZIP, period.\n"
          ]
        }
      ],
      "source": [
        "!wget -O CRC-VAL-HE-7K.zip https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
        "!unzip -qq CRC-VAL-HE-7K.zip -d val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "xc2tPigjv6Is",
        "outputId": "a7e9f8ab-42bb-4ab3-a6e0-8bacd79f8926",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-60-68f730c495db>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"HoViT22_withAug_7Ktest.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "#torch.save(model.state_dict(), \"HoViT22_withAug_7Ktest.pth\")\n",
        "model.load_state_dict(torch.load(\"HoViT22_withAug_7Ktest.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "rldaXFNXpT4r"
      },
      "outputs": [],
      "source": [
        "test_7k_dir = './val/CRC-VAL-HE-7K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Belqw8QytnZL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "test7k_dataset = Dataset(dir=test_7k_dir, aug=False)\n",
        "test7k_dataloader = DataLoader(test7k_dataset, batch_size=32, shuffle=False, num_workers=8, pin_memory=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2y3cywDpjUQ",
        "outputId": "c6e63114-98c9-4bd3-ef46-995a6d1b8d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 225/225 [00:05<00:00, 43.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.2637, Test Accuracy: 92.76%\n",
            "Overall - F1: 0.9091, Recall: 0.9161, Precision: 0.9059\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9411, Recall: 0.8901, Precision: 0.9983\n",
            "Class 1 - F1: 0.9994, Recall: 1.0000, Precision: 0.9988\n",
            "Class 2 - F1: 0.9047, Recall: 0.9941, Precision: 0.8300\n",
            "Class 3 - F1: 0.9890, Recall: 0.9921, Precision: 0.9859\n",
            "Class 4 - F1: 0.9295, Recall: 0.9807, Precision: 0.8834\n",
            "Class 5 - F1: 0.8246, Recall: 0.8497, Precision: 0.8010\n",
            "Class 6 - F1: 0.9578, Recall: 0.9501, Precision: 0.9657\n",
            "Class 7 - F1: 0.6886, Recall: 0.6461, Precision: 0.7371\n",
            "Class 8 - F1: 0.9474, Recall: 0.9424, Precision: 0.9525\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test7k_dataloader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "p4pYjMPUpy2m",
        "outputId": "3d0affe1-8425-4d2b-9cca-c6ed225e5e30"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "5EnagUDtpzDU",
        "outputId": "5c4c49be-c46f-49c0-9734-c56fb1a5856b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 225\n",
            "Average Time: 7.82 ms\n",
            "Standard Deviation: 1.17 ms\n",
            "Maximum Time: 13.25 ms\n",
            "Minimum Time: 6.58 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test7k_dataloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hHScyX3ReqPp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}