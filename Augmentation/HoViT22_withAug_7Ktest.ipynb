{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "f5897300-51e7-47cb-9ab0-f918e37a336f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=01b2b71eab197118c53cd6f5bba97d41a8cfd4d31d371752f3ba315b528823bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "bd07a7d7-d6c6-404e-a3df-3c8c499483cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-02-24 02:13:35--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.45.92, 188.185.48.194, 188.185.43.25, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.45.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-02-24 02:13:36--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  17.8MB/s    in 11m 22s \n",
            "\n",
            "2025-02-24 02:24:59 (16.3 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=2, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=2, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "e01a2982-dadd-433d-a6e9-a6f04a899cfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "e7859a9b-2629-4b79-9e77-239fca063148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 4,909,234\n",
            "Trainable params: 4,909,234\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.82\n",
            "Params size (MB): 19.64\n",
            "Estimated Total Size (MB): 936.72\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "72df6f74-195d-4acb-b90c-81a9523264d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.82\n",
            "Params size (MB): 19.64\n",
            "Estimated Total Size (MB): 936.72\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.82\n",
            "Params size (MB): 19.64\n",
            "Estimated Total Size (MB): 936.72\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "f0b414ba-8e92-4715-9c5c-27f6e1233e9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "g18xh7W1tv8W"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from glob import glob\n",
        "import cv2\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, dir, aug=False):\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.aug = aug\n",
        "        self.samples = [i for i in glob(os.path.join(dir, '**/*')) if os.path.isfile(i)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        class_name = os.path.basename(self.samples[idx]).split('-')[0]\n",
        "        label = {\n",
        "            'ADI': 0,\n",
        "            'BACK': 1,\n",
        "            'DEB': 2,\n",
        "            'LYM': 3,\n",
        "            'MUC': 4,\n",
        "            'MUS': 5,\n",
        "            'NORM': 6,\n",
        "            'STR': 7,\n",
        "            'TUM': 8,\n",
        "        }\n",
        "\n",
        "        img = cv2.imread(self.samples[idx], -1)[:, :, ::-1]\n",
        "        img = np.float32(img) / 255.0\n",
        "\n",
        "        if self.aug:\n",
        "            if random.random() < 0.5:\n",
        "                img = img[::-1]\n",
        "\n",
        "            if random.random() < 0.5:\n",
        "                img = img[:, ::-1]\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                if random.random() < 0.5:\n",
        "                    img += np.random.normal(\n",
        "                        0.0, np.random.uniform(0.01, 0.2),\n",
        "                        (img.shape[0], img.shape[1], img.shape[2])\n",
        "                    )\n",
        "                else:\n",
        "                    x = np.random.uniform(0.02, 0.15)\n",
        "                    img += np.random.uniform(\n",
        "                        -x, x,\n",
        "                        (img.shape[0], img.shape[1], img.shape[2])\n",
        "                    )\n",
        "\n",
        "            if random.random() < 0.9:\n",
        "                img += np.random.uniform(-0.15, 0.15, (1, 1, 3))\n",
        "                img *= np.random.uniform(0.85, 1.15, (1, 1, 3))\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                kX, kY = np.random.randint(0, 4, 2) * 2 + 1\n",
        "                if random.random() < 0.5:\n",
        "                    img = cv2.GaussianBlur(img, (kX, kY), 0)\n",
        "                else:\n",
        "                    img = cv2.blur(img, (kX, kY))\n",
        "\n",
        "        img = np.uint8(np.clip(img, 0, 1) * 255.0)\n",
        "        img = self.transform(Image.fromarray(img))\n",
        "\n",
        "        return img, label[class_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset(dir=train_dir, aug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "train_data = Subset(dataset, load_train_idx)\n",
        "val_data = Subset(dataset, load_val_idx)\n",
        "test_data = Subset(dataset, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "996f9141-d5a5-4ecc-8e35-c7c62b899565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    val_losses.append(epoch_loss)\n",
        "    val_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "1f7ef208-8788-4ba4-97ac-1a11f0fa19ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:04<00:00,  5.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.8917, Train Accuracy: 67.88%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.5169, Validation Accuracy: 81.79%\n",
            "Balanced Accuracy: 0.8116\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4488, Train Accuracy: 83.97%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.3839, Validation Accuracy: 86.70%\n",
            "Balanced Accuracy: 0.8651\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3283, Train Accuracy: 88.53%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.2493, Validation Accuracy: 91.28%\n",
            "Balanced Accuracy: 0.9121\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2632, Train Accuracy: 90.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.2370, Validation Accuracy: 91.99%\n",
            "Balanced Accuracy: 0.9219\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2210, Train Accuracy: 92.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.2177, Validation Accuracy: 92.69%\n",
            "Balanced Accuracy: 0.9276\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:01<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1964, Train Accuracy: 93.29%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1932, Validation Accuracy: 93.09%\n",
            "Balanced Accuracy: 0.9325\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1750, Train Accuracy: 94.07%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1481, Validation Accuracy: 95.22%\n",
            "Balanced Accuracy: 0.9523\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1594, Train Accuracy: 94.65%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1499, Validation Accuracy: 95.02%\n",
            "Balanced Accuracy: 0.9517\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1444, Train Accuracy: 95.14%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1445, Validation Accuracy: 95.27%\n",
            "Balanced Accuracy: 0.9529\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1324, Train Accuracy: 95.40%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1338, Validation Accuracy: 95.57%\n",
            "Balanced Accuracy: 0.9567\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1215, Train Accuracy: 95.90%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1285, Validation Accuracy: 95.81%\n",
            "Balanced Accuracy: 0.9590\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1155, Train Accuracy: 96.08%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1304, Validation Accuracy: 95.61%\n",
            "Balanced Accuracy: 0.9581\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1056, Train Accuracy: 96.37%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1075, Validation Accuracy: 96.55%\n",
            "Balanced Accuracy: 0.9661\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0983, Train Accuracy: 96.65%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1211, Validation Accuracy: 96.16%\n",
            "Balanced Accuracy: 0.9618\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:04<00:00,  5.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0945, Train Accuracy: 96.76%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1175, Validation Accuracy: 96.15%\n",
            "Balanced Accuracy: 0.9629\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0885, Train Accuracy: 97.01%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1323, Validation Accuracy: 95.70%\n",
            "Balanced Accuracy: 0.9590\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0826, Train Accuracy: 97.21%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1110, Validation Accuracy: 96.31%\n",
            "Balanced Accuracy: 0.9641\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0774, Train Accuracy: 97.35%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1028, Validation Accuracy: 96.67%\n",
            "Balanced Accuracy: 0.9668\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0752, Train Accuracy: 97.47%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1108, Validation Accuracy: 96.44%\n",
            "Balanced Accuracy: 0.9636\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0680, Train Accuracy: 97.68%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1028, Validation Accuracy: 96.79%\n",
            "Balanced Accuracy: 0.9685\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0674, Train Accuracy: 97.76%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1001, Validation Accuracy: 96.77%\n",
            "Balanced Accuracy: 0.9683\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0614, Train Accuracy: 97.85%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0975, Validation Accuracy: 96.98%\n",
            "Balanced Accuracy: 0.9701\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:04<00:00,  5.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0589, Train Accuracy: 98.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0999, Validation Accuracy: 96.99%\n",
            "Balanced Accuracy: 0.9707\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:08<00:00,  5.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0574, Train Accuracy: 98.04%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1134, Validation Accuracy: 96.42%\n",
            "Balanced Accuracy: 0.9653\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0549, Train Accuracy: 98.10%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1007, Validation Accuracy: 96.99%\n",
            "Balanced Accuracy: 0.9706\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:02<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0504, Train Accuracy: 98.26%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1014, Validation Accuracy: 96.97%\n",
            "Balanced Accuracy: 0.9701\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0502, Train Accuracy: 98.24%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1047, Validation Accuracy: 96.84%\n",
            "Balanced Accuracy: 0.9694\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0462, Train Accuracy: 98.40%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0946, Validation Accuracy: 97.20%\n",
            "Balanced Accuracy: 0.9724\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:03<00:00,  5.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0446, Train Accuracy: 98.48%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:23<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1063, Validation Accuracy: 96.86%\n",
            "Balanced Accuracy: 0.9692\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:04<00:00,  5.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0455, Train Accuracy: 98.43%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:22<00:00,  5.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0976, Validation Accuracy: 96.96%\n",
            "Balanced Accuracy: 0.9701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "c2f1fea1-2a3a-49ee-fc06-ceba6268a366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test: 100%|██████████| 469/469 [01:23<00:00,  5.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0979, Test Accuracy: 97.13%\n",
            "Balanced Accuracy: 0.9720\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "67688ac4-d0bd-41d9-fb13-2cf1cb6dd12c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 6.40 ms\n",
            "Standard Deviation: 0.42 ms\n",
            "Maximum Time: 9.87 ms\n",
            "Minimum Time: 6.07 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "22fb93e9-59db-4f5a-eb14-b29bc48ae1f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         1.74%     320.954us        18.37%       3.385ms     141.044us       0.000us         0.00%       2.537ms     105.721us            24  \n",
            "                                           aten::linear         0.50%      92.319us        13.83%       2.548ms     141.571us       0.000us         0.00%       1.830ms     101.642us            18  \n",
            "                                               aten::mm         3.67%     675.700us        11.33%       2.087ms     130.456us       1.806ms        38.83%       1.806ms     112.865us            16  \n",
            "                                           aten::conv2d         0.87%     161.078us        26.39%       4.863ms     810.490us       0.000us         0.00%     723.317us     120.553us             6  \n",
            "                                      aten::convolution         0.39%      72.251us        25.52%       4.702ms     783.644us       0.000us         0.00%     723.317us     120.553us             6  \n",
            "                                     aten::_convolution         6.41%       1.181ms        25.13%       4.630ms     771.602us       0.000us         0.00%     723.317us     120.553us             6  \n",
            "                                aten::cudnn_convolution        16.73%       3.082ms        18.43%       3.396ms     565.964us     708.789us        15.24%     708.789us     118.131us             6  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     678.873us        14.60%     678.873us     169.718us             4  \n",
            "                                              aten::bmm         1.43%     262.664us         1.80%     331.902us      41.488us     567.961us        12.21%     567.961us      70.995us             8  \n",
            "                                       aten::batch_norm         0.82%     150.472us        39.27%       7.236ms     314.611us       0.000us         0.00%     544.344us      23.667us            23  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 18.425ms\n",
            "Self CUDA time total: 4.651ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    val_losses.append(epoch_loss)\n",
        "    val_accuracies.append(accuracy)\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbSpMMWGk3bf",
        "outputId": "b32d39ae-04bb-46f5-9445-1adcccb6bc77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-02-24 06:47:45--  https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.48.194, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 800276929 (763M) [application/octet-stream]\n",
            "Saving to: ‘CRC-VAL-HE-7K.zip’\n",
            "\n",
            "CRC-VAL-HE-7K.zip   100%[===================>] 763.20M  7.13MB/s    in 91s     \n",
            "\n",
            "2025-02-24 06:49:17 (8.36 MB/s) - ‘CRC-VAL-HE-7K.zip’ saved [800276929/800276929]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O CRC-VAL-HE-7K.zip https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
        "!unzip -qq CRC-VAL-HE-7K.zip -d val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "xc2tPigjv6Is"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"HoViT22_withAug_7Ktest.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rldaXFNXpT4r"
      },
      "outputs": [],
      "source": [
        "test_7k_dir = './val/CRC-VAL-HE-7K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Belqw8QytnZL"
      },
      "outputs": [],
      "source": [
        "test7k_dataset = Dataset(dir=test_7k_dir, aug=False)\n",
        "test7k_dataloader = DataLoader(test7k_dataset, batch_size=32, shuffle=False, num_workers=8, pin_memory=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2y3cywDpjUQ",
        "outputId": "2e65eea0-4e4f-40e1-c9bf-f6b49d17560c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test: 100%|██████████| 225/225 [00:10<00:00, 20.89it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 5.6973, Test Accuracy: 21.94%\n",
            "Overall - F1: 0.1278, Recall: 0.2025, Precision: 0.2528\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.5994, Recall: 0.4283, Precision: 0.9983\n",
            "Class 1 - F1: 0.2925, Recall: 1.0000, Precision: 0.1713\n",
            "Class 2 - F1: 0.1394, Recall: 0.3304, Precision: 0.0883\n",
            "Class 3 - F1: 0.1103, Recall: 0.0584, Precision: 1.0000\n",
            "Class 4 - F1: 0.0087, Recall: 0.0058, Precision: 0.0172\n",
            "Class 5 - F1: 0.0000, Recall: 0.0000, Precision: 0.0000\n",
            "Class 6 - F1: 0.0000, Recall: 0.0000, Precision: 0.0000\n",
            "Class 7 - F1: 0.0000, Recall: 0.0000, Precision: 0.0000\n",
            "Class 8 - F1: 0.0000, Recall: 0.0000, Precision: 0.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, ext_test_loader, criterion, test7k_dataloader, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "p4pYjMPUpy2m",
        "outputId": "e74c7801-3f04-44fd-d60b-d5484bf6133b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EnagUDtpzDU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
