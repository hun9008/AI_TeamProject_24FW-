{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "4597dfa4-fd81-4ad6-ea60-55401313dec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=e9f6300f2519237ce218d5931b0d9c19bbce92788bbf83c6433a7efbb904805a\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "88ef1363-ac98-4aa1-d050-2bd8867d5a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-26 18:45:16--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.45.92, 188.185.43.25, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.45.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-02-26 18:45:17--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  24.1MB/s    in 8m 12s  \n",
            "\n",
            "2025-02-26 18:53:29 (22.6 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "e1018a72-0fb0-4419-c683-97f9aa6cff05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "9a531820-6ef4-475b-af3f-4628df229eef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "0f07b18d-ab17-4c1a-a10f-05cf7b8f3487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "3429614e-a335-437b-91b0-19437da9c3e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "g18xh7W1tv8W"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from glob import glob\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, dir, aug=False):\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.aug = aug\n",
        "        self.samples = [i for i in glob(os.path.join(dir, '**/*')) if os.path.isfile(i)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        class_name = os.path.basename(self.samples[idx]).split('-')[0]\n",
        "        label = {\n",
        "            'ADI': 0,\n",
        "            'BACK': 1,\n",
        "            'DEB': 2,\n",
        "            'LYM': 3,\n",
        "            'MUC': 4,\n",
        "            'MUS': 5,\n",
        "            'NORM': 6,\n",
        "            'STR': 7,\n",
        "            'TUM': 8,\n",
        "        }\n",
        "\n",
        "        img = cv2.imread(self.samples[idx], -1)[:, :, ::-1]\n",
        "        img = np.float32(img) / 255.0\n",
        "\n",
        "        if self.aug:\n",
        "            if random.random() < 0.5:\n",
        "                img = img[::-1]\n",
        "\n",
        "            if random.random() < 0.5:\n",
        "                img = img[:, ::-1]\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                if random.random() < 0.5:\n",
        "                    img += np.random.normal(\n",
        "                        0.0, np.random.uniform(0.01, 0.2),\n",
        "\n",
        "                        (img.shape[0], img.shape[1], img.shape[2])\n",
        "                    )\n",
        "                else:\n",
        "                    x = np.random.uniform(0.02, 0.15)\n",
        "                    img += np.random.uniform(\n",
        "                        -x, x,\n",
        "                        (img.shape[0], img.shape[1], img.shape[2])\n",
        "                    )\n",
        "\n",
        "            if random.random() < 0.9:\n",
        "                img += np.random.uniform(-0.15, 0.15, (1, 1, 3))\n",
        "                img *= np.random.uniform(0.85, 1.15, (1, 1, 3))\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                kX, kY = np.random.randint(0, 4, 2) * 2 + 1\n",
        "                if random.random() < 0.5:\n",
        "                    img = cv2.GaussianBlur(img, (kX, kY), 0)\n",
        "                else:\n",
        "                    img = cv2.blur(img, (kX, kY))\n",
        "\n",
        "        img = np.uint8(np.clip(img, 0, 1) * 255.0)\n",
        "        img = self.transform(Image.fromarray(img))\n",
        "\n",
        "        return img, label[class_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset(dir=train_dir, aug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "#train_data = Subset(dataset, load_train_idx)\n",
        "#val_data = Subset(dataset, load_val_idx)\n",
        "test_data = Subset(dataset, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "df7a59e6-36b0-4a26-a2e7-465d47fcc514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "#train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "#val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "#print(f\"Train set size: {len(train_data)}\")\n",
        "#print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    val_losses.append(epoch_loss)\n",
        "    val_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('HoViT44_withAug_7Ktest.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI01eursppvQ",
        "outputId": "912d5885-1700-4b14-904c-16ad9810058c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-399596f23d1c>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('HoViT44_withAug_7Ktest.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "81aee095-bbb5-4287-e914-5e0fdfc5395f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:33<00:00, 14.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0360, Test Accuracy: 98.92%\n",
            "Balanced Accuracy: 0.9894\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "f8219859-4498-4da5-8b09-bf6db2a89449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 12.22 ms\n",
            "Standard Deviation: 0.52 ms\n",
            "Maximum Time: 18.78 ms\n",
            "Minimum Time: 11.53 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "9da645cf-e261-4a6b-d065-264bb52c550d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         2.00%     357.626us        21.19%       3.785ms      78.859us       0.000us         0.00%       5.053ms     105.261us            48  \n",
            "                                           aten::linear         0.97%     172.768us        13.15%       2.350ms      69.108us       0.000us         0.00%       3.616ms     106.346us            34  \n",
            "                                               aten::mm         5.92%       1.057ms         9.11%       1.628ms      50.863us       3.592ms        44.10%       3.592ms     112.257us            32  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.354ms        16.62%       1.354ms     169.195us             8  \n",
            "                                              aten::bmm         2.59%     461.857us         3.28%     586.627us      36.664us       1.133ms        13.91%       1.133ms      70.813us            16  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     986.968us        12.12%     986.968us     123.371us             8  \n",
            "                                       aten::batch_norm         1.35%     240.834us        23.20%       4.145ms     106.280us       0.000us         0.00%     853.694us      21.890us            39  \n",
            "                           aten::_batch_norm_impl_index         1.64%     293.425us        21.85%       3.904ms     100.105us       0.000us         0.00%     853.694us      21.890us            39  \n",
            "                                            aten::copy_         4.63%     827.350us        10.55%       1.886ms      22.996us     819.990us        10.07%     819.990us      10.000us            82  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     767.003us         9.42%     767.003us      95.875us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 17.867ms\n",
            "Self CUDA time total: 8.145ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2y3cywDpjUQ",
        "outputId": "7bdf96e1-1e01-465b-a02e-4e7cd162aca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:33<00:00, 14.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0360, Test Accuracy: 98.92%\n",
            "Overall - F1: 0.9893, Recall: 0.9894, Precision: 0.9891\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9943, Recall: 0.9943, Precision: 0.9943\n",
            "Class 1 - F1: 0.9965, Recall: 0.9987, Precision: 0.9944\n",
            "Class 2 - F1: 0.9871, Recall: 0.9802, Precision: 0.9941\n",
            "Class 3 - F1: 0.9986, Recall: 0.9989, Precision: 0.9983\n",
            "Class 4 - F1: 0.9914, Recall: 0.9955, Precision: 0.9873\n",
            "Class 5 - F1: 0.9859, Recall: 0.9821, Precision: 0.9897\n",
            "Class 6 - F1: 0.9907, Recall: 0.9891, Precision: 0.9922\n",
            "Class 7 - F1: 0.9701, Recall: 0.9754, Precision: 0.9648\n",
            "Class 8 - F1: 0.9889, Recall: 0.9907, Precision: 0.9871\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "p4pYjMPUpy2m",
        "outputId": "30167683-96e5-4f74-9775-47fb01ad21fc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hHScyX3ReqPp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}