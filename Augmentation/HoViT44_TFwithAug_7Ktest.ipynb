{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "b7b4ab85-2219-406f-b3be-e7ae593e1bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=7cb34d4e88a779e3fa6565d9af1ae2f1d31b5b9dc67d36998b8bceceaa7e71d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "6ee6e229-1df6-4f91-f91e-f79184dab3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-26 18:47:00--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.45.92, 188.185.43.25, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.45.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-02-26 18:47:01--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  24.8MB/s    in 7m 44s  \n",
            "\n",
            "2025-02-26 18:54:44 (24.0 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_9sIsiJ2ldL",
        "outputId": "ed6dfabb-cfae-46b1-efbb-0725bf4783a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.5.1+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.48.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.3.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchao\n",
        "!pip install torchtune"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZPMfB8vT2qjy",
        "outputId": "f552659a-54df-41fe-d3d9-0e655277d47e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchao\n",
            "  Downloading torchao-0.8.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "Downloading torchao-0.8.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (4.7 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/4.7 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/4.7 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchao\n",
            "Successfully installed torchao-0.8.0\n",
            "Collecting torchtune\n",
            "  Downloading torchtune-0.5.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting datasets (from torchtune)\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: huggingface_hub[hf_transfer] in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.28.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.5.2)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.3.9)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.2.0)\n",
            "Collecting tiktoken (from torchtune)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting blobfile>=2 (from torchtune)\n",
            "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtune) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtune) (4.67.1)\n",
            "Collecting omegaconf (from torchtune)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from torchtune) (5.9.5)\n",
            "Requirement already satisfied: Pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from torchtune) (11.1.0)\n",
            "Collecting pycryptodomex>=3.8 (from blobfile>=2->torchtune)\n",
            "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (2.3.0)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (5.3.1)\n",
            "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->torchtune)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (2.32.3)\n",
            "Collecting xxhash (from datasets->torchtune)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->torchtune)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->torchtune) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (3.11.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]->torchtune) (4.12.2)\n",
            "Collecting hf-transfer>=0.1.4 (from huggingface_hub[hf_transfer]->torchtune)\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->torchtune)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->torchtune) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->torchtune) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->torchtune) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->torchtune) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->torchtune) (1.17.0)\n",
            "Downloading torchtune-0.5.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.3/810.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=e121ee0e4473a7cb452d6bfdda8dff8252cd27160b8956c23928a05839d061d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, xxhash, pycryptodomex, omegaconf, hf-transfer, dill, tiktoken, multiprocess, blobfile, datasets, torchtune\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 blobfile-3.0.0 datasets-3.3.2 dill-0.3.8 hf-transfer-0.1.9 multiprocess-0.70.16 omegaconf-2.3.0 pycryptodomex-3.21.0 tiktoken-0.9.0 torchtune-0.5.0 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "663d5a9543a645d6b5e78e89771c3ef6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtune.modules.peft import LoRALinear"
      ],
      "metadata": {
        "id": "7VFmN8Yv2vjz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_lora_model(model, rank=8, alpha=16, exclude=[]):\n",
        "    for name, module in model.named_children():\n",
        "        if name in exclude:\n",
        "            continue\n",
        "        if isinstance(module, nn.Linear):\n",
        "            lora_linear = LoRALinear(\n",
        "                in_dim=module.in_features,\n",
        "                out_dim=module.out_features,\n",
        "                rank=rank,\n",
        "                alpha=alpha,\n",
        "                use_bias=module.bias is not None\n",
        "            )\n",
        "            lora_linear.weight.data = module.weight.data #모델이 처음부터 다시 학습할 필요 없게 하기 위해\n",
        "            if module.bias is not None:\n",
        "                lora_linear.bias.data = module.bias.data\n",
        "            lora_linear.to(module.weight.device)\n",
        "            # 기존 linear layer를 loRA linear로 교체체\n",
        "            setattr(model, name, lora_linear)\n",
        "        # 재귀함수 (하위모듈도 확인)\n",
        "        else:\n",
        "            convert_to_lora_model(module, rank, alpha, exclude)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "xM9fPVgw2xbJ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class LevitStage_TinyFusion(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, num_select, downsample=True):\n",
        "        super(LevitStage_TinyFusion, self).__init__()\n",
        "        assert num_select <= num_blocks\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "        self.num_blocks = num_blocks\n",
        "        self.num_select = num_select\n",
        "        init_probs = torch.ones(num_blocks) / num_blocks\n",
        "        self.gumbel_gate = nn.Parameter(torch.log(init_probs))\n",
        "\n",
        "\n",
        "    def forward(self, x, tau=1):\n",
        "        x = self.downsample(x)\n",
        "\n",
        "        if self.training:\n",
        "            gate_probs = F.gumbel_softmax(self.gumbel_gate, tau=tau, hard=False)\n",
        "        else:\n",
        "            gate_probs = F.gumbel_softmax(self.gumbel_gate, tau=tau, hard=True)\n",
        "\n",
        "        for i in range(self.num_blocks):\n",
        "            if gate_probs[i] > 0: # skip zero blocks\n",
        "              x = x + gate_probs[i] * self.blocks[i](x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "dMufn6p-3F_X"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LevitDistilledTinyfusion(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilledTinyfusion, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage_TinyFusion(dim=256, out_dim=256, num_heads=4, num_blocks=4, num_select=2, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage_TinyFusion(dim=256, out_dim=384, num_heads=6, num_blocks=4, num_select=2, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x, tau):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x, tau)\n",
        "        x = self.stage2(x, tau)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "kIR4o8va3Im9"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LevitDistilledTinyfusion(num_classes=9)"
      ],
      "metadata": {
        "id": "B68yiGFF3S88"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "f1928a40-d5f6-4d0f-9f96-624725da825e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilledTinyfusion(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage_TinyFusion(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage_TinyFusion(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 100\n",
        "weight_decay = 1e-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "def51d24-3b38-4ea6-87b3-0a2599612598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilledTinyfusion                                [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage_TinyFusion: 1-2                            [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  --                        1,584,400\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "├─LevitStage_TinyFusion: 1-3                            [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-10                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-11                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 --                        3,555,366\n",
            "│    │    └─LevitBlock: 3-12                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,336,104\n",
            "Trainable params: 8,336,104\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 12.76\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 650.55\n",
            "Params size (MB): 12.79\n",
            "Estimated Total Size (MB): 682.60\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), tau = 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "3209b33c-5242-4371-dd0b-0f90fbcfd54c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilledTinyfusion                                [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage_TinyFusion: 1-2                            [32, 196, 256]            4\n",
            "│    └─gumbel_gate                                                                ├─4\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  --                        1,583,616\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage_TinyFusion: 1-3                            [32, 49, 384]             --\n",
            "│    └─gumbel_gate                                                                ├─4\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-10                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-11                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 --                        3,555,660\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-12                            [32, 49, 384]             1,185,024\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,336,402\n",
            "Trainable params: 8,336,402\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 12.76\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 650.55\n",
            "Params size (MB): 12.79\n",
            "Estimated Total Size (MB): 682.60\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilledTinyfusion                                [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage_TinyFusion: 1-2                            [32, 196, 256]            4\n",
            "│    └─gumbel_gate                                                                ├─4\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  --                        1,583,616\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage_TinyFusion: 1-3                            [32, 49, 384]             --\n",
            "│    └─gumbel_gate                                                                ├─4\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-10                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-11                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 --                        3,555,660\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-12                            [32, 49, 384]             1,185,024\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,336,402\n",
            "Trainable params: 8,336,402\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 12.76\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 650.55\n",
            "Params size (MB): 12.79\n",
            "Estimated Total Size (MB): 682.60\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2, tau = 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "c458ec0d-5ffe-4740-d7a2-19bd1f523933"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilledTinyfusion(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage_TinyFusion(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage_TinyFusion(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "NcNx9kgbdulf"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ],
      "metadata": {
        "id": "y_1SUIuidwbE"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "g18xh7W1tv8W"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from glob import glob\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, dir, aug=False):\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.aug = aug\n",
        "        self.samples = [i for i in glob(os.path.join(dir, '**/*')) if os.path.isfile(i)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        class_name = os.path.basename(self.samples[idx]).split('-')[0]\n",
        "        label = {\n",
        "            'ADI': 0,\n",
        "            'BACK': 1,\n",
        "            'DEB': 2,\n",
        "            'LYM': 3,\n",
        "            'MUC': 4,\n",
        "            'MUS': 5,\n",
        "            'NORM': 6,\n",
        "            'STR': 7,\n",
        "            'TUM': 8,\n",
        "        }\n",
        "\n",
        "        img = cv2.imread(self.samples[idx], -1)[:, :, ::-1]\n",
        "        img = np.float32(img) / 255.0\n",
        "\n",
        "        if self.aug:\n",
        "            if random.random() < 0.5:\n",
        "                img = img[::-1]\n",
        "\n",
        "            if random.random() < 0.5:\n",
        "                img = img[:, ::-1]\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                if random.random() < 0.5:\n",
        "                    img += np.random.normal(\n",
        "                        0.0, np.random.uniform(0.01, 0.2),\n",
        "                        (img.shape[0], img.shape[1], img.shape[2])\n",
        "                    )\n",
        "                else:\n",
        "                    x = np.random.uniform(0.02, 0.15)\n",
        "                    img += np.random.uniform(\n",
        "                        -x, x,\n",
        "                        (img.shape[0], img.shape[1], img.shape[2])\n",
        "                    )\n",
        "\n",
        "            if random.random() < 0.9:\n",
        "                img += np.random.uniform(-0.15, 0.15, (1, 1, 3))\n",
        "                img *= np.random.uniform(0.85, 1.15, (1, 1, 3))\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                kX, kY = np.random.randint(0, 4, 2) * 2 + 1\n",
        "                if random.random() < 0.5:\n",
        "                    img = cv2.GaussianBlur(img, (kX, kY), 0)\n",
        "                else:\n",
        "                    img = cv2.blur(img, (kX, kY))\n",
        "\n",
        "        img = np.uint8(np.clip(img, 0, 1) * 255.0)\n",
        "        img = self.transform(Image.fromarray(img))\n",
        "\n",
        "        return img, label[class_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset1 = Dataset(dir=train_dir, aug=True)\n",
        "dataset2 = Dataset(dir=train_dir, aug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "train_data = Subset(dataset, load_train_idx)\n",
        "val_data = Subset(dataset, load_val_idx)\n",
        "test_data = Subset(dataset, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "54bf5392-9c06-41a5-fab1-dbc0c7debef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gumbel_params = []\n",
        "other_params = []\n",
        "exclude = [\"head\", \"head_dist\"]\n",
        "\n",
        "for name, module in model.named_children():\n",
        "    if name in exclude:\n",
        "        print(exclude)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if \"gumbel_gate\" in name:\n",
        "        gumbel_params.append(param)\n",
        "        print(name)\n",
        "    else:\n",
        "        other_params.append(param)\n",
        "\n",
        "#model = convert_to_lora_model(model, exclude=exclude)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrBLmUdJ4IZD",
        "outputId": "69b77bfc-faf5-4996-df0d-b4a7595a53d8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['head', 'head_dist']\n",
            "['head', 'head_dist']\n",
            "stage1.gumbel_gate\n",
            "stage2.gumbel_gate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch, total_epcohs=100):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    tau_max = 1\n",
        "    tau_min = 0.1\n",
        "    total_steps = total_epcohs * len(train_loader)\n",
        "    train_steps = epoch * len(train_loader)\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        tau = tau_max - (tau_max - tau_min) * min(1.0, (train_steps + i) / total_steps)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, tau)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Tau: {tau:.4f}\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)\n",
        "\n",
        "    print(\"Each stage of block probabilities:\")\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, LevitStage_TinyFusion):\n",
        "            gate_probs = torch.softmax(module.gumbel_gate, dim=0) # 각 block의 확률\n",
        "            topk_indx = torch.topk(gate_probs, module.num_select).indices.tolist() # 상위 k개의 index\n",
        "            print(f\"{name}\")\n",
        "            for i, prob in enumerate(gate_probs):\n",
        "                mask = \" \" if i in topk_indx else \"*\" # mask\n",
        "                print(f\"Block {i}: {prob:.4f} {mask}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, criterion, device, phase=\"Validation\", epoch=0, total_epcohs=100):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    tau_max = 1\n",
        "    tau_min = 0.1\n",
        "    total_steps = total_epcohs * len(data_loader)\n",
        "    train_steps = epoch * len(data_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            if phase == \"Validation\":\n",
        "                tau = tau_max - (tau_max - tau_min) * min(1.0, (train_steps + i) / total_steps)\n",
        "            elif phase == \"Test\":\n",
        "                tau = 1e-5\n",
        "            outputs = model(inputs, tau)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "    print(f\"Tau: {tau:.4f}\")\n",
        "\n",
        "    val_losses.append(epoch_loss)\n",
        "    val_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter name: {name}, requires_grad: {param.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E_O1ooo4c1A",
        "outputId": "634b936d-7648-4395-dae4-8b21c8345b2d"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter name: stem.conv1.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv1.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv1.bn.bias, requires_grad: True\n",
            "Parameter name: stem.conv2.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv2.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv2.bn.bias, requires_grad: True\n",
            "Parameter name: stem.conv3.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv3.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv3.bn.bias, requires_grad: True\n",
            "Parameter name: stem.conv4.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv4.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv4.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.gumbel_gate, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.gumbel_gate, requires_grad: True\n",
            "Parameter name: stage2.downsample.conv.weight, requires_grad: True\n",
            "Parameter name: stage2.downsample.conv.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: conv1x1.0.weight, requires_grad: True\n",
            "Parameter name: conv1x1.0.bias, requires_grad: True\n",
            "Parameter name: conv1x1.1.weight, requires_grad: True\n",
            "Parameter name: conv1x1.1.bias, requires_grad: True\n",
            "Parameter name: head.bn.weight, requires_grad: True\n",
            "Parameter name: head.bn.bias, requires_grad: True\n",
            "Parameter name: head.linear.weight, requires_grad: True\n",
            "Parameter name: head.linear.bias, requires_grad: True\n",
            "Parameter name: head_dist.bn.weight, requires_grad: True\n",
            "Parameter name: head_dist.bn.bias, requires_grad: True\n",
            "Parameter name: head_dist.linear.weight, requires_grad: True\n",
            "Parameter name: head_dist.linear.bias, requires_grad: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transfer_weights(pretrained_model: LevitDistilled, tinyfusion_model: LevitDistilledTinyfusion, num_blocks):\n",
        "\n",
        "    pretrained_dict = pretrained_model.state_dict()\n",
        "    tinyfusion_dict = tinyfusion_model.state_dict()\n",
        "\n",
        "    new_state_dict = {}\n",
        "\n",
        "    # 1️⃣ 공통된 가중치 복사 (stem, conv1x1, head, head_dist)\n",
        "    for key in tinyfusion_dict.keys():\n",
        "        if key in pretrained_dict and not key.startswith(\"stage\"):\n",
        "            new_state_dict[key] = pretrained_dict[key]\n",
        "\n",
        "    stage = []\n",
        "    for i in range(num_blocks):\n",
        "        stage.append(f\"stage{i}\")\n",
        "    # 2️⃣ stage1, stage2의 가중치 변환 적용\n",
        "    for stage_name in stage:\n",
        "        for i in range(num_blocks):  # num_blocks=4\n",
        "            old_key = f\"{stage_name}.blocks.{i}\"  # 원래 모델의 key\n",
        "            new_key = f\"{stage_name}.blocks.{i}\"  # TinyFusion 모델의 key\n",
        "\n",
        "            if old_key in pretrained_dict and new_key in tinyfusion_dict:\n",
        "                new_state_dict[new_key] = pretrained_dict[old_key]\n",
        "\n",
        "    # 3️⃣ `gumble_gate`는 원래 모델에 없으므로, 초기화된 값 유지 (로드 안함)\n",
        "    print(\"✅ 가중치 변환 완료! TinyFusion 모델에 적용합니다.\")\n",
        "\n",
        "    # 4️⃣ 변환된 가중치를 TinyFusion 모델에 로드 (strict=False)\n",
        "    tinyfusion_model.load_state_dict(new_state_dict, strict=False)"
      ],
      "metadata": {
        "id": "QhOOoBYs4hBm"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = LevitDistilled(num_classes=9)\n",
        "pretrained_model.stage1.blocks[0].attn.compute_attention_bias(14)\n",
        "pretrained_model.stage1.blocks[1].attn.compute_attention_bias(14)\n",
        "pretrained_model.stage1.blocks[2].attn.compute_attention_bias(14)\n",
        "pretrained_model.stage1.blocks[3].attn.compute_attention_bias(14)\n",
        "pretrained_model.stage2.blocks[0].attn.compute_attention_bias(7)\n",
        "pretrained_model.stage2.blocks[1].attn.compute_attention_bias(7)\n",
        "pretrained_model.stage2.blocks[2].attn.compute_attention_bias(7)\n",
        "pretrained_model.stage2.blocks[3].attn.compute_attention_bias(7)\n",
        "model.stage1.blocks[0].attn.compute_attention_bias(14)\n",
        "model.stage1.blocks[1].attn.compute_attention_bias(14)\n",
        "model.stage1.blocks[2].attn.compute_attention_bias(14)\n",
        "model.stage1.blocks[3].attn.compute_attention_bias(14)\n",
        "model.stage2.blocks[0].attn.compute_attention_bias(7)\n",
        "model.stage2.blocks[1].attn.compute_attention_bias(7)\n",
        "model.stage2.blocks[2].attn.compute_attention_bias(7)\n",
        "model.stage2.blocks[3].attn.compute_attention_bias(7)\n",
        "pretrained_model.load_state_dict(torch.load(\"HoViT44_withAug_7Ktest.pth\", weights_only=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNXAaJwH4j3M",
        "outputId": "bc037c7c-28aa-414b-bc11-59b2a3a3b576"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_weights(pretrained_model, model, num_blocks=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX1-SnT95apa",
        "outputId": "de3c5e98-f05d-454b-e879-de2ca7cd77e3"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 가중치 변환 완료! TinyFusion 모델에 적용합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = convert_to_lora_model(model, exclude=exclude)"
      ],
      "metadata": {
        "id": "PFqz6dOv5cBi"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gumbel_gate 파라미터가 포함되어 있는지 확인\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter name: {name}, requires_grad: {param.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZFIjbOp5ei1",
        "outputId": "c78ce620-d3ae-495f-ce92-e43f7522bbce"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter name: stem.conv1.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv1.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv1.bn.bias, requires_grad: True\n",
            "Parameter name: stem.conv2.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv2.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv2.bn.bias, requires_grad: True\n",
            "Parameter name: stem.conv3.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv3.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv3.bn.bias, requires_grad: True\n",
            "Parameter name: stem.conv4.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv4.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv4.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.gumbel_gate, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.gumbel_gate, requires_grad: True\n",
            "Parameter name: stage2.downsample.conv.weight, requires_grad: True\n",
            "Parameter name: stage2.downsample.conv.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: conv1x1.0.weight, requires_grad: True\n",
            "Parameter name: conv1x1.0.bias, requires_grad: True\n",
            "Parameter name: conv1x1.1.weight, requires_grad: True\n",
            "Parameter name: conv1x1.1.bias, requires_grad: True\n",
            "Parameter name: head.bn.weight, requires_grad: True\n",
            "Parameter name: head.bn.bias, requires_grad: True\n",
            "Parameter name: head.linear.weight, requires_grad: True\n",
            "Parameter name: head.linear.bias, requires_grad: True\n",
            "Parameter name: head_dist.bn.weight, requires_grad: True\n",
            "Parameter name: head_dist.bn.bias, requires_grad: True\n",
            "Parameter name: head_dist.linear.weight, requires_grad: True\n",
            "Parameter name: head_dist.linear.bias, requires_grad: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if \"lora_a\" in name or \"lora_b\" in name:\n",
        "        param.requires_grad = True\n",
        "        print(f\"✅ LoRA Trainable: {name}\")\n",
        "    elif \"gumbel_gate\" in name:\n",
        "        param.requires_grad = True\n",
        "        print(f\"✅ TinyFusion Trainable: {name}\")\n",
        "    elif \"head\" in name or \"head_dist\" in name:\n",
        "        param.requires_grad = True\n",
        "        print(f\"✅ Head Trainable: {name}\")\n",
        "    elif \"conv1x1\" in name:\n",
        "        param.requires_grad = True\n",
        "        print(f\"✅ Conv1x1 Trainable: {name}\")\n",
        "    elif \"attention_biases\" in name:\n",
        "        param.requires_grad = True\n",
        "        print(f\"✅ Attention Biases Trainable: {name}\")\n",
        "    else:\n",
        "        param.requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELoFunmQ5fyT",
        "outputId": "c76c8aaa-a28d-4673-9852-51fdd8c61d81"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ TinyFusion Trainable: stage1.gumbel_gate\n",
            "✅ Attention Biases Trainable: stage1.blocks.0.attn.attention_biases\n",
            "✅ LoRA Trainable: stage1.blocks.0.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.0.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.0.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.0.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.0.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.0.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.0.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.0.mlp.ln2.linear.lora_b.weight\n",
            "✅ Attention Biases Trainable: stage1.blocks.1.attn.attention_biases\n",
            "✅ LoRA Trainable: stage1.blocks.1.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.1.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.1.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.1.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.1.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.1.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.1.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.1.mlp.ln2.linear.lora_b.weight\n",
            "✅ Attention Biases Trainable: stage1.blocks.2.attn.attention_biases\n",
            "✅ LoRA Trainable: stage1.blocks.2.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.2.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.2.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.2.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.2.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.2.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.2.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.2.mlp.ln2.linear.lora_b.weight\n",
            "✅ Attention Biases Trainable: stage1.blocks.3.attn.attention_biases\n",
            "✅ LoRA Trainable: stage1.blocks.3.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.3.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.3.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.3.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.3.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.3.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.3.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.3.mlp.ln2.linear.lora_b.weight\n",
            "✅ TinyFusion Trainable: stage2.gumbel_gate\n",
            "✅ Attention Biases Trainable: stage2.blocks.0.attn.attention_biases\n",
            "✅ LoRA Trainable: stage2.blocks.0.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.0.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.0.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.0.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.0.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.0.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.0.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.0.mlp.ln2.linear.lora_b.weight\n",
            "✅ Attention Biases Trainable: stage2.blocks.1.attn.attention_biases\n",
            "✅ LoRA Trainable: stage2.blocks.1.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.1.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.1.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.1.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.1.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.1.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.1.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.1.mlp.ln2.linear.lora_b.weight\n",
            "✅ Attention Biases Trainable: stage2.blocks.2.attn.attention_biases\n",
            "✅ LoRA Trainable: stage2.blocks.2.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.2.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.2.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.2.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.2.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.2.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.2.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.2.mlp.ln2.linear.lora_b.weight\n",
            "✅ Attention Biases Trainable: stage2.blocks.3.attn.attention_biases\n",
            "✅ LoRA Trainable: stage2.blocks.3.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.3.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.3.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.3.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.3.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.3.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.3.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.3.mlp.ln2.linear.lora_b.weight\n",
            "✅ Conv1x1 Trainable: conv1x1.0.weight\n",
            "✅ Conv1x1 Trainable: conv1x1.0.bias\n",
            "✅ Conv1x1 Trainable: conv1x1.1.weight\n",
            "✅ Conv1x1 Trainable: conv1x1.1.bias\n",
            "✅ Head Trainable: head.bn.weight\n",
            "✅ Head Trainable: head.bn.bias\n",
            "✅ Head Trainable: head.linear.weight\n",
            "✅ Head Trainable: head.linear.bias\n",
            "✅ Head Trainable: head_dist.bn.weight\n",
            "✅ Head Trainable: head_dist.bn.bias\n",
            "✅ Head Trainable: head_dist.linear.weight\n",
            "✅ Head Trainable: head_dist.linear.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gumbel_gate 파라미터가 포함되어 있는지 확인\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter name: {name}, requires_grad: {param.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFLWmD5T5k-v",
        "outputId": "bb4a28bb-854e-405c-8a5d-19b7d24aea1e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter name: stem.conv1.linear.weight, requires_grad: False\n",
            "Parameter name: stem.conv1.bn.weight, requires_grad: False\n",
            "Parameter name: stem.conv1.bn.bias, requires_grad: False\n",
            "Parameter name: stem.conv2.linear.weight, requires_grad: False\n",
            "Parameter name: stem.conv2.bn.weight, requires_grad: False\n",
            "Parameter name: stem.conv2.bn.bias, requires_grad: False\n",
            "Parameter name: stem.conv3.linear.weight, requires_grad: False\n",
            "Parameter name: stem.conv3.bn.weight, requires_grad: False\n",
            "Parameter name: stem.conv3.bn.bias, requires_grad: False\n",
            "Parameter name: stem.conv4.linear.weight, requires_grad: False\n",
            "Parameter name: stem.conv4.bn.weight, requires_grad: False\n",
            "Parameter name: stem.conv4.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.gumbel_gate, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.gumbel_gate, requires_grad: True\n",
            "Parameter name: stage2.downsample.conv.weight, requires_grad: False\n",
            "Parameter name: stage2.downsample.conv.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: conv1x1.0.weight, requires_grad: True\n",
            "Parameter name: conv1x1.0.bias, requires_grad: True\n",
            "Parameter name: conv1x1.1.weight, requires_grad: True\n",
            "Parameter name: conv1x1.1.bias, requires_grad: True\n",
            "Parameter name: head.bn.weight, requires_grad: True\n",
            "Parameter name: head.bn.bias, requires_grad: True\n",
            "Parameter name: head.linear.weight, requires_grad: True\n",
            "Parameter name: head.linear.bias, requires_grad: True\n",
            "Parameter name: head_dist.bn.weight, requires_grad: True\n",
            "Parameter name: head_dist.bn.bias, requires_grad: True\n",
            "Parameter name: head_dist.linear.weight, requires_grad: True\n",
            "Parameter name: head_dist.linear.bias, requires_grad: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "a3ec9587-7c89-4131-eeb5-6402adcedbe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4755, Train Accuracy: 84.56%\n",
            "Tau: 0.9910\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.2715  \n",
            "Block 1: 0.2604  \n",
            "Block 2: 0.2334 *\n",
            "Block 3: 0.2346 *\n",
            "stage2\n",
            "Block 0: 0.2624  \n",
            "Block 1: 0.2681  \n",
            "Block 2: 0.2387 *\n",
            "Block 3: 0.2308 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5290, Validation Accuracy: 81.50%\n",
            "Balanced Accuracy: 0.8080\n",
            "Tau: 0.9910\n",
            "\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2425, Train Accuracy: 91.82%\n",
            "Tau: 0.9820\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.2924  \n",
            "Block 1: 0.2644  \n",
            "Block 2: 0.2149 *\n",
            "Block 3: 0.2282 *\n",
            "stage2\n",
            "Block 0: 0.2730  \n",
            "Block 1: 0.2758  \n",
            "Block 2: 0.2285 *\n",
            "Block 3: 0.2227 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4490, Validation Accuracy: 84.30%\n",
            "Balanced Accuracy: 0.8386\n",
            "Tau: 0.9820\n",
            "\n",
            "Epoch 3/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1905, Train Accuracy: 93.56%\n",
            "Tau: 0.9730\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.3306  \n",
            "Block 1: 0.2591  \n",
            "Block 2: 0.1961 *\n",
            "Block 3: 0.2141 *\n",
            "stage2\n",
            "Block 0: 0.2869  \n",
            "Block 1: 0.2786  \n",
            "Block 2: 0.2225 *\n",
            "Block 3: 0.2120 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3677, Validation Accuracy: 87.39%\n",
            "Balanced Accuracy: 0.8733\n",
            "Tau: 0.9730\n",
            "\n",
            "Epoch 4/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1579, Train Accuracy: 94.67%\n",
            "Tau: 0.9640\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.3497  \n",
            "Block 1: 0.2635  \n",
            "Block 2: 0.1838 *\n",
            "Block 3: 0.2031 *\n",
            "stage2\n",
            "Block 0: 0.3010  \n",
            "Block 1: 0.2822  \n",
            "Block 2: 0.2140 *\n",
            "Block 3: 0.2028 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2783, Validation Accuracy: 90.45%\n",
            "Balanced Accuracy: 0.9031\n",
            "Tau: 0.9640\n",
            "\n",
            "Epoch 5/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1388, Train Accuracy: 95.23%\n",
            "Tau: 0.9550\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.3821  \n",
            "Block 1: 0.2623  \n",
            "Block 2: 0.1669 *\n",
            "Block 3: 0.1888 *\n",
            "stage2\n",
            "Block 0: 0.3119  \n",
            "Block 1: 0.2818  \n",
            "Block 2: 0.2124 *\n",
            "Block 3: 0.1939 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2813, Validation Accuracy: 90.35%\n",
            "Balanced Accuracy: 0.9027\n",
            "Tau: 0.9550\n",
            "\n",
            "Epoch 6/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1189, Train Accuracy: 95.99%\n",
            "Tau: 0.9460\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.4178  \n",
            "Block 1: 0.2567  \n",
            "Block 2: 0.1530 *\n",
            "Block 3: 0.1725 *\n",
            "stage2\n",
            "Block 0: 0.3198  \n",
            "Block 1: 0.2849  \n",
            "Block 2: 0.2088 *\n",
            "Block 3: 0.1865 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2615, Validation Accuracy: 91.17%\n",
            "Balanced Accuracy: 0.9108\n",
            "Tau: 0.9460\n",
            "\n",
            "Epoch 7/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1065, Train Accuracy: 96.38%\n",
            "Tau: 0.9370\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.4458  \n",
            "Block 1: 0.2555  \n",
            "Block 2: 0.1394 *\n",
            "Block 3: 0.1593 *\n",
            "stage2\n",
            "Block 0: 0.3432  \n",
            "Block 1: 0.2825  \n",
            "Block 2: 0.2014 *\n",
            "Block 3: 0.1729 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2514, Validation Accuracy: 91.49%\n",
            "Balanced Accuracy: 0.9120\n",
            "Tau: 0.9370\n",
            "\n",
            "Epoch 8/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0948, Train Accuracy: 96.69%\n",
            "Tau: 0.9280\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.4821  \n",
            "Block 1: 0.2467  \n",
            "Block 2: 0.1243 *\n",
            "Block 3: 0.1469 *\n",
            "stage2\n",
            "Block 0: 0.3645  \n",
            "Block 1: 0.2795  \n",
            "Block 2: 0.1895 *\n",
            "Block 3: 0.1665 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2628, Validation Accuracy: 91.16%\n",
            "Balanced Accuracy: 0.9116\n",
            "Tau: 0.9280\n",
            "\n",
            "Epoch 9/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0847, Train Accuracy: 97.09%\n",
            "Tau: 0.9190\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.5152  \n",
            "Block 1: 0.2364  \n",
            "Block 2: 0.1120 *\n",
            "Block 3: 0.1364 *\n",
            "stage2\n",
            "Block 0: 0.3792  \n",
            "Block 1: 0.2839  \n",
            "Block 2: 0.1806 *\n",
            "Block 3: 0.1563 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2457, Validation Accuracy: 91.89%\n",
            "Balanced Accuracy: 0.9185\n",
            "Tau: 0.9190\n",
            "\n",
            "Epoch 10/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0748, Train Accuracy: 97.45%\n",
            "Tau: 0.9100\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.5442  \n",
            "Block 1: 0.2297  \n",
            "Block 2: 0.1016 *\n",
            "Block 3: 0.1245 *\n",
            "stage2\n",
            "Block 0: 0.3946  \n",
            "Block 1: 0.2863  \n",
            "Block 2: 0.1682 *\n",
            "Block 3: 0.1510 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2301, Validation Accuracy: 92.61%\n",
            "Balanced Accuracy: 0.9276\n",
            "Tau: 0.9100\n",
            "\n",
            "Epoch 11/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0673, Train Accuracy: 97.72%\n",
            "Tau: 0.9010\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.5792  \n",
            "Block 1: 0.2141  \n",
            "Block 2: 0.0924 *\n",
            "Block 3: 0.1144 *\n",
            "stage2\n",
            "Block 0: 0.4126  \n",
            "Block 1: 0.2767  \n",
            "Block 2: 0.1665 *\n",
            "Block 3: 0.1443 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2078, Validation Accuracy: 93.20%\n",
            "Balanced Accuracy: 0.9321\n",
            "Tau: 0.9010\n",
            "\n",
            "Epoch 12/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0597, Train Accuracy: 97.94%\n",
            "Tau: 0.8920\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.6084  \n",
            "Block 1: 0.2089  \n",
            "Block 2: 0.0811 *\n",
            "Block 3: 0.1016 *\n",
            "stage2\n",
            "Block 0: 0.4286  \n",
            "Block 1: 0.2806  \n",
            "Block 2: 0.1534 *\n",
            "Block 3: 0.1374 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2176, Validation Accuracy: 93.06%\n",
            "Balanced Accuracy: 0.9315\n",
            "Tau: 0.8920\n",
            "\n",
            "Epoch 13/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0527, Train Accuracy: 98.21%\n",
            "Tau: 0.8830\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.6365  \n",
            "Block 1: 0.1982  \n",
            "Block 2: 0.0722 *\n",
            "Block 3: 0.0931 *\n",
            "stage2\n",
            "Block 0: 0.4382  \n",
            "Block 1: 0.2767  \n",
            "Block 2: 0.1530 *\n",
            "Block 3: 0.1321 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2065, Validation Accuracy: 93.67%\n",
            "Balanced Accuracy: 0.9367\n",
            "Tau: 0.8830\n",
            "\n",
            "Epoch 14/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0480, Train Accuracy: 98.33%\n",
            "Tau: 0.8740\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.6702  \n",
            "Block 1: 0.1841  \n",
            "Block 2: 0.0652 *\n",
            "Block 3: 0.0804 *\n",
            "stage2\n",
            "Block 0: 0.4579  \n",
            "Block 1: 0.2707  \n",
            "Block 2: 0.1447 *\n",
            "Block 3: 0.1267 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2076, Validation Accuracy: 93.61%\n",
            "Balanced Accuracy: 0.9360\n",
            "Tau: 0.8740\n",
            "\n",
            "Epoch 15/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0425, Train Accuracy: 98.53%\n",
            "Tau: 0.8650\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.6859  \n",
            "Block 1: 0.1742  \n",
            "Block 2: 0.0626 *\n",
            "Block 3: 0.0773 *\n",
            "stage2\n",
            "Block 0: 0.4665  \n",
            "Block 1: 0.2762  \n",
            "Block 2: 0.1407 *\n",
            "Block 3: 0.1166 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1891, Validation Accuracy: 94.19%\n",
            "Balanced Accuracy: 0.9431\n",
            "Tau: 0.8650\n",
            "\n",
            "Epoch 16/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0414, Train Accuracy: 98.59%\n",
            "Tau: 0.8560\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.7210  \n",
            "Block 1: 0.1603  \n",
            "Block 2: 0.0519 *\n",
            "Block 3: 0.0668 *\n",
            "stage2\n",
            "Block 0: 0.4744  \n",
            "Block 1: 0.2786  \n",
            "Block 2: 0.1358 *\n",
            "Block 3: 0.1112 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1803, Validation Accuracy: 94.37%\n",
            "Balanced Accuracy: 0.9454\n",
            "Tau: 0.8560\n",
            "\n",
            "Epoch 17/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0358, Train Accuracy: 98.78%\n",
            "Tau: 0.8470\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.7420  \n",
            "Block 1: 0.1523  \n",
            "Block 2: 0.0455 *\n",
            "Block 3: 0.0602 *\n",
            "stage2\n",
            "Block 0: 0.4845  \n",
            "Block 1: 0.2800  \n",
            "Block 2: 0.1297 *\n",
            "Block 3: 0.1057 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1593, Validation Accuracy: 95.16%\n",
            "Balanced Accuracy: 0.9515\n",
            "Tau: 0.8470\n",
            "\n",
            "Epoch 18/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0323, Train Accuracy: 98.88%\n",
            "Tau: 0.8380\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.7712  \n",
            "Block 1: 0.1335  \n",
            "Block 2: 0.0396 *\n",
            "Block 3: 0.0557 *\n",
            "stage2\n",
            "Block 0: 0.5072  \n",
            "Block 1: 0.2773  \n",
            "Block 2: 0.1179 *\n",
            "Block 3: 0.0976 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1691, Validation Accuracy: 95.13%\n",
            "Balanced Accuracy: 0.9506\n",
            "Tau: 0.8380\n",
            "\n",
            "Epoch 19/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0304, Train Accuracy: 98.97%\n",
            "Tau: 0.8290\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.7924  \n",
            "Block 1: 0.1228  \n",
            "Block 2: 0.0361 *\n",
            "Block 3: 0.0487 *\n",
            "stage2\n",
            "Block 0: 0.5117  \n",
            "Block 1: 0.2828  \n",
            "Block 2: 0.1149 *\n",
            "Block 3: 0.0906 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1781, Validation Accuracy: 94.65%\n",
            "Balanced Accuracy: 0.9479\n",
            "Tau: 0.8290\n",
            "\n",
            "Epoch 20/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0283, Train Accuracy: 99.03%\n",
            "Tau: 0.8200\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.8094  \n",
            "Block 1: 0.1143  \n",
            "Block 2: 0.0325 *\n",
            "Block 3: 0.0438 *\n",
            "stage2\n",
            "Block 0: 0.5253  \n",
            "Block 1: 0.2830  \n",
            "Block 2: 0.1075 *\n",
            "Block 3: 0.0841 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1853, Validation Accuracy: 94.33%\n",
            "Balanced Accuracy: 0.9448\n",
            "Tau: 0.8200\n",
            "\n",
            "Epoch 21/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0274, Train Accuracy: 99.09%\n",
            "Tau: 0.8110\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.8257  \n",
            "Block 1: 0.1046  \n",
            "Block 2: 0.0297 *\n",
            "Block 3: 0.0400 *\n",
            "stage2\n",
            "Block 0: 0.5433  \n",
            "Block 1: 0.2787  \n",
            "Block 2: 0.1004 *\n",
            "Block 3: 0.0776 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1769, Validation Accuracy: 94.66%\n",
            "Balanced Accuracy: 0.9484\n",
            "Tau: 0.8110\n",
            "\n",
            "Epoch 22/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0260, Train Accuracy: 99.10%\n",
            "Tau: 0.8020\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.8378  \n",
            "Block 1: 0.0989  \n",
            "Block 2: 0.0274 *\n",
            "Block 3: 0.0360 *\n",
            "stage2\n",
            "Block 0: 0.5540  \n",
            "Block 1: 0.2788  \n",
            "Block 2: 0.0957 *\n",
            "Block 3: 0.0715 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1744, Validation Accuracy: 95.05%\n",
            "Balanced Accuracy: 0.9525\n",
            "Tau: 0.8020\n",
            "\n",
            "Epoch 23/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0224, Train Accuracy: 99.25%\n",
            "Tau: 0.7930\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.8559  \n",
            "Block 1: 0.0882  \n",
            "Block 2: 0.0240 *\n",
            "Block 3: 0.0319 *\n",
            "stage2\n",
            "Block 0: 0.5639  \n",
            "Block 1: 0.2749  \n",
            "Block 2: 0.0913 *\n",
            "Block 3: 0.0698 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1919, Validation Accuracy: 94.51%\n",
            "Balanced Accuracy: 0.9471\n",
            "Tau: 0.7930\n",
            "\n",
            "Epoch 24/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0209, Train Accuracy: 99.30%\n",
            "Tau: 0.7840\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.8715  \n",
            "Block 1: 0.0790  \n",
            "Block 2: 0.0209 *\n",
            "Block 3: 0.0287 *\n",
            "stage2\n",
            "Block 0: 0.5765  \n",
            "Block 1: 0.2702  \n",
            "Block 2: 0.0849 *\n",
            "Block 3: 0.0684 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1540, Validation Accuracy: 95.65%\n",
            "Balanced Accuracy: 0.9584\n",
            "Tau: 0.7840\n",
            "\n",
            "Epoch 25/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0202, Train Accuracy: 99.28%\n",
            "Tau: 0.7750\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.8855  \n",
            "Block 1: 0.0710  \n",
            "Block 2: 0.0184 *\n",
            "Block 3: 0.0251 *\n",
            "stage2\n",
            "Block 0: 0.5939  \n",
            "Block 1: 0.2652  \n",
            "Block 2: 0.0772 *\n",
            "Block 3: 0.0637 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1544, Validation Accuracy: 95.83%\n",
            "Balanced Accuracy: 0.9598\n",
            "Tau: 0.7750\n",
            "\n",
            "Epoch 26/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0184, Train Accuracy: 99.37%\n",
            "Tau: 0.7660\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.8979  \n",
            "Block 1: 0.0634  \n",
            "Block 2: 0.0164 *\n",
            "Block 3: 0.0222 *\n",
            "stage2\n",
            "Block 0: 0.5949  \n",
            "Block 1: 0.2664  \n",
            "Block 2: 0.0764 *\n",
            "Block 3: 0.0622 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1428, Validation Accuracy: 96.23%\n",
            "Balanced Accuracy: 0.9634\n",
            "Tau: 0.7660\n",
            "\n",
            "Epoch 27/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0184, Train Accuracy: 99.37%\n",
            "Tau: 0.7570\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9039  \n",
            "Block 1: 0.0598  \n",
            "Block 2: 0.0154 *\n",
            "Block 3: 0.0208 *\n",
            "stage2\n",
            "Block 0: 0.6097  \n",
            "Block 1: 0.2584  \n",
            "Block 2: 0.0726 *\n",
            "Block 3: 0.0594 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1977, Validation Accuracy: 94.89%\n",
            "Balanced Accuracy: 0.9520\n",
            "Tau: 0.7570\n",
            "\n",
            "Epoch 28/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0184, Train Accuracy: 99.37%\n",
            "Tau: 0.7480\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9144  \n",
            "Block 1: 0.0530  \n",
            "Block 2: 0.0134 *\n",
            "Block 3: 0.0192 *\n",
            "stage2\n",
            "Block 0: 0.6244  \n",
            "Block 1: 0.2527  \n",
            "Block 2: 0.0686 *\n",
            "Block 3: 0.0542 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1467, Validation Accuracy: 95.97%\n",
            "Balanced Accuracy: 0.9602\n",
            "Tau: 0.7480\n",
            "\n",
            "Epoch 29/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0160, Train Accuracy: 99.48%\n",
            "Tau: 0.7390\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9233  \n",
            "Block 1: 0.0477  \n",
            "Block 2: 0.0120 *\n",
            "Block 3: 0.0171 *\n",
            "stage2\n",
            "Block 0: 0.6442  \n",
            "Block 1: 0.2385  \n",
            "Block 2: 0.0660 *\n",
            "Block 3: 0.0512 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1536, Validation Accuracy: 95.71%\n",
            "Balanced Accuracy: 0.9582\n",
            "Tau: 0.7390\n",
            "\n",
            "Epoch 30/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0159, Train Accuracy: 99.46%\n",
            "Tau: 0.7300\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9302  \n",
            "Block 1: 0.0440  \n",
            "Block 2: 0.0108 *\n",
            "Block 3: 0.0151 *\n",
            "stage2\n",
            "Block 0: 0.6525  \n",
            "Block 1: 0.2395  \n",
            "Block 2: 0.0608 *\n",
            "Block 3: 0.0472 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1328, Validation Accuracy: 96.45%\n",
            "Balanced Accuracy: 0.9655\n",
            "Tau: 0.7300\n",
            "\n",
            "Epoch 31/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0152, Train Accuracy: 99.49%\n",
            "Tau: 0.7210\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9333  \n",
            "Block 1: 0.0422  \n",
            "Block 2: 0.0100 *\n",
            "Block 3: 0.0144 *\n",
            "stage2\n",
            "Block 0: 0.6566  \n",
            "Block 1: 0.2410  \n",
            "Block 2: 0.0570 *\n",
            "Block 3: 0.0454 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1632, Validation Accuracy: 95.64%\n",
            "Balanced Accuracy: 0.9585\n",
            "Tau: 0.7210\n",
            "\n",
            "Epoch 32/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0132, Train Accuracy: 99.55%\n",
            "Tau: 0.7120\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9394  \n",
            "Block 1: 0.0380  \n",
            "Block 2: 0.0091 *\n",
            "Block 3: 0.0135 *\n",
            "stage2\n",
            "Block 0: 0.6573  \n",
            "Block 1: 0.2445  \n",
            "Block 2: 0.0540 *\n",
            "Block 3: 0.0441 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1455, Validation Accuracy: 96.48%\n",
            "Balanced Accuracy: 0.9652\n",
            "Tau: 0.7120\n",
            "\n",
            "Epoch 33/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0131, Train Accuracy: 99.57%\n",
            "Tau: 0.7030\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9450  \n",
            "Block 1: 0.0344  \n",
            "Block 2: 0.0084 *\n",
            "Block 3: 0.0122 *\n",
            "stage2\n",
            "Block 0: 0.6761  \n",
            "Block 1: 0.2311  \n",
            "Block 2: 0.0519 *\n",
            "Block 3: 0.0409 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1755, Validation Accuracy: 95.75%\n",
            "Balanced Accuracy: 0.9595\n",
            "Tau: 0.7030\n",
            "\n",
            "Epoch 34/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0140, Train Accuracy: 99.53%\n",
            "Tau: 0.6940\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9526  \n",
            "Block 1: 0.0292  \n",
            "Block 2: 0.0077 *\n",
            "Block 3: 0.0105 *\n",
            "stage2\n",
            "Block 0: 0.6829  \n",
            "Block 1: 0.2294  \n",
            "Block 2: 0.0484 *\n",
            "Block 3: 0.0393 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1761, Validation Accuracy: 96.03%\n",
            "Balanced Accuracy: 0.9618\n",
            "Tau: 0.6940\n",
            "\n",
            "Epoch 35/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0119, Train Accuracy: 99.60%\n",
            "Tau: 0.6850\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9583  \n",
            "Block 1: 0.0255  \n",
            "Block 2: 0.0069 *\n",
            "Block 3: 0.0094 *\n",
            "stage2\n",
            "Block 0: 0.6887  \n",
            "Block 1: 0.2264  \n",
            "Block 2: 0.0473 *\n",
            "Block 3: 0.0376 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1582, Validation Accuracy: 96.28%\n",
            "Balanced Accuracy: 0.9638\n",
            "Tau: 0.6850\n",
            "\n",
            "Epoch 36/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0126, Train Accuracy: 99.57%\n",
            "Tau: 0.6760\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9614  \n",
            "Block 1: 0.0236  \n",
            "Block 2: 0.0064 *\n",
            "Block 3: 0.0086 *\n",
            "stage2\n",
            "Block 0: 0.6969  \n",
            "Block 1: 0.2213  \n",
            "Block 2: 0.0458 *\n",
            "Block 3: 0.0360 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1388, Validation Accuracy: 96.72%\n",
            "Balanced Accuracy: 0.9680\n",
            "Tau: 0.6760\n",
            "\n",
            "Epoch 37/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0123, Train Accuracy: 99.56%\n",
            "Tau: 0.6670\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9650  \n",
            "Block 1: 0.0216  \n",
            "Block 2: 0.0057 *\n",
            "Block 3: 0.0076 *\n",
            "stage2\n",
            "Block 0: 0.7100  \n",
            "Block 1: 0.2134  \n",
            "Block 2: 0.0431 *\n",
            "Block 3: 0.0335 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1586, Validation Accuracy: 96.24%\n",
            "Balanced Accuracy: 0.9631\n",
            "Tau: 0.6670\n",
            "\n",
            "Epoch 38/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0112, Train Accuracy: 99.61%\n",
            "Tau: 0.6580\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9677  \n",
            "Block 1: 0.0200  \n",
            "Block 2: 0.0053 *\n",
            "Block 3: 0.0070 *\n",
            "stage2\n",
            "Block 0: 0.7355  \n",
            "Block 1: 0.1955  \n",
            "Block 2: 0.0384 *\n",
            "Block 3: 0.0306 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1540, Validation Accuracy: 96.31%\n",
            "Balanced Accuracy: 0.9649\n",
            "Tau: 0.6580\n",
            "\n",
            "Epoch 39/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0118, Train Accuracy: 99.60%\n",
            "Tau: 0.6490\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9719  \n",
            "Block 1: 0.0173  \n",
            "Block 2: 0.0046 *\n",
            "Block 3: 0.0063 *\n",
            "stage2\n",
            "Block 0: 0.7482  \n",
            "Block 1: 0.1878  \n",
            "Block 2: 0.0361 *\n",
            "Block 3: 0.0279 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1450, Validation Accuracy: 96.72%\n",
            "Balanced Accuracy: 0.9688\n",
            "Tau: 0.6490\n",
            "\n",
            "Epoch 40/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0114, Train Accuracy: 99.59%\n",
            "Tau: 0.6400\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9738  \n",
            "Block 1: 0.0159  \n",
            "Block 2: 0.0043 *\n",
            "Block 3: 0.0060 *\n",
            "stage2\n",
            "Block 0: 0.7480  \n",
            "Block 1: 0.1897  \n",
            "Block 2: 0.0356 *\n",
            "Block 3: 0.0268 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1333, Validation Accuracy: 96.88%\n",
            "Balanced Accuracy: 0.9696\n",
            "Tau: 0.6400\n",
            "Model weights saved to HoViT_44_tinyfusion_base_r8a16_39.pth\n",
            "40 model test result:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1669, Test Accuracy: 96.43%\n",
            "Balanced Accuracy: 0.9655\n",
            "Tau: 0.0000\n",
            "\n",
            "Epoch 41/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0107, Train Accuracy: 99.64%\n",
            "Tau: 0.6310\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9761  \n",
            "Block 1: 0.0147  \n",
            "Block 2: 0.0038 *\n",
            "Block 3: 0.0054 *\n",
            "stage2\n",
            "Block 0: 0.7524  \n",
            "Block 1: 0.1853  \n",
            "Block 2: 0.0354 *\n",
            "Block 3: 0.0269 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1277, Validation Accuracy: 97.01%\n",
            "Balanced Accuracy: 0.9699\n",
            "Tau: 0.6310\n",
            "\n",
            "Epoch 42/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0099, Train Accuracy: 99.68%\n",
            "Tau: 0.6220\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9786  \n",
            "Block 1: 0.0130  \n",
            "Block 2: 0.0036 *\n",
            "Block 3: 0.0048 *\n",
            "stage2\n",
            "Block 0: 0.7496  \n",
            "Block 1: 0.1898  \n",
            "Block 2: 0.0346 *\n",
            "Block 3: 0.0260 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1478, Validation Accuracy: 96.54%\n",
            "Balanced Accuracy: 0.9673\n",
            "Tau: 0.6220\n",
            "\n",
            "Epoch 43/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0090, Train Accuracy: 99.71%\n",
            "Tau: 0.6130\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9808  \n",
            "Block 1: 0.0115  \n",
            "Block 2: 0.0034 *\n",
            "Block 3: 0.0044 *\n",
            "stage2\n",
            "Block 0: 0.7609  \n",
            "Block 1: 0.1822  \n",
            "Block 2: 0.0327 *\n",
            "Block 3: 0.0242 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1373, Validation Accuracy: 96.81%\n",
            "Balanced Accuracy: 0.9687\n",
            "Tau: 0.6130\n",
            "\n",
            "Epoch 44/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0103, Train Accuracy: 99.64%\n",
            "Tau: 0.6040\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9818  \n",
            "Block 1: 0.0109  \n",
            "Block 2: 0.0031 *\n",
            "Block 3: 0.0042 *\n",
            "stage2\n",
            "Block 0: 0.7648  \n",
            "Block 1: 0.1820  \n",
            "Block 2: 0.0307 *\n",
            "Block 3: 0.0224 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1435, Validation Accuracy: 96.81%\n",
            "Balanced Accuracy: 0.9681\n",
            "Tau: 0.6040\n",
            "\n",
            "Epoch 45/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0096, Train Accuracy: 99.66%\n",
            "Tau: 0.5950\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9829  \n",
            "Block 1: 0.0103  \n",
            "Block 2: 0.0030 *\n",
            "Block 3: 0.0039 *\n",
            "stage2\n",
            "Block 0: 0.7633  \n",
            "Block 1: 0.1867  \n",
            "Block 2: 0.0284 *\n",
            "Block 3: 0.0216 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1430, Validation Accuracy: 96.79%\n",
            "Balanced Accuracy: 0.9682\n",
            "Tau: 0.5950\n",
            "\n",
            "Epoch 46/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0099, Train Accuracy: 99.69%\n",
            "Tau: 0.5860\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9843  \n",
            "Block 1: 0.0094  \n",
            "Block 2: 0.0028 *\n",
            "Block 3: 0.0035 *\n",
            "stage2\n",
            "Block 0: 0.7661  \n",
            "Block 1: 0.1857  \n",
            "Block 2: 0.0278 *\n",
            "Block 3: 0.0204 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1474, Validation Accuracy: 96.74%\n",
            "Balanced Accuracy: 0.9682\n",
            "Tau: 0.5860\n",
            "\n",
            "Epoch 47/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0090, Train Accuracy: 99.67%\n",
            "Tau: 0.5770\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9854  \n",
            "Block 1: 0.0088  \n",
            "Block 2: 0.0026 *\n",
            "Block 3: 0.0032 *\n",
            "stage2\n",
            "Block 0: 0.7662  \n",
            "Block 1: 0.1865  \n",
            "Block 2: 0.0274 *\n",
            "Block 3: 0.0198 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1426, Validation Accuracy: 96.78%\n",
            "Balanced Accuracy: 0.9685\n",
            "Tau: 0.5770\n",
            "\n",
            "Epoch 48/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0078, Train Accuracy: 99.72%\n",
            "Tau: 0.5680\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9869  \n",
            "Block 1: 0.0077  \n",
            "Block 2: 0.0024 *\n",
            "Block 3: 0.0029 *\n",
            "stage2\n",
            "Block 0: 0.7816  \n",
            "Block 1: 0.1731  \n",
            "Block 2: 0.0258 *\n",
            "Block 3: 0.0196 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1413, Validation Accuracy: 96.95%\n",
            "Balanced Accuracy: 0.9706\n",
            "Tau: 0.5680\n",
            "\n",
            "Epoch 49/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0097, Train Accuracy: 99.65%\n",
            "Tau: 0.5590\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9874  \n",
            "Block 1: 0.0075  \n",
            "Block 2: 0.0023 *\n",
            "Block 3: 0.0028 *\n",
            "stage2\n",
            "Block 0: 0.7983  \n",
            "Block 1: 0.1608  \n",
            "Block 2: 0.0229 *\n",
            "Block 3: 0.0179 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1507, Validation Accuracy: 96.89%\n",
            "Balanced Accuracy: 0.9696\n",
            "Tau: 0.5590\n",
            "\n",
            "Epoch 50/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0086, Train Accuracy: 99.70%\n",
            "Tau: 0.5500\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9880  \n",
            "Block 1: 0.0071  \n",
            "Block 2: 0.0022 *\n",
            "Block 3: 0.0027 *\n",
            "stage2\n",
            "Block 0: 0.8210  \n",
            "Block 1: 0.1424  \n",
            "Block 2: 0.0205 *\n",
            "Block 3: 0.0160 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1487, Validation Accuracy: 97.07%\n",
            "Balanced Accuracy: 0.9710\n",
            "Tau: 0.5500\n",
            "Model weights saved to HoViT_44_tinyfusion_base_r8a16_49.pth\n",
            "50 model test result:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1762, Test Accuracy: 96.53%\n",
            "Balanced Accuracy: 0.9659\n",
            "Tau: 0.0000\n",
            "\n",
            "Epoch 51/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0085, Train Accuracy: 99.71%\n",
            "Tau: 0.5410\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9886  \n",
            "Block 1: 0.0067  \n",
            "Block 2: 0.0021 *\n",
            "Block 3: 0.0025 *\n",
            "stage2\n",
            "Block 0: 0.8241  \n",
            "Block 1: 0.1414  \n",
            "Block 2: 0.0195 *\n",
            "Block 3: 0.0150 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1392, Validation Accuracy: 97.23%\n",
            "Balanced Accuracy: 0.9728\n",
            "Tau: 0.5410\n",
            "\n",
            "Epoch 52/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0084, Train Accuracy: 99.71%\n",
            "Tau: 0.5320\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9896  \n",
            "Block 1: 0.0061  \n",
            "Block 2: 0.0019 *\n",
            "Block 3: 0.0023 *\n",
            "stage2\n",
            "Block 0: 0.8321  \n",
            "Block 1: 0.1351  \n",
            "Block 2: 0.0185 *\n",
            "Block 3: 0.0143 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1740, Validation Accuracy: 96.69%\n",
            "Balanced Accuracy: 0.9680\n",
            "Tau: 0.5320\n",
            "\n",
            "Epoch 53/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0078, Train Accuracy: 99.73%\n",
            "Tau: 0.5230\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9906  \n",
            "Block 1: 0.0055  \n",
            "Block 2: 0.0017 *\n",
            "Block 3: 0.0022 *\n",
            "stage2\n",
            "Block 0: 0.8466  \n",
            "Block 1: 0.1220  \n",
            "Block 2: 0.0174 *\n",
            "Block 3: 0.0140 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1523, Validation Accuracy: 96.95%\n",
            "Balanced Accuracy: 0.9705\n",
            "Tau: 0.5230\n",
            "\n",
            "Epoch 54/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0082, Train Accuracy: 99.70%\n",
            "Tau: 0.5140\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9912  \n",
            "Block 1: 0.0051  \n",
            "Block 2: 0.0016 *\n",
            "Block 3: 0.0020 *\n",
            "stage2\n",
            "Block 0: 0.8563  \n",
            "Block 1: 0.1147  \n",
            "Block 2: 0.0162 *\n",
            "Block 3: 0.0127 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1598, Validation Accuracy: 96.90%\n",
            "Balanced Accuracy: 0.9697\n",
            "Tau: 0.5140\n",
            "\n",
            "Epoch 55/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0091, Train Accuracy: 99.71%\n",
            "Tau: 0.5050\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9913  \n",
            "Block 1: 0.0051  \n",
            "Block 2: 0.0016 *\n",
            "Block 3: 0.0020 *\n",
            "stage2\n",
            "Block 0: 0.8630  \n",
            "Block 1: 0.1107  \n",
            "Block 2: 0.0146 *\n",
            "Block 3: 0.0117 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1435, Validation Accuracy: 97.32%\n",
            "Balanced Accuracy: 0.9737\n",
            "Tau: 0.5050\n",
            "\n",
            "Epoch 56/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0076, Train Accuracy: 99.75%\n",
            "Tau: 0.4960\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9920  \n",
            "Block 1: 0.0046  \n",
            "Block 2: 0.0016 *\n",
            "Block 3: 0.0019 *\n",
            "stage2\n",
            "Block 0: 0.8651  \n",
            "Block 1: 0.1100  \n",
            "Block 2: 0.0140 *\n",
            "Block 3: 0.0109 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1396, Validation Accuracy: 97.27%\n",
            "Balanced Accuracy: 0.9730\n",
            "Tau: 0.4960\n",
            "\n",
            "Epoch 57/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0069, Train Accuracy: 99.79%\n",
            "Tau: 0.4870\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9925  \n",
            "Block 1: 0.0043  \n",
            "Block 2: 0.0014 *\n",
            "Block 3: 0.0018 *\n",
            "stage2\n",
            "Block 0: 0.8750  \n",
            "Block 1: 0.1019  \n",
            "Block 2: 0.0130 *\n",
            "Block 3: 0.0101 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1528, Validation Accuracy: 96.97%\n",
            "Balanced Accuracy: 0.9703\n",
            "Tau: 0.4870\n",
            "\n",
            "Epoch 58/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0073, Train Accuracy: 99.75%\n",
            "Tau: 0.4780\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9933  \n",
            "Block 1: 0.0038  \n",
            "Block 2: 0.0013 *\n",
            "Block 3: 0.0016 *\n",
            "stage2\n",
            "Block 0: 0.8842  \n",
            "Block 1: 0.0938  \n",
            "Block 2: 0.0124 *\n",
            "Block 3: 0.0095 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1584, Validation Accuracy: 97.07%\n",
            "Balanced Accuracy: 0.9711\n",
            "Tau: 0.4780\n",
            "\n",
            "Epoch 59/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0081, Train Accuracy: 99.73%\n",
            "Tau: 0.4690\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9934  \n",
            "Block 1: 0.0037  \n",
            "Block 2: 0.0013 *\n",
            "Block 3: 0.0016 *\n",
            "stage2\n",
            "Block 0: 0.8870  \n",
            "Block 1: 0.0913  \n",
            "Block 2: 0.0120 *\n",
            "Block 3: 0.0097 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1479, Validation Accuracy: 97.33%\n",
            "Balanced Accuracy: 0.9734\n",
            "Tau: 0.4690\n",
            "\n",
            "Epoch 60/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0079, Train Accuracy: 99.73%\n",
            "Tau: 0.4600\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9938  \n",
            "Block 1: 0.0035  \n",
            "Block 2: 0.0012 *\n",
            "Block 3: 0.0015 *\n",
            "stage2\n",
            "Block 0: 0.8956  \n",
            "Block 1: 0.0842  \n",
            "Block 2: 0.0112 *\n",
            "Block 3: 0.0090 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1679, Validation Accuracy: 97.25%\n",
            "Balanced Accuracy: 0.9730\n",
            "Tau: 0.4600\n",
            "Model weights saved to HoViT_44_tinyfusion_base_r8a16_59.pth\n",
            "60 model test result:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1960, Test Accuracy: 96.87%\n",
            "Balanced Accuracy: 0.9694\n",
            "Tau: 0.0000\n",
            "\n",
            "Epoch 61/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0065, Train Accuracy: 99.79%\n",
            "Tau: 0.4510\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9942  \n",
            "Block 1: 0.0032  \n",
            "Block 2: 0.0012 *\n",
            "Block 3: 0.0014 *\n",
            "stage2\n",
            "Block 0: 0.8950  \n",
            "Block 1: 0.0853  \n",
            "Block 2: 0.0108 *\n",
            "Block 3: 0.0089 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1580, Validation Accuracy: 96.85%\n",
            "Balanced Accuracy: 0.9691\n",
            "Tau: 0.4510\n",
            "\n",
            "Epoch 62/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0077, Train Accuracy: 99.75%\n",
            "Tau: 0.4420\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9946  \n",
            "Block 1: 0.0030  \n",
            "Block 2: 0.0011 *\n",
            "Block 3: 0.0013 *\n",
            "stage2\n",
            "Block 0: 0.8978  \n",
            "Block 1: 0.0833  \n",
            "Block 2: 0.0103 *\n",
            "Block 3: 0.0085 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1654, Validation Accuracy: 97.29%\n",
            "Balanced Accuracy: 0.9728\n",
            "Tau: 0.4420\n",
            "\n",
            "Epoch 63/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0066, Train Accuracy: 99.78%\n",
            "Tau: 0.4330\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9947  \n",
            "Block 1: 0.0029  \n",
            "Block 2: 0.0011 *\n",
            "Block 3: 0.0013 *\n",
            "stage2\n",
            "Block 0: 0.9070  \n",
            "Block 1: 0.0753  \n",
            "Block 2: 0.0097 *\n",
            "Block 3: 0.0080 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1452, Validation Accuracy: 97.48%\n",
            "Balanced Accuracy: 0.9747\n",
            "Tau: 0.4330\n",
            "\n",
            "Epoch 64/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0065, Train Accuracy: 99.78%\n",
            "Tau: 0.4240\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9951  \n",
            "Block 1: 0.0028  \n",
            "Block 2: 0.0010 *\n",
            "Block 3: 0.0012 *\n",
            "stage2\n",
            "Block 0: 0.9184  \n",
            "Block 1: 0.0657  \n",
            "Block 2: 0.0086 *\n",
            "Block 3: 0.0073 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1544, Validation Accuracy: 97.16%\n",
            "Balanced Accuracy: 0.9716\n",
            "Tau: 0.4240\n",
            "\n",
            "Epoch 65/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0065, Train Accuracy: 99.78%\n",
            "Tau: 0.4150\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9953  \n",
            "Block 1: 0.0026  \n",
            "Block 2: 0.0010 *\n",
            "Block 3: 0.0011 *\n",
            "stage2\n",
            "Block 0: 0.9222  \n",
            "Block 1: 0.0624  \n",
            "Block 2: 0.0084 *\n",
            "Block 3: 0.0070 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1684, Validation Accuracy: 96.99%\n",
            "Balanced Accuracy: 0.9705\n",
            "Tau: 0.4150\n",
            "\n",
            "Epoch 66/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0072, Train Accuracy: 99.77%\n",
            "Tau: 0.4060\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9956  \n",
            "Block 1: 0.0025  \n",
            "Block 2: 0.0009 *\n",
            "Block 3: 0.0011 *\n",
            "stage2\n",
            "Block 0: 0.9260  \n",
            "Block 1: 0.0595  \n",
            "Block 2: 0.0080 *\n",
            "Block 3: 0.0065 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1666, Validation Accuracy: 97.11%\n",
            "Balanced Accuracy: 0.9714\n",
            "Tau: 0.4060\n",
            "\n",
            "Epoch 67/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0059, Train Accuracy: 99.79%\n",
            "Tau: 0.3970\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9958  \n",
            "Block 1: 0.0023  \n",
            "Block 2: 0.0009 *\n",
            "Block 3: 0.0010 *\n",
            "stage2\n",
            "Block 0: 0.9279  \n",
            "Block 1: 0.0580  \n",
            "Block 2: 0.0077 *\n",
            "Block 3: 0.0064 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1772, Validation Accuracy: 97.18%\n",
            "Balanced Accuracy: 0.9726\n",
            "Tau: 0.3970\n",
            "\n",
            "Epoch 68/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0058, Train Accuracy: 99.81%\n",
            "Tau: 0.3880\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9959  \n",
            "Block 1: 0.0021  \n",
            "Block 2: 0.0009 *\n",
            "Block 3: 0.0010 *\n",
            "stage2\n",
            "Block 0: 0.9298  \n",
            "Block 1: 0.0567  \n",
            "Block 2: 0.0074 *\n",
            "Block 3: 0.0062 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1564, Validation Accuracy: 97.25%\n",
            "Balanced Accuracy: 0.9725\n",
            "Tau: 0.3880\n",
            "\n",
            "Epoch 69/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0064, Train Accuracy: 99.78%\n",
            "Tau: 0.3790\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9962  \n",
            "Block 1: 0.0020  \n",
            "Block 2: 0.0008 *\n",
            "Block 3: 0.0010 *\n",
            "stage2\n",
            "Block 0: 0.9341  \n",
            "Block 1: 0.0531  \n",
            "Block 2: 0.0068 *\n",
            "Block 3: 0.0060 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1576, Validation Accuracy: 97.21%\n",
            "Balanced Accuracy: 0.9725\n",
            "Tau: 0.3790\n",
            "\n",
            "Epoch 70/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0061, Train Accuracy: 99.81%\n",
            "Tau: 0.3700\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9964  \n",
            "Block 1: 0.0019  \n",
            "Block 2: 0.0008 *\n",
            "Block 3: 0.0009 *\n",
            "stage2\n",
            "Block 0: 0.9377  \n",
            "Block 1: 0.0500  \n",
            "Block 2: 0.0065 *\n",
            "Block 3: 0.0057 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1621, Validation Accuracy: 97.21%\n",
            "Balanced Accuracy: 0.9726\n",
            "Tau: 0.3700\n",
            "Model weights saved to HoViT_44_tinyfusion_base_r8a16_69.pth\n",
            "70 model test result:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1798, Test Accuracy: 97.07%\n",
            "Balanced Accuracy: 0.9718\n",
            "Tau: 0.0000\n",
            "\n",
            "Epoch 71/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0053, Train Accuracy: 99.82%\n",
            "Tau: 0.3610\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9965  \n",
            "Block 1: 0.0019  \n",
            "Block 2: 0.0007 *\n",
            "Block 3: 0.0009 *\n",
            "stage2\n",
            "Block 0: 0.9422  \n",
            "Block 1: 0.0465  \n",
            "Block 2: 0.0061 *\n",
            "Block 3: 0.0052 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1965, Validation Accuracy: 96.60%\n",
            "Balanced Accuracy: 0.9659\n",
            "Tau: 0.3610\n",
            "\n",
            "Epoch 72/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0058, Train Accuracy: 99.80%\n",
            "Tau: 0.3520\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9966  \n",
            "Block 1: 0.0018  \n",
            "Block 2: 0.0007 *\n",
            "Block 3: 0.0009 *\n",
            "stage2\n",
            "Block 0: 0.9470  \n",
            "Block 1: 0.0425  \n",
            "Block 2: 0.0056 *\n",
            "Block 3: 0.0048 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1456, Validation Accuracy: 97.31%\n",
            "Balanced Accuracy: 0.9737\n",
            "Tau: 0.3520\n",
            "\n",
            "Epoch 73/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0056, Train Accuracy: 99.80%\n",
            "Tau: 0.3430\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9968  \n",
            "Block 1: 0.0017  \n",
            "Block 2: 0.0007 *\n",
            "Block 3: 0.0008 *\n",
            "stage2\n",
            "Block 0: 0.9492  \n",
            "Block 1: 0.0408  \n",
            "Block 2: 0.0053 *\n",
            "Block 3: 0.0047 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1593, Validation Accuracy: 97.19%\n",
            "Balanced Accuracy: 0.9722\n",
            "Tau: 0.3430\n",
            "\n",
            "Epoch 74/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0057, Train Accuracy: 99.80%\n",
            "Tau: 0.3340\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9969  \n",
            "Block 1: 0.0016  \n",
            "Block 2: 0.0007 *\n",
            "Block 3: 0.0008 *\n",
            "stage2\n",
            "Block 0: 0.9518  \n",
            "Block 1: 0.0386  \n",
            "Block 2: 0.0051 *\n",
            "Block 3: 0.0045 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1641, Validation Accuracy: 97.34%\n",
            "Balanced Accuracy: 0.9738\n",
            "Tau: 0.3340\n",
            "\n",
            "Epoch 75/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0054, Train Accuracy: 99.81%\n",
            "Tau: 0.3250\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9970  \n",
            "Block 1: 0.0015  \n",
            "Block 2: 0.0007 *\n",
            "Block 3: 0.0008 *\n",
            "stage2\n",
            "Block 0: 0.9560  \n",
            "Block 1: 0.0349  \n",
            "Block 2: 0.0049 *\n",
            "Block 3: 0.0042 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1614, Validation Accuracy: 97.33%\n",
            "Balanced Accuracy: 0.9733\n",
            "Tau: 0.3250\n",
            "\n",
            "Epoch 76/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0055, Train Accuracy: 99.82%\n",
            "Tau: 0.3160\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9971  \n",
            "Block 1: 0.0015  \n",
            "Block 2: 0.0006 *\n",
            "Block 3: 0.0008 *\n",
            "stage2\n",
            "Block 0: 0.9593  \n",
            "Block 1: 0.0322  \n",
            "Block 2: 0.0045 *\n",
            "Block 3: 0.0040 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1631, Validation Accuracy: 97.43%\n",
            "Balanced Accuracy: 0.9742\n",
            "Tau: 0.3160\n",
            "\n",
            "Epoch 77/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0059, Train Accuracy: 99.79%\n",
            "Tau: 0.3070\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9973  \n",
            "Block 1: 0.0014  \n",
            "Block 2: 0.0006 *\n",
            "Block 3: 0.0007 *\n",
            "stage2\n",
            "Block 0: 0.9622  \n",
            "Block 1: 0.0298  \n",
            "Block 2: 0.0042 *\n",
            "Block 3: 0.0038 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1508, Validation Accuracy: 97.48%\n",
            "Balanced Accuracy: 0.9752\n",
            "Tau: 0.3070\n",
            "\n",
            "Epoch 78/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0045, Train Accuracy: 99.86%\n",
            "Tau: 0.2980\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9973  \n",
            "Block 1: 0.0014  \n",
            "Block 2: 0.0006 *\n",
            "Block 3: 0.0007 *\n",
            "stage2\n",
            "Block 0: 0.9633  \n",
            "Block 1: 0.0289  \n",
            "Block 2: 0.0041 *\n",
            "Block 3: 0.0037 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1567, Validation Accuracy: 97.31%\n",
            "Balanced Accuracy: 0.9729\n",
            "Tau: 0.2980\n",
            "\n",
            "Epoch 79/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0057, Train Accuracy: 99.81%\n",
            "Tau: 0.2890\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9974  \n",
            "Block 1: 0.0013  \n",
            "Block 2: 0.0006 *\n",
            "Block 3: 0.0007 *\n",
            "stage2\n",
            "Block 0: 0.9646  \n",
            "Block 1: 0.0278  \n",
            "Block 2: 0.0039 *\n",
            "Block 3: 0.0036 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1633, Validation Accuracy: 97.20%\n",
            "Balanced Accuracy: 0.9726\n",
            "Tau: 0.2890\n",
            "\n",
            "Epoch 80/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0055, Train Accuracy: 99.82%\n",
            "Tau: 0.2800\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9974  \n",
            "Block 1: 0.0013  \n",
            "Block 2: 0.0006 *\n",
            "Block 3: 0.0007 *\n",
            "stage2\n",
            "Block 0: 0.9666  \n",
            "Block 1: 0.0262  \n",
            "Block 2: 0.0038 *\n",
            "Block 3: 0.0034 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1695, Validation Accuracy: 97.25%\n",
            "Balanced Accuracy: 0.9725\n",
            "Tau: 0.2800\n",
            "Model weights saved to HoViT_44_tinyfusion_base_r8a16_79.pth\n",
            "80 model test result:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1879, Test Accuracy: 97.15%\n",
            "Balanced Accuracy: 0.9718\n",
            "Tau: 0.0000\n",
            "\n",
            "Epoch 81/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0051, Train Accuracy: 99.82%\n",
            "Tau: 0.2710\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9975  \n",
            "Block 1: 0.0013  \n",
            "Block 2: 0.0006 *\n",
            "Block 3: 0.0007 *\n",
            "stage2\n",
            "Block 0: 0.9680  \n",
            "Block 1: 0.0250  \n",
            "Block 2: 0.0037 *\n",
            "Block 3: 0.0033 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1733, Validation Accuracy: 97.16%\n",
            "Balanced Accuracy: 0.9719\n",
            "Tau: 0.2710\n",
            "\n",
            "Epoch 82/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0052, Train Accuracy: 99.82%\n",
            "Tau: 0.2620\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9976  \n",
            "Block 1: 0.0012  \n",
            "Block 2: 0.0005 *\n",
            "Block 3: 0.0006 *\n",
            "stage2\n",
            "Block 0: 0.9699  \n",
            "Block 1: 0.0232  \n",
            "Block 2: 0.0037 *\n",
            "Block 3: 0.0032 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1832, Validation Accuracy: 97.24%\n",
            "Balanced Accuracy: 0.9728\n",
            "Tau: 0.2620\n",
            "\n",
            "Epoch 83/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0052, Train Accuracy: 99.81%\n",
            "Tau: 0.2530\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9976  \n",
            "Block 1: 0.0012  \n",
            "Block 2: 0.0005 *\n",
            "Block 3: 0.0006 *\n",
            "stage2\n",
            "Block 0: 0.9694  \n",
            "Block 1: 0.0237  \n",
            "Block 2: 0.0037 *\n",
            "Block 3: 0.0032 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1545, Validation Accuracy: 97.43%\n",
            "Balanced Accuracy: 0.9746\n",
            "Tau: 0.2530\n",
            "\n",
            "Epoch 84/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0054, Train Accuracy: 99.82%\n",
            "Tau: 0.2440\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9977  \n",
            "Block 1: 0.0012  \n",
            "Block 2: 0.0005 *\n",
            "Block 3: 0.0006 *\n",
            "stage2\n",
            "Block 0: 0.9711  \n",
            "Block 1: 0.0222  \n",
            "Block 2: 0.0036 *\n",
            "Block 3: 0.0032 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1575, Validation Accuracy: 97.45%\n",
            "Balanced Accuracy: 0.9750\n",
            "Tau: 0.2440\n",
            "\n",
            "Epoch 85/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0047, Train Accuracy: 99.83%\n",
            "Tau: 0.2350\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9978  \n",
            "Block 1: 0.0012  \n",
            "Block 2: 0.0005 *\n",
            "Block 3: 0.0006 *\n",
            "stage2\n",
            "Block 0: 0.9718  \n",
            "Block 1: 0.0218  \n",
            "Block 2: 0.0035 *\n",
            "Block 3: 0.0030 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1631, Validation Accuracy: 97.36%\n",
            "Balanced Accuracy: 0.9733\n",
            "Tau: 0.2350\n",
            "\n",
            "Epoch 86/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0046, Train Accuracy: 99.84%\n",
            "Tau: 0.2260\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9978  \n",
            "Block 1: 0.0011  \n",
            "Block 2: 0.0005 *\n",
            "Block 3: 0.0006 *\n",
            "stage2\n",
            "Block 0: 0.9749  \n",
            "Block 1: 0.0191  \n",
            "Block 2: 0.0032 *\n",
            "Block 3: 0.0028 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1638, Validation Accuracy: 97.47%\n",
            "Balanced Accuracy: 0.9750\n",
            "Tau: 0.2260\n",
            "\n",
            "Epoch 87/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0048, Train Accuracy: 99.82%\n",
            "Tau: 0.2170\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9978  \n",
            "Block 1: 0.0011  \n",
            "Block 2: 0.0005 *\n",
            "Block 3: 0.0005 *\n",
            "stage2\n",
            "Block 0: 0.9762  \n",
            "Block 1: 0.0181  \n",
            "Block 2: 0.0031 *\n",
            "Block 3: 0.0027 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1595, Validation Accuracy: 97.55%\n",
            "Balanced Accuracy: 0.9752\n",
            "Tau: 0.2170\n",
            "\n",
            "Epoch 88/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0047, Train Accuracy: 99.84%\n",
            "Tau: 0.2080\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9980  \n",
            "Block 1: 0.0011  \n",
            "Block 2: 0.0005 *\n",
            "Block 3: 0.0005 *\n",
            "stage2\n",
            "Block 0: 0.9769  \n",
            "Block 1: 0.0174  \n",
            "Block 2: 0.0030 *\n",
            "Block 3: 0.0026 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1639, Validation Accuracy: 97.43%\n",
            "Balanced Accuracy: 0.9742\n",
            "Tau: 0.2080\n",
            "\n",
            "Epoch 89/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0056, Train Accuracy: 99.81%\n",
            "Tau: 0.1990\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9980  \n",
            "Block 1: 0.0010  \n",
            "Block 2: 0.0004 *\n",
            "Block 3: 0.0005 *\n",
            "stage2\n",
            "Block 0: 0.9788  \n",
            "Block 1: 0.0159  \n",
            "Block 2: 0.0028 *\n",
            "Block 3: 0.0025 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1765, Validation Accuracy: 97.33%\n",
            "Balanced Accuracy: 0.9734\n",
            "Tau: 0.1990\n",
            "\n",
            "Epoch 90/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0041, Train Accuracy: 99.86%\n",
            "Tau: 0.1900\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9981  \n",
            "Block 1: 0.0010  \n",
            "Block 2: 0.0004 *\n",
            "Block 3: 0.0005 *\n",
            "stage2\n",
            "Block 0: 0.9804  \n",
            "Block 1: 0.0147  \n",
            "Block 2: 0.0027 *\n",
            "Block 3: 0.0023 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1575, Validation Accuracy: 97.31%\n",
            "Balanced Accuracy: 0.9731\n",
            "Tau: 0.1900\n",
            "Model weights saved to HoViT_44_tinyfusion_base_r8a16_89.pth\n",
            "90 model test result:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1819, Test Accuracy: 97.20%\n",
            "Balanced Accuracy: 0.9724\n",
            "Tau: 0.0000\n",
            "\n",
            "Epoch 91/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0045, Train Accuracy: 99.86%\n",
            "Tau: 0.1810\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9982  \n",
            "Block 1: 0.0010  \n",
            "Block 2: 0.0004 *\n",
            "Block 3: 0.0005 *\n",
            "stage2\n",
            "Block 0: 0.9808  \n",
            "Block 1: 0.0143  \n",
            "Block 2: 0.0026 *\n",
            "Block 3: 0.0023 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1599, Validation Accuracy: 97.35%\n",
            "Balanced Accuracy: 0.9744\n",
            "Tau: 0.1810\n",
            "\n",
            "Epoch 92/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  18%|█▊        | 396/2188 [00:31<02:22, 12.59it/s]"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, phase=\"Validation\", epoch=epoch)\n",
        "    if((epoch+1) % 10 == 0 and epoch > 30):\n",
        "        save_path = f\"HoViT_44_tinyfusion_base_r8a16_{epoch}.pth\"\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Model weights saved to {save_path}\")\n",
        "        print(f\"{epoch+1} model test result:\")\n",
        "        evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq3Yxnau6V3e"
      },
      "outputs": [],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlazeL-a0WTt"
      },
      "outputs": [],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c77rmtOz0XuA"
      },
      "outputs": [],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbSpMMWGk3bf"
      },
      "outputs": [],
      "source": [
        "!wget -O CRC-VAL-HE-7K.zip https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
        "!unzip -qq CRC-VAL-HE-7K.zip -d val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc2tPigjv6Is"
      },
      "outputs": [],
      "source": [
        "#torch.save(model.state_dict(), \"HoViT22_withAug_7Ktest.pth\")\n",
        "model.load_state_dict(torch.load(\"HoViT22_withAug_7Ktest.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rldaXFNXpT4r"
      },
      "outputs": [],
      "source": [
        "test_7k_dir = './val/CRC-VAL-HE-7K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Belqw8QytnZL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "test7k_dataset = Dataset(dir=test_7k_dir, aug=False)\n",
        "#test7k_dataloader = DataLoader(test7k_dataset, batch_size=32, shuffle=False, num_workers=8, pin_memory=False, drop_last=False)\n",
        "test7k_dataloader = DataLoader(test7k_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2y3cywDpjUQ",
        "outputId": "c6e63114-98c9-4bd3-ef46-995a6d1b8d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 225/225 [00:05<00:00, 43.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.2637, Test Accuracy: 92.76%\n",
            "Overall - F1: 0.9091, Recall: 0.9161, Precision: 0.9059\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9411, Recall: 0.8901, Precision: 0.9983\n",
            "Class 1 - F1: 0.9994, Recall: 1.0000, Precision: 0.9988\n",
            "Class 2 - F1: 0.9047, Recall: 0.9941, Precision: 0.8300\n",
            "Class 3 - F1: 0.9890, Recall: 0.9921, Precision: 0.9859\n",
            "Class 4 - F1: 0.9295, Recall: 0.9807, Precision: 0.8834\n",
            "Class 5 - F1: 0.8246, Recall: 0.8497, Precision: 0.8010\n",
            "Class 6 - F1: 0.9578, Recall: 0.9501, Precision: 0.9657\n",
            "Class 7 - F1: 0.6886, Recall: 0.6461, Precision: 0.7371\n",
            "Class 8 - F1: 0.9474, Recall: 0.9424, Precision: 0.9525\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test7k_dataloader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "p4pYjMPUpy2m",
        "outputId": "3d0affe1-8425-4d2b-9cca-c6ed225e5e30"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EnagUDtpzDU",
        "outputId": "5c4c49be-c46f-49c0-9734-c56fb1a5856b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 225\n",
            "Average Time: 7.82 ms\n",
            "Standard Deviation: 1.17 ms\n",
            "Maximum Time: 13.25 ms\n",
            "Minimum Time: 6.58 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test7k_dataloader, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}