{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "d1064d54-5546-482c-8bca-7a38183d0500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=bae2f6d34315ddad4a1833bfb5c0b38b180094f29bd796f812407d7beb916e25\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "db30a0cd-b082-424d-bfc2-671b8fe3baa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-26 09:46:51--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.45.92, 188.185.43.25, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-02-26 09:46:51--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  16.3MB/s    in 19m 17s \n",
            "\n",
            "2025-02-26 10:06:08 (9.64 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "631903eb-0407-4c83-c7b5-f9f8d6c621d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "3213bddf-fd97-486c-ecf9-c60e73459491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "1091bf06-40b2-4fae-951e-67124be53211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "79930977-4c0c-490c-aee0-55a78d9e66d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "g18xh7W1tv8W"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from glob import glob\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, dir, aug=False):\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.aug = aug\n",
        "        self.samples = [i for i in glob(os.path.join(dir, '**/*')) if os.path.isfile(i)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        class_name = os.path.basename(self.samples[idx]).split('-')[0]\n",
        "        label = {\n",
        "            'ADI': 0,\n",
        "            'BACK': 1,\n",
        "            'DEB': 2,\n",
        "            'LYM': 3,\n",
        "            'MUC': 4,\n",
        "            'MUS': 5,\n",
        "            'NORM': 6,\n",
        "            'STR': 7,\n",
        "            'TUM': 8,\n",
        "        }\n",
        "\n",
        "        img = cv2.imread(self.samples[idx], -1)[:, :, ::-1]\n",
        "        img = np.float32(img) / 255.0\n",
        "\n",
        "        if self.aug:\n",
        "            if random.random() < 0.5:\n",
        "                img = img[::-1]\n",
        "\n",
        "            if random.random() < 0.5:\n",
        "                img = img[:, ::-1]\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                if random.random() < 0.5:\n",
        "                    img += np.random.normal(\n",
        "                        0.0, np.random.uniform(0.01, 0.2),\n",
        "                        (img.shape[0], img.shape[1], img.shape[2])\n",
        "                    )\n",
        "                else:\n",
        "                    x = np.random.uniform(0.02, 0.15)\n",
        "                    img += np.random.uniform(\n",
        "                        -x, x,\n",
        "                        (img.shape[0], img.shape[1], img.shape[2])\n",
        "                    )\n",
        "\n",
        "            if random.random() < 0.9:\n",
        "                img += np.random.uniform(-0.15, 0.15, (1, 1, 3))\n",
        "                img *= np.random.uniform(0.85, 1.15, (1, 1, 3))\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                kX, kY = np.random.randint(0, 4, 2) * 2 + 1\n",
        "                if random.random() < 0.5:\n",
        "                    img = cv2.GaussianBlur(img, (kX, kY), 0)\n",
        "                else:\n",
        "                    img = cv2.blur(img, (kX, kY))\n",
        "\n",
        "        img = np.uint8(np.clip(img, 0, 1) * 255.0)\n",
        "        img = self.transform(Image.fromarray(img))\n",
        "\n",
        "        return img, label[class_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset(dir=train_dir, aug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "train_data = Subset(dataset, load_train_idx)\n",
        "val_data = Subset(dataset, load_val_idx)\n",
        "test_data = Subset(dataset, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "bb1e48ad-14ae-46e4-9557-3f104107f349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    val_losses.append(epoch_loss)\n",
        "    val_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "f9cc314b-40de-489c-cf8e-aafa4a420760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:33<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.1289, Train Accuracy: 58.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6558, Validation Accuracy: 75.67%\n",
            "Balanced Accuracy: 0.7467\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:34<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5798, Train Accuracy: 79.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:25<00:00,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4737, Validation Accuracy: 82.75%\n",
            "Balanced Accuracy: 0.8172\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:34<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4113, Train Accuracy: 85.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3181, Validation Accuracy: 89.07%\n",
            "Balanced Accuracy: 0.8858\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:33<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3294, Train Accuracy: 88.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2695, Validation Accuracy: 90.91%\n",
            "Balanced Accuracy: 0.9067\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:35<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2687, Train Accuracy: 90.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2524, Validation Accuracy: 91.39%\n",
            "Balanced Accuracy: 0.9105\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:33<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2295, Train Accuracy: 92.07%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1843, Validation Accuracy: 93.89%\n",
            "Balanced Accuracy: 0.9353\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:34<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1954, Train Accuracy: 93.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1740, Validation Accuracy: 94.21%\n",
            "Balanced Accuracy: 0.9405\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:33<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1736, Train Accuracy: 94.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:25<00:00,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1478, Validation Accuracy: 95.18%\n",
            "Balanced Accuracy: 0.9505\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:32<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1558, Train Accuracy: 94.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:25<00:00,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1416, Validation Accuracy: 95.49%\n",
            "Balanced Accuracy: 0.9543\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:32<00:00,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1385, Train Accuracy: 95.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1359, Validation Accuracy: 95.61%\n",
            "Balanced Accuracy: 0.9539\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:33<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1302, Train Accuracy: 95.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1145, Validation Accuracy: 96.31%\n",
            "Balanced Accuracy: 0.9630\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:33<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1174, Train Accuracy: 96.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1153, Validation Accuracy: 96.28%\n",
            "Balanced Accuracy: 0.9613\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:35<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1092, Train Accuracy: 96.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:25<00:00,  5.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1034, Validation Accuracy: 96.62%\n",
            "Balanced Accuracy: 0.9656\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:32<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1006, Train Accuracy: 96.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1185, Validation Accuracy: 96.15%\n",
            "Balanced Accuracy: 0.9602\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:34<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0957, Train Accuracy: 96.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1059, Validation Accuracy: 96.71%\n",
            "Balanced Accuracy: 0.9674\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:34<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0886, Train Accuracy: 96.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1007, Validation Accuracy: 96.62%\n",
            "Balanced Accuracy: 0.9656\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:33<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0823, Train Accuracy: 97.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:25<00:00,  5.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0954, Validation Accuracy: 96.98%\n",
            "Balanced Accuracy: 0.9699\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:32<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0786, Train Accuracy: 97.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1107, Validation Accuracy: 96.73%\n",
            "Balanced Accuracy: 0.9661\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:33<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0754, Train Accuracy: 97.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0909, Validation Accuracy: 97.07%\n",
            "Balanced Accuracy: 0.9690\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:31<00:00,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0720, Train Accuracy: 97.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:25<00:00,  5.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0909, Validation Accuracy: 97.13%\n",
            "Balanced Accuracy: 0.9708\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:32<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0647, Train Accuracy: 97.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:25<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0889, Validation Accuracy: 97.23%\n",
            "Balanced Accuracy: 0.9720\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:33<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0651, Train Accuracy: 97.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0910, Validation Accuracy: 97.23%\n",
            "Balanced Accuracy: 0.9717\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:34<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0591, Train Accuracy: 97.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0909, Validation Accuracy: 97.17%\n",
            "Balanced Accuracy: 0.9713\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:33<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0580, Train Accuracy: 98.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0865, Validation Accuracy: 97.36%\n",
            "Balanced Accuracy: 0.9727\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:32<00:00,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0533, Train Accuracy: 98.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0895, Validation Accuracy: 97.39%\n",
            "Balanced Accuracy: 0.9740\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:34<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0528, Train Accuracy: 98.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1003, Validation Accuracy: 97.12%\n",
            "Balanced Accuracy: 0.9701\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:37<00:00,  4.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0489, Train Accuracy: 98.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:25<00:00,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0916, Validation Accuracy: 97.27%\n",
            "Balanced Accuracy: 0.9717\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:34<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0490, Train Accuracy: 98.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:24<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0904, Validation Accuracy: 97.27%\n",
            "Balanced Accuracy: 0.9728\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:33<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0443, Train Accuracy: 98.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:25<00:00,  5.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0870, Validation Accuracy: 97.25%\n",
            "Balanced Accuracy: 0.9716\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:34<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0449, Train Accuracy: 98.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [01:25<00:00,  5.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0841, Validation Accuracy: 97.45%\n",
            "Balanced Accuracy: 0.9748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "f1f3d3a0-1c14-4e07-f160-846a74386eaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [01:25<00:00,  5.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0909, Test Accuracy: 97.27%\n",
            "Balanced Accuracy: 0.9731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "0c7c9fe3-4ac5-4b27-9ffe-5cd8026eb442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 10.38 ms\n",
            "Standard Deviation: 0.34 ms\n",
            "Maximum Time: 12.27 ms\n",
            "Minimum Time: 9.85 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "b3816423-059b-4b27-aba7-b28ac8f1b3a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         2.46%     534.505us        22.79%       4.956ms     103.240us       0.000us         0.00%       5.070ms     105.620us            48  \n",
            "                                           aten::linear         0.97%     211.588us        14.97%       3.256ms      95.758us       0.000us         0.00%       3.628ms     106.714us            34  \n",
            "                                               aten::mm         5.52%       1.201ms        11.31%       2.460ms      76.886us       3.604ms        43.99%       3.604ms     112.623us            32  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.355ms        16.54%       1.355ms     169.368us             8  \n",
            "                                              aten::bmm         2.41%     524.847us         3.05%     662.640us      41.415us       1.136ms        13.86%       1.136ms      70.980us            16  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     987.713us        12.06%     987.713us     123.464us             8  \n",
            "                                       aten::batch_norm         1.09%     236.362us        35.29%       7.673ms     196.755us       0.000us         0.00%     868.481us      22.269us            39  \n",
            "                           aten::_batch_norm_impl_index         1.93%     418.663us        34.20%       7.437ms     190.694us       0.000us         0.00%     868.481us      22.269us            39  \n",
            "                                            aten::copy_         3.90%     847.932us         8.97%       1.950ms      23.782us     826.308us        10.09%     826.308us      10.077us            82  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     772.864us         9.43%     772.864us      96.608us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 21.746ms\n",
            "Self CUDA time total: 8.193ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "xc2tPigjv6Is"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"HoViT44_withAug_7Ktest.pth\")\n",
        "#model.load_state_dict(torch.load(\"HoViT44_withAug_7Ktest.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbSpMMWGk3bf",
        "outputId": "f12b8995-074d-4f6e-d3d8-0d84a0c79127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-26 14:47:50--  https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.45.92, 188.185.48.194, 188.185.43.25, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.45.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 800276929 (763M) [application/octet-stream]\n",
            "Saving to: ‘CRC-VAL-HE-7K.zip’\n",
            "\n",
            "CRC-VAL-HE-7K.zip   100%[===================>] 763.20M  1.18MB/s    in 9m 39s  \n",
            "\n",
            "2025-02-26 14:57:29 (1.32 MB/s) - ‘CRC-VAL-HE-7K.zip’ saved [800276929/800276929]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O CRC-VAL-HE-7K.zip https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
        "!unzip -qq CRC-VAL-HE-7K.zip -d val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "rldaXFNXpT4r"
      },
      "outputs": [],
      "source": [
        "test_7k_dir = './val/CRC-VAL-HE-7K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Belqw8QytnZL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "test7k_dataset = Dataset(dir=test_7k_dir, aug=False)\n",
        "test7k_dataloader = DataLoader(test7k_dataset, batch_size=32, shuffle=False, num_workers=8, pin_memory=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2y3cywDpjUQ",
        "outputId": "c09cc50e-68a5-4329-cea3-7fa727848e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 225/225 [00:05<00:00, 37.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1893, Test Accuracy: 94.28%\n",
            "Overall - F1: 0.9184, Recall: 0.9236, Precision: 0.9142\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9849, Recall: 0.9738, Precision: 0.9962\n",
            "Class 1 - F1: 0.9982, Recall: 1.0000, Precision: 0.9965\n",
            "Class 2 - F1: 0.8750, Recall: 0.9292, Precision: 0.8268\n",
            "Class 3 - F1: 0.9543, Recall: 0.9543, Precision: 0.9543\n",
            "Class 4 - F1: 0.9756, Recall: 0.9855, Precision: 0.9659\n",
            "Class 5 - F1: 0.8239, Recall: 0.8142, Precision: 0.8339\n",
            "Class 6 - F1: 0.9684, Recall: 0.9703, Precision: 0.9664\n",
            "Class 7 - F1: 0.7216, Recall: 0.7387, Precision: 0.7052\n",
            "Class 8 - F1: 0.9641, Recall: 0.9465, Precision: 0.9823\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test7k_dataloader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "p4pYjMPUpy2m",
        "outputId": "623c0fc9-bfcf-416e-da7f-1ed7eb80420c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "5EnagUDtpzDU",
        "outputId": "f25af857-3f15-47aa-a31f-b02dcdf552fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 225\n",
            "Average Time: 12.86 ms\n",
            "Standard Deviation: 1.23 ms\n",
            "Maximum Time: 21.76 ms\n",
            "Minimum Time: 11.56 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test7k_dataloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MOLSL09JxKdp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}