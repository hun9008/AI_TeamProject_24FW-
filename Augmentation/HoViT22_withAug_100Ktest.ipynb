{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "4597dfa4-fd81-4ad6-ea60-55401313dec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=e9f6300f2519237ce218d5931b0d9c19bbce92788bbf83c6433a7efbb904805a\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "88ef1363-ac98-4aa1-d050-2bd8867d5a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-26 18:45:16--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.45.92, 188.185.43.25, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.45.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-02-26 18:45:17--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  24.1MB/s    in 8m 12s  \n",
            "\n",
            "2025-02-26 18:53:29 (22.6 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=2, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=2, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "10cede32-eab1-4d5c-9aaf-aed432464960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "3bf2a73c-d50d-420d-dd4a-52e35356fb65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 4,909,234\n",
            "Trainable params: 4,909,234\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.82\n",
            "Params size (MB): 19.64\n",
            "Estimated Total Size (MB): 936.72\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "b946353f-684c-4091-e9a4-b4d07caca8bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.82\n",
            "Params size (MB): 19.64\n",
            "Estimated Total Size (MB): 936.72\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.82\n",
            "Params size (MB): 19.64\n",
            "Estimated Total Size (MB): 936.72\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "e801bfd6-7f07-4138-b857-1d62d884531d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "g18xh7W1tv8W"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from glob import glob\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, dir, aug=False):\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.aug = aug\n",
        "        self.samples = [i for i in glob(os.path.join(dir, '**/*')) if os.path.isfile(i)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        class_name = os.path.basename(self.samples[idx]).split('-')[0]\n",
        "        label = {\n",
        "            'ADI': 0,\n",
        "            'BACK': 1,\n",
        "            'DEB': 2,\n",
        "            'LYM': 3,\n",
        "            'MUC': 4,\n",
        "            'MUS': 5,\n",
        "            'NORM': 6,\n",
        "            'STR': 7,\n",
        "            'TUM': 8,\n",
        "        }\n",
        "\n",
        "        img = cv2.imread(self.samples[idx], -1)[:, :, ::-1]\n",
        "        img = np.float32(img) / 255.0\n",
        "\n",
        "        if self.aug:\n",
        "            if random.random() < 0.5:\n",
        "                img = img[::-1]\n",
        "\n",
        "            if random.random() < 0.5:\n",
        "                img = img[:, ::-1]\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                if random.random() < 0.5:\n",
        "                    img += np.random.normal(\n",
        "                        0.0, np.random.uniform(0.01, 0.2),\n",
        "\n",
        "                        (img.shape[0], img.shape[1], img.shape[2])\n",
        "                    )\n",
        "                else:\n",
        "                    x = np.random.uniform(0.02, 0.15)\n",
        "                    img += np.random.uniform(\n",
        "                        -x, x,\n",
        "                        (img.shape[0], img.shape[1], img.shape[2])\n",
        "                    )\n",
        "\n",
        "            if random.random() < 0.9:\n",
        "                img += np.random.uniform(-0.15, 0.15, (1, 1, 3))\n",
        "                img *= np.random.uniform(0.85, 1.15, (1, 1, 3))\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                kX, kY = np.random.randint(0, 4, 2) * 2 + 1\n",
        "                if random.random() < 0.5:\n",
        "                    img = cv2.GaussianBlur(img, (kX, kY), 0)\n",
        "                else:\n",
        "                    img = cv2.blur(img, (kX, kY))\n",
        "\n",
        "        img = np.uint8(np.clip(img, 0, 1) * 255.0)\n",
        "        img = self.transform(Image.fromarray(img))\n",
        "\n",
        "        return img, label[class_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset(dir=train_dir, aug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "#train_data = Subset(dataset, load_train_idx)\n",
        "#val_data = Subset(dataset, load_val_idx)\n",
        "test_data = Subset(dataset, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "c37046f3-9511-4eb3-e921-c02dc7ca9154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "#train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "#val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "#print(f\"Train set size: {len(train_data)}\")\n",
        "#print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    val_losses.append(epoch_loss)\n",
        "    val_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('HoViT22_withAug_7Ktest.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI01eursppvQ",
        "outputId": "f730d932-94dd-4309-920d-f82b6c8d89bb"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-86-55c7f1826b29>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('HoViT22_withAug_7Ktest.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "0059caf5-97d6-44a4-cbe6-4c02937db25b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:30<00:00, 15.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0480, Test Accuracy: 98.65%\n",
            "Balanced Accuracy: 0.9870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "dbef21e2-c274-4530-bf96-1bf10047cfc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 7.36 ms\n",
            "Standard Deviation: 0.32 ms\n",
            "Maximum Time: 10.36 ms\n",
            "Minimum Time: 6.88 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "693e1a87-168e-483e-9a0f-6e7d75582e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         2.21%     186.439us        23.10%       1.951ms      81.308us       0.000us         0.00%       2.530ms     105.433us            24  \n",
            "                                           aten::linear         0.98%      82.485us        15.37%       1.298ms      72.116us       0.000us         0.00%       1.824ms     101.333us            18  \n",
            "                                               aten::mm         6.53%     551.677us         9.91%     837.388us      52.337us       1.800ms        38.78%       1.800ms     112.502us            16  \n",
            "                                           aten::conv2d         0.46%      38.776us        17.81%       1.505ms     250.757us       0.000us         0.00%     720.863us     120.144us             6  \n",
            "                                      aten::convolution         0.75%      63.753us        17.35%       1.466ms     244.294us       0.000us         0.00%     720.863us     120.144us             6  \n",
            "                                     aten::_convolution         1.27%     107.519us        16.60%       1.402ms     233.669us       0.000us         0.00%     720.863us     120.144us             6  \n",
            "                                aten::cudnn_convolution        12.15%       1.026ms        14.70%       1.242ms     206.969us     706.079us        15.21%     706.079us     117.680us             6  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     677.214us        14.59%     677.214us     169.304us             4  \n",
            "                                              aten::bmm         2.90%     244.709us         3.68%     310.479us      38.810us     566.815us        12.21%     566.815us      70.852us             8  \n",
            "                                       aten::batch_norm         1.54%     130.416us        28.80%       2.432ms     105.747us       0.000us         0.00%     545.695us      23.726us            23  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 8.446ms\n",
            "Self CUDA time total: 4.641ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2y3cywDpjUQ",
        "outputId": "795861af-0959-488c-d55b-0734a478e107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:30<00:00, 15.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0480, Test Accuracy: 98.65%\n",
            "Overall - F1: 0.9864, Recall: 0.9870, Precision: 0.9859\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9881, Recall: 0.9777, Precision: 0.9987\n",
            "Class 1 - F1: 0.9953, Recall: 0.9975, Precision: 0.9931\n",
            "Class 2 - F1: 0.9907, Recall: 0.9930, Precision: 0.9884\n",
            "Class 3 - F1: 0.9986, Recall: 0.9994, Precision: 0.9977\n",
            "Class 4 - F1: 0.9832, Recall: 0.9917, Precision: 0.9748\n",
            "Class 5 - F1: 0.9818, Recall: 0.9811, Precision: 0.9825\n",
            "Class 6 - F1: 0.9853, Recall: 0.9884, Precision: 0.9823\n",
            "Class 7 - F1: 0.9705, Recall: 0.9793, Precision: 0.9619\n",
            "Class 8 - F1: 0.9843, Recall: 0.9750, Precision: 0.9939\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "p4pYjMPUpy2m",
        "outputId": "448f4e72-f3fe-47e5-9682-6a5845e2b615"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hHScyX3ReqPp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}