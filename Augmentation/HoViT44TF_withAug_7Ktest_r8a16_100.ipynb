{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "b7b4ab85-2219-406f-b3be-e7ae593e1bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=7cb34d4e88a779e3fa6565d9af1ae2f1d31b5b9dc67d36998b8bceceaa7e71d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "6ee6e229-1df6-4f91-f91e-f79184dab3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-26 18:47:00--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.45.92, 188.185.43.25, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.45.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-02-26 18:47:01--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  24.8MB/s    in 7m 44s  \n",
            "\n",
            "2025-02-26 18:54:44 (24.0 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_9sIsiJ2ldL",
        "outputId": "ed6dfabb-cfae-46b1-efbb-0725bf4783a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.5.1+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.48.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.3.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchao\n",
        "!pip install torchtune"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZPMfB8vT2qjy",
        "outputId": "f552659a-54df-41fe-d3d9-0e655277d47e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchao\n",
            "  Downloading torchao-0.8.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (14 kB)\n",
            "Downloading torchao-0.8.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (4.7 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/4.7 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/4.7 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchao\n",
            "Successfully installed torchao-0.8.0\n",
            "Collecting torchtune\n",
            "  Downloading torchtune-0.5.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting datasets (from torchtune)\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: huggingface_hub[hf_transfer] in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.28.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.5.2)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.3.9)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.2.0)\n",
            "Collecting tiktoken (from torchtune)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting blobfile>=2 (from torchtune)\n",
            "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtune) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtune) (4.67.1)\n",
            "Collecting omegaconf (from torchtune)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from torchtune) (5.9.5)\n",
            "Requirement already satisfied: Pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from torchtune) (11.1.0)\n",
            "Collecting pycryptodomex>=3.8 (from blobfile>=2->torchtune)\n",
            "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (2.3.0)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (5.3.1)\n",
            "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->torchtune)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (2.32.3)\n",
            "Collecting xxhash (from datasets->torchtune)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->torchtune)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->torchtune) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (3.11.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]->torchtune) (4.12.2)\n",
            "Collecting hf-transfer>=0.1.4 (from huggingface_hub[hf_transfer]->torchtune)\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->torchtune)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->torchtune) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->torchtune) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->torchtune) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->torchtune) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->torchtune) (1.17.0)\n",
            "Downloading torchtune-0.5.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.3/810.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=e121ee0e4473a7cb452d6bfdda8dff8252cd27160b8956c23928a05839d061d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, xxhash, pycryptodomex, omegaconf, hf-transfer, dill, tiktoken, multiprocess, blobfile, datasets, torchtune\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 blobfile-3.0.0 datasets-3.3.2 dill-0.3.8 hf-transfer-0.1.9 multiprocess-0.70.16 omegaconf-2.3.0 pycryptodomex-3.21.0 tiktoken-0.9.0 torchtune-0.5.0 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "663d5a9543a645d6b5e78e89771c3ef6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtune.modules.peft import LoRALinear"
      ],
      "metadata": {
        "id": "7VFmN8Yv2vjz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_lora_model(model, rank=8, alpha=16, exclude=[]):\n",
        "    for name, module in model.named_children():\n",
        "        if name in exclude:\n",
        "            continue\n",
        "        if isinstance(module, nn.Linear):\n",
        "            lora_linear = LoRALinear(\n",
        "                in_dim=module.in_features,\n",
        "                out_dim=module.out_features,\n",
        "                rank=rank,\n",
        "                alpha=alpha,\n",
        "                use_bias=module.bias is not None\n",
        "            )\n",
        "            lora_linear.weight.data = module.weight.data #모델이 처음부터 다시 학습할 필요 없게 하기 위해\n",
        "            if module.bias is not None:\n",
        "                lora_linear.bias.data = module.bias.data\n",
        "            lora_linear.to(module.weight.device)\n",
        "            # 기존 linear layer를 loRA linear로 교체체\n",
        "            setattr(model, name, lora_linear)\n",
        "        # 재귀함수 (하위모듈도 확인)\n",
        "        else:\n",
        "            convert_to_lora_model(module, rank, alpha, exclude)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "xM9fPVgw2xbJ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class LevitStage_TinyFusion(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, num_select, downsample=True):\n",
        "        super(LevitStage_TinyFusion, self).__init__()\n",
        "        assert num_select <= num_blocks\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "        self.num_blocks = num_blocks\n",
        "        self.num_select = num_select\n",
        "        init_probs = torch.ones(num_blocks) / num_blocks\n",
        "        self.gumbel_gate = nn.Parameter(torch.log(init_probs))\n",
        "\n",
        "\n",
        "    def forward(self, x, tau=1):\n",
        "        x = self.downsample(x)\n",
        "\n",
        "        if self.training:\n",
        "            gate_probs = F.gumbel_softmax(self.gumbel_gate, tau=tau, hard=False)\n",
        "        else:\n",
        "            gate_probs = F.gumbel_softmax(self.gumbel_gate, tau=tau, hard=True)\n",
        "\n",
        "        for i in range(self.num_blocks):\n",
        "            if gate_probs[i] > 0: # skip zero blocks\n",
        "              x = x + gate_probs[i] * self.blocks[i](x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "dMufn6p-3F_X"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LevitDistilledTinyfusion(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilledTinyfusion, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage_TinyFusion(dim=256, out_dim=256, num_heads=4, num_blocks=4, num_select=2, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage_TinyFusion(dim=256, out_dim=384, num_heads=6, num_blocks=4, num_select=2, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x, tau):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x, tau)\n",
        "        x = self.stage2(x, tau)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "kIR4o8va3Im9"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LevitDistilledTinyfusion(num_classes=9)"
      ],
      "metadata": {
        "id": "B68yiGFF3S88"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "f1928a40-d5f6-4d0f-9f96-624725da825e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilledTinyfusion(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage_TinyFusion(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage_TinyFusion(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 100\n",
        "weight_decay = 1e-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "def51d24-3b38-4ea6-87b3-0a2599612598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilledTinyfusion                                [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage_TinyFusion: 1-2                            [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  --                        1,584,400\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "├─LevitStage_TinyFusion: 1-3                            [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-10                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-11                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 --                        3,555,366\n",
            "│    │    └─LevitBlock: 3-12                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,336,104\n",
            "Trainable params: 8,336,104\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 12.76\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 650.55\n",
            "Params size (MB): 12.79\n",
            "Estimated Total Size (MB): 682.60\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), tau = 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "3209b33c-5242-4371-dd0b-0f90fbcfd54c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilledTinyfusion                                [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage_TinyFusion: 1-2                            [32, 196, 256]            4\n",
            "│    └─gumbel_gate                                                                ├─4\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  --                        1,583,616\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage_TinyFusion: 1-3                            [32, 49, 384]             --\n",
            "│    └─gumbel_gate                                                                ├─4\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-10                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-11                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 --                        3,555,660\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-12                            [32, 49, 384]             1,185,024\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,336,402\n",
            "Trainable params: 8,336,402\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 12.76\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 650.55\n",
            "Params size (MB): 12.79\n",
            "Estimated Total Size (MB): 682.60\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilledTinyfusion                                [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage_TinyFusion: 1-2                            [32, 196, 256]            4\n",
            "│    └─gumbel_gate                                                                ├─4\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  --                        1,583,616\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage_TinyFusion: 1-3                            [32, 49, 384]             --\n",
            "│    └─gumbel_gate                                                                ├─4\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-10                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-11                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 --                        3,555,660\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-12                            [32, 49, 384]             1,185,024\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,336,402\n",
            "Trainable params: 8,336,402\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 12.76\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 650.55\n",
            "Params size (MB): 12.79\n",
            "Estimated Total Size (MB): 682.60\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2, tau = 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "c458ec0d-5ffe-4740-d7a2-19bd1f523933"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilledTinyfusion(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage_TinyFusion(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage_TinyFusion(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "NcNx9kgbdulf"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ],
      "metadata": {
        "id": "y_1SUIuidwbE"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "g18xh7W1tv8W"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from glob import glob\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, dir, aug=False):\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        self.aug = aug\n",
        "        self.samples = [i for i in glob(os.path.join(dir, '**/*')) if os.path.isfile(i)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        class_name = os.path.basename(self.samples[idx]).split('-')[0]\n",
        "        label = {\n",
        "            'ADI': 0,\n",
        "            'BACK': 1,\n",
        "            'DEB': 2,\n",
        "            'LYM': 3,\n",
        "            'MUC': 4,\n",
        "            'MUS': 5,\n",
        "            'NORM': 6,\n",
        "            'STR': 7,\n",
        "            'TUM': 8,\n",
        "        }\n",
        "\n",
        "        img = cv2.imread(self.samples[idx], -1)[:, :, ::-1]\n",
        "        img = np.float32(img) / 255.0\n",
        "\n",
        "        if self.aug:\n",
        "            if random.random() < 0.5:\n",
        "                img = img[::-1]\n",
        "\n",
        "            if random.random() < 0.5:\n",
        "                img = img[:, ::-1]\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                if random.random() < 0.5:\n",
        "                    img += np.random.normal(\n",
        "                        0.0, np.random.uniform(0.01, 0.2),\n",
        "                        (img.shape[0], img.shape[1], img.shape[2])\n",
        "                    )\n",
        "                else:\n",
        "                    x = np.random.uniform(0.02, 0.15)\n",
        "                    img += np.random.uniform(\n",
        "                        -x, x,\n",
        "                        (img.shape[0], img.shape[1], img.shape[2])\n",
        "                    )\n",
        "\n",
        "            if random.random() < 0.9:\n",
        "                img += np.random.uniform(-0.15, 0.15, (1, 1, 3))\n",
        "                img *= np.random.uniform(0.85, 1.15, (1, 1, 3))\n",
        "\n",
        "            if random.random() < 0.3:\n",
        "                kX, kY = np.random.randint(0, 4, 2) * 2 + 1\n",
        "                if random.random() < 0.5:\n",
        "                    img = cv2.GaussianBlur(img, (kX, kY), 0)\n",
        "                else:\n",
        "                    img = cv2.blur(img, (kX, kY))\n",
        "\n",
        "        img = np.uint8(np.clip(img, 0, 1) * 255.0)\n",
        "        img = self.transform(Image.fromarray(img))\n",
        "\n",
        "        return img, label[class_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset1 = Dataset(dir=train_dir, aug=True)\n",
        "dataset2 = Dataset(dir=train_dir, aug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "train_data = Subset(dataset, load_train_idx)\n",
        "val_data = Subset(dataset, load_val_idx)\n",
        "test_data = Subset(dataset, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "54bf5392-9c06-41a5-fab1-dbc0c7debef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gumbel_params = []\n",
        "other_params = []\n",
        "exclude = [\"head\", \"head_dist\"]\n",
        "\n",
        "for name, module in model.named_children():\n",
        "    if name in exclude:\n",
        "        print(exclude)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if \"gumbel_gate\" in name:\n",
        "        gumbel_params.append(param)\n",
        "        print(name)\n",
        "    else:\n",
        "        other_params.append(param)\n",
        "\n",
        "#model = convert_to_lora_model(model, exclude=exclude)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrBLmUdJ4IZD",
        "outputId": "69b77bfc-faf5-4996-df0d-b4a7595a53d8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['head', 'head_dist']\n",
            "['head', 'head_dist']\n",
            "stage1.gumbel_gate\n",
            "stage2.gumbel_gate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch, total_epcohs=100):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    tau_max = 1\n",
        "    tau_min = 0.1\n",
        "    total_steps = total_epcohs * len(train_loader)\n",
        "    train_steps = epoch * len(train_loader)\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        tau = tau_max - (tau_max - tau_min) * min(1.0, (train_steps + i) / total_steps)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, tau)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Tau: {tau:.4f}\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)\n",
        "\n",
        "    print(\"Each stage of block probabilities:\")\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, LevitStage_TinyFusion):\n",
        "            gate_probs = torch.softmax(module.gumbel_gate, dim=0) # 각 block의 확률\n",
        "            topk_indx = torch.topk(gate_probs, module.num_select).indices.tolist() # 상위 k개의 index\n",
        "            print(f\"{name}\")\n",
        "            for i, prob in enumerate(gate_probs):\n",
        "                mask = \" \" if i in topk_indx else \"*\" # mask\n",
        "                print(f\"Block {i}: {prob:.4f} {mask}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, criterion, device, phase=\"Validation\", epoch=0, total_epcohs=100):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    tau_max = 1\n",
        "    tau_min = 0.1\n",
        "    total_steps = total_epcohs * len(data_loader)\n",
        "    train_steps = epoch * len(data_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            if phase == \"Validation\":\n",
        "                tau = tau_max - (tau_max - tau_min) * min(1.0, (train_steps + i) / total_steps)\n",
        "            elif phase == \"Test\":\n",
        "                tau = 1e-5\n",
        "            outputs = model(inputs, tau)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "    print(f\"Tau: {tau:.4f}\")\n",
        "\n",
        "    val_losses.append(epoch_loss)\n",
        "    val_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs, tau=0.1)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter name: {name}, requires_grad: {param.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E_O1ooo4c1A",
        "outputId": "634b936d-7648-4395-dae4-8b21c8345b2d"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter name: stem.conv1.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv1.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv1.bn.bias, requires_grad: True\n",
            "Parameter name: stem.conv2.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv2.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv2.bn.bias, requires_grad: True\n",
            "Parameter name: stem.conv3.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv3.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv3.bn.bias, requires_grad: True\n",
            "Parameter name: stem.conv4.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv4.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv4.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.gumbel_gate, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.gumbel_gate, requires_grad: True\n",
            "Parameter name: stage2.downsample.conv.weight, requires_grad: True\n",
            "Parameter name: stage2.downsample.conv.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: conv1x1.0.weight, requires_grad: True\n",
            "Parameter name: conv1x1.0.bias, requires_grad: True\n",
            "Parameter name: conv1x1.1.weight, requires_grad: True\n",
            "Parameter name: conv1x1.1.bias, requires_grad: True\n",
            "Parameter name: head.bn.weight, requires_grad: True\n",
            "Parameter name: head.bn.bias, requires_grad: True\n",
            "Parameter name: head.linear.weight, requires_grad: True\n",
            "Parameter name: head.linear.bias, requires_grad: True\n",
            "Parameter name: head_dist.bn.weight, requires_grad: True\n",
            "Parameter name: head_dist.bn.bias, requires_grad: True\n",
            "Parameter name: head_dist.linear.weight, requires_grad: True\n",
            "Parameter name: head_dist.linear.bias, requires_grad: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transfer_weights(pretrained_model: LevitDistilled, tinyfusion_model: LevitDistilledTinyfusion, num_blocks):\n",
        "\n",
        "    pretrained_dict = pretrained_model.state_dict()\n",
        "    tinyfusion_dict = tinyfusion_model.state_dict()\n",
        "\n",
        "    new_state_dict = {}\n",
        "\n",
        "    # 1️⃣ 공통된 가중치 복사 (stem, conv1x1, head, head_dist)\n",
        "    for key in tinyfusion_dict.keys():\n",
        "        if key in pretrained_dict and not key.startswith(\"stage\"):\n",
        "            new_state_dict[key] = pretrained_dict[key]\n",
        "\n",
        "    stage = []\n",
        "    for i in range(num_blocks):\n",
        "        stage.append(f\"stage{i}\")\n",
        "    # 2️⃣ stage1, stage2의 가중치 변환 적용\n",
        "    for stage_name in stage:\n",
        "        for i in range(num_blocks):  # num_blocks=4\n",
        "            old_key = f\"{stage_name}.blocks.{i}\"  # 원래 모델의 key\n",
        "            new_key = f\"{stage_name}.blocks.{i}\"  # TinyFusion 모델의 key\n",
        "\n",
        "            if old_key in pretrained_dict and new_key in tinyfusion_dict:\n",
        "                new_state_dict[new_key] = pretrained_dict[old_key]\n",
        "\n",
        "    # 3️⃣ `gumble_gate`는 원래 모델에 없으므로, 초기화된 값 유지 (로드 안함)\n",
        "    print(\"✅ 가중치 변환 완료! TinyFusion 모델에 적용합니다.\")\n",
        "\n",
        "    # 4️⃣ 변환된 가중치를 TinyFusion 모델에 로드 (strict=False)\n",
        "    tinyfusion_model.load_state_dict(new_state_dict, strict=False)"
      ],
      "metadata": {
        "id": "QhOOoBYs4hBm"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = LevitDistilled(num_classes=9)\n",
        "pretrained_model.stage1.blocks[0].attn.compute_attention_bias(14)\n",
        "pretrained_model.stage1.blocks[1].attn.compute_attention_bias(14)\n",
        "pretrained_model.stage1.blocks[2].attn.compute_attention_bias(14)\n",
        "pretrained_model.stage1.blocks[3].attn.compute_attention_bias(14)\n",
        "pretrained_model.stage2.blocks[0].attn.compute_attention_bias(7)\n",
        "pretrained_model.stage2.blocks[1].attn.compute_attention_bias(7)\n",
        "pretrained_model.stage2.blocks[2].attn.compute_attention_bias(7)\n",
        "pretrained_model.stage2.blocks[3].attn.compute_attention_bias(7)\n",
        "model.stage1.blocks[0].attn.compute_attention_bias(14)\n",
        "model.stage1.blocks[1].attn.compute_attention_bias(14)\n",
        "model.stage1.blocks[2].attn.compute_attention_bias(14)\n",
        "model.stage1.blocks[3].attn.compute_attention_bias(14)\n",
        "model.stage2.blocks[0].attn.compute_attention_bias(7)\n",
        "model.stage2.blocks[1].attn.compute_attention_bias(7)\n",
        "model.stage2.blocks[2].attn.compute_attention_bias(7)\n",
        "model.stage2.blocks[3].attn.compute_attention_bias(7)\n",
        "pretrained_model.load_state_dict(torch.load(\"HoViT44_withAug_7Ktest.pth\", weights_only=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNXAaJwH4j3M",
        "outputId": "bc037c7c-28aa-414b-bc11-59b2a3a3b576"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_weights(pretrained_model, model, num_blocks=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX1-SnT95apa",
        "outputId": "de3c5e98-f05d-454b-e879-de2ca7cd77e3"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 가중치 변환 완료! TinyFusion 모델에 적용합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = convert_to_lora_model(model, exclude=exclude)"
      ],
      "metadata": {
        "id": "PFqz6dOv5cBi"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gumbel_gate 파라미터가 포함되어 있는지 확인\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter name: {name}, requires_grad: {param.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZFIjbOp5ei1",
        "outputId": "c78ce620-d3ae-495f-ce92-e43f7522bbce"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter name: stem.conv1.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv1.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv1.bn.bias, requires_grad: True\n",
            "Parameter name: stem.conv2.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv2.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv2.bn.bias, requires_grad: True\n",
            "Parameter name: stem.conv3.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv3.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv3.bn.bias, requires_grad: True\n",
            "Parameter name: stem.conv4.linear.weight, requires_grad: True\n",
            "Parameter name: stem.conv4.bn.weight, requires_grad: True\n",
            "Parameter name: stem.conv4.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.gumbel_gate, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.gumbel_gate, requires_grad: True\n",
            "Parameter name: stage2.downsample.conv.weight, requires_grad: True\n",
            "Parameter name: stage2.downsample.conv.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.bn.bias, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.linear.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.bn.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.bn.bias, requires_grad: True\n",
            "Parameter name: conv1x1.0.weight, requires_grad: True\n",
            "Parameter name: conv1x1.0.bias, requires_grad: True\n",
            "Parameter name: conv1x1.1.weight, requires_grad: True\n",
            "Parameter name: conv1x1.1.bias, requires_grad: True\n",
            "Parameter name: head.bn.weight, requires_grad: True\n",
            "Parameter name: head.bn.bias, requires_grad: True\n",
            "Parameter name: head.linear.weight, requires_grad: True\n",
            "Parameter name: head.linear.bias, requires_grad: True\n",
            "Parameter name: head_dist.bn.weight, requires_grad: True\n",
            "Parameter name: head_dist.bn.bias, requires_grad: True\n",
            "Parameter name: head_dist.linear.weight, requires_grad: True\n",
            "Parameter name: head_dist.linear.bias, requires_grad: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if \"lora_a\" in name or \"lora_b\" in name:\n",
        "        param.requires_grad = True\n",
        "        print(f\"✅ LoRA Trainable: {name}\")\n",
        "    elif \"gumbel_gate\" in name:\n",
        "        param.requires_grad = True\n",
        "        print(f\"✅ TinyFusion Trainable: {name}\")\n",
        "    elif \"head\" in name or \"head_dist\" in name:\n",
        "        param.requires_grad = True\n",
        "        print(f\"✅ Head Trainable: {name}\")\n",
        "    elif \"conv1x1\" in name:\n",
        "        param.requires_grad = True\n",
        "        print(f\"✅ Conv1x1 Trainable: {name}\")\n",
        "    elif \"attention_biases\" in name:\n",
        "        param.requires_grad = True\n",
        "        print(f\"✅ Attention Biases Trainable: {name}\")\n",
        "    else:\n",
        "        param.requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELoFunmQ5fyT",
        "outputId": "c76c8aaa-a28d-4673-9852-51fdd8c61d81"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ TinyFusion Trainable: stage1.gumbel_gate\n",
            "✅ Attention Biases Trainable: stage1.blocks.0.attn.attention_biases\n",
            "✅ LoRA Trainable: stage1.blocks.0.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.0.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.0.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.0.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.0.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.0.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.0.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.0.mlp.ln2.linear.lora_b.weight\n",
            "✅ Attention Biases Trainable: stage1.blocks.1.attn.attention_biases\n",
            "✅ LoRA Trainable: stage1.blocks.1.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.1.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.1.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.1.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.1.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.1.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.1.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.1.mlp.ln2.linear.lora_b.weight\n",
            "✅ Attention Biases Trainable: stage1.blocks.2.attn.attention_biases\n",
            "✅ LoRA Trainable: stage1.blocks.2.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.2.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.2.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.2.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.2.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.2.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.2.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.2.mlp.ln2.linear.lora_b.weight\n",
            "✅ Attention Biases Trainable: stage1.blocks.3.attn.attention_biases\n",
            "✅ LoRA Trainable: stage1.blocks.3.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.3.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.3.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.3.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.3.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.3.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage1.blocks.3.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage1.blocks.3.mlp.ln2.linear.lora_b.weight\n",
            "✅ TinyFusion Trainable: stage2.gumbel_gate\n",
            "✅ Attention Biases Trainable: stage2.blocks.0.attn.attention_biases\n",
            "✅ LoRA Trainable: stage2.blocks.0.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.0.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.0.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.0.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.0.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.0.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.0.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.0.mlp.ln2.linear.lora_b.weight\n",
            "✅ Attention Biases Trainable: stage2.blocks.1.attn.attention_biases\n",
            "✅ LoRA Trainable: stage2.blocks.1.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.1.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.1.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.1.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.1.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.1.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.1.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.1.mlp.ln2.linear.lora_b.weight\n",
            "✅ Attention Biases Trainable: stage2.blocks.2.attn.attention_biases\n",
            "✅ LoRA Trainable: stage2.blocks.2.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.2.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.2.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.2.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.2.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.2.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.2.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.2.mlp.ln2.linear.lora_b.weight\n",
            "✅ Attention Biases Trainable: stage2.blocks.3.attn.attention_biases\n",
            "✅ LoRA Trainable: stage2.blocks.3.attn.qkv.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.3.attn.qkv.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.3.attn.proj.1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.3.attn.proj.1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.3.mlp.ln1.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.3.mlp.ln1.linear.lora_b.weight\n",
            "✅ LoRA Trainable: stage2.blocks.3.mlp.ln2.linear.lora_a.weight\n",
            "✅ LoRA Trainable: stage2.blocks.3.mlp.ln2.linear.lora_b.weight\n",
            "✅ Conv1x1 Trainable: conv1x1.0.weight\n",
            "✅ Conv1x1 Trainable: conv1x1.0.bias\n",
            "✅ Conv1x1 Trainable: conv1x1.1.weight\n",
            "✅ Conv1x1 Trainable: conv1x1.1.bias\n",
            "✅ Head Trainable: head.bn.weight\n",
            "✅ Head Trainable: head.bn.bias\n",
            "✅ Head Trainable: head.linear.weight\n",
            "✅ Head Trainable: head.linear.bias\n",
            "✅ Head Trainable: head_dist.bn.weight\n",
            "✅ Head Trainable: head_dist.bn.bias\n",
            "✅ Head Trainable: head_dist.linear.weight\n",
            "✅ Head Trainable: head_dist.linear.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gumbel_gate 파라미터가 포함되어 있는지 확인\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter name: {name}, requires_grad: {param.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFLWmD5T5k-v",
        "outputId": "bb4a28bb-854e-405c-8a5d-19b7d24aea1e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter name: stem.conv1.linear.weight, requires_grad: False\n",
            "Parameter name: stem.conv1.bn.weight, requires_grad: False\n",
            "Parameter name: stem.conv1.bn.bias, requires_grad: False\n",
            "Parameter name: stem.conv2.linear.weight, requires_grad: False\n",
            "Parameter name: stem.conv2.bn.weight, requires_grad: False\n",
            "Parameter name: stem.conv2.bn.bias, requires_grad: False\n",
            "Parameter name: stem.conv3.linear.weight, requires_grad: False\n",
            "Parameter name: stem.conv3.bn.weight, requires_grad: False\n",
            "Parameter name: stem.conv3.bn.bias, requires_grad: False\n",
            "Parameter name: stem.conv4.linear.weight, requires_grad: False\n",
            "Parameter name: stem.conv4.bn.weight, requires_grad: False\n",
            "Parameter name: stem.conv4.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.gumbel_gate, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.0.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.1.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.2.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage1.blocks.3.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.gumbel_gate, requires_grad: True\n",
            "Parameter name: stage2.downsample.conv.weight, requires_grad: False\n",
            "Parameter name: stage2.downsample.conv.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.0.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.1.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.2.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.attn.attention_biases, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.attn.qkv.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.qkv.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.attn.qkv.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.attn.proj.1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.mlp.ln1.bn.bias, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.linear.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.linear.lora_a.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.linear.lora_b.weight, requires_grad: True\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.bn.weight, requires_grad: False\n",
            "Parameter name: stage2.blocks.3.mlp.ln2.bn.bias, requires_grad: False\n",
            "Parameter name: conv1x1.0.weight, requires_grad: True\n",
            "Parameter name: conv1x1.0.bias, requires_grad: True\n",
            "Parameter name: conv1x1.1.weight, requires_grad: True\n",
            "Parameter name: conv1x1.1.bias, requires_grad: True\n",
            "Parameter name: head.bn.weight, requires_grad: True\n",
            "Parameter name: head.bn.bias, requires_grad: True\n",
            "Parameter name: head.linear.weight, requires_grad: True\n",
            "Parameter name: head.linear.bias, requires_grad: True\n",
            "Parameter name: head_dist.bn.weight, requires_grad: True\n",
            "Parameter name: head_dist.bn.bias, requires_grad: True\n",
            "Parameter name: head_dist.linear.weight, requires_grad: True\n",
            "Parameter name: head_dist.linear.bias, requires_grad: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "a3ec9587-7c89-4131-eeb5-6402adcedbe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4755, Train Accuracy: 84.56%\n",
            "Tau: 0.9910\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.2715  \n",
            "Block 1: 0.2604  \n",
            "Block 2: 0.2334 *\n",
            "Block 3: 0.2346 *\n",
            "stage2\n",
            "Block 0: 0.2624  \n",
            "Block 1: 0.2681  \n",
            "Block 2: 0.2387 *\n",
            "Block 3: 0.2308 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5290, Validation Accuracy: 81.50%\n",
            "Balanced Accuracy: 0.8080\n",
            "Tau: 0.9910\n",
            "\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2425, Train Accuracy: 91.82%\n",
            "Tau: 0.9820\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.2924  \n",
            "Block 1: 0.2644  \n",
            "Block 2: 0.2149 *\n",
            "Block 3: 0.2282 *\n",
            "stage2\n",
            "Block 0: 0.2730  \n",
            "Block 1: 0.2758  \n",
            "Block 2: 0.2285 *\n",
            "Block 3: 0.2227 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4490, Validation Accuracy: 84.30%\n",
            "Balanced Accuracy: 0.8386\n",
            "Tau: 0.9820\n",
            "\n",
            "Epoch 3/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1905, Train Accuracy: 93.56%\n",
            "Tau: 0.9730\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.3306  \n",
            "Block 1: 0.2591  \n",
            "Block 2: 0.1961 *\n",
            "Block 3: 0.2141 *\n",
            "stage2\n",
            "Block 0: 0.2869  \n",
            "Block 1: 0.2786  \n",
            "Block 2: 0.2225 *\n",
            "Block 3: 0.2120 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3677, Validation Accuracy: 87.39%\n",
            "Balanced Accuracy: 0.8733\n",
            "Tau: 0.9730\n",
            "\n",
            "Epoch 4/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1579, Train Accuracy: 94.67%\n",
            "Tau: 0.9640\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.3497  \n",
            "Block 1: 0.2635  \n",
            "Block 2: 0.1838 *\n",
            "Block 3: 0.2031 *\n",
            "stage2\n",
            "Block 0: 0.3010  \n",
            "Block 1: 0.2822  \n",
            "Block 2: 0.2140 *\n",
            "Block 3: 0.2028 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2783, Validation Accuracy: 90.45%\n",
            "Balanced Accuracy: 0.9031\n",
            "Tau: 0.9640\n",
            "\n",
            "Epoch 5/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1388, Train Accuracy: 95.23%\n",
            "Tau: 0.9550\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.3821  \n",
            "Block 1: 0.2623  \n",
            "Block 2: 0.1669 *\n",
            "Block 3: 0.1888 *\n",
            "stage2\n",
            "Block 0: 0.3119  \n",
            "Block 1: 0.2818  \n",
            "Block 2: 0.2124 *\n",
            "Block 3: 0.1939 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2813, Validation Accuracy: 90.35%\n",
            "Balanced Accuracy: 0.9027\n",
            "Tau: 0.9550\n",
            "\n",
            "Epoch 6/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1189, Train Accuracy: 95.99%\n",
            "Tau: 0.9460\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.4178  \n",
            "Block 1: 0.2567  \n",
            "Block 2: 0.1530 *\n",
            "Block 3: 0.1725 *\n",
            "stage2\n",
            "Block 0: 0.3198  \n",
            "Block 1: 0.2849  \n",
            "Block 2: 0.2088 *\n",
            "Block 3: 0.1865 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2615, Validation Accuracy: 91.17%\n",
            "Balanced Accuracy: 0.9108\n",
            "Tau: 0.9460\n",
            "\n",
            "Epoch 7/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1065, Train Accuracy: 96.38%\n",
            "Tau: 0.9370\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.4458  \n",
            "Block 1: 0.2555  \n",
            "Block 2: 0.1394 *\n",
            "Block 3: 0.1593 *\n",
            "stage2\n",
            "Block 0: 0.3432  \n",
            "Block 1: 0.2825  \n",
            "Block 2: 0.2014 *\n",
            "Block 3: 0.1729 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2514, Validation Accuracy: 91.49%\n",
            "Balanced Accuracy: 0.9120\n",
            "Tau: 0.9370\n",
            "\n",
            "Epoch 8/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0948, Train Accuracy: 96.69%\n",
            "Tau: 0.9280\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.4821  \n",
            "Block 1: 0.2467  \n",
            "Block 2: 0.1243 *\n",
            "Block 3: 0.1469 *\n",
            "stage2\n",
            "Block 0: 0.3645  \n",
            "Block 1: 0.2795  \n",
            "Block 2: 0.1895 *\n",
            "Block 3: 0.1665 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2628, Validation Accuracy: 91.16%\n",
            "Balanced Accuracy: 0.9116\n",
            "Tau: 0.9280\n",
            "\n",
            "Epoch 9/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0847, Train Accuracy: 97.09%\n",
            "Tau: 0.9190\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.5152  \n",
            "Block 1: 0.2364  \n",
            "Block 2: 0.1120 *\n",
            "Block 3: 0.1364 *\n",
            "stage2\n",
            "Block 0: 0.3792  \n",
            "Block 1: 0.2839  \n",
            "Block 2: 0.1806 *\n",
            "Block 3: 0.1563 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2457, Validation Accuracy: 91.89%\n",
            "Balanced Accuracy: 0.9185\n",
            "Tau: 0.9190\n",
            "\n",
            "Epoch 10/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0748, Train Accuracy: 97.45%\n",
            "Tau: 0.9100\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.5442  \n",
            "Block 1: 0.2297  \n",
            "Block 2: 0.1016 *\n",
            "Block 3: 0.1245 *\n",
            "stage2\n",
            "Block 0: 0.3946  \n",
            "Block 1: 0.2863  \n",
            "Block 2: 0.1682 *\n",
            "Block 3: 0.1510 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2301, Validation Accuracy: 92.61%\n",
            "Balanced Accuracy: 0.9276\n",
            "Tau: 0.9100\n",
            "\n",
            "Epoch 11/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0673, Train Accuracy: 97.72%\n",
            "Tau: 0.9010\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.5792  \n",
            "Block 1: 0.2141  \n",
            "Block 2: 0.0924 *\n",
            "Block 3: 0.1144 *\n",
            "stage2\n",
            "Block 0: 0.4126  \n",
            "Block 1: 0.2767  \n",
            "Block 2: 0.1665 *\n",
            "Block 3: 0.1443 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2078, Validation Accuracy: 93.20%\n",
            "Balanced Accuracy: 0.9321\n",
            "Tau: 0.9010\n",
            "\n",
            "Epoch 12/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0597, Train Accuracy: 97.94%\n",
            "Tau: 0.8920\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.6084  \n",
            "Block 1: 0.2089  \n",
            "Block 2: 0.0811 *\n",
            "Block 3: 0.1016 *\n",
            "stage2\n",
            "Block 0: 0.4286  \n",
            "Block 1: 0.2806  \n",
            "Block 2: 0.1534 *\n",
            "Block 3: 0.1374 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2176, Validation Accuracy: 93.06%\n",
            "Balanced Accuracy: 0.9315\n",
            "Tau: 0.8920\n",
            "\n",
            "Epoch 13/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0527, Train Accuracy: 98.21%\n",
            "Tau: 0.8830\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.6365  \n",
            "Block 1: 0.1982  \n",
            "Block 2: 0.0722 *\n",
            "Block 3: 0.0931 *\n",
            "stage2\n",
            "Block 0: 0.4382  \n",
            "Block 1: 0.2767  \n",
            "Block 2: 0.1530 *\n",
            "Block 3: 0.1321 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2065, Validation Accuracy: 93.67%\n",
            "Balanced Accuracy: 0.9367\n",
            "Tau: 0.8830\n",
            "\n",
            "Epoch 14/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0480, Train Accuracy: 98.33%\n",
            "Tau: 0.8740\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.6702  \n",
            "Block 1: 0.1841  \n",
            "Block 2: 0.0652 *\n",
            "Block 3: 0.0804 *\n",
            "stage2\n",
            "Block 0: 0.4579  \n",
            "Block 1: 0.2707  \n",
            "Block 2: 0.1447 *\n",
            "Block 3: 0.1267 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2076, Validation Accuracy: 93.61%\n",
            "Balanced Accuracy: 0.9360\n",
            "Tau: 0.8740\n",
            "\n",
            "Epoch 15/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0425, Train Accuracy: 98.53%\n",
            "Tau: 0.8650\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.6859  \n",
            "Block 1: 0.1742  \n",
            "Block 2: 0.0626 *\n",
            "Block 3: 0.0773 *\n",
            "stage2\n",
            "Block 0: 0.4665  \n",
            "Block 1: 0.2762  \n",
            "Block 2: 0.1407 *\n",
            "Block 3: 0.1166 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1891, Validation Accuracy: 94.19%\n",
            "Balanced Accuracy: 0.9431\n",
            "Tau: 0.8650\n",
            "\n",
            "Epoch 16/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0414, Train Accuracy: 98.59%\n",
            "Tau: 0.8560\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.7210  \n",
            "Block 1: 0.1603  \n",
            "Block 2: 0.0519 *\n",
            "Block 3: 0.0668 *\n",
            "stage2\n",
            "Block 0: 0.4744  \n",
            "Block 1: 0.2786  \n",
            "Block 2: 0.1358 *\n",
            "Block 3: 0.1112 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1803, Validation Accuracy: 94.37%\n",
            "Balanced Accuracy: 0.9454\n",
            "Tau: 0.8560\n",
            "\n",
            "Epoch 17/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0358, Train Accuracy: 98.78%\n",
            "Tau: 0.8470\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.7420  \n",
            "Block 1: 0.1523  \n",
            "Block 2: 0.0455 *\n",
            "Block 3: 0.0602 *\n",
            "stage2\n",
            "Block 0: 0.4845  \n",
            "Block 1: 0.2800  \n",
            "Block 2: 0.1297 *\n",
            "Block 3: 0.1057 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1593, Validation Accuracy: 95.16%\n",
            "Balanced Accuracy: 0.9515\n",
            "Tau: 0.8470\n",
            "\n",
            "Epoch 18/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0323, Train Accuracy: 98.88%\n",
            "Tau: 0.8380\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.7712  \n",
            "Block 1: 0.1335  \n",
            "Block 2: 0.0396 *\n",
            "Block 3: 0.0557 *\n",
            "stage2\n",
            "Block 0: 0.5072  \n",
            "Block 1: 0.2773  \n",
            "Block 2: 0.1179 *\n",
            "Block 3: 0.0976 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1691, Validation Accuracy: 95.13%\n",
            "Balanced Accuracy: 0.9506\n",
            "Tau: 0.8380\n",
            "\n",
            "Epoch 19/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0304, Train Accuracy: 98.97%\n",
            "Tau: 0.8290\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.7924  \n",
            "Block 1: 0.1228  \n",
            "Block 2: 0.0361 *\n",
            "Block 3: 0.0487 *\n",
            "stage2\n",
            "Block 0: 0.5117  \n",
            "Block 1: 0.2828  \n",
            "Block 2: 0.1149 *\n",
            "Block 3: 0.0906 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1781, Validation Accuracy: 94.65%\n",
            "Balanced Accuracy: 0.9479\n",
            "Tau: 0.8290\n",
            "\n",
            "Epoch 20/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0283, Train Accuracy: 99.03%\n",
            "Tau: 0.8200\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.8094  \n",
            "Block 1: 0.1143  \n",
            "Block 2: 0.0325 *\n",
            "Block 3: 0.0438 *\n",
            "stage2\n",
            "Block 0: 0.5253  \n",
            "Block 1: 0.2830  \n",
            "Block 2: 0.1075 *\n",
            "Block 3: 0.0841 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1853, Validation Accuracy: 94.33%\n",
            "Balanced Accuracy: 0.9448\n",
            "Tau: 0.8200\n",
            "\n",
            "Epoch 21/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0274, Train Accuracy: 99.09%\n",
            "Tau: 0.8110\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.8257  \n",
            "Block 1: 0.1046  \n",
            "Block 2: 0.0297 *\n",
            "Block 3: 0.0400 *\n",
            "stage2\n",
            "Block 0: 0.5433  \n",
            "Block 1: 0.2787  \n",
            "Block 2: 0.1004 *\n",
            "Block 3: 0.0776 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1769, Validation Accuracy: 94.66%\n",
            "Balanced Accuracy: 0.9484\n",
            "Tau: 0.8110\n",
            "\n",
            "Epoch 22/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0260, Train Accuracy: 99.10%\n",
            "Tau: 0.8020\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.8378  \n",
            "Block 1: 0.0989  \n",
            "Block 2: 0.0274 *\n",
            "Block 3: 0.0360 *\n",
            "stage2\n",
            "Block 0: 0.5540  \n",
            "Block 1: 0.2788  \n",
            "Block 2: 0.0957 *\n",
            "Block 3: 0.0715 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1744, Validation Accuracy: 95.05%\n",
            "Balanced Accuracy: 0.9525\n",
            "Tau: 0.8020\n",
            "\n",
            "Epoch 23/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0224, Train Accuracy: 99.25%\n",
            "Tau: 0.7930\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.8559  \n",
            "Block 1: 0.0882  \n",
            "Block 2: 0.0240 *\n",
            "Block 3: 0.0319 *\n",
            "stage2\n",
            "Block 0: 0.5639  \n",
            "Block 1: 0.2749  \n",
            "Block 2: 0.0913 *\n",
            "Block 3: 0.0698 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1919, Validation Accuracy: 94.51%\n",
            "Balanced Accuracy: 0.9471\n",
            "Tau: 0.7930\n",
            "\n",
            "Epoch 24/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0209, Train Accuracy: 99.30%\n",
            "Tau: 0.7840\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.8715  \n",
            "Block 1: 0.0790  \n",
            "Block 2: 0.0209 *\n",
            "Block 3: 0.0287 *\n",
            "stage2\n",
            "Block 0: 0.5765  \n",
            "Block 1: 0.2702  \n",
            "Block 2: 0.0849 *\n",
            "Block 3: 0.0684 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1540, Validation Accuracy: 95.65%\n",
            "Balanced Accuracy: 0.9584\n",
            "Tau: 0.7840\n",
            "\n",
            "Epoch 25/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0202, Train Accuracy: 99.28%\n",
            "Tau: 0.7750\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.8855  \n",
            "Block 1: 0.0710  \n",
            "Block 2: 0.0184 *\n",
            "Block 3: 0.0251 *\n",
            "stage2\n",
            "Block 0: 0.5939  \n",
            "Block 1: 0.2652  \n",
            "Block 2: 0.0772 *\n",
            "Block 3: 0.0637 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1544, Validation Accuracy: 95.83%\n",
            "Balanced Accuracy: 0.9598\n",
            "Tau: 0.7750\n",
            "\n",
            "Epoch 26/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0184, Train Accuracy: 99.37%\n",
            "Tau: 0.7660\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.8979  \n",
            "Block 1: 0.0634  \n",
            "Block 2: 0.0164 *\n",
            "Block 3: 0.0222 *\n",
            "stage2\n",
            "Block 0: 0.5949  \n",
            "Block 1: 0.2664  \n",
            "Block 2: 0.0764 *\n",
            "Block 3: 0.0622 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1428, Validation Accuracy: 96.23%\n",
            "Balanced Accuracy: 0.9634\n",
            "Tau: 0.7660\n",
            "\n",
            "Epoch 27/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0184, Train Accuracy: 99.37%\n",
            "Tau: 0.7570\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9039  \n",
            "Block 1: 0.0598  \n",
            "Block 2: 0.0154 *\n",
            "Block 3: 0.0208 *\n",
            "stage2\n",
            "Block 0: 0.6097  \n",
            "Block 1: 0.2584  \n",
            "Block 2: 0.0726 *\n",
            "Block 3: 0.0594 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1977, Validation Accuracy: 94.89%\n",
            "Balanced Accuracy: 0.9520\n",
            "Tau: 0.7570\n",
            "\n",
            "Epoch 28/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0184, Train Accuracy: 99.37%\n",
            "Tau: 0.7480\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9144  \n",
            "Block 1: 0.0530  \n",
            "Block 2: 0.0134 *\n",
            "Block 3: 0.0192 *\n",
            "stage2\n",
            "Block 0: 0.6244  \n",
            "Block 1: 0.2527  \n",
            "Block 2: 0.0686 *\n",
            "Block 3: 0.0542 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1467, Validation Accuracy: 95.97%\n",
            "Balanced Accuracy: 0.9602\n",
            "Tau: 0.7480\n",
            "\n",
            "Epoch 29/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0160, Train Accuracy: 99.48%\n",
            "Tau: 0.7390\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9233  \n",
            "Block 1: 0.0477  \n",
            "Block 2: 0.0120 *\n",
            "Block 3: 0.0171 *\n",
            "stage2\n",
            "Block 0: 0.6442  \n",
            "Block 1: 0.2385  \n",
            "Block 2: 0.0660 *\n",
            "Block 3: 0.0512 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1536, Validation Accuracy: 95.71%\n",
            "Balanced Accuracy: 0.9582\n",
            "Tau: 0.7390\n",
            "\n",
            "Epoch 30/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0159, Train Accuracy: 99.46%\n",
            "Tau: 0.7300\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9302  \n",
            "Block 1: 0.0440  \n",
            "Block 2: 0.0108 *\n",
            "Block 3: 0.0151 *\n",
            "stage2\n",
            "Block 0: 0.6525  \n",
            "Block 1: 0.2395  \n",
            "Block 2: 0.0608 *\n",
            "Block 3: 0.0472 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1328, Validation Accuracy: 96.45%\n",
            "Balanced Accuracy: 0.9655\n",
            "Tau: 0.7300\n",
            "\n",
            "Epoch 31/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0152, Train Accuracy: 99.49%\n",
            "Tau: 0.7210\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9333  \n",
            "Block 1: 0.0422  \n",
            "Block 2: 0.0100 *\n",
            "Block 3: 0.0144 *\n",
            "stage2\n",
            "Block 0: 0.6566  \n",
            "Block 1: 0.2410  \n",
            "Block 2: 0.0570 *\n",
            "Block 3: 0.0454 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1632, Validation Accuracy: 95.64%\n",
            "Balanced Accuracy: 0.9585\n",
            "Tau: 0.7210\n",
            "\n",
            "Epoch 32/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0132, Train Accuracy: 99.55%\n",
            "Tau: 0.7120\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9394  \n",
            "Block 1: 0.0380  \n",
            "Block 2: 0.0091 *\n",
            "Block 3: 0.0135 *\n",
            "stage2\n",
            "Block 0: 0.6573  \n",
            "Block 1: 0.2445  \n",
            "Block 2: 0.0540 *\n",
            "Block 3: 0.0441 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1455, Validation Accuracy: 96.48%\n",
            "Balanced Accuracy: 0.9652\n",
            "Tau: 0.7120\n",
            "\n",
            "Epoch 33/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0131, Train Accuracy: 99.57%\n",
            "Tau: 0.7030\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9450  \n",
            "Block 1: 0.0344  \n",
            "Block 2: 0.0084 *\n",
            "Block 3: 0.0122 *\n",
            "stage2\n",
            "Block 0: 0.6761  \n",
            "Block 1: 0.2311  \n",
            "Block 2: 0.0519 *\n",
            "Block 3: 0.0409 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1755, Validation Accuracy: 95.75%\n",
            "Balanced Accuracy: 0.9595\n",
            "Tau: 0.7030\n",
            "\n",
            "Epoch 34/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0140, Train Accuracy: 99.53%\n",
            "Tau: 0.6940\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9526  \n",
            "Block 1: 0.0292  \n",
            "Block 2: 0.0077 *\n",
            "Block 3: 0.0105 *\n",
            "stage2\n",
            "Block 0: 0.6829  \n",
            "Block 1: 0.2294  \n",
            "Block 2: 0.0484 *\n",
            "Block 3: 0.0393 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1761, Validation Accuracy: 96.03%\n",
            "Balanced Accuracy: 0.9618\n",
            "Tau: 0.6940\n",
            "\n",
            "Epoch 35/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0119, Train Accuracy: 99.60%\n",
            "Tau: 0.6850\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9583  \n",
            "Block 1: 0.0255  \n",
            "Block 2: 0.0069 *\n",
            "Block 3: 0.0094 *\n",
            "stage2\n",
            "Block 0: 0.6887  \n",
            "Block 1: 0.2264  \n",
            "Block 2: 0.0473 *\n",
            "Block 3: 0.0376 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1582, Validation Accuracy: 96.28%\n",
            "Balanced Accuracy: 0.9638\n",
            "Tau: 0.6850\n",
            "\n",
            "Epoch 36/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0126, Train Accuracy: 99.57%\n",
            "Tau: 0.6760\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9614  \n",
            "Block 1: 0.0236  \n",
            "Block 2: 0.0064 *\n",
            "Block 3: 0.0086 *\n",
            "stage2\n",
            "Block 0: 0.6969  \n",
            "Block 1: 0.2213  \n",
            "Block 2: 0.0458 *\n",
            "Block 3: 0.0360 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1388, Validation Accuracy: 96.72%\n",
            "Balanced Accuracy: 0.9680\n",
            "Tau: 0.6760\n",
            "\n",
            "Epoch 37/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0123, Train Accuracy: 99.56%\n",
            "Tau: 0.6670\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9650  \n",
            "Block 1: 0.0216  \n",
            "Block 2: 0.0057 *\n",
            "Block 3: 0.0076 *\n",
            "stage2\n",
            "Block 0: 0.7100  \n",
            "Block 1: 0.2134  \n",
            "Block 2: 0.0431 *\n",
            "Block 3: 0.0335 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1586, Validation Accuracy: 96.24%\n",
            "Balanced Accuracy: 0.9631\n",
            "Tau: 0.6670\n",
            "\n",
            "Epoch 38/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0112, Train Accuracy: 99.61%\n",
            "Tau: 0.6580\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9677  \n",
            "Block 1: 0.0200  \n",
            "Block 2: 0.0053 *\n",
            "Block 3: 0.0070 *\n",
            "stage2\n",
            "Block 0: 0.7355  \n",
            "Block 1: 0.1955  \n",
            "Block 2: 0.0384 *\n",
            "Block 3: 0.0306 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1540, Validation Accuracy: 96.31%\n",
            "Balanced Accuracy: 0.9649\n",
            "Tau: 0.6580\n",
            "\n",
            "Epoch 39/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0118, Train Accuracy: 99.60%\n",
            "Tau: 0.6490\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9719  \n",
            "Block 1: 0.0173  \n",
            "Block 2: 0.0046 *\n",
            "Block 3: 0.0063 *\n",
            "stage2\n",
            "Block 0: 0.7482  \n",
            "Block 1: 0.1878  \n",
            "Block 2: 0.0361 *\n",
            "Block 3: 0.0279 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1450, Validation Accuracy: 96.72%\n",
            "Balanced Accuracy: 0.9688\n",
            "Tau: 0.6490\n",
            "\n",
            "Epoch 40/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0114, Train Accuracy: 99.59%\n",
            "Tau: 0.6400\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9738  \n",
            "Block 1: 0.0159  \n",
            "Block 2: 0.0043 *\n",
            "Block 3: 0.0060 *\n",
            "stage2\n",
            "Block 0: 0.7480  \n",
            "Block 1: 0.1897  \n",
            "Block 2: 0.0356 *\n",
            "Block 3: 0.0268 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1333, Validation Accuracy: 96.88%\n",
            "Balanced Accuracy: 0.9696\n",
            "Tau: 0.6400\n",
            "Model weights saved to HoViT_44_tinyfusion_base_r8a16_39.pth\n",
            "40 model test result:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1669, Test Accuracy: 96.43%\n",
            "Balanced Accuracy: 0.9655\n",
            "Tau: 0.0000\n",
            "\n",
            "Epoch 41/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0107, Train Accuracy: 99.64%\n",
            "Tau: 0.6310\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9761  \n",
            "Block 1: 0.0147  \n",
            "Block 2: 0.0038 *\n",
            "Block 3: 0.0054 *\n",
            "stage2\n",
            "Block 0: 0.7524  \n",
            "Block 1: 0.1853  \n",
            "Block 2: 0.0354 *\n",
            "Block 3: 0.0269 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1277, Validation Accuracy: 97.01%\n",
            "Balanced Accuracy: 0.9699\n",
            "Tau: 0.6310\n",
            "\n",
            "Epoch 42/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0099, Train Accuracy: 99.68%\n",
            "Tau: 0.6220\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9786  \n",
            "Block 1: 0.0130  \n",
            "Block 2: 0.0036 *\n",
            "Block 3: 0.0048 *\n",
            "stage2\n",
            "Block 0: 0.7496  \n",
            "Block 1: 0.1898  \n",
            "Block 2: 0.0346 *\n",
            "Block 3: 0.0260 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1478, Validation Accuracy: 96.54%\n",
            "Balanced Accuracy: 0.9673\n",
            "Tau: 0.6220\n",
            "\n",
            "Epoch 43/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0090, Train Accuracy: 99.71%\n",
            "Tau: 0.6130\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9808  \n",
            "Block 1: 0.0115  \n",
            "Block 2: 0.0034 *\n",
            "Block 3: 0.0044 *\n",
            "stage2\n",
            "Block 0: 0.7609  \n",
            "Block 1: 0.1822  \n",
            "Block 2: 0.0327 *\n",
            "Block 3: 0.0242 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1373, Validation Accuracy: 96.81%\n",
            "Balanced Accuracy: 0.9687\n",
            "Tau: 0.6130\n",
            "\n",
            "Epoch 44/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0103, Train Accuracy: 99.64%\n",
            "Tau: 0.6040\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9818  \n",
            "Block 1: 0.0109  \n",
            "Block 2: 0.0031 *\n",
            "Block 3: 0.0042 *\n",
            "stage2\n",
            "Block 0: 0.7648  \n",
            "Block 1: 0.1820  \n",
            "Block 2: 0.0307 *\n",
            "Block 3: 0.0224 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1435, Validation Accuracy: 96.81%\n",
            "Balanced Accuracy: 0.9681\n",
            "Tau: 0.6040\n",
            "\n",
            "Epoch 45/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0096, Train Accuracy: 99.66%\n",
            "Tau: 0.5950\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9829  \n",
            "Block 1: 0.0103  \n",
            "Block 2: 0.0030 *\n",
            "Block 3: 0.0039 *\n",
            "stage2\n",
            "Block 0: 0.7633  \n",
            "Block 1: 0.1867  \n",
            "Block 2: 0.0284 *\n",
            "Block 3: 0.0216 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1430, Validation Accuracy: 96.79%\n",
            "Balanced Accuracy: 0.9682\n",
            "Tau: 0.5950\n",
            "\n",
            "Epoch 46/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0099, Train Accuracy: 99.69%\n",
            "Tau: 0.5860\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9843  \n",
            "Block 1: 0.0094  \n",
            "Block 2: 0.0028 *\n",
            "Block 3: 0.0035 *\n",
            "stage2\n",
            "Block 0: 0.7661  \n",
            "Block 1: 0.1857  \n",
            "Block 2: 0.0278 *\n",
            "Block 3: 0.0204 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1474, Validation Accuracy: 96.74%\n",
            "Balanced Accuracy: 0.9682\n",
            "Tau: 0.5860\n",
            "\n",
            "Epoch 47/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0090, Train Accuracy: 99.67%\n",
            "Tau: 0.5770\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9854  \n",
            "Block 1: 0.0088  \n",
            "Block 2: 0.0026 *\n",
            "Block 3: 0.0032 *\n",
            "stage2\n",
            "Block 0: 0.7662  \n",
            "Block 1: 0.1865  \n",
            "Block 2: 0.0274 *\n",
            "Block 3: 0.0198 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1426, Validation Accuracy: 96.78%\n",
            "Balanced Accuracy: 0.9685\n",
            "Tau: 0.5770\n",
            "\n",
            "Epoch 48/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0078, Train Accuracy: 99.72%\n",
            "Tau: 0.5680\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9869  \n",
            "Block 1: 0.0077  \n",
            "Block 2: 0.0024 *\n",
            "Block 3: 0.0029 *\n",
            "stage2\n",
            "Block 0: 0.7816  \n",
            "Block 1: 0.1731  \n",
            "Block 2: 0.0258 *\n",
            "Block 3: 0.0196 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1413, Validation Accuracy: 96.95%\n",
            "Balanced Accuracy: 0.9706\n",
            "Tau: 0.5680\n",
            "\n",
            "Epoch 49/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0097, Train Accuracy: 99.65%\n",
            "Tau: 0.5590\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9874  \n",
            "Block 1: 0.0075  \n",
            "Block 2: 0.0023 *\n",
            "Block 3: 0.0028 *\n",
            "stage2\n",
            "Block 0: 0.7983  \n",
            "Block 1: 0.1608  \n",
            "Block 2: 0.0229 *\n",
            "Block 3: 0.0179 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1507, Validation Accuracy: 96.89%\n",
            "Balanced Accuracy: 0.9696\n",
            "Tau: 0.5590\n",
            "\n",
            "Epoch 50/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0086, Train Accuracy: 99.70%\n",
            "Tau: 0.5500\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9880  \n",
            "Block 1: 0.0071  \n",
            "Block 2: 0.0022 *\n",
            "Block 3: 0.0027 *\n",
            "stage2\n",
            "Block 0: 0.8210  \n",
            "Block 1: 0.1424  \n",
            "Block 2: 0.0205 *\n",
            "Block 3: 0.0160 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1487, Validation Accuracy: 97.07%\n",
            "Balanced Accuracy: 0.9710\n",
            "Tau: 0.5500\n",
            "Model weights saved to HoViT_44_tinyfusion_base_r8a16_49.pth\n",
            "50 model test result:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1762, Test Accuracy: 96.53%\n",
            "Balanced Accuracy: 0.9659\n",
            "Tau: 0.0000\n",
            "\n",
            "Epoch 51/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0085, Train Accuracy: 99.71%\n",
            "Tau: 0.5410\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9886  \n",
            "Block 1: 0.0067  \n",
            "Block 2: 0.0021 *\n",
            "Block 3: 0.0025 *\n",
            "stage2\n",
            "Block 0: 0.8241  \n",
            "Block 1: 0.1414  \n",
            "Block 2: 0.0195 *\n",
            "Block 3: 0.0150 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1392, Validation Accuracy: 97.23%\n",
            "Balanced Accuracy: 0.9728\n",
            "Tau: 0.5410\n",
            "\n",
            "Epoch 52/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0084, Train Accuracy: 99.71%\n",
            "Tau: 0.5320\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9896  \n",
            "Block 1: 0.0061  \n",
            "Block 2: 0.0019 *\n",
            "Block 3: 0.0023 *\n",
            "stage2\n",
            "Block 0: 0.8321  \n",
            "Block 1: 0.1351  \n",
            "Block 2: 0.0185 *\n",
            "Block 3: 0.0143 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1740, Validation Accuracy: 96.69%\n",
            "Balanced Accuracy: 0.9680\n",
            "Tau: 0.5320\n",
            "\n",
            "Epoch 53/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0078, Train Accuracy: 99.73%\n",
            "Tau: 0.5230\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9906  \n",
            "Block 1: 0.0055  \n",
            "Block 2: 0.0017 *\n",
            "Block 3: 0.0022 *\n",
            "stage2\n",
            "Block 0: 0.8466  \n",
            "Block 1: 0.1220  \n",
            "Block 2: 0.0174 *\n",
            "Block 3: 0.0140 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1523, Validation Accuracy: 96.95%\n",
            "Balanced Accuracy: 0.9705\n",
            "Tau: 0.5230\n",
            "\n",
            "Epoch 54/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0082, Train Accuracy: 99.70%\n",
            "Tau: 0.5140\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9912  \n",
            "Block 1: 0.0051  \n",
            "Block 2: 0.0016 *\n",
            "Block 3: 0.0020 *\n",
            "stage2\n",
            "Block 0: 0.8563  \n",
            "Block 1: 0.1147  \n",
            "Block 2: 0.0162 *\n",
            "Block 3: 0.0127 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1598, Validation Accuracy: 96.90%\n",
            "Balanced Accuracy: 0.9697\n",
            "Tau: 0.5140\n",
            "\n",
            "Epoch 55/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0091, Train Accuracy: 99.71%\n",
            "Tau: 0.5050\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9913  \n",
            "Block 1: 0.0051  \n",
            "Block 2: 0.0016 *\n",
            "Block 3: 0.0020 *\n",
            "stage2\n",
            "Block 0: 0.8630  \n",
            "Block 1: 0.1107  \n",
            "Block 2: 0.0146 *\n",
            "Block 3: 0.0117 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1435, Validation Accuracy: 97.32%\n",
            "Balanced Accuracy: 0.9737\n",
            "Tau: 0.5050\n",
            "\n",
            "Epoch 56/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0076, Train Accuracy: 99.75%\n",
            "Tau: 0.4960\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9920  \n",
            "Block 1: 0.0046  \n",
            "Block 2: 0.0016 *\n",
            "Block 3: 0.0019 *\n",
            "stage2\n",
            "Block 0: 0.8651  \n",
            "Block 1: 0.1100  \n",
            "Block 2: 0.0140 *\n",
            "Block 3: 0.0109 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1396, Validation Accuracy: 97.27%\n",
            "Balanced Accuracy: 0.9730\n",
            "Tau: 0.4960\n",
            "\n",
            "Epoch 57/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0069, Train Accuracy: 99.79%\n",
            "Tau: 0.4870\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9925  \n",
            "Block 1: 0.0043  \n",
            "Block 2: 0.0014 *\n",
            "Block 3: 0.0018 *\n",
            "stage2\n",
            "Block 0: 0.8750  \n",
            "Block 1: 0.1019  \n",
            "Block 2: 0.0130 *\n",
            "Block 3: 0.0101 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1528, Validation Accuracy: 96.97%\n",
            "Balanced Accuracy: 0.9703\n",
            "Tau: 0.4870\n",
            "\n",
            "Epoch 58/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0073, Train Accuracy: 99.75%\n",
            "Tau: 0.4780\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9933  \n",
            "Block 1: 0.0038  \n",
            "Block 2: 0.0013 *\n",
            "Block 3: 0.0016 *\n",
            "stage2\n",
            "Block 0: 0.8842  \n",
            "Block 1: 0.0938  \n",
            "Block 2: 0.0124 *\n",
            "Block 3: 0.0095 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1584, Validation Accuracy: 97.07%\n",
            "Balanced Accuracy: 0.9711\n",
            "Tau: 0.4780\n",
            "\n",
            "Epoch 59/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0081, Train Accuracy: 99.73%\n",
            "Tau: 0.4690\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9934  \n",
            "Block 1: 0.0037  \n",
            "Block 2: 0.0013 *\n",
            "Block 3: 0.0016 *\n",
            "stage2\n",
            "Block 0: 0.8870  \n",
            "Block 1: 0.0913  \n",
            "Block 2: 0.0120 *\n",
            "Block 3: 0.0097 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1479, Validation Accuracy: 97.33%\n",
            "Balanced Accuracy: 0.9734\n",
            "Tau: 0.4690\n",
            "\n",
            "Epoch 60/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0079, Train Accuracy: 99.73%\n",
            "Tau: 0.4600\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9938  \n",
            "Block 1: 0.0035  \n",
            "Block 2: 0.0012 *\n",
            "Block 3: 0.0015 *\n",
            "stage2\n",
            "Block 0: 0.8956  \n",
            "Block 1: 0.0842  \n",
            "Block 2: 0.0112 *\n",
            "Block 3: 0.0090 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1679, Validation Accuracy: 97.25%\n",
            "Balanced Accuracy: 0.9730\n",
            "Tau: 0.4600\n",
            "Model weights saved to HoViT_44_tinyfusion_base_r8a16_59.pth\n",
            "60 model test result:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1960, Test Accuracy: 96.87%\n",
            "Balanced Accuracy: 0.9694\n",
            "Tau: 0.0000\n",
            "\n",
            "Epoch 61/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0065, Train Accuracy: 99.79%\n",
            "Tau: 0.4510\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9942  \n",
            "Block 1: 0.0032  \n",
            "Block 2: 0.0012 *\n",
            "Block 3: 0.0014 *\n",
            "stage2\n",
            "Block 0: 0.8950  \n",
            "Block 1: 0.0853  \n",
            "Block 2: 0.0108 *\n",
            "Block 3: 0.0089 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1580, Validation Accuracy: 96.85%\n",
            "Balanced Accuracy: 0.9691\n",
            "Tau: 0.4510\n",
            "\n",
            "Epoch 62/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0077, Train Accuracy: 99.75%\n",
            "Tau: 0.4420\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9946  \n",
            "Block 1: 0.0030  \n",
            "Block 2: 0.0011 *\n",
            "Block 3: 0.0013 *\n",
            "stage2\n",
            "Block 0: 0.8978  \n",
            "Block 1: 0.0833  \n",
            "Block 2: 0.0103 *\n",
            "Block 3: 0.0085 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1654, Validation Accuracy: 97.29%\n",
            "Balanced Accuracy: 0.9728\n",
            "Tau: 0.4420\n",
            "\n",
            "Epoch 63/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0066, Train Accuracy: 99.78%\n",
            "Tau: 0.4330\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9947  \n",
            "Block 1: 0.0029  \n",
            "Block 2: 0.0011 *\n",
            "Block 3: 0.0013 *\n",
            "stage2\n",
            "Block 0: 0.9070  \n",
            "Block 1: 0.0753  \n",
            "Block 2: 0.0097 *\n",
            "Block 3: 0.0080 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1452, Validation Accuracy: 97.48%\n",
            "Balanced Accuracy: 0.9747\n",
            "Tau: 0.4330\n",
            "\n",
            "Epoch 64/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0065, Train Accuracy: 99.78%\n",
            "Tau: 0.4240\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9951  \n",
            "Block 1: 0.0028  \n",
            "Block 2: 0.0010 *\n",
            "Block 3: 0.0012 *\n",
            "stage2\n",
            "Block 0: 0.9184  \n",
            "Block 1: 0.0657  \n",
            "Block 2: 0.0086 *\n",
            "Block 3: 0.0073 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1544, Validation Accuracy: 97.16%\n",
            "Balanced Accuracy: 0.9716\n",
            "Tau: 0.4240\n",
            "\n",
            "Epoch 65/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0065, Train Accuracy: 99.78%\n",
            "Tau: 0.4150\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9953  \n",
            "Block 1: 0.0026  \n",
            "Block 2: 0.0010 *\n",
            "Block 3: 0.0011 *\n",
            "stage2\n",
            "Block 0: 0.9222  \n",
            "Block 1: 0.0624  \n",
            "Block 2: 0.0084 *\n",
            "Block 3: 0.0070 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1684, Validation Accuracy: 96.99%\n",
            "Balanced Accuracy: 0.9705\n",
            "Tau: 0.4150\n",
            "\n",
            "Epoch 66/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0072, Train Accuracy: 99.77%\n",
            "Tau: 0.4060\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9956  \n",
            "Block 1: 0.0025  \n",
            "Block 2: 0.0009 *\n",
            "Block 3: 0.0011 *\n",
            "stage2\n",
            "Block 0: 0.9260  \n",
            "Block 1: 0.0595  \n",
            "Block 2: 0.0080 *\n",
            "Block 3: 0.0065 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1666, Validation Accuracy: 97.11%\n",
            "Balanced Accuracy: 0.9714\n",
            "Tau: 0.4060\n",
            "\n",
            "Epoch 67/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0059, Train Accuracy: 99.79%\n",
            "Tau: 0.3970\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9958  \n",
            "Block 1: 0.0023  \n",
            "Block 2: 0.0009 *\n",
            "Block 3: 0.0010 *\n",
            "stage2\n",
            "Block 0: 0.9279  \n",
            "Block 1: 0.0580  \n",
            "Block 2: 0.0077 *\n",
            "Block 3: 0.0064 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1772, Validation Accuracy: 97.18%\n",
            "Balanced Accuracy: 0.9726\n",
            "Tau: 0.3970\n",
            "\n",
            "Epoch 68/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0058, Train Accuracy: 99.81%\n",
            "Tau: 0.3880\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9959  \n",
            "Block 1: 0.0021  \n",
            "Block 2: 0.0009 *\n",
            "Block 3: 0.0010 *\n",
            "stage2\n",
            "Block 0: 0.9298  \n",
            "Block 1: 0.0567  \n",
            "Block 2: 0.0074 *\n",
            "Block 3: 0.0062 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1564, Validation Accuracy: 97.25%\n",
            "Balanced Accuracy: 0.9725\n",
            "Tau: 0.3880\n",
            "\n",
            "Epoch 69/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0064, Train Accuracy: 99.78%\n",
            "Tau: 0.3790\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9962  \n",
            "Block 1: 0.0020  \n",
            "Block 2: 0.0008 *\n",
            "Block 3: 0.0010 *\n",
            "stage2\n",
            "Block 0: 0.9341  \n",
            "Block 1: 0.0531  \n",
            "Block 2: 0.0068 *\n",
            "Block 3: 0.0060 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1576, Validation Accuracy: 97.21%\n",
            "Balanced Accuracy: 0.9725\n",
            "Tau: 0.3790\n",
            "\n",
            "Epoch 70/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0061, Train Accuracy: 99.81%\n",
            "Tau: 0.3700\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9964  \n",
            "Block 1: 0.0019  \n",
            "Block 2: 0.0008 *\n",
            "Block 3: 0.0009 *\n",
            "stage2\n",
            "Block 0: 0.9377  \n",
            "Block 1: 0.0500  \n",
            "Block 2: 0.0065 *\n",
            "Block 3: 0.0057 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1621, Validation Accuracy: 97.21%\n",
            "Balanced Accuracy: 0.9726\n",
            "Tau: 0.3700\n",
            "Model weights saved to HoViT_44_tinyfusion_base_r8a16_69.pth\n",
            "70 model test result:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1798, Test Accuracy: 97.07%\n",
            "Balanced Accuracy: 0.9718\n",
            "Tau: 0.0000\n",
            "\n",
            "Epoch 71/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0053, Train Accuracy: 99.82%\n",
            "Tau: 0.3610\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9965  \n",
            "Block 1: 0.0019  \n",
            "Block 2: 0.0007 *\n",
            "Block 3: 0.0009 *\n",
            "stage2\n",
            "Block 0: 0.9422  \n",
            "Block 1: 0.0465  \n",
            "Block 2: 0.0061 *\n",
            "Block 3: 0.0052 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1965, Validation Accuracy: 96.60%\n",
            "Balanced Accuracy: 0.9659\n",
            "Tau: 0.3610\n",
            "\n",
            "Epoch 72/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0058, Train Accuracy: 99.80%\n",
            "Tau: 0.3520\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9966  \n",
            "Block 1: 0.0018  \n",
            "Block 2: 0.0007 *\n",
            "Block 3: 0.0009 *\n",
            "stage2\n",
            "Block 0: 0.9470  \n",
            "Block 1: 0.0425  \n",
            "Block 2: 0.0056 *\n",
            "Block 3: 0.0048 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1456, Validation Accuracy: 97.31%\n",
            "Balanced Accuracy: 0.9737\n",
            "Tau: 0.3520\n",
            "\n",
            "Epoch 73/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0056, Train Accuracy: 99.80%\n",
            "Tau: 0.3430\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9968  \n",
            "Block 1: 0.0017  \n",
            "Block 2: 0.0007 *\n",
            "Block 3: 0.0008 *\n",
            "stage2\n",
            "Block 0: 0.9492  \n",
            "Block 1: 0.0408  \n",
            "Block 2: 0.0053 *\n",
            "Block 3: 0.0047 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1593, Validation Accuracy: 97.19%\n",
            "Balanced Accuracy: 0.9722\n",
            "Tau: 0.3430\n",
            "\n",
            "Epoch 74/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0057, Train Accuracy: 99.80%\n",
            "Tau: 0.3340\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9969  \n",
            "Block 1: 0.0016  \n",
            "Block 2: 0.0007 *\n",
            "Block 3: 0.0008 *\n",
            "stage2\n",
            "Block 0: 0.9518  \n",
            "Block 1: 0.0386  \n",
            "Block 2: 0.0051 *\n",
            "Block 3: 0.0045 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1641, Validation Accuracy: 97.34%\n",
            "Balanced Accuracy: 0.9738\n",
            "Tau: 0.3340\n",
            "\n",
            "Epoch 75/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0054, Train Accuracy: 99.81%\n",
            "Tau: 0.3250\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9970  \n",
            "Block 1: 0.0015  \n",
            "Block 2: 0.0007 *\n",
            "Block 3: 0.0008 *\n",
            "stage2\n",
            "Block 0: 0.9560  \n",
            "Block 1: 0.0349  \n",
            "Block 2: 0.0049 *\n",
            "Block 3: 0.0042 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1614, Validation Accuracy: 97.33%\n",
            "Balanced Accuracy: 0.9733\n",
            "Tau: 0.3250\n",
            "\n",
            "Epoch 76/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0055, Train Accuracy: 99.82%\n",
            "Tau: 0.3160\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9971  \n",
            "Block 1: 0.0015  \n",
            "Block 2: 0.0006 *\n",
            "Block 3: 0.0008 *\n",
            "stage2\n",
            "Block 0: 0.9593  \n",
            "Block 1: 0.0322  \n",
            "Block 2: 0.0045 *\n",
            "Block 3: 0.0040 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1631, Validation Accuracy: 97.43%\n",
            "Balanced Accuracy: 0.9742\n",
            "Tau: 0.3160\n",
            "\n",
            "Epoch 77/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0059, Train Accuracy: 99.79%\n",
            "Tau: 0.3070\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9973  \n",
            "Block 1: 0.0014  \n",
            "Block 2: 0.0006 *\n",
            "Block 3: 0.0007 *\n",
            "stage2\n",
            "Block 0: 0.9622  \n",
            "Block 1: 0.0298  \n",
            "Block 2: 0.0042 *\n",
            "Block 3: 0.0038 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1508, Validation Accuracy: 97.48%\n",
            "Balanced Accuracy: 0.9752\n",
            "Tau: 0.3070\n",
            "\n",
            "Epoch 78/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0045, Train Accuracy: 99.86%\n",
            "Tau: 0.2980\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9973  \n",
            "Block 1: 0.0014  \n",
            "Block 2: 0.0006 *\n",
            "Block 3: 0.0007 *\n",
            "stage2\n",
            "Block 0: 0.9633  \n",
            "Block 1: 0.0289  \n",
            "Block 2: 0.0041 *\n",
            "Block 3: 0.0037 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1567, Validation Accuracy: 97.31%\n",
            "Balanced Accuracy: 0.9729\n",
            "Tau: 0.2980\n",
            "\n",
            "Epoch 79/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0057, Train Accuracy: 99.81%\n",
            "Tau: 0.2890\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9974  \n",
            "Block 1: 0.0013  \n",
            "Block 2: 0.0006 *\n",
            "Block 3: 0.0007 *\n",
            "stage2\n",
            "Block 0: 0.9646  \n",
            "Block 1: 0.0278  \n",
            "Block 2: 0.0039 *\n",
            "Block 3: 0.0036 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1633, Validation Accuracy: 97.20%\n",
            "Balanced Accuracy: 0.9726\n",
            "Tau: 0.2890\n",
            "\n",
            "Epoch 80/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0055, Train Accuracy: 99.82%\n",
            "Tau: 0.2800\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9974  \n",
            "Block 1: 0.0013  \n",
            "Block 2: 0.0006 *\n",
            "Block 3: 0.0007 *\n",
            "stage2\n",
            "Block 0: 0.9666  \n",
            "Block 1: 0.0262  \n",
            "Block 2: 0.0038 *\n",
            "Block 3: 0.0034 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1695, Validation Accuracy: 97.25%\n",
            "Balanced Accuracy: 0.9725\n",
            "Tau: 0.2800\n",
            "Model weights saved to HoViT_44_tinyfusion_base_r8a16_79.pth\n",
            "80 model test result:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1879, Test Accuracy: 97.15%\n",
            "Balanced Accuracy: 0.9718\n",
            "Tau: 0.0000\n",
            "\n",
            "Epoch 81/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0051, Train Accuracy: 99.82%\n",
            "Tau: 0.2710\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9975  \n",
            "Block 1: 0.0013  \n",
            "Block 2: 0.0006 *\n",
            "Block 3: 0.0007 *\n",
            "stage2\n",
            "Block 0: 0.9680  \n",
            "Block 1: 0.0250  \n",
            "Block 2: 0.0037 *\n",
            "Block 3: 0.0033 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1733, Validation Accuracy: 97.16%\n",
            "Balanced Accuracy: 0.9719\n",
            "Tau: 0.2710\n",
            "\n",
            "Epoch 82/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0052, Train Accuracy: 99.82%\n",
            "Tau: 0.2620\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9976  \n",
            "Block 1: 0.0012  \n",
            "Block 2: 0.0005 *\n",
            "Block 3: 0.0006 *\n",
            "stage2\n",
            "Block 0: 0.9699  \n",
            "Block 1: 0.0232  \n",
            "Block 2: 0.0037 *\n",
            "Block 3: 0.0032 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1832, Validation Accuracy: 97.24%\n",
            "Balanced Accuracy: 0.9728\n",
            "Tau: 0.2620\n",
            "\n",
            "Epoch 83/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0052, Train Accuracy: 99.81%\n",
            "Tau: 0.2530\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9976  \n",
            "Block 1: 0.0012  \n",
            "Block 2: 0.0005 *\n",
            "Block 3: 0.0006 *\n",
            "stage2\n",
            "Block 0: 0.9694  \n",
            "Block 1: 0.0237  \n",
            "Block 2: 0.0037 *\n",
            "Block 3: 0.0032 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1545, Validation Accuracy: 97.43%\n",
            "Balanced Accuracy: 0.9746\n",
            "Tau: 0.2530\n",
            "\n",
            "Epoch 84/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0054, Train Accuracy: 99.82%\n",
            "Tau: 0.2440\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9977  \n",
            "Block 1: 0.0012  \n",
            "Block 2: 0.0005 *\n",
            "Block 3: 0.0006 *\n",
            "stage2\n",
            "Block 0: 0.9711  \n",
            "Block 1: 0.0222  \n",
            "Block 2: 0.0036 *\n",
            "Block 3: 0.0032 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1575, Validation Accuracy: 97.45%\n",
            "Balanced Accuracy: 0.9750\n",
            "Tau: 0.2440\n",
            "\n",
            "Epoch 85/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0047, Train Accuracy: 99.83%\n",
            "Tau: 0.2350\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9978  \n",
            "Block 1: 0.0012  \n",
            "Block 2: 0.0005 *\n",
            "Block 3: 0.0006 *\n",
            "stage2\n",
            "Block 0: 0.9718  \n",
            "Block 1: 0.0218  \n",
            "Block 2: 0.0035 *\n",
            "Block 3: 0.0030 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1631, Validation Accuracy: 97.36%\n",
            "Balanced Accuracy: 0.9733\n",
            "Tau: 0.2350\n",
            "\n",
            "Epoch 86/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0046, Train Accuracy: 99.84%\n",
            "Tau: 0.2260\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9978  \n",
            "Block 1: 0.0011  \n",
            "Block 2: 0.0005 *\n",
            "Block 3: 0.0006 *\n",
            "stage2\n",
            "Block 0: 0.9749  \n",
            "Block 1: 0.0191  \n",
            "Block 2: 0.0032 *\n",
            "Block 3: 0.0028 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1638, Validation Accuracy: 97.47%\n",
            "Balanced Accuracy: 0.9750\n",
            "Tau: 0.2260\n",
            "\n",
            "Epoch 87/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0048, Train Accuracy: 99.82%\n",
            "Tau: 0.2170\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9978  \n",
            "Block 1: 0.0011  \n",
            "Block 2: 0.0005 *\n",
            "Block 3: 0.0005 *\n",
            "stage2\n",
            "Block 0: 0.9762  \n",
            "Block 1: 0.0181  \n",
            "Block 2: 0.0031 *\n",
            "Block 3: 0.0027 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1595, Validation Accuracy: 97.55%\n",
            "Balanced Accuracy: 0.9752\n",
            "Tau: 0.2170\n",
            "\n",
            "Epoch 88/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0047, Train Accuracy: 99.84%\n",
            "Tau: 0.2080\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9980  \n",
            "Block 1: 0.0011  \n",
            "Block 2: 0.0005 *\n",
            "Block 3: 0.0005 *\n",
            "stage2\n",
            "Block 0: 0.9769  \n",
            "Block 1: 0.0174  \n",
            "Block 2: 0.0030 *\n",
            "Block 3: 0.0026 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1639, Validation Accuracy: 97.43%\n",
            "Balanced Accuracy: 0.9742\n",
            "Tau: 0.2080\n",
            "\n",
            "Epoch 89/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0056, Train Accuracy: 99.81%\n",
            "Tau: 0.1990\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9980  \n",
            "Block 1: 0.0010  \n",
            "Block 2: 0.0004 *\n",
            "Block 3: 0.0005 *\n",
            "stage2\n",
            "Block 0: 0.9788  \n",
            "Block 1: 0.0159  \n",
            "Block 2: 0.0028 *\n",
            "Block 3: 0.0025 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1765, Validation Accuracy: 97.33%\n",
            "Balanced Accuracy: 0.9734\n",
            "Tau: 0.1990\n",
            "\n",
            "Epoch 90/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0041, Train Accuracy: 99.86%\n",
            "Tau: 0.1900\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9981  \n",
            "Block 1: 0.0010  \n",
            "Block 2: 0.0004 *\n",
            "Block 3: 0.0005 *\n",
            "stage2\n",
            "Block 0: 0.9804  \n",
            "Block 1: 0.0147  \n",
            "Block 2: 0.0027 *\n",
            "Block 3: 0.0023 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1575, Validation Accuracy: 97.31%\n",
            "Balanced Accuracy: 0.9731\n",
            "Tau: 0.1900\n",
            "Model weights saved to HoViT_44_tinyfusion_base_r8a16_89.pth\n",
            "90 model test result:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1819, Test Accuracy: 97.20%\n",
            "Balanced Accuracy: 0.9724\n",
            "Tau: 0.0000\n",
            "\n",
            "Epoch 91/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0045, Train Accuracy: 99.86%\n",
            "Tau: 0.1810\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9982  \n",
            "Block 1: 0.0010  \n",
            "Block 2: 0.0004 *\n",
            "Block 3: 0.0005 *\n",
            "stage2\n",
            "Block 0: 0.9808  \n",
            "Block 1: 0.0143  \n",
            "Block 2: 0.0026 *\n",
            "Block 3: 0.0023 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1599, Validation Accuracy: 97.35%\n",
            "Balanced Accuracy: 0.9744\n",
            "Tau: 0.1810\n",
            "\n",
            "Epoch 92/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0048, Train Accuracy: 99.84%\n",
            "Tau: 0.1720\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9982  \n",
            "Block 1: 0.0009  \n",
            "Block 2: 0.0004 *\n",
            "Block 3: 0.0005 *\n",
            "stage2\n",
            "Block 0: 0.9820  \n",
            "Block 1: 0.0134  \n",
            "Block 2: 0.0025 *\n",
            "Block 3: 0.0021 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1565, Validation Accuracy: 97.51%\n",
            "Balanced Accuracy: 0.9748\n",
            "Tau: 0.1720\n",
            "\n",
            "Epoch 93/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0045, Train Accuracy: 99.87%\n",
            "Tau: 0.1630\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9983  \n",
            "Block 1: 0.0009  \n",
            "Block 2: 0.0004 *\n",
            "Block 3: 0.0005 *\n",
            "stage2\n",
            "Block 0: 0.9823  \n",
            "Block 1: 0.0132  \n",
            "Block 2: 0.0024 *\n",
            "Block 3: 0.0021 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1733, Validation Accuracy: 97.11%\n",
            "Balanced Accuracy: 0.9715\n",
            "Tau: 0.1630\n",
            "\n",
            "Epoch 94/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0048, Train Accuracy: 99.83%\n",
            "Tau: 0.1540\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9983  \n",
            "Block 1: 0.0009  \n",
            "Block 2: 0.0004 *\n",
            "Block 3: 0.0004 *\n",
            "stage2\n",
            "Block 0: 0.9834  \n",
            "Block 1: 0.0122  \n",
            "Block 2: 0.0024 *\n",
            "Block 3: 0.0020 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1566, Validation Accuracy: 97.39%\n",
            "Balanced Accuracy: 0.9737\n",
            "Tau: 0.1540\n",
            "\n",
            "Epoch 95/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:55<00:00, 12.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0050, Train Accuracy: 99.84%\n",
            "Tau: 0.1450\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9984  \n",
            "Block 1: 0.0009  \n",
            "Block 2: 0.0004 *\n",
            "Block 3: 0.0004 *\n",
            "stage2\n",
            "Block 0: 0.9833  \n",
            "Block 1: 0.0123  \n",
            "Block 2: 0.0024 *\n",
            "Block 3: 0.0020 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1634, Validation Accuracy: 97.29%\n",
            "Balanced Accuracy: 0.9726\n",
            "Tau: 0.1450\n",
            "\n",
            "Epoch 96/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0043, Train Accuracy: 99.85%\n",
            "Tau: 0.1360\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9984  \n",
            "Block 1: 0.0008  \n",
            "Block 2: 0.0004 *\n",
            "Block 3: 0.0004 *\n",
            "stage2\n",
            "Block 0: 0.9837  \n",
            "Block 1: 0.0119  \n",
            "Block 2: 0.0023 *\n",
            "Block 3: 0.0020 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1604, Validation Accuracy: 97.49%\n",
            "Balanced Accuracy: 0.9753\n",
            "Tau: 0.1360\n",
            "\n",
            "Epoch 97/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0051, Train Accuracy: 99.84%\n",
            "Tau: 0.1270\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9984  \n",
            "Block 1: 0.0008  \n",
            "Block 2: 0.0004 *\n",
            "Block 3: 0.0004 *\n",
            "stage2\n",
            "Block 0: 0.9831  \n",
            "Block 1: 0.0125  \n",
            "Block 2: 0.0024 *\n",
            "Block 3: 0.0021 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1491, Validation Accuracy: 97.52%\n",
            "Balanced Accuracy: 0.9748\n",
            "Tau: 0.1270\n",
            "\n",
            "Epoch 98/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0039, Train Accuracy: 99.87%\n",
            "Tau: 0.1180\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9985  \n",
            "Block 1: 0.0008  \n",
            "Block 2: 0.0003 *\n",
            "Block 3: 0.0004 *\n",
            "stage2\n",
            "Block 0: 0.9828  \n",
            "Block 1: 0.0128  \n",
            "Block 2: 0.0024 *\n",
            "Block 3: 0.0020 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1564, Validation Accuracy: 97.42%\n",
            "Balanced Accuracy: 0.9744\n",
            "Tau: 0.1180\n",
            "\n",
            "Epoch 99/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0038, Train Accuracy: 99.87%\n",
            "Tau: 0.1090\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9985  \n",
            "Block 1: 0.0008  \n",
            "Block 2: 0.0003 *\n",
            "Block 3: 0.0004 *\n",
            "stage2\n",
            "Block 0: 0.9836  \n",
            "Block 1: 0.0122  \n",
            "Block 2: 0.0023 *\n",
            "Block 3: 0.0020 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1717, Validation Accuracy: 97.35%\n",
            "Balanced Accuracy: 0.9741\n",
            "Tau: 0.1090\n",
            "\n",
            "Epoch 100/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:53<00:00, 12.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0043, Train Accuracy: 99.86%\n",
            "Tau: 0.1000\n",
            "Each stage of block probabilities:\n",
            "stage1\n",
            "Block 0: 0.9985  \n",
            "Block 1: 0.0008  \n",
            "Block 2: 0.0003 *\n",
            "Block 3: 0.0004 *\n",
            "stage2\n",
            "Block 0: 0.9833  \n",
            "Block 1: 0.0124  \n",
            "Block 2: 0.0022 *\n",
            "Block 3: 0.0020 *\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1578, Validation Accuracy: 97.50%\n",
            "Balanced Accuracy: 0.9751\n",
            "Tau: 0.1000\n",
            "Model weights saved to HoViT_44_tinyfusion_base_r8a16_99.pth\n",
            "100 model test result:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1810, Test Accuracy: 97.27%\n",
            "Balanced Accuracy: 0.9733\n",
            "Tau: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, phase=\"Validation\", epoch=epoch)\n",
        "    if((epoch+1) % 10 == 0 and epoch > 30):\n",
        "        save_path = f\"HoViT_44_tinyfusion_base_r8a16_{epoch}.pth\"\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Model weights saved to {save_path}\")\n",
        "        print(f\"{epoch+1} model test result:\")\n",
        "        evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "yq3Yxnau6V3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1611e987-f462-49b4-f989-0b8a8bc22d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1807, Test Accuracy: 97.27%\n",
            "Balanced Accuracy: 0.9733\n",
            "Tau: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "dlazeL-a0WTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7630e568-7a0a-45de-941c-a6d194903315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 7.44 ms\n",
            "Standard Deviation: 0.39 ms\n",
            "Maximum Time: 11.39 ms\n",
            "Minimum Time: 7.06 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "c77rmtOz0XuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbccf8fa-ddcd-4f4d-dfa2-7e03027cb299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         2.16%     303.637us        14.20%       1.993ms      71.162us       0.000us         0.00%       1.508ms      53.867us            28  \n",
            "                                           aten::linear         0.93%     130.494us        12.26%       1.720ms      66.163us       0.000us         0.00%       1.167ms      44.896us            26  \n",
            "                                               aten::mm         5.39%     756.059us         7.87%       1.105ms      46.050us       1.144ms        34.65%       1.144ms      47.676us            24  \n",
            "                                           aten::conv2d         1.18%     166.244us        22.48%       3.155ms     525.850us       0.000us         0.00%     613.050us     102.175us             6  \n",
            "                                      aten::convolution         0.43%      59.952us        21.30%       2.989ms     498.143us       0.000us         0.00%     613.050us     102.175us             6  \n",
            "                                     aten::_convolution        10.85%       1.523ms        20.87%       2.929ms     488.151us       0.000us         0.00%     613.050us     102.175us             6  \n",
            "                                aten::cudnn_convolution         7.73%       1.084ms         9.62%       1.350ms     225.043us     598.042us        18.11%     598.042us      99.674us             6  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     408.829us        12.38%     408.829us      45.425us             9  \n",
            "                                       aten::batch_norm         0.62%      86.818us        36.39%       5.107ms     340.479us       0.000us         0.00%     350.559us      23.371us            15  \n",
            "                           aten::_batch_norm_impl_index         1.78%     250.238us        35.77%       5.020ms     334.691us       0.000us         0.00%     350.559us      23.371us            15  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 14.034ms\n",
            "Self CUDA time total: 3.302ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input, tau=0.1)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs, tau=0.1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_moDYMWp3KH",
        "outputId": "09e43868-df72-4786-9cd3-76e383cb36f5"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:21<00:00, 21.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1806, Test Accuracy: 97.25%\n",
            "Overall - F1: 0.9724, Recall: 0.9732, Precision: 0.9718\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9936, Recall: 0.9955, Precision: 0.9917\n",
            "Class 1 - F1: 0.9978, Recall: 0.9994, Precision: 0.9962\n",
            "Class 2 - F1: 0.9686, Recall: 0.9739, Precision: 0.9633\n",
            "Class 3 - F1: 0.9939, Recall: 0.9919, Precision: 0.9959\n",
            "Class 4 - F1: 0.9669, Recall: 0.9738, Precision: 0.9601\n",
            "Class 5 - F1: 0.9617, Recall: 0.9581, Precision: 0.9653\n",
            "Class 6 - F1: 0.9715, Recall: 0.9833, Precision: 0.9599\n",
            "Class 7 - F1: 0.9238, Recall: 0.9164, Precision: 0.9313\n",
            "Class 8 - F1: 0.9742, Recall: 0.9665, Precision: 0.9820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "xbSpMMWGk3bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02cf03f4-12de-46db-a819-f672e15980cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-27 09:06:41--  https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.45.92, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 800276929 (763M) [application/octet-stream]\n",
            "Saving to: ‘CRC-VAL-HE-7K.zip’\n",
            "\n",
            "CRC-VAL-HE-7K.zip   100%[===================>] 763.20M  24.8MB/s    in 5m 44s  \n",
            "\n",
            "2025-02-27 09:12:26 (2.22 MB/s) - ‘CRC-VAL-HE-7K.zip’ saved [800276929/800276929]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O CRC-VAL-HE-7K.zip https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
        "!unzip -qq CRC-VAL-HE-7K.zip -d val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "rldaXFNXpT4r"
      },
      "outputs": [],
      "source": [
        "test_7k_dir = './val/CRC-VAL-HE-7K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(root=test_7k_dir, transform=transform)"
      ],
      "metadata": {
        "id": "p0bL6aK1sQOb"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "Belqw8QytnZL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#test7k_dataset = Dataset(dir=test_7k_dir, aug=False)\n",
        "#test7k_dataloader = DataLoader(test7k_dataset, batch_size=32, shuffle=False, num_workers=8, pin_memory=False, drop_last=False)\n",
        "test7k_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2y3cywDpjUQ",
        "outputId": "3f86e961-ef80-4c3a-c6f9-59485a921c23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 225/225 [00:10<00:00, 21.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.7122, Test Accuracy: 89.87%\n",
            "Overall - F1: 0.8661, Recall: 0.8747, Precision: 0.8645\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9648, Recall: 0.9619, Precision: 0.9677\n",
            "Class 1 - F1: 0.9941, Recall: 1.0000, Precision: 0.9883\n",
            "Class 2 - F1: 0.8112, Recall: 0.9440, Precision: 0.7111\n",
            "Class 3 - F1: 0.8569, Recall: 0.7792, Precision: 0.9518\n",
            "Class 4 - F1: 0.9239, Recall: 0.8850, Precision: 0.9662\n",
            "Class 5 - F1: 0.7946, Recall: 0.7973, Precision: 0.7919\n",
            "Class 6 - F1: 0.8764, Recall: 0.9474, Precision: 0.8153\n",
            "Class 7 - F1: 0.6260, Recall: 0.6223, Precision: 0.6298\n",
            "Class 8 - F1: 0.9466, Recall: 0.9351, Precision: 0.9584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test7k_dataloader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "p4pYjMPUpy2m",
        "outputId": "b5b3e8f3-e03c-45b5-f8b4-c515df1bc51c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "5EnagUDtpzDU",
        "outputId": "fd07624b-db27-4dd9-f795-f9953829edb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 225\n",
            "Average Time: 7.50 ms\n",
            "Standard Deviation: 0.41 ms\n",
            "Maximum Time: 9.23 ms\n",
            "Minimum Time: 7.06 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test7k_dataloader, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}