{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZ4WpzfV-Tjs",
    "outputId": "4124c1c4-0f24-4630-9a9e-03461362d703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fIkD9oN5-Tjt"
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import itertools\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pRfXGTlB-Tjt"
   },
   "outputs": [],
   "source": [
    "ViT = timm.create_model('vit_base_patch16_224', pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-zh9808W-Tjt"
   },
   "outputs": [],
   "source": [
    "model = ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1nJ8zxl-Tjt",
    "outputId": "8eed939d-232d-4015-e32f-5f525f6a5a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (patch_drop): Identity()\n",
      "  (norm_pre): Identity()\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (fc_norm): Identity()\n",
      "  (head_drop): Dropout(p=0.0, inplace=False)\n",
      "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QHwNG0O0-Tju",
    "outputId": "ab4e496a-a24a-492f-c469-0164e3c8a8b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "VisionTransformer                        [32, 1000]                152,064\n",
      "├─PatchEmbed: 1-1                        [32, 196, 768]            --\n",
      "│    └─Conv2d: 2-1                       [32, 768, 14, 14]         590,592\n",
      "│    └─Identity: 2-2                     [32, 196, 768]            --\n",
      "├─Dropout: 1-2                           [32, 197, 768]            --\n",
      "├─Identity: 1-3                          [32, 197, 768]            --\n",
      "├─Identity: 1-4                          [32, 197, 768]            --\n",
      "├─Sequential: 1-5                        [32, 197, 768]            --\n",
      "│    └─Block: 2-3                        [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-1               [32, 197, 768]            1,536\n",
      "│    │    └─Attention: 3-2               [32, 197, 768]            2,362,368\n",
      "│    │    └─Identity: 3-3                [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-4                [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-5               [32, 197, 768]            1,536\n",
      "│    │    └─Mlp: 3-6                     [32, 197, 768]            4,722,432\n",
      "│    │    └─Identity: 3-7                [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-8                [32, 197, 768]            --\n",
      "│    └─Block: 2-4                        [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-9               [32, 197, 768]            1,536\n",
      "│    │    └─Attention: 3-10              [32, 197, 768]            2,362,368\n",
      "│    │    └─Identity: 3-11               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-12               [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-13              [32, 197, 768]            1,536\n",
      "│    │    └─Mlp: 3-14                    [32, 197, 768]            4,722,432\n",
      "│    │    └─Identity: 3-15               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-16               [32, 197, 768]            --\n",
      "│    └─Block: 2-5                        [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-17              [32, 197, 768]            1,536\n",
      "│    │    └─Attention: 3-18              [32, 197, 768]            2,362,368\n",
      "│    │    └─Identity: 3-19               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-20               [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-21              [32, 197, 768]            1,536\n",
      "│    │    └─Mlp: 3-22                    [32, 197, 768]            4,722,432\n",
      "│    │    └─Identity: 3-23               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-24               [32, 197, 768]            --\n",
      "│    └─Block: 2-6                        [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-25              [32, 197, 768]            1,536\n",
      "│    │    └─Attention: 3-26              [32, 197, 768]            2,362,368\n",
      "│    │    └─Identity: 3-27               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-28               [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-29              [32, 197, 768]            1,536\n",
      "│    │    └─Mlp: 3-30                    [32, 197, 768]            4,722,432\n",
      "│    │    └─Identity: 3-31               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-32               [32, 197, 768]            --\n",
      "│    └─Block: 2-7                        [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-33              [32, 197, 768]            1,536\n",
      "│    │    └─Attention: 3-34              [32, 197, 768]            2,362,368\n",
      "│    │    └─Identity: 3-35               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-36               [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-37              [32, 197, 768]            1,536\n",
      "│    │    └─Mlp: 3-38                    [32, 197, 768]            4,722,432\n",
      "│    │    └─Identity: 3-39               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-40               [32, 197, 768]            --\n",
      "│    └─Block: 2-8                        [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-41              [32, 197, 768]            1,536\n",
      "│    │    └─Attention: 3-42              [32, 197, 768]            2,362,368\n",
      "│    │    └─Identity: 3-43               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-44               [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-45              [32, 197, 768]            1,536\n",
      "│    │    └─Mlp: 3-46                    [32, 197, 768]            4,722,432\n",
      "│    │    └─Identity: 3-47               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-48               [32, 197, 768]            --\n",
      "│    └─Block: 2-9                        [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-49              [32, 197, 768]            1,536\n",
      "│    │    └─Attention: 3-50              [32, 197, 768]            2,362,368\n",
      "│    │    └─Identity: 3-51               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-52               [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-53              [32, 197, 768]            1,536\n",
      "│    │    └─Mlp: 3-54                    [32, 197, 768]            4,722,432\n",
      "│    │    └─Identity: 3-55               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-56               [32, 197, 768]            --\n",
      "│    └─Block: 2-10                       [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-57              [32, 197, 768]            1,536\n",
      "│    │    └─Attention: 3-58              [32, 197, 768]            2,362,368\n",
      "│    │    └─Identity: 3-59               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-60               [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-61              [32, 197, 768]            1,536\n",
      "│    │    └─Mlp: 3-62                    [32, 197, 768]            4,722,432\n",
      "│    │    └─Identity: 3-63               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-64               [32, 197, 768]            --\n",
      "│    └─Block: 2-11                       [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-65              [32, 197, 768]            1,536\n",
      "│    │    └─Attention: 3-66              [32, 197, 768]            2,362,368\n",
      "│    │    └─Identity: 3-67               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-68               [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-69              [32, 197, 768]            1,536\n",
      "│    │    └─Mlp: 3-70                    [32, 197, 768]            4,722,432\n",
      "│    │    └─Identity: 3-71               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-72               [32, 197, 768]            --\n",
      "│    └─Block: 2-12                       [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-73              [32, 197, 768]            1,536\n",
      "│    │    └─Attention: 3-74              [32, 197, 768]            2,362,368\n",
      "│    │    └─Identity: 3-75               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-76               [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-77              [32, 197, 768]            1,536\n",
      "│    │    └─Mlp: 3-78                    [32, 197, 768]            4,722,432\n",
      "│    │    └─Identity: 3-79               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-80               [32, 197, 768]            --\n",
      "│    └─Block: 2-13                       [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-81              [32, 197, 768]            1,536\n",
      "│    │    └─Attention: 3-82              [32, 197, 768]            2,362,368\n",
      "│    │    └─Identity: 3-83               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-84               [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-85              [32, 197, 768]            1,536\n",
      "│    │    └─Mlp: 3-86                    [32, 197, 768]            4,722,432\n",
      "│    │    └─Identity: 3-87               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-88               [32, 197, 768]            --\n",
      "│    └─Block: 2-14                       [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-89              [32, 197, 768]            1,536\n",
      "│    │    └─Attention: 3-90              [32, 197, 768]            2,362,368\n",
      "│    │    └─Identity: 3-91               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-92               [32, 197, 768]            --\n",
      "│    │    └─LayerNorm: 3-93              [32, 197, 768]            1,536\n",
      "│    │    └─Mlp: 3-94                    [32, 197, 768]            4,722,432\n",
      "│    │    └─Identity: 3-95               [32, 197, 768]            --\n",
      "│    │    └─Identity: 3-96               [32, 197, 768]            --\n",
      "├─LayerNorm: 1-6                         [32, 197, 768]            1,536\n",
      "├─Identity: 1-7                          [32, 768]                 --\n",
      "├─Dropout: 1-8                           [32, 768]                 --\n",
      "├─Linear: 1-9                            [32, 1000]                769,000\n",
      "==========================================================================================\n",
      "Total params: 86,567,656\n",
      "Trainable params: 86,567,656\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 6.45\n",
      "==========================================================================================\n",
      "Input size (MB): 19.27\n",
      "Forward/backward pass size (MB): 5190.12\n",
      "Params size (MB): 345.66\n",
      "Estimated Total Size (MB): 5555.05\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\timm\\models\\vision_transformer.py:92: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  x = F.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, input_size=(32, 3, 224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11376\\1618003646.py:19: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path=wnid_dir)\n"
     ]
    }
   ],
   "source": [
    "# extract the .tar files of training dataset\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "# Paths\n",
    "train_tar_dir = \"./data/train/\"\n",
    "output_dir = \"./data/train\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Extract each tar file into a subdirectory\n",
    "for tar_file in os.listdir(train_tar_dir):\n",
    "    if tar_file.endswith(\".tar\"):\n",
    "        tar_path = os.path.join(train_tar_dir, tar_file)\n",
    "        wnid = os.path.splitext(tar_file)[0]\n",
    "        wnid_dir = os.path.join(output_dir, wnid)\n",
    "        os.makedirs(wnid_dir, exist_ok=True)\n",
    "        with tarfile.open(tar_path) as tar:\n",
    "            tar.extractall(path=wnid_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11376\\2295415744.py:32: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path=wnid_dir)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All WNIDs processed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import pickle\n",
    "\n",
    "# Paths\n",
    "train_tar_dir = \"./data/train/\"  # .tar 파일 경로\n",
    "output_dir = \"./data/train_org/\"  # 디렉토리가 생성될 경로\n",
    "meta_file = \"./data/data.pkl\"  # WNID 매핑 정보 파일\n",
    "\n",
    "# Load metadata\n",
    "with open(meta_file, \"rb\") as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "wnid_to_name = metadata[0]  # WNID to readable name mapping\n",
    "expected_wnids = set(wnid_to_name.keys())  # pkl 파일의 WNID 키\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Extract each tar file and verify WNID\n",
    "actual_wnids = set()\n",
    "for tar_file in os.listdir(train_tar_dir):\n",
    "    if tar_file.endswith(\".tar\"):\n",
    "        tar_path = os.path.join(train_tar_dir, tar_file)\n",
    "        wnid = os.path.splitext(tar_file)[0]  # Extract WNID from tar file name\n",
    "        actual_wnids.add(wnid)  # Track processed WNIDs\n",
    "\n",
    "        if wnid in expected_wnids:\n",
    "            wnid_dir = os.path.join(output_dir, wnid)\n",
    "            os.makedirs(wnid_dir, exist_ok=True)\n",
    "            with tarfile.open(tar_path) as tar:\n",
    "                tar.extractall(path=wnid_dir)\n",
    "        else:\n",
    "            print(f\"Warning: WNID {wnid} not found in metadata.\")\n",
    "\n",
    "# Find missing WNIDs\n",
    "missing_wnids = expected_wnids - actual_wnids\n",
    "if missing_wnids:\n",
    "    print(f\"Missing directories for the following WNIDs: {missing_wnids}\")\n",
    "else:\n",
    "    print(\"All WNIDs processed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Mapping ILSVRC2012_ID to WNIDs\n",
    "wnid_to_ilsvrc2012_id = {i + 1: wnid for i, wnid in enumerate(wnid_to_name.keys())}\n",
    "\n",
    "# Inverse mapping for reverse lookup\n",
    "ilsvrc2012_id_to_wnid = {v: k for k, v in wnid_to_ilsvrc2012_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceeding with 50000 validation images and 50000 WNIDs.\n",
      "All validation images have been successfully reorganized.\n",
      "Validation data reorganization complete.\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "val_dir = \"./data/val/ILSVRC2012_img_val/\"  # Directory containing the validation images\n",
    "output_val_dir = \"./data/val_org/\"  # Output directory for organized validation images\n",
    "meta_file = \"./data/data.pkl\"  # WNID mapping metadata\n",
    "\n",
    "# Load metadata\n",
    "with open(meta_file, \"rb\") as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "wnid_to_name = metadata[0]  # WNID to readable name mapping\n",
    "wnid_list = metadata[1]  # List of WNIDs for the validation set\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_val_dir, exist_ok=True)\n",
    "\n",
    "# We don't have explicit image-to-WNID mappings, so we assume the order of WNIDs in metadata[1] corresponds to images in the validation set.\n",
    "# For this, we'll need to know how many images are in the validation set to correctly assign WNIDs.\n",
    "\n",
    "# Validate we have enough WNIDs to match the number of validation images\n",
    "num_images = len(os.listdir(val_dir))\n",
    "num_wnids = len(wnid_list)\n",
    "\n",
    "if num_images != num_wnids:\n",
    "    print(f\"Warning: Number of images ({num_images}) doesn't match the number of WNIDs ({num_wnids}) in the metadata.\")\n",
    "else:\n",
    "    print(f\"Proceeding with {num_images} validation images and {num_wnids} WNIDs.\")\n",
    "\n",
    "# Create the WNID directories and move the validation images\n",
    "missing_wnids = set()\n",
    "for i, wnid in enumerate(wnid_list):\n",
    "    if wnid in wnid_to_name:\n",
    "        wnid_dir = os.path.join(output_val_dir, wnid)\n",
    "        os.makedirs(wnid_dir, exist_ok=True)\n",
    "\n",
    "        # Assume the images are named in the order of metadata[1], so the i-th image corresponds to the i-th WNID\n",
    "        image_filename = f\"ILSVRC2012_val_{str(i).zfill(8)}.JPEG\"\n",
    "        src_image_path = os.path.join(val_dir, image_filename)\n",
    "        dst_image_path = os.path.join(wnid_dir, image_filename)\n",
    "\n",
    "        if os.path.exists(src_image_path):\n",
    "            shutil.move(src_image_path, dst_image_path)\n",
    "        else:\n",
    "            continue\n",
    "            #print(f\"Warning: Image {image_filename} not found in {val_dir}\")\n",
    "    else:\n",
    "        missing_wnids.add(wnid)\n",
    "\n",
    "# Check for any missing WNIDs\n",
    "if missing_wnids:\n",
    "    print(f\"Warning: The following WNIDs are missing in metadata: {missing_wnids}\")\n",
    "else:\n",
    "    print(\"All validation images have been successfully reorganized.\")\n",
    "\n",
    "print(\"Validation data reorganization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "t_4Bi7QH-Tju"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = ImageFolder(root=\"./data/train_org\", transform=transform)\n",
    "val_dataset = ImageFolder(root=\"./data/val_org\", transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "00vn4SgK-Tju"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "6QhtYgzv-Tju"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(data_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "xRbL3I9k-Tju"
   },
   "outputs": [],
   "source": [
    "def measure_inference_time(model, data_loader, device):\n",
    "    model.eval()\n",
    "    times = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            start_time = torch.cuda.Event(enable_timing=True)\n",
    "            end_time = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "            start_time.record()\n",
    "            _ = model(inputs)  # inference 수행\n",
    "            end_time.record()\n",
    "\n",
    "            # 시간 측정\n",
    "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
    "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
    "            times.append(elapsed_time)\n",
    "\n",
    "    # 통계량 계산\n",
    "    times_np = np.array(times)\n",
    "    total_inferences = len(times_np)\n",
    "    avg_time = np.mean(times_np)\n",
    "    std_dev = np.std(times_np)\n",
    "    max_time = np.max(times_np)\n",
    "    min_time = np.min(times_np)\n",
    "\n",
    "    # 결과 출력\n",
    "    print(f\"Inference Time Measurement Results:\")\n",
    "    print(f\"Total Inferences: {total_inferences}\")\n",
    "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
    "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
    "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
    "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
    "\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdo6nUlY-Tju",
    "outputId": "c2082db7-43ad-4238-f624-674fb71f2717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▍                                                                 | 139/20019 [02:54<6:27:50,  1.17s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    train(model, train_loader, criterion, optimizer, device)\n",
    "    evaluate(model, val_loader, criterion, device, phase=\"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNeatTAl-Tju",
    "outputId": "2a3a2466-f929-4b48-ae26-1086f257c0e8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nFinal Test Evaluation\")\n",
    "evaluate(model, test_loader, criterion, device, phase=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSTDj_5B-Tju",
    "outputId": "d59ceb09-6d65-4cb3-8961-b4d3c6c53747"
   },
   "outputs": [],
   "source": [
    "times = measure_inference_time(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4Ehs40pRV9T"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
