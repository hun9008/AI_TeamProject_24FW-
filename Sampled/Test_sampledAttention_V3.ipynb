{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OV5wSsg8_y4t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearNorm(nn.Linear):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__(in_features, out_features)\n",
        "        nn.init.xavier_uniform_(self.weight)"
      ],
      "metadata": {
        "id": "iJ2jmIjn_9PC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, measure_time=False):\n",
        "        start_time = time.time()\n",
        "\n",
        "        B, N, C = x.shape\n",
        "        print(f\"Input shape: {x.shape}\")\n",
        "\n",
        "        time_records = {}\n",
        "\n",
        "        # QKV 연산\n",
        "        t1 = time.time()\n",
        "        qkv = self.qkv(x)\n",
        "        t2 = time.time()\n",
        "        time_records[\"QKV computation\"] = (t2 - t1) * 1000\n",
        "\n",
        "        # Reshaping 및 분할\n",
        "        t3 = time.time()\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        t4 = time.time()\n",
        "        time_records[\"Reshape & split\"] = (t4 - t3) * 1000\n",
        "\n",
        "        # 어텐션 스코어 계산\n",
        "        t5 = time.time()\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        t6 = time.time()\n",
        "        time_records[\"Attention computation\"] = (t6 - t5) * 1000\n",
        "\n",
        "        # 어텐션 적용 후 값 계산\n",
        "        t9 = time.time()\n",
        "        x = (attn @ v)\n",
        "        t10 = time.time()\n",
        "        time_records[\"Attention output computation\"] = (t10 - t9) * 1000\n",
        "\n",
        "        # 차원 변환 및 최종 투영\n",
        "        t11 = time.time()\n",
        "        x = x.transpose(1, 2).reshape(B, N, C)\n",
        "        final_output = self.proj(x)\n",
        "        t12 = time.time()\n",
        "        time_records[\"Final projection\"] = (t12 - t11) * 1000\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        total_time_ms = total_time * 1000\n",
        "        # print(f\"Total forward pass time: {total_time_ms:.3f} ms\\n\")\n",
        "\n",
        "        # 테이블 출력\n",
        "        # print(f\"{'Stage':<35}{'Time (ms)':<15}{'Percentage (%)'}\")\n",
        "        # print(\"=\" * 65)\n",
        "        # for stage, time_ms in time_records.items():\n",
        "        #     percentage = (time_ms / total_time_ms) * 100\n",
        "        #     print(f\"{stage:<35}{time_ms:<15.3f}{percentage:.2f}%\")\n",
        "\n",
        "        return final_output, time_records if measure_time else final_output"
      ],
      "metadata": {
        "id": "n8CjRlmafXyL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SampledAttention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2, sample_ratio=0.5):\n",
        "        super(SampledAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.sample_ratio = sample_ratio\n",
        "\n",
        "    def forward(self, x, measure_time=False):\n",
        "        start_time = time.time()\n",
        "\n",
        "        B, N, C = x.shape\n",
        "        print(f\"Input shape: {x.shape}\")\n",
        "\n",
        "        time_records = {}\n",
        "\n",
        "        # QKV 연산\n",
        "        t1 = time.time()\n",
        "        qkv = self.qkv(x)\n",
        "        t2 = time.time()\n",
        "        time_records[\"QKV computation\"] = (t2 - t1) * 1000\n",
        "\n",
        "        # Reshaping 및 분할\n",
        "        t3 = time.time()\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        t4 = time.time()\n",
        "        time_records[\"Reshape & split\"] = (t4 - t3) * 1000\n",
        "\n",
        "        # 샘플링 인덱스 선택\n",
        "        t5 = time.time()\n",
        "        num_samples = int(N * self.sample_ratio)\n",
        "        prob = torch.ones(N, device=x.device) / N\n",
        "        sampled_indices = torch.multinomial(prob, num_samples, replacement=False)\n",
        "        t6 = time.time()\n",
        "        time_records[\"Sampling\"] = (t6 - t5) * 1000\n",
        "\n",
        "\n",
        "        # 샘플링된 Q, K, V 추출\n",
        "        t7 = time.time()\n",
        "        sampled_q = q[:, :, sampled_indices, :]\n",
        "        sampled_k = k[:, :, sampled_indices, :]\n",
        "        sampled_v = v[:, :, sampled_indices, :]\n",
        "        t8 = time.time()\n",
        "        time_records[\"Sampled QKV extraction\"] = (t8 - t7) * 1000\n",
        "\n",
        "        # 어텐션 연산\n",
        "        t9 = time.time()\n",
        "        attn_sampled = (sampled_q @ sampled_k.transpose(-2, -1)) * self.scale\n",
        "        attn_sampled = attn_sampled.softmax(dim=-1)\n",
        "        t10 = time.time()\n",
        "        time_records[\"Attention computation\"] = (t10 - t9) * 1000\n",
        "\n",
        "        # 어텐션을 적용한 출력 생성\n",
        "        t11 = time.time()\n",
        "        output_sampled = (attn_sampled @ sampled_v)\n",
        "        t12 = time.time()\n",
        "        time_records[\"Output sampled computation\"] = (t12 - t11) * 1000\n",
        "\n",
        "        # 전체 출력 생성\n",
        "        t13 = time.time()\n",
        "        output = torch.zeros(B, self.num_heads, N, v.size(-1), device=x.device)\n",
        "        output[:, :, sampled_indices, :] = output_sampled\n",
        "        t14 = time.time()\n",
        "        time_records[\"Output reconstruction\"] = (t14 - t13) * 1000\n",
        "\n",
        "        # 차원 변환 및 최종 투영\n",
        "        t15 = time.time()\n",
        "        output = output.transpose(1, 2).reshape(B, N, C)\n",
        "        final_output = self.proj(output)\n",
        "        t16 = time.time()\n",
        "        time_records[\"Final projection\"] = (t16 - t15) * 1000\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        total_time_ms = total_time * 1000\n",
        "        # print(f\"Total forward pass time: {total_time_ms:.3f} ms\\n\")\n",
        "\n",
        "        # # 테이블 출력\n",
        "        # print(f\"{'Stage':<30}{'Time (ms)':<15}{'Percentage (%)'}\")\n",
        "        # print(\"=\" * 55)\n",
        "        # for stage, time_ms in time_records.items():\n",
        "        #     percentage = (time_ms / total_time_ms) * 100\n",
        "        #     print(f\"{stage:<30}{time_ms:<15.3f}{percentage:.2f}%\")\n",
        "\n",
        "        return final_output, time_records if measure_time else final_output"
      ],
      "metadata": {
        "id": "6vLgglxzAGeJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B, N, C = 32, 128, 256  # Batch, Sequence Length, Embedding Dim\n",
        "num_heads = 8\n",
        "num_runs = 5  # 실행 횟수\n",
        "\n",
        "def measure_execution_time(model, x, device):\n",
        "    stage_times = defaultdict(list)\n",
        "\n",
        "    # stage_times = {  # 각 단계별 시간 저장용\n",
        "    #     \"QKV computation\": [],\n",
        "    #     \"Reshape & split\": [],\n",
        "    #     \"Attention score computation\": [],\n",
        "    #     \"Softmax application\": [],\n",
        "    #     \"Attention output computation\": [],\n",
        "    #     \"Final projection\": [],\n",
        "    #     \"Total forward pass\": []\n",
        "    # }\n",
        "\n",
        "    for i in range(num_runs):\n",
        "        if device == \"cuda\":\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        start_time = time.time()\n",
        "        _, time_records = model(x, measure_time=True)  # 실행 및 시간 측정\n",
        "        if device == \"cuda\":\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        total_time = (time.time() - start_time) * 1000  # ms 변환\n",
        "        stage_times[\"Total forward pass\"].append(total_time)\n",
        "\n",
        "        if i > 0:  # 첫 실행 제외\n",
        "            for stage, t in time_records.items():\n",
        "                stage_times[stage].append(t)\n",
        "\n",
        "    # 평균 계산\n",
        "    avg_stage_times = {stage: sum(times) / len(times) for stage, times in stage_times.items()}\n",
        "\n",
        "    print(f\"\\nAverage Execution Time on {device.upper()} (excluding first run)\")\n",
        "    print(\"=\" * 65)\n",
        "    print(f\"{'Stage':<35}{'Time (ms)':<15}\")\n",
        "    print(\"=\" * 65)\n",
        "    total_avg_time = avg_stage_times[\"Total forward pass\"]\n",
        "    for stage, avg_time in avg_stage_times.items():\n",
        "        percentage = (avg_time / total_avg_time) * 100\n",
        "        print(f\"{stage:<35}{avg_time:<15.3f}\")\n",
        "\n",
        "    print(\"||\" * 65)\n",
        "    print(f\"{'Total':<35}{total_avg_time:<15.3f}\")\n",
        "    attn = avg_stage_times[\"Attention computation\"]\n",
        "    print(f\"{'attn':<35}{attn:<15.3f}\")\n",
        "    attn_percentage = (avg_stage_times[\"Attention computation\"] / total_avg_time) * 100\n",
        "    print(f\"{'attn percent':<35}{attn_percentage:<15.3f}\")\n",
        "    print(\"||\" * 65)\n",
        "\n",
        "    return avg_stage_times"
      ],
      "metadata": {
        "id": "JJjoOWvffbn0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"\\nRunning on CUDA...\")\n",
        "    x_cuda = torch.randn(B, N, C).cuda()\n",
        "    attn_cuda = Attention(dim=C, num_heads=num_heads).cuda()\n",
        "    measure_execution_time(attn_cuda, x_cuda, \"cuda\")\n",
        "\n",
        "# CPU 실행\n",
        "print(\"\\nRunning on CPU...\")\n",
        "x_cpu = torch.randn(B, N, C)\n",
        "attn_cpu = Attention(dim=C, num_heads=num_heads)\n",
        "measure_execution_time(attn_cpu, x_cpu, \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_QNQycBgr2k",
        "outputId": "9077d774-ef1e-47cf-a274-80be38b654f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running on CUDA...\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "\n",
            "Average Execution Time on CUDA (excluding first run)\n",
            "=================================================================\n",
            "Stage                              Time (ms)      \n",
            "=================================================================\n",
            "Total forward pass                 0.855          \n",
            "QKV computation                    0.263          \n",
            "Reshape & split                    0.037          \n",
            "Attention computation              0.163          \n",
            "Attention output computation       0.057          \n",
            "Final projection                   0.130          \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
            "Total                              0.855          \n",
            "attn                               0.163          \n",
            "attn percent                       19.077         \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
            "\n",
            "Running on CPU...\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "\n",
            "Average Execution Time on CPU (excluding first run)\n",
            "=================================================================\n",
            "Stage                              Time (ms)      \n",
            "=================================================================\n",
            "Total forward pass                 10.851         \n",
            "QKV computation                    2.879          \n",
            "Reshape & split                    0.064          \n",
            "Attention computation              5.649          \n",
            "Attention output computation       0.899          \n",
            "Final projection                   1.431          \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
            "Total                              10.851         \n",
            "attn                               5.649          \n",
            "attn percent                       52.063         \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Total forward pass': 10.85062026977539,\n",
              " 'QKV computation': 2.878546714782715,\n",
              " 'Reshape & split': 0.06395578384399414,\n",
              " 'Attention computation': 5.649149417877197,\n",
              " 'Attention output computation': 0.8988380432128906,\n",
              " 'Final projection': 1.431286334991455}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"\\nRunning on CUDA...\")\n",
        "    x_cuda = torch.randn(B, N, C).cuda()\n",
        "    attn_cuda = SampledAttention(dim=C, num_heads=num_heads).cuda()\n",
        "    measure_execution_time(attn_cuda, x_cuda, \"cuda\")\n",
        "\n",
        "# CPU 실행\n",
        "print(\"\\nRunning on CPU...\")\n",
        "x_cpu = torch.randn(B, N, C)\n",
        "attn_cpu = SampledAttention(dim=C, num_heads=num_heads)\n",
        "measure_execution_time(attn_cpu, x_cpu, \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZxSfadlAIf-",
        "outputId": "c666c9b7-17ac-482f-dddf-f2fc6d09c675"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running on CUDA...\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "\n",
            "Average Execution Time on CUDA (excluding first run)\n",
            "=================================================================\n",
            "Stage                              Time (ms)      \n",
            "=================================================================\n",
            "Total forward pass                 1.530          \n",
            "QKV computation                    0.286          \n",
            "Reshape & split                    0.051          \n",
            "Sampling                           0.304          \n",
            "Sampled QKV extraction             0.143          \n",
            "Attention computation              0.148          \n",
            "Output sampled computation         0.058          \n",
            "Output reconstruction              0.090          \n",
            "Final projection                   0.172          \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
            "Total                              1.530          \n",
            "attn                               0.148          \n",
            "attn percent                       9.704          \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
            "\n",
            "Running on CPU...\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "\n",
            "Average Execution Time on CPU (excluding first run)\n",
            "=================================================================\n",
            "Stage                              Time (ms)      \n",
            "=================================================================\n",
            "Total forward pass                 10.745         \n",
            "QKV computation                    4.091          \n",
            "Reshape & split                    0.053          \n",
            "Sampling                           0.201          \n",
            "Sampled QKV extraction             0.962          \n",
            "Attention computation              1.604          \n",
            "Output sampled computation         0.264          \n",
            "Output reconstruction              0.449          \n",
            "Final projection                   2.725          \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
            "Total                              10.745         \n",
            "attn                               1.604          \n",
            "attn percent                       14.927         \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Total forward pass': 10.745048522949219,\n",
              " 'QKV computation': 4.091382026672363,\n",
              " 'Reshape & split': 0.052988529205322266,\n",
              " 'Sampling': 0.20056962966918945,\n",
              " 'Sampled QKV extraction': 0.9617805480957031,\n",
              " 'Attention computation': 1.6039609909057617,\n",
              " 'Output sampled computation': 0.2637505531311035,\n",
              " 'Output reconstruction': 0.44864416122436523,\n",
              " 'Final projection': 2.724885940551758}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SampledAttention_v2(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2, sample_ratio=0.5):\n",
        "        super(SampledAttention_v2, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.sample_ratio = sample_ratio\n",
        "\n",
        "    def forward(self, x, measure_time=False):\n",
        "        start_time = time.time()\n",
        "\n",
        "        B, N, C = x.shape\n",
        "        print(f\"Input shape: {x.shape}\")\n",
        "\n",
        "        time_records = {}\n",
        "\n",
        "        # QKV 연산\n",
        "        t1 = time.time()\n",
        "        qkv = self.qkv(x)\n",
        "        t2 = time.time()\n",
        "        time_records[\"QKV computation\"] = (t2 - t1) * 1000\n",
        "\n",
        "        # Reshaping 및 분할\n",
        "        t3 = time.time()\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        t4 = time.time()\n",
        "        time_records[\"Reshape & split\"] = (t4 - t3) * 1000\n",
        "\n",
        "        # 마스크 생성\n",
        "        t5 = time.time()\n",
        "        mask = torch.arange(N, device=x.device) % 2\n",
        "        mask = mask.unsqueeze(0).unsqueeze(0).unsqueeze(-1)  # (1, 1, N, 1)\n",
        "        mask = mask.expand(B, self.num_heads, N, q.shape[-1])\n",
        "        t6 = time.time()\n",
        "        time_records[\"Mask generation\"] = (t6 - t5) * 1000\n",
        "\n",
        "        # 마스크 적용\n",
        "        t7 = time.time()\n",
        "        masked_q = q * mask\n",
        "        masked_k = k * mask\n",
        "        t8 = time.time()\n",
        "        time_records[\"Mask application\"] = (t8 - t7) * 1000\n",
        "\n",
        "        # 홀수 인덱스 선택\n",
        "        t9 = time.time()\n",
        "        selected_indices = torch.arange(N, device=x.device) % 2 == 1\n",
        "        t10 = time.time()\n",
        "        time_records[\"Index selection\"] = (t10 - t9) * 1000\n",
        "\n",
        "        # 샘플링된 Q, K 추출\n",
        "        t11 = time.time()\n",
        "        masked_q = masked_q[:, :, selected_indices, :]\n",
        "        masked_k = masked_k[:, :, selected_indices, :]\n",
        "        t12 = time.time()\n",
        "        time_records[\"Sampled QK extraction\"] = (t12 - t11) * 1000\n",
        "\n",
        "        # 어텐션 연산\n",
        "        t13 = time.time()\n",
        "        masked_attn = (masked_q @ masked_k.transpose(-2, -1)) * self.scale\n",
        "        masked_attn = masked_attn.softmax(dim=-1)\n",
        "        t14 = time.time()\n",
        "        time_records[\"Attention computation\"] = (t14 - t13) * 1000\n",
        "\n",
        "        # 어텐션을 적용한 출력 생성\n",
        "        t15 = time.time()\n",
        "        restored_attn = torch.zeros(B, self.num_heads, N, N, device=x.device)\n",
        "        restored_attn[:, :, selected_indices, :][:, :, :, selected_indices] = masked_attn\n",
        "        t16 = time.time()\n",
        "        time_records[\"Attention restoration\"] = (t16 - t15) * 1000\n",
        "\n",
        "        # 최종 출력 생성\n",
        "        t17 = time.time()\n",
        "        x = (restored_attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        final_output = self.proj(x)\n",
        "        t18 = time.time()\n",
        "        time_records[\"Final projection\"] = (t18 - t17) * 1000\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        total_time_ms = total_time * 1000\n",
        "        # print(f\"Total forward pass time: {total_time_ms:.3f} ms\\n\")\n",
        "\n",
        "        # # 테이블 출력\n",
        "        # print(f\"{'Stage':<30}{'Time (ms)':<15}{'Percentage (%)'}\")\n",
        "        # print(\"=\" * 55)\n",
        "        # for stage, time_ms in time_records.items():\n",
        "        #     percentage = (time_ms / total_time_ms) * 100\n",
        "        #     print(f\"{stage:<30}{time_ms:<15.3f}{percentage:.2f}%\")\n",
        "\n",
        "        return final_output, time_records if measure_time else final_output"
      ],
      "metadata": {
        "id": "qFxbUCOvBYFI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"\\nRunning on CUDA...\")\n",
        "    x_cuda = torch.randn(B, N, C).cuda()\n",
        "    attn_cuda = SampledAttention_v2(dim=C, num_heads=num_heads).cuda()\n",
        "    measure_execution_time(attn_cuda, x_cuda, \"cuda\")\n",
        "\n",
        "# CPU 실행\n",
        "print(\"\\nRunning on CPU...\")\n",
        "x_cpu = torch.randn(B, N, C)\n",
        "attn_cpu = SampledAttention_v2(dim=C, num_heads=num_heads)\n",
        "measure_execution_time(attn_cpu, x_cpu, \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AzvR_fxdJiD",
        "outputId": "565d02a8-82f4-44a5-92ff-e6e7cb786eb3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running on CUDA...\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "\n",
            "Average Execution Time on CUDA (excluding first run)\n",
            "=================================================================\n",
            "Stage                              Time (ms)      \n",
            "=================================================================\n",
            "Total forward pass                 1.561          \n",
            "QKV computation                    0.275          \n",
            "Reshape & split                    0.042          \n",
            "Mask generation                    0.079          \n",
            "Mask application                   0.035          \n",
            "Index selection                    0.049          \n",
            "Sampled QK extraction              0.190          \n",
            "Attention computation              0.118          \n",
            "Attention restoration              0.238          \n",
            "Final projection                   0.229          \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
            "Total                              1.561          \n",
            "attn                               0.118          \n",
            "attn percent                       7.530          \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
            "\n",
            "Running on CPU...\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "\n",
            "Average Execution Time on CPU (excluding first run)\n",
            "=================================================================\n",
            "Stage                              Time (ms)      \n",
            "=================================================================\n",
            "Total forward pass                 15.824         \n",
            "QKV computation                    4.144          \n",
            "Reshape & split                    0.072          \n",
            "Mask generation                    0.108          \n",
            "Mask application                   1.328          \n",
            "Index selection                    0.069          \n",
            "Sampled QK extraction              0.639          \n",
            "Attention computation              1.239          \n",
            "Attention restoration              3.730          \n",
            "Final projection                   3.449          \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
            "Total                              15.824         \n",
            "attn                               1.239          \n",
            "attn percent                       7.833          \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Total forward pass': 15.823698043823242,\n",
              " 'QKV computation': 4.1435956954956055,\n",
              " 'Reshape & split': 0.07158517837524414,\n",
              " 'Mask generation': 0.10752677917480469,\n",
              " 'Mask application': 1.328110694885254,\n",
              " 'Index selection': 0.06943941116333008,\n",
              " 'Sampled QK extraction': 0.6388425827026367,\n",
              " 'Attention computation': 1.239478588104248,\n",
              " 'Attention restoration': 3.7297606468200684,\n",
              " 'Final projection': 3.448605537414551}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SampledAttention_v3(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2, sample_ratio=0.5):\n",
        "        super(SampledAttention_v3, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.sample_ratio = sample_ratio\n",
        "\n",
        "    def forward(self, x, measure_time=False):\n",
        "        start_time = time.time()\n",
        "\n",
        "        B, N, C = x.shape\n",
        "        print(f\"Input shape: {x.shape}\")\n",
        "\n",
        "        time_records = {}\n",
        "\n",
        "        # QKV 연산\n",
        "        t1 = time.time()\n",
        "        qkv = self.qkv(x)\n",
        "        t2 = time.time()\n",
        "        time_records[\"QKV computation\"] = (t2 - t1) * 1000\n",
        "\n",
        "        # Reshaping 및 분할\n",
        "        t3 = time.time()\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        t4 = time.time()\n",
        "        time_records[\"Reshape & split\"] = (t4 - t3) * 1000\n",
        "\n",
        "        # 마스크 생성\n",
        "        t5 = time.time()\n",
        "        mask = torch.arange(N, device=x.device) % 2\n",
        "        mask = (torch.arange(N, device=x.device) % 2).bool()\n",
        "        mask = mask.view(1, 1, N, 1)\n",
        "        t6 = time.time()\n",
        "        time_records[\"Mask generation\"] = (t6 - t5) * 1000\n",
        "\n",
        "        # 마스크 적용\n",
        "        t7 = time.time()\n",
        "        #masked_q = q * mask\n",
        "        #masked_k = k * mask\n",
        "        q *= mask\n",
        "        k *= mask\n",
        "        t8 = time.time()\n",
        "        time_records[\"Mask application\"] = (t8 - t7) * 1000\n",
        "\n",
        "        # 홀수 인덱스 선택\n",
        "        t9 = time.time()\n",
        "        odd_indices = torch.arange(N, device=x.device)[mask.view(-1)]\n",
        "        t10 = time.time()\n",
        "        time_records[\"Index selection\"] = (t10 - t9) * 1000\n",
        "\n",
        "        # 샘플링된 Q, K 추출\n",
        "        t11 = time.time()\n",
        "        masked_q = q[:, :, odd_indices, :]\n",
        "        masked_k = k[:, :, odd_indices, :]\n",
        "        t12 = time.time()\n",
        "        time_records[\"Sampled QK extraction\"] = (t12 - t11) * 1000\n",
        "\n",
        "        # 어텐션 연산\n",
        "        t13 = time.time()\n",
        "        masked_attn = (masked_q @ masked_k.transpose(-2, -1)) * self.scale\n",
        "        masked_attn = masked_attn.softmax(dim=-1)\n",
        "        t14 = time.time()\n",
        "        time_records[\"Attention computation\"] = (t14 - t13) * 1000\n",
        "\n",
        "        # 어텐션을 적용한 출력 생성\n",
        "        t15 = time.time()\n",
        "        restored_attn = torch.zeros(B, self.num_heads, N, N, device=x.device)\n",
        "        restored_attn[:, :, odd_indices, :][:, :, :, odd_indices] = masked_attn\n",
        "        t16 = time.time()\n",
        "        time_records[\"Attention restoration\"] = (t16 - t15) * 1000\n",
        "\n",
        "        # 최종 출력 생성\n",
        "        t17 = time.time()\n",
        "        x = (restored_attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        final_output = self.proj(x)\n",
        "        t18 = time.time()\n",
        "        time_records[\"Final projection\"] = (t18 - t17) * 1000\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        total_time_ms = total_time * 1000\n",
        "        # print(f\"Total forward pass time: {total_time_ms:.3f} ms\\n\")\n",
        "\n",
        "        # # 테이블 출력\n",
        "        # print(f\"{'Stage':<30}{'Time (ms)':<15}{'Percentage (%)'}\")\n",
        "        # print(\"=\" * 55)\n",
        "        # for stage, time_ms in time_records.items():\n",
        "        #     percentage = (time_ms / total_time_ms) * 100\n",
        "        #     print(f\"{stage:<30}{time_ms:<15.3f}{percentage:.2f}%\")\n",
        "\n",
        "        return final_output, time_records if measure_time else final_output"
      ],
      "metadata": {
        "id": "BZmNVJrHdL9R"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"\\nRunning on CUDA...\")\n",
        "    x_cuda = torch.randn(B, N, C).cuda()\n",
        "    attn_cuda = SampledAttention_v3(dim=C, num_heads=num_heads).cuda()\n",
        "    measure_execution_time(attn_cuda, x_cuda, \"cuda\")\n",
        "\n",
        "# CPU 실행\n",
        "print(\"\\nRunning on CPU...\")\n",
        "x_cpu = torch.randn(B, N, C)\n",
        "attn_cpu = SampledAttention_v3(dim=C, num_heads=num_heads)\n",
        "measure_execution_time(attn_cpu, x_cpu, \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63Vscawp0c3p",
        "outputId": "dca350c3-c6ae-4607-c339-408c1c9b932c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running on CUDA...\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "\n",
            "Average Execution Time on CUDA (excluding first run)\n",
            "=================================================================\n",
            "Stage                              Time (ms)      \n",
            "=================================================================\n",
            "Total forward pass                 1.514          \n",
            "QKV computation                    0.245          \n",
            "Reshape & split                    0.091          \n",
            "Mask generation                    0.114          \n",
            "Mask application                   0.045          \n",
            "Index selection                    0.107          \n",
            "Sampled QK extraction              0.073          \n",
            "Attention computation              0.115          \n",
            "Attention restoration              0.100          \n",
            "Final projection                   0.210          \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
            "Total                              1.514          \n",
            "attn                               0.115          \n",
            "attn percent                       7.610          \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
            "\n",
            "Running on CPU...\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "Input shape: torch.Size([32, 128, 256])\n",
            "\n",
            "Average Execution Time on CPU (excluding first run)\n",
            "=================================================================\n",
            "Stage                              Time (ms)      \n",
            "=================================================================\n",
            "Total forward pass                 15.934         \n",
            "QKV computation                    4.980          \n",
            "Reshape & split                    0.064          \n",
            "Mask generation                    0.120          \n",
            "Mask application                   0.364          \n",
            "Index selection                    0.113          \n",
            "Sampled QK extraction              0.722          \n",
            "Attention computation              1.497          \n",
            "Attention restoration              3.760          \n",
            "Final projection                   4.047          \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
            "Total                              15.934         \n",
            "attn                               1.497          \n",
            "attn percent                       9.392          \n",
            "||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Total forward pass': 15.934228897094727,\n",
              " 'QKV computation': 4.9803853034973145,\n",
              " 'Reshape & split': 0.06449222564697266,\n",
              " 'Mask generation': 0.12040138244628906,\n",
              " 'Mask application': 0.36388635635375977,\n",
              " 'Index selection': 0.1131296157836914,\n",
              " 'Sampled QK extraction': 0.7218122482299805,\n",
              " 'Attention computation': 1.4966130256652832,\n",
              " 'Attention restoration': 3.7601590156555176,\n",
              " 'Final projection': 4.047036170959473}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3GgiM-uk0uYR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}