{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hun9008/AI_TeamProject_24FW-/blob/main/Swin_trasformer_cosine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJyw3HY_uCS5",
        "outputId": "6610a6ca-dabb-41a9-8e88-b32589cdb112"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: timm\n",
            "Successfully installed timm-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zMDsnpE0t0iA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from timm import create_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2k7-FprSt0iB"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Swin Transformer는 224x224 입력\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF6zKMZKt0iB",
        "outputId": "e3bdf24a-0b49-440c-e401-5d481f44ccff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:18<00:00, 9101830.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180,
          "referenced_widgets": [
            "169958af4a6e4cef9338d8635a834da9",
            "271c0bc5254e43eeb813597347f990a3",
            "fe3621d55bfc440cbb91500bef022eba",
            "47637e66cfaf4a09a637afdac17d6f4c",
            "946ca32e5b9346e1a27951f9f6fa3812",
            "af9c7692c63c4e0abc6ea04ae3317a24",
            "83b16b6249934ab38cbf3526f99f8236",
            "c8014eae21d349048d80883a07030b7b",
            "b5b6efc7ea144ae4b6ea34abdb48112a",
            "4aeaf420886e46fa98b4b4d133f33c17",
            "4182ab3411c04c8dafc4e3999071698d"
          ]
        },
        "id": "qCrw5b05t0iC",
        "outputId": "b1f9fb94-d3c7-433c-fc58-7cb0df18846e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "169958af4a6e4cef9338d8635a834da9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "swin_transforemr = create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvoqVshjt0iC",
        "outputId": "83fe087e-d442-4688-dd95-850d25715f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SwinTransformer(\n",
            "  (patch_embed): PatchEmbed(\n",
            "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (layers): Sequential(\n",
            "    (0): SwinTransformerStage(\n",
            "      (downsample): Identity()\n",
            "      (blocks): Sequential(\n",
            "        (0): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path1): Identity()\n",
            "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path1): DropPath(drop_prob=0.009)\n",
            "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (drop_path2): DropPath(drop_prob=0.009)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): SwinTransformerStage(\n",
            "      (downsample): PatchMerging(\n",
            "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
            "      )\n",
            "      (blocks): Sequential(\n",
            "        (0): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path1): DropPath(drop_prob=0.018)\n",
            "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (drop_path2): DropPath(drop_prob=0.018)\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path1): DropPath(drop_prob=0.027)\n",
            "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (drop_path2): DropPath(drop_prob=0.027)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): SwinTransformerStage(\n",
            "      (downsample): PatchMerging(\n",
            "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
            "      )\n",
            "      (blocks): Sequential(\n",
            "        (0): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path1): DropPath(drop_prob=0.036)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (drop_path2): DropPath(drop_prob=0.036)\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path1): DropPath(drop_prob=0.045)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (drop_path2): DropPath(drop_prob=0.045)\n",
            "        )\n",
            "        (2): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path1): DropPath(drop_prob=0.055)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (drop_path2): DropPath(drop_prob=0.055)\n",
            "        )\n",
            "        (3): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path1): DropPath(drop_prob=0.064)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (drop_path2): DropPath(drop_prob=0.064)\n",
            "        )\n",
            "        (4): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path1): DropPath(drop_prob=0.073)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (drop_path2): DropPath(drop_prob=0.073)\n",
            "        )\n",
            "        (5): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path1): DropPath(drop_prob=0.082)\n",
            "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (drop_path2): DropPath(drop_prob=0.082)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): SwinTransformerStage(\n",
            "      (downsample): PatchMerging(\n",
            "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
            "      )\n",
            "      (blocks): Sequential(\n",
            "        (0): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path1): DropPath(drop_prob=0.091)\n",
            "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (drop_path2): DropPath(drop_prob=0.091)\n",
            "        )\n",
            "        (1): SwinTransformerBlock(\n",
            "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): WindowAttention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "            (softmax): Softmax(dim=-1)\n",
            "          )\n",
            "          (drop_path1): DropPath(drop_prob=0.100)\n",
            "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (drop_path2): DropPath(drop_prob=0.100)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (head): ClassifierHead(\n",
            "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (fc): Linear(in_features=768, out_features=10, bias=True)\n",
            "    (flatten): Identity()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(swin_transforemr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FHg8AIApt0iD"
      },
      "outputs": [],
      "source": [
        "window_attention = swin_transforemr.layers[0].blocks[0].attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BU3JRPSht0iD"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r2IjzWVZt0iD"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "class CustomWindowAttention(nn.Module):\n",
        "    def __init__(self, original_attention, output_dim):\n",
        "        super().__init__()\n",
        "        self.qkv = original_attention.qkv\n",
        "        self.softmax = original_attention.softmax\n",
        "        self.cosine_similarity = nn.CosineSimilarity(dim=-1)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.linear = nn.Linear(output_dim, output_dim)\n",
        "    def forward(self, x, mask=None):\n",
        "        B, N, C = x.shape\n",
        "        # qkv 계산 및 q, k, v로 분할\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, C).permute(2, 0, 1, 3)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        # 코사인 유사도를 계산 (q와 k는 마지막 차원에서 코사인 유사도 계산)\n",
        "        attn = nn.CosineSimilarity(dim=-1)(q.unsqueeze(2), k.unsqueeze(1)) / (C ** 0.5)\n",
        "        attn = self.softmax(attn)\n",
        "\n",
        "        output = torch.matmul(attn, v)\n",
        "        output = self.linear(output)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        output = output + x\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YRdiwSEJt0iD"
      },
      "outputs": [],
      "source": [
        "swin_transforemr.layers[0].blocks[0].attn = CustomWindowAttention(swin_transforemr.layers[0].blocks[0].attn, 96)\n",
        "swin_transforemr.layers[0].blocks[1].attn = CustomWindowAttention(swin_transforemr.layers[0].blocks[1].attn, 96)\n",
        "swin_transforemr.layers[1].blocks[0].attn = CustomWindowAttention(swin_transforemr.layers[1].blocks[0].attn, 192)\n",
        "swin_transforemr.layers[1].blocks[1].attn = CustomWindowAttention(swin_transforemr.layers[1].blocks[1].attn, 192)\n",
        "swin_transforemr.layers[2].blocks[0].attn = CustomWindowAttention(swin_transforemr.layers[2].blocks[0].attn, 384)\n",
        "swin_transforemr.layers[2].blocks[1].attn = CustomWindowAttention(swin_transforemr.layers[2].blocks[1].attn, 384)\n",
        "swin_transforemr.layers[2].blocks[2].attn = CustomWindowAttention(swin_transforemr.layers[2].blocks[2].attn, 384)\n",
        "swin_transforemr.layers[2].blocks[3].attn = CustomWindowAttention(swin_transforemr.layers[2].blocks[3].attn, 384)\n",
        "swin_transforemr.layers[2].blocks[4].attn = CustomWindowAttention(swin_transforemr.layers[2].blocks[4].attn, 384)\n",
        "swin_transforemr.layers[2].blocks[5].attn = CustomWindowAttention(swin_transforemr.layers[2].blocks[5].attn, 384)\n",
        "swin_transforemr.layers[3].blocks[0].attn = CustomWindowAttention(swin_transforemr.layers[3].blocks[0].attn, 768)\n",
        "swin_transforemr.layers[3].blocks[1].attn = CustomWindowAttention(swin_transforemr.layers[3].blocks[1].attn, 768)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qcOzBmhmt0iE"
      },
      "outputs": [],
      "source": [
        "model = swin_transforemr.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "m9amFiWyt0iF",
        "outputId": "06e1a107-c351-4d19-ad8c-28b962279311"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ed96d6044a73>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    for images, labels in trainloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            predicted = torch.max(outputs.to(device), 1)[1]\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "            correct += (labels == predicted).sum()\n",
        "    print(\n",
        "        f\"epoch {epoch+1} - test loss: {test_loss / len(testloader):.4f}, accuracy: {correct / len(testloader):.4f}\"\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "169958af4a6e4cef9338d8635a834da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_271c0bc5254e43eeb813597347f990a3",
              "IPY_MODEL_fe3621d55bfc440cbb91500bef022eba",
              "IPY_MODEL_47637e66cfaf4a09a637afdac17d6f4c"
            ],
            "layout": "IPY_MODEL_946ca32e5b9346e1a27951f9f6fa3812"
          }
        },
        "271c0bc5254e43eeb813597347f990a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af9c7692c63c4e0abc6ea04ae3317a24",
            "placeholder": "​",
            "style": "IPY_MODEL_83b16b6249934ab38cbf3526f99f8236",
            "value": "model.safetensors: 100%"
          }
        },
        "fe3621d55bfc440cbb91500bef022eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8014eae21d349048d80883a07030b7b",
            "max": 114286722,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5b6efc7ea144ae4b6ea34abdb48112a",
            "value": 114286722
          }
        },
        "47637e66cfaf4a09a637afdac17d6f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aeaf420886e46fa98b4b4d133f33c17",
            "placeholder": "​",
            "style": "IPY_MODEL_4182ab3411c04c8dafc4e3999071698d",
            "value": " 114M/114M [00:00&lt;00:00, 175MB/s]"
          }
        },
        "946ca32e5b9346e1a27951f9f6fa3812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af9c7692c63c4e0abc6ea04ae3317a24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83b16b6249934ab38cbf3526f99f8236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8014eae21d349048d80883a07030b7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5b6efc7ea144ae4b6ea34abdb48112a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4aeaf420886e46fa98b4b4d133f33c17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4182ab3411c04c8dafc4e3999071698d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}