{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed9b5d69ddec416ebda8a316b3cc8c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89a412b300c248de8271fbb29ce4eac1",
              "IPY_MODEL_ce912487b8f54b94a8c4a31fa3936036",
              "IPY_MODEL_36229bb06f384d95a365fbbebdcb752c"
            ],
            "layout": "IPY_MODEL_17c6653bc8604e6da5b9474a4b32b6b1"
          }
        },
        "89a412b300c248de8271fbb29ce4eac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c3df506e0124e75ab7bcec242552fa3",
            "placeholder": "​",
            "style": "IPY_MODEL_1f0e7c52f8024162bb83e111bb3d4910",
            "value": "model.safetensors: 100%"
          }
        },
        "ce912487b8f54b94a8c4a31fa3936036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c1271ddd4314c42ac3bc10246a0bfca",
            "max": 102469840,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d68aa4d471d1484f91a8ceb6d69b270b",
            "value": 102469840
          }
        },
        "36229bb06f384d95a365fbbebdcb752c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1c6f0c0618e4b47b6a1a18f57d6e44f",
            "placeholder": "​",
            "style": "IPY_MODEL_d477e348e78a4fa4a3bd626efa8fe623",
            "value": " 102M/102M [00:00&lt;00:00, 159MB/s]"
          }
        },
        "17c6653bc8604e6da5b9474a4b32b6b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c3df506e0124e75ab7bcec242552fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f0e7c52f8024162bb83e111bb3d4910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c1271ddd4314c42ac3bc10246a0bfca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d68aa4d471d1484f91a8ceb6d69b270b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1c6f0c0618e4b47b6a1a18f57d6e44f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d477e348e78a4fa4a3bd626efa8fe623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install triton torchinfo utils\n",
        "!pip install -U git+https://github.com/sustcsonglin/flash-linear-attention"
      ],
      "metadata": {
        "id": "NYaLHklOKVhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364f7520-723b-44be-89fa-d5d6dbc553c3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.2.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: utils\n",
            "  Building wheel for utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13906 sha256=72245c113f8405134841d74b8b7092f0391c1046df08f76a6fcc4a60e0b41de6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/39/f5/9d0ca31dba85773ececf0a7f5469f18810e1c8a8ed9da28ca7\n",
            "Successfully built utils\n",
            "Installing collected packages: utils, triton, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 triton-3.1.0 utils-1.0.2\n",
            "Collecting git+https://github.com/sustcsonglin/flash-linear-attention\n",
            "  Cloning https://github.com/sustcsonglin/flash-linear-attention to /tmp/pip-req-build-wvk9p27s\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/sustcsonglin/flash-linear-attention /tmp/pip-req-build-wvk9p27s\n",
            "  Resolved https://github.com/sustcsonglin/flash-linear-attention to commit 014b41f12140fbc488fe34824321c6f80c9a0766\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton>=2.2 in /usr/local/lib/python3.10/dist-packages (from fla==0.1) (3.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from fla==0.1) (4.46.2)\n",
            "Collecting datasets (from fla==0.1)\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from fla==0.1) (0.8.0)\n",
            "Collecting ninja (from fla==0.1)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.2->fla==0.1) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->fla==0.1) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->fla==0.1) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->fla==0.1)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->fla==0.1) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->fla==0.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->fla==0.1) (4.66.6)\n",
            "Collecting xxhash (from datasets->fla==0.1)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->fla==0.1)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->fla==0.1)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->fla==0.1) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->fla==0.1) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->fla==0.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->fla==0.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->fla==0.1) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->fla==0.1) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->fla==0.1) (0.20.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->fla==0.1) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->fla==0.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->fla==0.1) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->fla==0.1) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->fla==0.1) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->fla==0.1) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->fla==0.1) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets->fla==0.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->fla==0.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->fla==0.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->fla==0.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->fla==0.1) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->fla==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->fla==0.1) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->fla==0.1) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->fla==0.1) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets->fla==0.1) (0.2.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fla\n",
            "  Building wheel for fla (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fla: filename=fla-0.1-py3-none-any.whl size=314708 sha256=8bd78f980b08c0c1ebd8abe116d97fb1ce1ade1c398625c99ed85c634f4434fa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nilvlv06/wheels/60/f1/20/f026085da3a701809d336b44118e9b7baf5c64c7f17f29118c\n",
            "Successfully built fla\n",
            "Installing collected packages: ninja, xxhash, fsspec, dill, multiprocess, datasets, fla\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fla-0.1 fsspec-2024.9.0 multiprocess-0.70.16 ninja-1.11.1.1 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: 11/11 merge GLA into LeViT_impl and then test model\n",
        "\n",
        "import torch\n",
        "from einops import rearrange\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import itertools\n",
        "import utils\n",
        "import timm\n",
        "\n",
        "from fla.ops.gla import fused_chunk_gla, chunk_gla, fused_recurrent_gla\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "#import os\n",
        "#os.environ['TRITON_DISABLE_BF16'] = '1'\n",
        "\n",
        "FLOPS_COUNTER = 0"
      ],
      "metadata": {
        "id": "DtecONBocuqe",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of LeViT"
      ],
      "metadata": {
        "id": "8V8h7AKzPHtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "mQ7ZefYFmqa0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vpSpWdFUlz46"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "Cx4hkNBpPcXV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ],
      "metadata": {
        "id": "dy9qBYfrPdra"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GLA (Gated Linear Attention) Module"
      ],
      "metadata": {
        "id": "WJyHnFqJeRaU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9lbVeLEgcrbN"
      },
      "outputs": [],
      "source": [
        "class GatedLinearAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.embed_dim = config.dim\n",
        "        self.num_heads = config.num_heads\n",
        "\n",
        "        self.gate_fn = nn.functional.silu\n",
        "        assert config.use_gk and not config.use_gv, \"Only use_gk is supported for simplicity.\"\n",
        "\n",
        "        self.q_proj = nn.Linear(self.embed_dim, self.embed_dim//2, bias=False)\n",
        "        self.k_proj = nn.Linear(self.embed_dim, self.embed_dim//2, bias=False)\n",
        "        self.k_gate =  nn.Sequential(nn.Linear(self.embed_dim, 16, bias=False), nn.Linear(16, self.embed_dim // 2))\n",
        "\n",
        "        self.v_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=False)\n",
        "        self.g_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=True)\n",
        "        self.out_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=False)\n",
        "\n",
        "        self.head_dim = self.embed_dim // self.num_heads\n",
        "        self.key_dim = self.embed_dim // self.num_heads\n",
        "        self.scaling = self.key_dim ** -0.5\n",
        "        self.group_norm = nn.LayerNorm(self.head_dim, eps=1e-5, elementwise_affine=False)\n",
        "\n",
        "        self.post_init()\n",
        "\n",
        "    def post_init(self):\n",
        "        nn.init.xavier_uniform_(self.q_proj.weight, gain=2 ** -2.5)\n",
        "        nn.init.xavier_uniform_(self.k_proj.weight, gain=2 ** -2.5)\n",
        "        if isinstance(self.k_gate, nn.Sequential):\n",
        "            nn.init.xavier_uniform_(self.k_gate[0].weight, gain=2 ** -2.5)\n",
        "            nn.init.xavier_uniform_(self.k_gate[1].weight, gain=2 ** -2.5)\n",
        "        else:\n",
        "            nn.init.xavier_uniform_(self.k_gate.weight, gain=2 ** -2.5)\n",
        "\n",
        "    def forward(self, x, hidden_states=None):\n",
        "        q = self.q_proj(x)\n",
        "        k = self.k_proj(x) * self.scaling\n",
        "        k_gate = self.k_gate(x)\n",
        "        v = self.v_proj(x)\n",
        "        g = self.g_proj(x)\n",
        "\n",
        "        output, new_hidden_states = self.gated_linear_attention(q, k, v, k_gate, hidden_states=hidden_states)\n",
        "        output = self.gate_fn(g) * output\n",
        "        output = self.out_proj(output)\n",
        "        return output#, new_hidden_states # this needs to be tensor, not tuple\n",
        "\n",
        "\n",
        "    def gated_linear_attention(self, q, k, v, gk, normalizer=16, hidden_states=None):\n",
        "        q = rearrange(q, 'b l (h d) -> b h l d', h = self.num_heads).contiguous()\n",
        "        k = rearrange(k, 'b l (h d) -> b h l d', h = self.num_heads).contiguous()\n",
        "        v = rearrange(v, 'b l (h d) -> b h l d', h = self.num_heads).contiguous()\n",
        "        gk = rearrange(gk, 'b l (h d) -> b h l d', h = self.num_heads).contiguous()\n",
        "        gk = F.logsigmoid(gk) / normalizer\n",
        "\n",
        "        # for storing original dtype\n",
        "        original_dtype = q.dtype\n",
        "\n",
        "        if self.training:\n",
        "            # cast inputs to float32 if needed\n",
        "            if q.dtype == torch.bfloat16:\n",
        "                q, k, v, gk = q.float(), k.float(), v.float(), gk.float()\n",
        "            o, new_hidden_states = fused_chunk_gla(q, k, v, gk, initial_state=hidden_states, output_final_state=True)\n",
        "            # cast back to origianl dtype if needed\n",
        "            if o.dtype != original_dtype:\n",
        "              o = o.type(original_dtype)\n",
        "\n",
        "        else:\n",
        "            o = fused_recurrent_gla(q, k, v, gk)\n",
        "\n",
        "            new_hidden_states = None\n",
        "\n",
        "        if isinstance(o, tuple):\n",
        "          o = o[0]\n",
        "\n",
        "        o = self.group_norm(o)\n",
        "        o = rearrange(o, 'b h l d -> b l (h d)')\n",
        "        return o, new_hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define seperate config object for GLA input\n",
        "class Config:\n",
        "    def __init__(self, dim, num_heads, use_gk=True, use_gv=False):\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.use_gk = use_gk\n",
        "        self.use_gv = use_gv"
      ],
      "metadata": {
        "id": "XlZzakcbdswK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.0, inplace=False)\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "yVtpR2thmUWp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2): # hidden state from GLA\n",
        "        super(LevitBlock, self).__init__()\n",
        "        #self.attn = Attention(dim, num_heads) # -> GLA, hidden state updates\n",
        "        self.attn = GatedLinearAttention(Config(dim, num_heads))\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZdJ9BSyUPkvh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionDownsample(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, attn_ratio=2):\n",
        "        super(AttentionDownsample, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.scale = (dim // num_heads) ** -0.5\n",
        "        inner_dim = dim * attn_ratio * num_heads\n",
        "        self.kv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.q = nn.Sequential(\n",
        "            nn.Conv2d(dim, dim, kernel_size=2, stride=2),\n",
        "            nn.Flatten(start_dim=1)\n",
        "        )\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        H = W = int(N ** 0.5)\n",
        "        x = x.reshape(B, C, H, W)\n",
        "\n",
        "        kv = self.kv(x.flatten(2).transpose(1, 2))\n",
        "        q = self.q(x)\n",
        "\n",
        "        q = q.reshape(B, -1, C)\n",
        "        x = self.proj(q)\n",
        "        return x"
      ],
      "metadata": {
        "id": "gRXUrjsTPkmA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LevitDownsample(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, attn_ratio=2):\n",
        "        super(LevitDownsample, self).__init__()\n",
        "        self.attn_downsample = AttentionDownsample(dim, out_dim, num_heads, attn_ratio)\n",
        "        self.mlp = LevitMlp(out_dim, out_dim * attn_ratio, out_dim)\n",
        "        self.drop_path = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.attn_downsample(x)\n",
        "        x = self.drop_path(self.mlp(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "Uz5pU7AFPkbD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.0):\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "ySowH5PKPum7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = LevitDownsample(dim, out_dim, num_heads) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "NRg0WFn7PrQR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GLALeViT(nn.Module):\n",
        "    def __init__(self, num_classes=37):\n",
        "        super(GLALeViT, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stages = nn.Sequential(\n",
        "            LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=3, downsample=False),\n",
        "            LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=3, downsample=True),\n",
        "            LevitStage(dim=384, out_dim=512, num_heads=8, num_blocks=2, downsample=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stages(x)\n",
        "        out = self.head(x.mean(dim=1))\n",
        "        out_dist = self.head_dist(x.mean(dim=1))\n",
        "        return out"
      ],
      "metadata": {
        "id": "M3cMGLOCPugr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet50 = timm.create_model('resnet50', pretrained=True)\n",
        "for param in ResNet50.parameters():\n",
        "    param.requires_grad = False\n",
        "ResNet50.fc = nn.Identity()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "ed9b5d69ddec416ebda8a316b3cc8c0a",
            "89a412b300c248de8271fbb29ce4eac1",
            "ce912487b8f54b94a8c4a31fa3936036",
            "36229bb06f384d95a365fbbebdcb752c",
            "17c6653bc8604e6da5b9474a4b32b6b1",
            "4c3df506e0124e75ab7bcec242552fa3",
            "1f0e7c52f8024162bb83e111bb3d4910",
            "9c1271ddd4314c42ac3bc10246a0bfca",
            "d68aa4d471d1484f91a8ceb6d69b270b",
            "b1c6f0c0618e4b47b6a1a18f57d6e44f",
            "d477e348e78a4fa4a3bd626efa8fe623"
          ]
        },
        "id": "g3lT5d4zC9fL",
        "outputId": "07662ca3-ee82-4882-d039-bf1262179699"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed9b5d69ddec416ebda8a316b3cc8c0a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LauncherModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.resnet = ResNet50\n",
        "        self.fc = nn.Linear(2048, 3 * 56 * 56)\n",
        "\n",
        "        self.upsample = nn.ConvTranspose2d(3, 3, kernel_size=4, stride=4, padding=0)\n",
        "\n",
        "        self.levit = GLALeViT()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)  # (32, 2048)\n",
        "        x = self.fc(x)  # (32, 9408)\n",
        "        x = x.view(x.size(0), 3, 56, 56)  # (32, 3, 56, 56)\n",
        "        x = self.upsample(x)  # (32, 3, 224, 224)\n",
        "        x = self.levit(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "XhVrDxiUC-j0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LauncherModel()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "2oS6ifwXdmyZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1ElLXJNrYGo",
        "outputId": "d73d0841-86c7-4cbf-f7ff-2909f4c359db"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LauncherModel(\n",
              "  (resnet): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (act1): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act1): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (drop_block): Identity()\n",
              "        (act2): ReLU(inplace=True)\n",
              "        (aa): Identity()\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (act3): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "    (fc): Identity()\n",
              "  )\n",
              "  (fc): Linear(in_features=2048, out_features=9408, bias=True)\n",
              "  (upsample): ConvTranspose2d(3, 3, kernel_size=(4, 4), stride=(4, 4))\n",
              "  (levit): GLALeViT(\n",
              "    (stem): Stem16(\n",
              "      (conv1): ConvNorm(\n",
              "        (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (act1): Hardswish()\n",
              "      (conv2): ConvNorm(\n",
              "        (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (act2): Hardswish()\n",
              "      (conv3): ConvNorm(\n",
              "        (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (act3): Hardswish()\n",
              "      (conv4): ConvNorm(\n",
              "        (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (stages): Sequential(\n",
              "      (0): LevitStage(\n",
              "        (downsample): Identity()\n",
              "        (blocks): Sequential(\n",
              "          (0): LevitBlock(\n",
              "            (attn): GatedLinearAttention(\n",
              "              (q_proj): Linear(in_features=256, out_features=128, bias=False)\n",
              "              (k_proj): Linear(in_features=256, out_features=128, bias=False)\n",
              "              (k_gate): Sequential(\n",
              "                (0): Linear(in_features=256, out_features=16, bias=False)\n",
              "                (1): Linear(in_features=16, out_features=128, bias=True)\n",
              "              )\n",
              "              (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (g_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (group_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=False)\n",
              "            )\n",
              "            (drop_path1): Identity()\n",
              "            (mlp): LevitMlp(\n",
              "              (ln1): LinearNorm(\n",
              "                (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "                (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (act): Hardswish()\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "              (ln2): LinearNorm(\n",
              "                (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (drop_path2): Identity()\n",
              "          )\n",
              "          (1): LevitBlock(\n",
              "            (attn): GatedLinearAttention(\n",
              "              (q_proj): Linear(in_features=256, out_features=128, bias=False)\n",
              "              (k_proj): Linear(in_features=256, out_features=128, bias=False)\n",
              "              (k_gate): Sequential(\n",
              "                (0): Linear(in_features=256, out_features=16, bias=False)\n",
              "                (1): Linear(in_features=16, out_features=128, bias=True)\n",
              "              )\n",
              "              (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (g_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (group_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=False)\n",
              "            )\n",
              "            (drop_path1): Identity()\n",
              "            (mlp): LevitMlp(\n",
              "              (ln1): LinearNorm(\n",
              "                (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "                (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (act): Hardswish()\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "              (ln2): LinearNorm(\n",
              "                (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (drop_path2): Identity()\n",
              "          )\n",
              "          (2): LevitBlock(\n",
              "            (attn): GatedLinearAttention(\n",
              "              (q_proj): Linear(in_features=256, out_features=128, bias=False)\n",
              "              (k_proj): Linear(in_features=256, out_features=128, bias=False)\n",
              "              (k_gate): Sequential(\n",
              "                (0): Linear(in_features=256, out_features=16, bias=False)\n",
              "                (1): Linear(in_features=16, out_features=128, bias=True)\n",
              "              )\n",
              "              (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (g_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (out_proj): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (group_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=False)\n",
              "            )\n",
              "            (drop_path1): Identity()\n",
              "            (mlp): LevitMlp(\n",
              "              (ln1): LinearNorm(\n",
              "                (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "                (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (act): Hardswish()\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "              (ln2): LinearNorm(\n",
              "                (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (drop_path2): Identity()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): LevitStage(\n",
              "        (downsample): LevitDownsample(\n",
              "          (attn_downsample): AttentionDownsample(\n",
              "            (kv): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=3072, bias=False)\n",
              "              (bn): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (q): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "              (1): Flatten(start_dim=1, end_dim=-1)\n",
              "            )\n",
              "            (proj): Sequential(\n",
              "              (0): Hardswish()\n",
              "              (1): LinearNorm(\n",
              "                (linear): Linear(in_features=256, out_features=384, bias=False)\n",
              "                (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (mlp): LevitMlp(\n",
              "            (ln1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "              (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (act): Hardswish()\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "            (ln2): LinearNorm(\n",
              "              (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (blocks): Sequential(\n",
              "          (0): LevitBlock(\n",
              "            (attn): GatedLinearAttention(\n",
              "              (q_proj): Linear(in_features=384, out_features=192, bias=False)\n",
              "              (k_proj): Linear(in_features=384, out_features=192, bias=False)\n",
              "              (k_gate): Sequential(\n",
              "                (0): Linear(in_features=384, out_features=16, bias=False)\n",
              "                (1): Linear(in_features=16, out_features=192, bias=True)\n",
              "              )\n",
              "              (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (g_proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (group_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=False)\n",
              "            )\n",
              "            (drop_path1): Identity()\n",
              "            (mlp): LevitMlp(\n",
              "              (ln1): LinearNorm(\n",
              "                (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "                (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (act): Hardswish()\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "              (ln2): LinearNorm(\n",
              "                (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "                (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (drop_path2): Identity()\n",
              "          )\n",
              "          (1): LevitBlock(\n",
              "            (attn): GatedLinearAttention(\n",
              "              (q_proj): Linear(in_features=384, out_features=192, bias=False)\n",
              "              (k_proj): Linear(in_features=384, out_features=192, bias=False)\n",
              "              (k_gate): Sequential(\n",
              "                (0): Linear(in_features=384, out_features=16, bias=False)\n",
              "                (1): Linear(in_features=16, out_features=192, bias=True)\n",
              "              )\n",
              "              (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (g_proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (group_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=False)\n",
              "            )\n",
              "            (drop_path1): Identity()\n",
              "            (mlp): LevitMlp(\n",
              "              (ln1): LinearNorm(\n",
              "                (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "                (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (act): Hardswish()\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "              (ln2): LinearNorm(\n",
              "                (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "                (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (drop_path2): Identity()\n",
              "          )\n",
              "          (2): LevitBlock(\n",
              "            (attn): GatedLinearAttention(\n",
              "              (q_proj): Linear(in_features=384, out_features=192, bias=False)\n",
              "              (k_proj): Linear(in_features=384, out_features=192, bias=False)\n",
              "              (k_gate): Sequential(\n",
              "                (0): Linear(in_features=384, out_features=16, bias=False)\n",
              "                (1): Linear(in_features=16, out_features=192, bias=True)\n",
              "              )\n",
              "              (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (g_proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (out_proj): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (group_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=False)\n",
              "            )\n",
              "            (drop_path1): Identity()\n",
              "            (mlp): LevitMlp(\n",
              "              (ln1): LinearNorm(\n",
              "                (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "                (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (act): Hardswish()\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "              (ln2): LinearNorm(\n",
              "                (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "                (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (drop_path2): Identity()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): LevitStage(\n",
              "        (downsample): LevitDownsample(\n",
              "          (attn_downsample): AttentionDownsample(\n",
              "            (kv): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=6144, bias=False)\n",
              "              (bn): BatchNorm1d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (q): Sequential(\n",
              "              (0): Conv2d(384, 384, kernel_size=(2, 2), stride=(2, 2))\n",
              "              (1): Flatten(start_dim=1, end_dim=-1)\n",
              "            )\n",
              "            (proj): Sequential(\n",
              "              (0): Hardswish()\n",
              "              (1): LinearNorm(\n",
              "                (linear): Linear(in_features=384, out_features=512, bias=False)\n",
              "                (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (mlp): LevitMlp(\n",
              "            (ln1): LinearNorm(\n",
              "              (linear): Linear(in_features=512, out_features=1024, bias=False)\n",
              "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (act): Hardswish()\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "            (ln2): LinearNorm(\n",
              "              (linear): Linear(in_features=1024, out_features=512, bias=False)\n",
              "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (blocks): Sequential(\n",
              "          (0): LevitBlock(\n",
              "            (attn): GatedLinearAttention(\n",
              "              (q_proj): Linear(in_features=512, out_features=256, bias=False)\n",
              "              (k_proj): Linear(in_features=512, out_features=256, bias=False)\n",
              "              (k_gate): Sequential(\n",
              "                (0): Linear(in_features=512, out_features=16, bias=False)\n",
              "                (1): Linear(in_features=16, out_features=256, bias=True)\n",
              "              )\n",
              "              (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (g_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (out_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (group_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=False)\n",
              "            )\n",
              "            (drop_path1): Identity()\n",
              "            (mlp): LevitMlp(\n",
              "              (ln1): LinearNorm(\n",
              "                (linear): Linear(in_features=512, out_features=1024, bias=False)\n",
              "                (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (act): Hardswish()\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "              (ln2): LinearNorm(\n",
              "                (linear): Linear(in_features=1024, out_features=512, bias=False)\n",
              "                (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (drop_path2): Identity()\n",
              "          )\n",
              "          (1): LevitBlock(\n",
              "            (attn): GatedLinearAttention(\n",
              "              (q_proj): Linear(in_features=512, out_features=256, bias=False)\n",
              "              (k_proj): Linear(in_features=512, out_features=256, bias=False)\n",
              "              (k_gate): Sequential(\n",
              "                (0): Linear(in_features=512, out_features=16, bias=False)\n",
              "                (1): Linear(in_features=16, out_features=256, bias=True)\n",
              "              )\n",
              "              (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (g_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (out_proj): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (group_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=False)\n",
              "            )\n",
              "            (drop_path1): Identity()\n",
              "            (mlp): LevitMlp(\n",
              "              (ln1): LinearNorm(\n",
              "                (linear): Linear(in_features=512, out_features=1024, bias=False)\n",
              "                (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (act): Hardswish()\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "              (ln2): LinearNorm(\n",
              "                (linear): Linear(in_features=1024, out_features=512, bias=False)\n",
              "                (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "            )\n",
              "            (drop_path2): Identity()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (head): NormLinear(\n",
              "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "      (linear): Linear(in_features=512, out_features=37, bias=True)\n",
              "    )\n",
              "    (head_dist): NormLinear(\n",
              "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "      (linear): Linear(in_features=512, out_features=37, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4KGu5baqAyR",
        "outputId": "4c0bced3-1556-4182-e6e9-9dfb6d1796c0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================================================================================================\n",
            "Layer (type:depth-idx)                                       Output Shape              Param #\n",
            "==============================================================================================================\n",
            "LauncherModel                                                [32, 37]                  --\n",
            "├─ResNet: 1-1                                                [32, 2048]                --\n",
            "│    └─Conv2d: 2-1                                           [32, 64, 112, 112]        (9,408)\n",
            "│    └─BatchNorm2d: 2-2                                      [32, 64, 112, 112]        (128)\n",
            "│    └─ReLU: 2-3                                             [32, 64, 112, 112]        --\n",
            "│    └─MaxPool2d: 2-4                                        [32, 64, 56, 56]          --\n",
            "│    └─Sequential: 2-5                                       [32, 256, 56, 56]         --\n",
            "│    │    └─Bottleneck: 3-1                                  [32, 256, 56, 56]         (75,008)\n",
            "│    │    └─Bottleneck: 3-2                                  [32, 256, 56, 56]         (70,400)\n",
            "│    │    └─Bottleneck: 3-3                                  [32, 256, 56, 56]         (70,400)\n",
            "│    └─Sequential: 2-6                                       [32, 512, 28, 28]         --\n",
            "│    │    └─Bottleneck: 3-4                                  [32, 512, 28, 28]         (379,392)\n",
            "│    │    └─Bottleneck: 3-5                                  [32, 512, 28, 28]         (280,064)\n",
            "│    │    └─Bottleneck: 3-6                                  [32, 512, 28, 28]         (280,064)\n",
            "│    │    └─Bottleneck: 3-7                                  [32, 512, 28, 28]         (280,064)\n",
            "│    └─Sequential: 2-7                                       [32, 1024, 14, 14]        --\n",
            "│    │    └─Bottleneck: 3-8                                  [32, 1024, 14, 14]        (1,512,448)\n",
            "│    │    └─Bottleneck: 3-9                                  [32, 1024, 14, 14]        (1,117,184)\n",
            "│    │    └─Bottleneck: 3-10                                 [32, 1024, 14, 14]        (1,117,184)\n",
            "│    │    └─Bottleneck: 3-11                                 [32, 1024, 14, 14]        (1,117,184)\n",
            "│    │    └─Bottleneck: 3-12                                 [32, 1024, 14, 14]        (1,117,184)\n",
            "│    │    └─Bottleneck: 3-13                                 [32, 1024, 14, 14]        (1,117,184)\n",
            "│    └─Sequential: 2-8                                       [32, 2048, 7, 7]          --\n",
            "│    │    └─Bottleneck: 3-14                                 [32, 2048, 7, 7]          (6,039,552)\n",
            "│    │    └─Bottleneck: 3-15                                 [32, 2048, 7, 7]          (4,462,592)\n",
            "│    │    └─Bottleneck: 3-16                                 [32, 2048, 7, 7]          (4,462,592)\n",
            "│    └─SelectAdaptivePool2d: 2-9                             [32, 2048]                --\n",
            "│    │    └─AdaptiveAvgPool2d: 3-17                          [32, 2048, 1, 1]          --\n",
            "│    │    └─Flatten: 3-18                                    [32, 2048]                --\n",
            "│    └─Identity: 2-10                                        [32, 2048]                --\n",
            "├─Linear: 1-2                                                [32, 9408]                19,276,992\n",
            "├─ConvTranspose2d: 1-3                                       [32, 3, 224, 224]         147\n",
            "├─GLALeViT: 1-4                                              [32, 37]                  --\n",
            "│    └─Stem16: 2-11                                          [32, 256, 14, 14]         --\n",
            "│    │    └─ConvNorm: 3-19                                   [32, 32, 112, 112]        928\n",
            "│    │    └─Hardswish: 3-20                                  [32, 32, 112, 112]        --\n",
            "│    │    └─ConvNorm: 3-21                                   [32, 64, 56, 56]          18,560\n",
            "│    │    └─Hardswish: 3-22                                  [32, 64, 56, 56]          --\n",
            "│    │    └─ConvNorm: 3-23                                   [32, 128, 28, 28]         73,984\n",
            "│    │    └─Hardswish: 3-24                                  [32, 128, 28, 28]         --\n",
            "│    │    └─ConvNorm: 3-25                                   [32, 256, 14, 14]         295,424\n",
            "│    └─Sequential: 2-12                                      [32, 9, 512]              --\n",
            "│    │    └─LevitStage: 3-26                                 [32, 196, 256]            1,597,056\n",
            "│    │    └─LevitStage: 3-27                                 [32, 49, 384]             5,321,408\n",
            "│    │    └─LevitStage: 3-28                                 [32, 9, 512]              8,437,632\n",
            "│    └─NormLinear: 2-13                                      [32, 37]                  --\n",
            "│    │    └─BatchNorm1d: 3-29                                [32, 512]                 1,024\n",
            "│    │    └─Dropout: 3-30                                    [32, 512]                 --\n",
            "│    │    └─Linear: 3-31                                     [32, 37]                  18,981\n",
            "│    └─NormLinear: 2-14                                      [32, 37]                  --\n",
            "│    │    └─BatchNorm1d: 3-32                                [32, 512]                 1,024\n",
            "│    │    └─Dropout: 3-33                                    [32, 512]                 --\n",
            "│    │    └─Linear: 3-34                                     [32, 37]                  18,981\n",
            "==============================================================================================================\n",
            "Total params: 58,570,173\n",
            "Trainable params: 35,062,141\n",
            "Non-trainable params: 23,508,032\n",
            "Total mult-adds (G): 156.76\n",
            "==============================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 7215.63\n",
            "Params size (MB): 234.28\n",
            "Estimated Total Size (MB): 7469.18\n",
            "==============================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "7K2FpPhprYDG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainval_data = datasets.OxfordIIITPet(root=\"data\", split=\"trainval\", target_types=\"category\", download=True, transform=transform)\n",
        "test_data = datasets.OxfordIIITPet(root=\"data\", split=\"test\", target_types=\"category\", download=True, transform=transform)\n",
        "combined_data = ConcatDataset([trainval_data, test_data])\n",
        "\n",
        "train_size = int(0.7 * len(combined_data))\n",
        "val_size = int(0.15 * len(combined_data))\n",
        "test_size = len(combined_data) - train_size - val_size\n",
        "train_data, val_data, test_data = random_split(combined_data, [train_size, val_size, test_size])"
      ],
      "metadata": {
        "id": "y8bImNeErX7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d670d13a-a57a-41bb-8c8e-eb52e7526498"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/pets/images.tar.gz to data/oxford-iiit-pet/images.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 792M/792M [00:21<00:00, 37.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/oxford-iiit-pet/images.tar.gz to data/oxford-iiit-pet\n",
            "Downloading https://thor.robots.ox.ac.uk/pets/annotations.tar.gz to data/oxford-iiit-pet/annotations.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19.2M/19.2M [00:01<00:00, 16.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/oxford-iiit-pet/annotations.tar.gz to data/oxford-iiit-pet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-EJl1EDrqWL",
        "outputId": "e880f408-5103-4d16-ca1c-618dd0dfaf75"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 5144\n",
            "Validation set size: 1102\n",
            "Test set size: 1103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Q3gXlU_5rqSx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "HxQ-bTtSrqQJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "9AxFISArrXwV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ],
      "metadata": {
        "id": "J0mP8LecrvlA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device)\n",
        "    evaluate(model, val_loader, criterion, device, phase=\"Validation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFoP-FZKrvbD",
        "outputId": "d45f2aae-7733-437d-fe6d-14b498a1ea98"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:57<00:00,  2.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.2799, Train Accuracy: 6.84%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 34.7455, Validation Accuracy: 3.27%\n",
            "\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.3531, Train Accuracy: 19.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 43.3360, Validation Accuracy: 2.27%\n",
            "\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.8434, Train Accuracy: 34.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:05<00:00,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 43.1318, Validation Accuracy: 2.54%\n",
            "\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.4569, Train Accuracy: 46.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 9.7438, Validation Accuracy: 10.44%\n",
            "\n",
            "Epoch 5/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.2547, Train Accuracy: 54.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.5905, Validation Accuracy: 21.51%\n",
            "\n",
            "Epoch 6/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.1465, Train Accuracy: 58.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 8.7159, Validation Accuracy: 5.81%\n",
            "\n",
            "Epoch 7/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.1463, Train Accuracy: 58.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:05<00:00,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 6.4988, Validation Accuracy: 15.34%\n",
            "\n",
            "Epoch 8/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.1460, Train Accuracy: 58.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1895, Validation Accuracy: 58.35%\n",
            "\n",
            "Epoch 9/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0181, Train Accuracy: 62.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.6585, Validation Accuracy: 47.10%\n",
            "\n",
            "Epoch 10/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.9724, Train Accuracy: 65.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.8947, Validation Accuracy: 26.86%\n",
            "\n",
            "Epoch 11/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.9078, Train Accuracy: 67.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.7423, Validation Accuracy: 48.64%\n",
            "\n",
            "Epoch 12/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.9262, Train Accuracy: 67.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.5574, Validation Accuracy: 52.18%\n",
            "\n",
            "Epoch 13/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.9202, Train Accuracy: 67.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:05<00:00,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.5223, Validation Accuracy: 51.36%\n",
            "\n",
            "Epoch 14/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.8141, Train Accuracy: 70.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 9.4874, Validation Accuracy: 10.53%\n",
            "\n",
            "Epoch 15/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.0151, Train Accuracy: 54.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 39.9461, Validation Accuracy: 2.90%\n",
            "\n",
            "Epoch 16/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.4130, Train Accuracy: 49.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.3277, Validation Accuracy: 54.81%\n",
            "\n",
            "Epoch 17/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.0833, Train Accuracy: 61.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.5208, Validation Accuracy: 52.90%\n",
            "\n",
            "Epoch 18/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.9534, Train Accuracy: 67.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.0049, Validation Accuracy: 42.56%\n",
            "\n",
            "Epoch 19/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.7726, Train Accuracy: 73.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:05<00:00,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.9804, Validation Accuracy: 35.39%\n",
            "\n",
            "Epoch 20/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.7196, Train Accuracy: 75.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.4602, Validation Accuracy: 40.20%\n",
            "\n",
            "Epoch 21/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6844, Train Accuracy: 76.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:05<00:00,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.7119, Validation Accuracy: 31.76%\n",
            "\n",
            "Epoch 22/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6067, Train Accuracy: 79.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.9464, Validation Accuracy: 41.29%\n",
            "\n",
            "Epoch 23/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5578, Train Accuracy: 80.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.7101, Validation Accuracy: 44.56%\n",
            "\n",
            "Epoch 24/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5586, Train Accuracy: 80.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 5.7854, Validation Accuracy: 19.69%\n",
            "\n",
            "Epoch 25/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5383, Train Accuracy: 81.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.7685, Validation Accuracy: 43.28%\n",
            "\n",
            "Epoch 26/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5431, Train Accuracy: 81.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.4956, Validation Accuracy: 58.26%\n",
            "\n",
            "Epoch 27/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5187, Train Accuracy: 81.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.3505, Validation Accuracy: 42.47%\n",
            "\n",
            "Epoch 28/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5278, Train Accuracy: 81.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0137, Validation Accuracy: 68.97%\n",
            "\n",
            "Epoch 29/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4610, Train Accuracy: 83.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.4777, Validation Accuracy: 62.34%\n",
            "\n",
            "Epoch 30/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4947, Train Accuracy: 83.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.2530, Validation Accuracy: 50.09%\n",
            "\n",
            "Epoch 31/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4840, Train Accuracy: 82.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 8.0298, Validation Accuracy: 16.06%\n",
            "\n",
            "Epoch 32/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4330, Train Accuracy: 84.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.6204, Validation Accuracy: 58.98%\n",
            "\n",
            "Epoch 33/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4289, Train Accuracy: 85.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.0940, Validation Accuracy: 51.81%\n",
            "\n",
            "Epoch 34/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4161, Train Accuracy: 85.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.4548, Validation Accuracy: 61.71%\n",
            "\n",
            "Epoch 35/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4311, Train Accuracy: 84.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8678, Validation Accuracy: 75.14%\n",
            "\n",
            "Epoch 36/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4104, Train Accuracy: 85.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9988, Validation Accuracy: 72.78%\n",
            "\n",
            "Epoch 37/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3841, Train Accuracy: 86.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:05<00:00,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.6274, Validation Accuracy: 60.34%\n",
            "\n",
            "Epoch 38/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3780, Train Accuracy: 86.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 4.3117, Validation Accuracy: 30.49%\n",
            "\n",
            "Epoch 39/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3864, Train Accuracy: 86.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 5.6317, Validation Accuracy: 25.77%\n",
            "\n",
            "Epoch 40/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4458, Train Accuracy: 84.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.9432, Validation Accuracy: 55.35%\n",
            "\n",
            "Epoch 41/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4100, Train Accuracy: 85.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.6259, Validation Accuracy: 62.16%\n",
            "\n",
            "Epoch 42/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3397, Train Accuracy: 88.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.7373, Validation Accuracy: 49.46%\n",
            "\n",
            "Epoch 43/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3559, Train Accuracy: 87.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:05<00:00,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 4.3290, Validation Accuracy: 36.48%\n",
            "\n",
            "Epoch 44/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3646, Train Accuracy: 87.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 38.8127, Validation Accuracy: 6.08%\n",
            "\n",
            "Epoch 45/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3813, Train Accuracy: 86.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.1127, Validation Accuracy: 53.18%\n",
            "\n",
            "Epoch 46/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3036, Train Accuracy: 89.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.4757, Validation Accuracy: 42.20%\n",
            "\n",
            "Epoch 47/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3122, Train Accuracy: 89.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.2266, Validation Accuracy: 70.87%\n",
            "\n",
            "Epoch 48/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2570, Train Accuracy: 90.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.9570, Validation Accuracy: 58.89%\n",
            "\n",
            "Epoch 49/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2209, Train Accuracy: 92.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:05<00:00,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0322, Validation Accuracy: 75.32%\n",
            "\n",
            "Epoch 50/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:34<00:00,  4.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2402, Train Accuracy: 91.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.8954, Validation Accuracy: 48.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gc2zQDfrvXz",
        "outputId": "9f217692-f79c-4b01-d568-2f5f860cfc8a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 35/35 [00:06<00:00,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.8617, Test Accuracy: 49.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH6ZUi6UrvVK",
        "outputId": "0a21847e-2d49-411d-9bdd-2fd2159f01cb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 35\n",
            "Average Time: 24.53 ms\n",
            "Standard Deviation: 0.57 ms\n",
            "Maximum Time: 24.67 ms\n",
            "Minimum Time: 21.20 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tTWtuIp6qFXC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}