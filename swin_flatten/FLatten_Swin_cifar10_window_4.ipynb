{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bEMpr27c0RCi",
    "outputId": "d86b304b-23be-4240-f2b5-1c77b82e8d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu112\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.19.1+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: timm in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: pytorch-ignite in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: einops in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (2.4.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (0.19.1+cu118)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (0.25.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (0.4.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-ignite) (24.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (75.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub->timm) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch->timm) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ignite\\handlers\\checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# Swin Transformer\n",
    "# Copyright (c) 2021 Microsoft\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Ze Liu\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu112\n",
    "!pip3 install timm pytorch-ignite einops matplotlib\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "from einops import rearrange\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "import ignite.metrics\n",
    "import ignite.contrib.handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cxGT3QPy0q0H"
   },
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wncXpbHk09rc"
   },
   "outputs": [],
   "source": [
    "def window_partition(x, window_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, H, W, C)\n",
    "        window_size (int): window size\n",
    "\n",
    "    Returns:\n",
    "        windows: (num_windows*B, window_size, window_size, C)\n",
    "    \"\"\"\n",
    "    B, H, W, C = x.shape\n",
    "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
    "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uvsOSiH-1DdL"
   },
   "outputs": [],
   "source": [
    "def window_reverse(windows, window_size, H, W):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        windows: (num_windows*B, window_size, window_size, C)\n",
    "        window_size (int): Window size\n",
    "        H (int): Height of image\n",
    "        W (int): Width of image\n",
    "\n",
    "    Returns:\n",
    "        x: (B, H, W, C)\n",
    "    \"\"\"\n",
    "    B = int(windows.shape[0] / (H * W / window_size / window_size))\n",
    "    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n",
    "    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Fp57DIJ41EBj"
   },
   "outputs": [],
   "source": [
    "class WindowAttention(nn.Module):\n",
    "    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n",
    "    It supports both of shifted and non-shifted window.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        window_size (tuple[int]): The height and width of the window.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set\n",
    "        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n",
    "        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size  # Wh, Ww\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        # define a parameter table of relative position bias\n",
    "        self.relative_position_bias_table = nn.Parameter(\n",
    "            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n",
    "\n",
    "        # get pair-wise relative position index for each token inside the window\n",
    "        coords_h = torch.arange(self.window_size[0])\n",
    "        coords_w = torch.arange(self.window_size[1])\n",
    "        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
    "        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to start from 0\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
    "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "        trunc_normal_(self.relative_position_bias_table, std=.02)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: input features with shape of (num_windows*B, N, C)\n",
    "            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n",
    "        \"\"\"\n",
    "        B_, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]  # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        q = q * self.scale\n",
    "        attn = (q @ k.transpose(-2, -1))\n",
    "\n",
    "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n",
    "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "        attn = attn + relative_position_bias.unsqueeze(0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.shape[0]\n",
    "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
    "            attn = attn.view(-1, self.num_heads, N, N)\n",
    "            attn = self.softmax(attn)\n",
    "        else:\n",
    "            attn = self.softmax(attn)\n",
    "\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'dim={self.dim}, window_size={self.window_size}, num_heads={self.num_heads}'\n",
    "\n",
    "    def flops(self, N):\n",
    "        # calculate flops for 1 window with token length of N\n",
    "        flops = 0\n",
    "        # qkv = self.qkv(x)\n",
    "        flops += N * self.dim * 3 * self.dim\n",
    "        # attn = (q @ k.transpose(-2, -1))\n",
    "        flops += self.num_heads * N * (self.dim // self.num_heads) * N\n",
    "        #  x = (attn @ v)\n",
    "        flops += self.num_heads * N * N * (self.dim // self.num_heads)\n",
    "        # x = self.proj(x)\n",
    "        flops += N * self.dim * self.dim\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "e_UlHriB1I6l"
   },
   "outputs": [],
   "source": [
    "class FocusedLinearAttention(nn.Module):\n",
    "    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n",
    "    It supports both of shifted and non-shifted window.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        window_size (tuple[int]): The height and width of the window.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set\n",
    "        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n",
    "        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.,\n",
    "                 focusing_factor=3, kernel_size=5):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size  # Wh, Ww\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "\n",
    "        self.focusing_factor = focusing_factor  # Used to sharpen attention distribution\n",
    "\n",
    "    # Linear layer to project input to query, key, and value\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)  # Output projection\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        # Depth-wise convolution for capturing local spatial information\n",
    "        self.dwc = nn.Conv2d(in_channels=head_dim, out_channels=head_dim, kernel_size=kernel_size,\n",
    "                            groups=head_dim, padding=kernel_size // 2)\n",
    "\n",
    "        # Learnable scale parameter\n",
    "        self.scale = nn.Parameter(torch.zeros(size=(1, 1, dim)))\n",
    "\n",
    "        # Learnable positional encoding\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(size=(1, window_size[0] * window_size[1], dim)))\n",
    "\n",
    "        print('Linear Attention window{} f{} kernel{}'.\n",
    "              format(window_size, focusing_factor, kernel_size))\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        B, N, C = x.shape\n",
    "\n",
    "        # Project input to query, key, and value\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, C).permute(2, 0, 1, 3)\n",
    "        q, k, v = qkv.unbind(0)\n",
    "\n",
    "        # Add positional encoding to keys\n",
    "        k = k + self.positional_encoding\n",
    "\n",
    "        focusing_factor = self.focusing_factor\n",
    "        kernel_function = nn.ReLU()\n",
    "\n",
    "        # Apply ReLU and add small epsilon to avoid zero values\n",
    "        q = kernel_function(q) + 1e-6\n",
    "        k = kernel_function(k) + 1e-6\n",
    "\n",
    "        # Compute scale using Softplus for stability\n",
    "        scale = nn.Softplus()(self.scale)\n",
    "        q = q / scale\n",
    "        k = k / scale\n",
    "\n",
    "        # Store original norms\n",
    "        q_norm = q.norm(dim=-1, keepdim=True)\n",
    "        k_norm = k.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # Apply focusing factor\n",
    "        q = q ** focusing_factor\n",
    "        k = k ** focusing_factor\n",
    "\n",
    "        # Renormalize to original norms\n",
    "        q = (q / q.norm(dim=-1, keepdim=True)) * q_norm\n",
    "        k = (k / k.norm(dim=-1, keepdim=True)) * k_norm\n",
    "\n",
    "        # Reshape for multi-head attention\n",
    "        q = q.reshape(B, N, self.num_heads, -1).permute(0, 2, 1, 3)\n",
    "        k = k.reshape(B, N, self.num_heads, -1).permute(0, 2, 1, 3)\n",
    "        v = v.reshape(B, N, self.num_heads, -1).permute(0, 2, 1, 3)\n",
    "\n",
    "        # Compute linear attention\n",
    "        z = 1 / (q @ k.mean(dim=-2, keepdim=True).transpose(-2, -1) + 1e-6)\n",
    "        kv = (k.transpose(-2, -1) * (N ** -0.5)) @ (v * (N ** -0.5))\n",
    "        x = q @ kv * z\n",
    "\n",
    "        # Reshape output\n",
    "        H = W = int(N ** 0.5)\n",
    "        x = x.transpose(1, 2).reshape(B, N, C)\n",
    "\n",
    "        # Apply depth-wise convolution to capture local spatial information\n",
    "        v = v.reshape(B * self.num_heads, H, W, -1).permute(0, 3, 1, 2)\n",
    "        x = x + self.dwc(v).reshape(B, C, N).permute(0, 2, 1)\n",
    "\n",
    "        # Final projection and dropout\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "    def eval(self):\n",
    "        super(FocusedLinearAttention, self).eval()\n",
    "        print('eval')\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'dim={self.dim}, window_size={self.window_size}, num_heads={self.num_heads}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DIR8e1tu1O5O"
   },
   "outputs": [],
   "source": [
    "class SwinTransformerBlock(nn.Module):\n",
    "    r\"\"\" Swin Transformer Block.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        input_resolution (tuple[int]): Input resulotion.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Window size.\n",
    "        shift_size (int): Shift size for SW-MSA.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
    "        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n",
    "        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU\n",
    "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, input_resolution, num_heads, window_size=7, shift_size=0,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
    "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm,\n",
    "                 focusing_factor=3, kernel_size=5, attn_type='L'):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        if min(self.input_resolution) <= self.window_size:\n",
    "            # if window size is larger than input resolution, we don't partition windows\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.input_resolution)\n",
    "        assert 0 <= self.shift_size < self.window_size, \"shift_size must in 0-window_size\"\n",
    "\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        assert attn_type in ['L', 'S']\n",
    "        if attn_type == 'L':\n",
    "            self.attn = FocusedLinearAttention(\n",
    "                dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,\n",
    "                qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop,\n",
    "                focusing_factor=focusing_factor, kernel_size=kernel_size)\n",
    "        else:\n",
    "            self.attn = WindowAttention(\n",
    "                dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,\n",
    "                qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "        if self.shift_size > 0:\n",
    "            # calculate attention mask for SW-MSA\n",
    "            H, W = self.input_resolution\n",
    "            img_mask = torch.zeros((1, H, W, 1))  # 1 H W 1\n",
    "            h_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            w_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            cnt = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    img_mask[:, h, w, :] = cnt\n",
    "                    cnt += 1\n",
    "\n",
    "            mask_windows = window_partition(img_mask, self.window_size)  # nW, window_size, window_size, 1\n",
    "            mask_windows = mask_windows.view(-1, self.window_size * self.window_size)\n",
    "            attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
    "            attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
    "        else:\n",
    "            attn_mask = None\n",
    "\n",
    "        self.register_buffer(\"attn_mask\", attn_mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        # cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        # partition windows\n",
    "        x_windows = window_partition(shifted_x, self.window_size)  # nW*B, window_size, window_size, C\n",
    "        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)  # nW*B, window_size*window_size, C\n",
    "\n",
    "        # W-MSA/SW-MSA\n",
    "        attn_windows = self.attn(x_windows, mask=self.attn_mask)  # nW*B, window_size*window_size, C\n",
    "\n",
    "        # merge windows\n",
    "        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n",
    "        shifted_x = window_reverse(attn_windows, self.window_size, H, W)  # B H' W' C\n",
    "\n",
    "        # reverse cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            x = shifted_x\n",
    "        x = x.view(B, H * W, C)\n",
    "\n",
    "        # FFN\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, \" \\\n",
    "               f\"window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}\"\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        H, W = self.input_resolution\n",
    "        # norm1\n",
    "        flops += self.dim * H * W\n",
    "        # W-MSA/SW-MSA\n",
    "        nW = H * W / self.window_size / self.window_size\n",
    "        flops += nW * self.attn.flops(self.window_size * self.window_size)\n",
    "        # mlp\n",
    "        flops += 2 * H * W * self.dim * self.dim * self.mlp_ratio\n",
    "        # norm2\n",
    "        flops += self.dim * H * W\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "blyYs6kZ1TeT"
   },
   "outputs": [],
   "source": [
    "class PatchMerging(nn.Module):\n",
    "    r\"\"\" Patch Merging Layer.\n",
    "\n",
    "    Args:\n",
    "        input_resolution (tuple[int]): Resolution of input feature.\n",
    "        dim (int): Number of input channels.\n",
    "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_resolution, dim, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.input_resolution = input_resolution\n",
    "        self.dim = dim\n",
    "        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n",
    "        self.norm = norm_layer(4 * dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: B, H*W, C\n",
    "        \"\"\"\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "        assert H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\"\n",
    "\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C\n",
    "        x = x.view(B, -1, 4 * C)  # B H/2*W/2 4*C\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = self.reduction(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"input_resolution={self.input_resolution}, dim={self.dim}\"\n",
    "\n",
    "    def flops(self):\n",
    "        H, W = self.input_resolution\n",
    "        flops = H * W * self.dim\n",
    "        flops += (H // 2) * (W // 2) * 4 * self.dim * 2 * self.dim\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XNJN4Z_01WBE"
   },
   "outputs": [],
   "source": [
    "class BasicLayer(nn.Module):\n",
    "    \"\"\" A basic Swin Transformer layer for one stage.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        input_resolution (tuple[int]): Input resolution.\n",
    "        depth (int): Number of blocks.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Local window size.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
    "        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0\n",
    "        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm\n",
    "        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None\n",
    "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, input_resolution, depth, num_heads, window_size,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., norm_layer=nn.LayerNorm, downsample=None, use_checkpoint=False,\n",
    "                 focusing_factor=3, kernel_size=5, attn_type='L'):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.depth = depth\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "\n",
    "        # build blocks\n",
    "        attn_types = [(attn_type if attn_type[0] != 'M' else ('L' if i < int(attn_type[1:]) else 'S')) for i in range(depth)]\n",
    "        window_sizes = [(window_size if attn_types[i] == 'L' else (7 if window_size <= 56 else 12)) for i in range(depth)]\n",
    "        self.blocks = nn.ModuleList([\n",
    "            SwinTransformerBlock(dim=dim, input_resolution=input_resolution,\n",
    "                                 num_heads=num_heads, window_size=window_sizes[i],\n",
    "                                 shift_size=0 if (i % 2 == 0) else window_sizes[i] // 2,\n",
    "                                 mlp_ratio=mlp_ratio,\n",
    "                                 qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                                 drop=drop, attn_drop=attn_drop,\n",
    "                                 drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
    "                                 norm_layer=norm_layer,\n",
    "                                 focusing_factor=focusing_factor,\n",
    "                                 kernel_size=kernel_size,\n",
    "                                 attn_type=attn_types[i])\n",
    "            for i in range(depth)])\n",
    "\n",
    "        # patch merging layer\n",
    "        if downsample is not None:\n",
    "            self.downsample = downsample(input_resolution, dim=dim, norm_layer=norm_layer)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x = checkpoint.checkpoint(blk, x)\n",
    "            else:\n",
    "                x = blk(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, depth={self.depth}\"\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        for blk in self.blocks:\n",
    "            flops += blk.flops()\n",
    "        if self.downsample is not None:\n",
    "            flops += self.downsample.flops()\n",
    "        return flops\n",
    "\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    r\"\"\" Image to Patch Embedding\n",
    "\n",
    "    Args:\n",
    "        img_size (int): Image size.  Default: 224.\n",
    "        patch_size (int): Patch token size. Default: 4.\n",
    "        in_chans (int): Number of input image channels. Default: 3.\n",
    "        embed_dim (int): Number of linear projection output channels. Default: 96.\n",
    "        norm_layer (nn.Module, optional): Normalization layer. Default: None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_size=224, patch_size=4, in_chans=3, embed_dim=96, norm_layer=None):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        patches_resolution = [img_size[0] // patch_size[0], img_size[1] // patch_size[1]]\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.patches_resolution = patches_resolution\n",
    "        self.num_patches = patches_resolution[0] * patches_resolution[1]\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        if norm_layer is not None:\n",
    "            self.norm = norm_layer(embed_dim)\n",
    "        else:\n",
    "            self.norm = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        # FIXME look at relaxing size constraints\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)  # B Ph*Pw C\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self):\n",
    "        Ho, Wo = self.patches_resolution\n",
    "        flops = Ho * Wo * self.embed_dim * self.in_chans * (self.patch_size[0] * self.patch_size[1])\n",
    "        if self.norm is not None:\n",
    "            flops += Ho * Wo * self.embed_dim\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LuascylH1a-6"
   },
   "outputs": [],
   "source": [
    "class FLattenSwinTransformer(nn.Module):\n",
    "    r\"\"\" Swin Transformer\n",
    "        A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -\n",
    "          https://arxiv.org/pdf/2103.14030\n",
    "\n",
    "    Args:\n",
    "        img_size (int | tuple(int)): Input image size. Default 224\n",
    "        patch_size (int | tuple(int)): Patch size. Default: 4\n",
    "        in_chans (int): Number of input image channels. Default: 3\n",
    "        num_classes (int): Number of classes for classification head. Default: 1000\n",
    "        embed_dim (int): Patch embedding dimension. Default: 96\n",
    "        depths (tuple(int)): Depth of each Swin Transformer layer.\n",
    "        num_heads (tuple(int)): Number of attention heads in different layers.\n",
    "        window_size (int): Window size. Default: 7\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4\n",
    "        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float): Override default qk scale of head_dim ** -0.5 if set. Default: None\n",
    "        drop_rate (float): Dropout rate. Default: 0\n",
    "        attn_drop_rate (float): Attention dropout rate. Default: 0\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.1\n",
    "        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.\n",
    "        ape (bool): If True, add absolute position embedding to the patch embedding. Default: False\n",
    "        patch_norm (bool): If True, add normalization after patch embedding. Default: True\n",
    "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_size=32, patch_size=4, in_chans=3, num_classes=1000,\n",
    "                 embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n",
    "                 window_size=7, mlp_ratio=4., qkv_bias=True, qk_scale=None,\n",
    "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n",
    "                 norm_layer=nn.LayerNorm, ape=False, patch_norm=True,\n",
    "                 use_checkpoint=False,\n",
    "                 focusing_factor=3, kernel_size=5, attn_type='LLLL', **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = len(depths)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ape = ape\n",
    "        self.patch_norm = patch_norm\n",
    "        self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "\n",
    "        # split image into non-overlapping patches\n",
    "        self.patch_embed = PatchEmbed(\n",
    "            img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim,\n",
    "            norm_layer=norm_layer if self.patch_norm else None)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        patches_resolution = self.patch_embed.patches_resolution\n",
    "        self.patches_resolution = patches_resolution\n",
    "\n",
    "        # absolute position embedding\n",
    "        if self.ape:\n",
    "            self.absolute_pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
    "            trunc_normal_(self.absolute_pos_embed, std=.02)\n",
    "\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        # stochastic depth\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n",
    "\n",
    "        # build layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i_layer in range(self.num_layers):\n",
    "            layer = BasicLayer(dim=int(embed_dim * 2 ** i_layer),\n",
    "                               input_resolution=(patches_resolution[0] // (2 ** i_layer),\n",
    "                                                 patches_resolution[1] // (2 ** i_layer)),\n",
    "                               depth=depths[i_layer],\n",
    "                               num_heads=num_heads[i_layer],\n",
    "                               window_size=window_size,\n",
    "                               mlp_ratio=self.mlp_ratio,\n",
    "                               qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                               drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                               drop_path=dpr[sum(depths[:i_layer]):sum(depths[:i_layer + 1])],\n",
    "                               norm_layer=norm_layer,\n",
    "                               downsample=PatchMerging if (i_layer < self.num_layers - 1) else None,\n",
    "                               use_checkpoint=use_checkpoint,\n",
    "                               focusing_factor=focusing_factor,\n",
    "                               kernel_size=kernel_size,\n",
    "                               attn_type=attn_type[i_layer] + (attn_type[self.num_layers:] if attn_type[i_layer] == 'M' else ''))\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.norm = norm_layer(self.num_features)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'absolute_pos_embed'}\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay_keywords(self):\n",
    "        return {'relative_position_bias_table'}\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        if self.ape:\n",
    "            x = x + self.absolute_pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.norm(x)  # B L C\n",
    "        x = self.avgpool(x.transpose(1, 2))  # B C 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        flops += self.patch_embed.flops()\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            flops += layer.flops()\n",
    "        flops += self.num_features * self.patches_resolution[0] * self.patches_resolution[1] // (2 ** self.num_layers)\n",
    "        flops += self.num_features * self.num_classes\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "CH3oe5YA1en5"
   },
   "outputs": [],
   "source": [
    "DATA_DIR='./data'\n",
    "\n",
    "IMAGE_SIZE = 32\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "NUM_WORKERS = 8\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CIG2Ai-N1rHK",
    "outputId": "4d641b02-cebf-4dd2-da65-46ad48144db5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4936866700842985690\n",
      "xla_global_id: -1\n",
      "]\n",
      "2.4.1+cu118\n",
      "11.8\n",
      "True\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)  # This will show the version of PyTorch\n",
    "print(torch.version.cuda)  # This will show the version of CUDA PyTorch is linked against\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c73u1cDN2wC4",
    "outputId": "ef5015da-5064-4dd4-d2fa-79d4631d2d7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float)\n",
    "])\n",
    "\n",
    "train_dset = datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=train_transform)\n",
    "test_dset = datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "KKpPWqWt2xoz"
   },
   "outputs": [],
   "source": [
    "def dataset_show_image(dset, idx):\n",
    "    X, Y = dset[idx]\n",
    "    title = \"Ground truth: {}\".format(dset.classes[Y])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(np.moveaxis(X.numpy(), 0, -1))\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "nL_w38GL3LeA",
    "outputId": "d173c5f6-0fe9-42f0-bd1f-98849ac90963"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_show_image(test_dset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWEj9CuI3Rjj",
    "outputId": "34daaffb-66fe-47a1-af42-101d1b24671e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Data loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),  # Swin Transformer expects 224x224 input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Attention window(4, 4) f2 kernel5\n",
      "Linear Attention window(4, 4) f2 kernel5\n",
      "Linear Attention window(4, 4) f2 kernel5\n",
      "Linear Attention window(4, 4) f2 kernel5\n",
      "Linear Attention window(2, 2) f2 kernel5\n",
      "Linear Attention window(2, 2) f2 kernel5\n",
      "Linear Attention window(2, 2) f2 kernel5\n",
      "Linear Attention window(2, 2) f2 kernel5\n",
      "Linear Attention window(2, 2) f2 kernel5\n",
      "Linear Attention window(2, 2) f2 kernel5\n",
      "Linear Attention window(1, 1) f2 kernel5\n",
      "Linear Attention window(1, 1) f2 kernel5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FLattenSwinTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.1, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): BasicLayer(\n",
       "      dim=96, input_resolution=(8, 8), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=96, input_resolution=(8, 8), num_heads=3, window_size=4, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=96, window_size=(4, 4), num_heads=3\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=96, input_resolution=(8, 8), num_heads=3, window_size=4, shift_size=2, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=96, window_size=(4, 4), num_heads=3\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.009)\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(8, 8), dim=96\n",
       "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicLayer(\n",
       "      dim=192, input_resolution=(4, 4), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=192, input_resolution=(4, 4), num_heads=6, window_size=4, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=192, window_size=(4, 4), num_heads=6\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.018)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=192, input_resolution=(4, 4), num_heads=6, window_size=4, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=192, window_size=(4, 4), num_heads=6\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.027)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(4, 4), dim=192\n",
       "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicLayer(\n",
       "      dim=384, input_resolution=(2, 2), depth=6\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(2, 2), num_heads=12, window_size=2, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=384, window_size=(2, 2), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.036)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(2, 2), num_heads=12, window_size=2, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=384, window_size=(2, 2), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.045)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(2, 2), num_heads=12, window_size=2, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=384, window_size=(2, 2), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.055)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(2, 2), num_heads=12, window_size=2, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=384, window_size=(2, 2), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.064)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(2, 2), num_heads=12, window_size=2, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=384, window_size=(2, 2), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.073)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(2, 2), num_heads=12, window_size=2, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=384, window_size=(2, 2), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.082)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(2, 2), dim=384\n",
       "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): BasicLayer(\n",
       "      dim=768, input_resolution=(1, 1), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=768, input_resolution=(1, 1), num_heads=24, window_size=1, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=768, window_size=(1, 1), num_heads=24\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.091)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=768, input_resolution=(1, 1), num_heads=24, window_size=1, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=768, window_size=(1, 1), num_heads=24\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.100)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (head): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model instantiation\n",
    "model = FLattenSwinTransformer(\n",
    "    img_size=32,\n",
    "    patch_size=4,\n",
    "    in_chans=3,\n",
    "    num_classes=10,  # CIFAR-10 has 10 classes\n",
    "    embed_dim=96,\n",
    "    depths=[2, 2, 6, 2], # 2,2,6,2\n",
    "    num_heads=[3, 6, 12, 24],\n",
    "    window_size=4,\n",
    "    mlp_ratio=4.,\n",
    "    qkv_bias=True,\n",
    "    drop_rate=0.1,\n",
    "    attn_drop_rate=0.1,\n",
    "    drop_path_rate=0.1,\n",
    "    ape=False,\n",
    "    patch_norm=True,\n",
    "    use_checkpoint=False,\n",
    "    focusing_factor=2, # p=3\n",
    "    kernel_size=5,\n",
    "    attn_type='LLLL'\n",
    ")\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqpdKvMZ6RWm",
    "outputId": "21ff8c31-b326-4f89-f11a-e2633d8435fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 27,538,090\n"
     ]
    }
   ],
   "source": [
    "# Optimizer and loss function\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Initialize lists to store losses\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "4PmtkvvX7z53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Training Loss: 1.8348, Accuracy: 31.38%\n",
      "Test Loss: 1.5759, Test Accuracy: 40.43%\n",
      "Epoch [2/100], Training Loss: 1.4540, Accuracy: 46.45%\n",
      "Test Loss: 1.3969, Test Accuracy: 49.72%\n",
      "Epoch [3/100], Training Loss: 1.2813, Accuracy: 53.61%\n",
      "Test Loss: 1.2239, Test Accuracy: 55.63%\n",
      "Epoch [4/100], Training Loss: 1.1597, Accuracy: 58.16%\n",
      "Test Loss: 1.1453, Test Accuracy: 59.37%\n",
      "Epoch [5/100], Training Loss: 1.0713, Accuracy: 61.40%\n",
      "Test Loss: 1.0132, Test Accuracy: 63.63%\n",
      "Epoch [6/100], Training Loss: 1.0015, Accuracy: 64.33%\n",
      "Test Loss: 0.9902, Test Accuracy: 64.29%\n",
      "Epoch [7/100], Training Loss: 0.9473, Accuracy: 66.28%\n",
      "Test Loss: 0.9232, Test Accuracy: 67.42%\n",
      "Epoch [8/100], Training Loss: 0.9173, Accuracy: 67.41%\n",
      "Test Loss: 0.9134, Test Accuracy: 67.60%\n",
      "Epoch [9/100], Training Loss: 0.8552, Accuracy: 69.58%\n",
      "Test Loss: 0.9029, Test Accuracy: 68.14%\n",
      "Epoch [10/100], Training Loss: 0.8174, Accuracy: 70.92%\n",
      "Test Loss: 0.9921, Test Accuracy: 64.92%\n",
      "Epoch [11/100], Training Loss: 0.8026, Accuracy: 71.64%\n",
      "Test Loss: 0.8768, Test Accuracy: 69.55%\n",
      "Epoch [12/100], Training Loss: 0.7625, Accuracy: 73.21%\n",
      "Test Loss: 0.9300, Test Accuracy: 67.22%\n",
      "Epoch [13/100], Training Loss: 0.7372, Accuracy: 73.88%\n",
      "Test Loss: 0.8937, Test Accuracy: 68.90%\n",
      "Epoch [14/100], Training Loss: 0.7063, Accuracy: 74.96%\n",
      "Test Loss: 0.8469, Test Accuracy: 70.28%\n",
      "Epoch [15/100], Training Loss: 0.6844, Accuracy: 75.79%\n",
      "Test Loss: 0.8660, Test Accuracy: 70.13%\n",
      "Epoch [16/100], Training Loss: 0.6640, Accuracy: 76.57%\n",
      "Test Loss: 0.8140, Test Accuracy: 71.74%\n",
      "Epoch [17/100], Training Loss: 0.6413, Accuracy: 77.35%\n",
      "Test Loss: 0.7913, Test Accuracy: 72.88%\n",
      "Epoch [18/100], Training Loss: 0.6228, Accuracy: 77.98%\n",
      "Test Loss: 0.8363, Test Accuracy: 71.49%\n",
      "Epoch [19/100], Training Loss: 0.5994, Accuracy: 78.57%\n",
      "Test Loss: 0.8221, Test Accuracy: 72.01%\n",
      "Epoch [20/100], Training Loss: 0.5916, Accuracy: 78.99%\n",
      "Test Loss: 0.8585, Test Accuracy: 71.52%\n",
      "Epoch [21/100], Training Loss: 0.5592, Accuracy: 79.92%\n",
      "Test Loss: 0.8321, Test Accuracy: 71.87%\n",
      "Epoch [22/100], Training Loss: 0.5463, Accuracy: 80.66%\n",
      "Test Loss: 0.8283, Test Accuracy: 72.45%\n",
      "Epoch [23/100], Training Loss: 0.5439, Accuracy: 80.88%\n",
      "Test Loss: 0.8351, Test Accuracy: 72.11%\n",
      "Epoch [24/100], Training Loss: 0.5186, Accuracy: 81.58%\n",
      "Test Loss: 0.8543, Test Accuracy: 71.59%\n",
      "Epoch [25/100], Training Loss: 0.4940, Accuracy: 82.57%\n",
      "Test Loss: 0.8211, Test Accuracy: 73.15%\n",
      "Epoch [26/100], Training Loss: 0.4806, Accuracy: 82.88%\n",
      "Test Loss: 0.8490, Test Accuracy: 72.94%\n",
      "Epoch [27/100], Training Loss: 0.4653, Accuracy: 83.30%\n",
      "Test Loss: 0.8041, Test Accuracy: 73.49%\n",
      "Epoch [28/100], Training Loss: 0.4618, Accuracy: 83.53%\n",
      "Test Loss: 0.8702, Test Accuracy: 72.76%\n",
      "Epoch [29/100], Training Loss: 0.4352, Accuracy: 84.51%\n",
      "Test Loss: 0.8528, Test Accuracy: 72.73%\n",
      "Epoch [30/100], Training Loss: 0.4217, Accuracy: 85.13%\n",
      "Test Loss: 0.8273, Test Accuracy: 72.86%\n",
      "Epoch [31/100], Training Loss: 0.4138, Accuracy: 85.26%\n",
      "Test Loss: 0.8453, Test Accuracy: 73.01%\n",
      "Epoch [32/100], Training Loss: 0.4035, Accuracy: 85.74%\n",
      "Test Loss: 0.8957, Test Accuracy: 71.14%\n",
      "Epoch [33/100], Training Loss: 0.3849, Accuracy: 86.35%\n",
      "Test Loss: 0.8811, Test Accuracy: 72.57%\n",
      "Epoch [34/100], Training Loss: 0.3734, Accuracy: 86.79%\n",
      "Test Loss: 0.8680, Test Accuracy: 72.80%\n",
      "Epoch [35/100], Training Loss: 0.3572, Accuracy: 87.31%\n",
      "Test Loss: 0.8355, Test Accuracy: 73.89%\n",
      "Epoch [36/100], Training Loss: 0.3603, Accuracy: 87.26%\n",
      "Test Loss: 0.8421, Test Accuracy: 74.51%\n",
      "Epoch [37/100], Training Loss: 0.3365, Accuracy: 88.07%\n",
      "Test Loss: 0.8436, Test Accuracy: 73.72%\n",
      "Epoch [38/100], Training Loss: 0.3249, Accuracy: 88.43%\n",
      "Test Loss: 0.8682, Test Accuracy: 73.53%\n",
      "Epoch [39/100], Training Loss: 0.3160, Accuracy: 88.81%\n",
      "Test Loss: 0.8809, Test Accuracy: 73.59%\n",
      "Epoch [40/100], Training Loss: 0.2992, Accuracy: 89.43%\n",
      "Test Loss: 0.8945, Test Accuracy: 73.10%\n",
      "Epoch [41/100], Training Loss: 0.2932, Accuracy: 89.82%\n",
      "Test Loss: 0.9318, Test Accuracy: 73.13%\n",
      "Epoch [42/100], Training Loss: 0.2943, Accuracy: 89.54%\n",
      "Test Loss: 0.9039, Test Accuracy: 72.70%\n",
      "Epoch [43/100], Training Loss: 0.2680, Accuracy: 90.69%\n",
      "Test Loss: 0.9694, Test Accuracy: 73.03%\n",
      "Epoch [44/100], Training Loss: 0.2665, Accuracy: 90.57%\n",
      "Test Loss: 0.8790, Test Accuracy: 74.04%\n",
      "Epoch [45/100], Training Loss: 0.2502, Accuracy: 91.16%\n",
      "Test Loss: 0.9250, Test Accuracy: 73.29%\n",
      "Epoch [46/100], Training Loss: 0.2400, Accuracy: 91.53%\n",
      "Test Loss: 0.9312, Test Accuracy: 73.88%\n",
      "Epoch [47/100], Training Loss: 0.2313, Accuracy: 91.94%\n",
      "Test Loss: 1.0250, Test Accuracy: 72.33%\n",
      "Epoch [48/100], Training Loss: 0.2244, Accuracy: 92.03%\n",
      "Test Loss: 0.9715, Test Accuracy: 73.41%\n",
      "Epoch [49/100], Training Loss: 0.2136, Accuracy: 92.49%\n",
      "Test Loss: 0.9723, Test Accuracy: 73.14%\n",
      "Epoch [50/100], Training Loss: 0.2083, Accuracy: 92.62%\n",
      "Test Loss: 0.9220, Test Accuracy: 74.21%\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        #_, predicted = outputs.max(1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    train_accuracy = 100. * correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)  # Store average training loss\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Training Loss: {avg_train_loss:.4f}, \"\n",
    "          f\"Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            #_, predicted = outputs.max(1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    avg_val_loss = test_loss / len(test_loader)\n",
    "    val_losses.append(avg_val_loss)  # Store average validation loss\n",
    "    test_accuracy = 100. * correct / total\n",
    "    print(f\"Test Loss: {avg_val_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss', color='blue', marker='o')\n",
    "plt.plot(val_losses, label='Validation Loss', color='orange', marker='o')\n",
    "plt.title('Training and Validation Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
