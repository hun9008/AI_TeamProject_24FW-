{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bEMpr27c0RCi",
    "outputId": "d86b304b-23be-4240-f2b5-1c77b82e8d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu112\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.19.1+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: timm in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: pytorch-ignite in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: einops in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (2.4.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (0.19.1+cu118)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (0.25.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (0.4.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-ignite) (24.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->timm) (75.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub->timm) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch->timm) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ignite\\handlers\\checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------\n",
    "# Swin Transformer\n",
    "# Copyright (c) 2021 Microsoft\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Ze Liu\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu112\n",
    "!pip3 install timm pytorch-ignite einops matplotlib\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "from einops import rearrange\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "import ignite.metrics\n",
    "import ignite.contrib.handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cxGT3QPy0q0H"
   },
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wncXpbHk09rc"
   },
   "outputs": [],
   "source": [
    "def window_partition(x, window_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, H, W, C)\n",
    "        window_size (int): window size\n",
    "\n",
    "    Returns:\n",
    "        windows: (num_windows*B, window_size, window_size, C)\n",
    "    \"\"\"\n",
    "    B, H, W, C = x.shape\n",
    "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
    "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uvsOSiH-1DdL"
   },
   "outputs": [],
   "source": [
    "def window_reverse(windows, window_size, H, W):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        windows: (num_windows*B, window_size, window_size, C)\n",
    "        window_size (int): Window size\n",
    "        H (int): Height of image\n",
    "        W (int): Width of image\n",
    "\n",
    "    Returns:\n",
    "        x: (B, H, W, C)\n",
    "    \"\"\"\n",
    "    B = int(windows.shape[0] / (H * W / window_size / window_size))\n",
    "    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n",
    "    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Fp57DIJ41EBj"
   },
   "outputs": [],
   "source": [
    "class WindowAttention(nn.Module):\n",
    "    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n",
    "    It supports both of shifted and non-shifted window.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        window_size (tuple[int]): The height and width of the window.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set\n",
    "        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n",
    "        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size  # Wh, Ww\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        # define a parameter table of relative position bias\n",
    "        self.relative_position_bias_table = nn.Parameter(\n",
    "            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n",
    "\n",
    "        # get pair-wise relative position index for each token inside the window\n",
    "        coords_h = torch.arange(self.window_size[0])\n",
    "        coords_w = torch.arange(self.window_size[1])\n",
    "        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
    "        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to start from 0\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
    "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "        trunc_normal_(self.relative_position_bias_table, std=.02)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: input features with shape of (num_windows*B, N, C)\n",
    "            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n",
    "        \"\"\"\n",
    "        B_, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]  # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        q = q * self.scale\n",
    "        attn = (q @ k.transpose(-2, -1))\n",
    "\n",
    "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n",
    "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "        attn = attn + relative_position_bias.unsqueeze(0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.shape[0]\n",
    "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
    "            attn = attn.view(-1, self.num_heads, N, N)\n",
    "            attn = self.softmax(attn)\n",
    "        else:\n",
    "            attn = self.softmax(attn)\n",
    "\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'dim={self.dim}, window_size={self.window_size}, num_heads={self.num_heads}'\n",
    "\n",
    "    def flops(self, N):\n",
    "        # calculate flops for 1 window with token length of N\n",
    "        flops = 0\n",
    "        # qkv = self.qkv(x)\n",
    "        flops += N * self.dim * 3 * self.dim\n",
    "        # attn = (q @ k.transpose(-2, -1))\n",
    "        flops += self.num_heads * N * (self.dim // self.num_heads) * N\n",
    "        #  x = (attn @ v)\n",
    "        flops += self.num_heads * N * N * (self.dim // self.num_heads)\n",
    "        # x = self.proj(x)\n",
    "        flops += N * self.dim * self.dim\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "e_UlHriB1I6l"
   },
   "outputs": [],
   "source": [
    "class FocusedLinearAttention(nn.Module):\n",
    "    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n",
    "    It supports both of shifted and non-shifted window.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        window_size (tuple[int]): The height and width of the window.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set\n",
    "        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n",
    "        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.,\n",
    "                 focusing_factor=3, kernel_size=5):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size  # Wh, Ww\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "\n",
    "        self.focusing_factor = focusing_factor  # Used to sharpen attention distribution\n",
    "\n",
    "    # Linear layer to project input to query, key, and value\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)  # Output projection\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        # Depth-wise convolution for capturing local spatial information\n",
    "        self.dwc = nn.Conv2d(in_channels=head_dim, out_channels=head_dim, kernel_size=kernel_size,\n",
    "                            groups=head_dim, padding=kernel_size // 2)\n",
    "\n",
    "        # Learnable scale parameter\n",
    "        self.scale = nn.Parameter(torch.zeros(size=(1, 1, dim)))\n",
    "\n",
    "        # Learnable positional encoding\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(size=(1, window_size[0] * window_size[1], dim)))\n",
    "\n",
    "        print('Linear Attention window{} f{} kernel{}'.\n",
    "              format(window_size, focusing_factor, kernel_size))\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        B, N, C = x.shape\n",
    "\n",
    "        # Project input to query, key, and value\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, C).permute(2, 0, 1, 3)\n",
    "        q, k, v = qkv.unbind(0)\n",
    "\n",
    "        # Add positional encoding to keys\n",
    "        k = k + self.positional_encoding\n",
    "\n",
    "        focusing_factor = self.focusing_factor\n",
    "        kernel_function = nn.ReLU()\n",
    "\n",
    "        # Apply ReLU and add small epsilon to avoid zero values\n",
    "        q = kernel_function(q) + 1e-6\n",
    "        k = kernel_function(k) + 1e-6\n",
    "\n",
    "        # Compute scale using Softplus for stability\n",
    "        scale = nn.Softplus()(self.scale)\n",
    "        q = q / scale\n",
    "        k = k / scale\n",
    "\n",
    "        # Store original norms\n",
    "        q_norm = q.norm(dim=-1, keepdim=True)\n",
    "        k_norm = k.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # Apply focusing factor\n",
    "        q = q ** focusing_factor\n",
    "        k = k ** focusing_factor\n",
    "\n",
    "        # Renormalize to original norms\n",
    "        q = (q / q.norm(dim=-1, keepdim=True)) * q_norm\n",
    "        k = (k / k.norm(dim=-1, keepdim=True)) * k_norm\n",
    "\n",
    "        # Reshape for multi-head attention\n",
    "        q = q.reshape(B, N, self.num_heads, -1).permute(0, 2, 1, 3)\n",
    "        k = k.reshape(B, N, self.num_heads, -1).permute(0, 2, 1, 3)\n",
    "        v = v.reshape(B, N, self.num_heads, -1).permute(0, 2, 1, 3)\n",
    "\n",
    "        # Compute linear attention\n",
    "        z = 1 / (q @ k.mean(dim=-2, keepdim=True).transpose(-2, -1) + 1e-6)\n",
    "        kv = (k.transpose(-2, -1) * (N ** -0.5)) @ (v * (N ** -0.5))\n",
    "        x = q @ kv * z\n",
    "\n",
    "        # Reshape output\n",
    "        H = W = int(N ** 0.5)\n",
    "        x = x.transpose(1, 2).reshape(B, N, C)\n",
    "\n",
    "        # Apply depth-wise convolution to capture local spatial information\n",
    "        v = v.reshape(B * self.num_heads, H, W, -1).permute(0, 3, 1, 2)\n",
    "        x = x + self.dwc(v).reshape(B, C, N).permute(0, 2, 1)\n",
    "\n",
    "        # Final projection and dropout\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "    def eval(self):\n",
    "        super(FocusedLinearAttention, self).eval()\n",
    "        print('eval')\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'dim={self.dim}, window_size={self.window_size}, num_heads={self.num_heads}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DIR8e1tu1O5O"
   },
   "outputs": [],
   "source": [
    "class SwinTransformerBlock(nn.Module):\n",
    "    r\"\"\" Swin Transformer Block.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        input_resolution (tuple[int]): Input resulotion.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Window size.\n",
    "        shift_size (int): Shift size for SW-MSA.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
    "        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n",
    "        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU\n",
    "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, input_resolution, num_heads, window_size=7, shift_size=0,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
    "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm,\n",
    "                 focusing_factor=3, kernel_size=5, attn_type='L'):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        if min(self.input_resolution) <= self.window_size:\n",
    "            # if window size is larger than input resolution, we don't partition windows\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.input_resolution)\n",
    "        assert 0 <= self.shift_size < self.window_size, \"shift_size must in 0-window_size\"\n",
    "\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        assert attn_type in ['L', 'S']\n",
    "        if attn_type == 'L':\n",
    "            self.attn = FocusedLinearAttention(\n",
    "                dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,\n",
    "                qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop,\n",
    "                focusing_factor=focusing_factor, kernel_size=kernel_size)\n",
    "        else:\n",
    "            self.attn = WindowAttention(\n",
    "                dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,\n",
    "                qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "        if self.shift_size > 0:\n",
    "            # calculate attention mask for SW-MSA\n",
    "            H, W = self.input_resolution\n",
    "            img_mask = torch.zeros((1, H, W, 1))  # 1 H W 1\n",
    "            h_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            w_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            cnt = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    img_mask[:, h, w, :] = cnt\n",
    "                    cnt += 1\n",
    "\n",
    "            mask_windows = window_partition(img_mask, self.window_size)  # nW, window_size, window_size, 1\n",
    "            mask_windows = mask_windows.view(-1, self.window_size * self.window_size)\n",
    "            attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
    "            attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
    "        else:\n",
    "            attn_mask = None\n",
    "\n",
    "        self.register_buffer(\"attn_mask\", attn_mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        # cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        # partition windows\n",
    "        x_windows = window_partition(shifted_x, self.window_size)  # nW*B, window_size, window_size, C\n",
    "        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)  # nW*B, window_size*window_size, C\n",
    "\n",
    "        # W-MSA/SW-MSA\n",
    "        attn_windows = self.attn(x_windows, mask=self.attn_mask)  # nW*B, window_size*window_size, C\n",
    "\n",
    "        # merge windows\n",
    "        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n",
    "        shifted_x = window_reverse(attn_windows, self.window_size, H, W)  # B H' W' C\n",
    "\n",
    "        # reverse cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            x = shifted_x\n",
    "        x = x.view(B, H * W, C)\n",
    "\n",
    "        # FFN\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, \" \\\n",
    "               f\"window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}\"\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        H, W = self.input_resolution\n",
    "        # norm1\n",
    "        flops += self.dim * H * W\n",
    "        # W-MSA/SW-MSA\n",
    "        nW = H * W / self.window_size / self.window_size\n",
    "        flops += nW * self.attn.flops(self.window_size * self.window_size)\n",
    "        # mlp\n",
    "        flops += 2 * H * W * self.dim * self.dim * self.mlp_ratio\n",
    "        # norm2\n",
    "        flops += self.dim * H * W\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "blyYs6kZ1TeT"
   },
   "outputs": [],
   "source": [
    "class PatchMerging(nn.Module):\n",
    "    r\"\"\" Patch Merging Layer.\n",
    "\n",
    "    Args:\n",
    "        input_resolution (tuple[int]): Resolution of input feature.\n",
    "        dim (int): Number of input channels.\n",
    "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_resolution, dim, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.input_resolution = input_resolution\n",
    "        self.dim = dim\n",
    "        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n",
    "        self.norm = norm_layer(4 * dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: B, H*W, C\n",
    "        \"\"\"\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "        assert H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\"\n",
    "\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C\n",
    "        x = x.view(B, -1, 4 * C)  # B H/2*W/2 4*C\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = self.reduction(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"input_resolution={self.input_resolution}, dim={self.dim}\"\n",
    "\n",
    "    def flops(self):\n",
    "        H, W = self.input_resolution\n",
    "        flops = H * W * self.dim\n",
    "        flops += (H // 2) * (W // 2) * 4 * self.dim * 2 * self.dim\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XNJN4Z_01WBE"
   },
   "outputs": [],
   "source": [
    "class BasicLayer(nn.Module):\n",
    "    \"\"\" A basic Swin Transformer layer for one stage.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        input_resolution (tuple[int]): Input resolution.\n",
    "        depth (int): Number of blocks.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Local window size.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
    "        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0\n",
    "        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm\n",
    "        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None\n",
    "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, input_resolution, depth, num_heads, window_size,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., norm_layer=nn.LayerNorm, downsample=None, use_checkpoint=False,\n",
    "                 focusing_factor=3, kernel_size=5, attn_type='L'):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.depth = depth\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "\n",
    "        # build blocks\n",
    "        attn_types = [(attn_type if attn_type[0] != 'M' else ('L' if i < int(attn_type[1:]) else 'S')) for i in range(depth)]\n",
    "        window_sizes = [(window_size if attn_types[i] == 'L' else (7 if window_size <= 56 else 12)) for i in range(depth)]\n",
    "        self.blocks = nn.ModuleList([\n",
    "            SwinTransformerBlock(dim=dim, input_resolution=input_resolution,\n",
    "                                 num_heads=num_heads, window_size=window_sizes[i],\n",
    "                                 shift_size=0 if (i % 2 == 0) else window_sizes[i] // 2,\n",
    "                                 mlp_ratio=mlp_ratio,\n",
    "                                 qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                                 drop=drop, attn_drop=attn_drop,\n",
    "                                 drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
    "                                 norm_layer=norm_layer,\n",
    "                                 focusing_factor=focusing_factor,\n",
    "                                 kernel_size=kernel_size,\n",
    "                                 attn_type=attn_types[i])\n",
    "            for i in range(depth)])\n",
    "\n",
    "        # patch merging layer\n",
    "        if downsample is not None:\n",
    "            self.downsample = downsample(input_resolution, dim=dim, norm_layer=norm_layer)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x = checkpoint.checkpoint(blk, x)\n",
    "            else:\n",
    "                x = blk(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, depth={self.depth}\"\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        for blk in self.blocks:\n",
    "            flops += blk.flops()\n",
    "        if self.downsample is not None:\n",
    "            flops += self.downsample.flops()\n",
    "        return flops\n",
    "\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    r\"\"\" Image to Patch Embedding\n",
    "\n",
    "    Args:\n",
    "        img_size (int): Image size.  Default: 224.\n",
    "        patch_size (int): Patch token size. Default: 4.\n",
    "        in_chans (int): Number of input image channels. Default: 3.\n",
    "        embed_dim (int): Number of linear projection output channels. Default: 96.\n",
    "        norm_layer (nn.Module, optional): Normalization layer. Default: None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_size=224, patch_size=4, in_chans=3, embed_dim=96, norm_layer=None):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        patches_resolution = [img_size[0] // patch_size[0], img_size[1] // patch_size[1]]\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.patches_resolution = patches_resolution\n",
    "        self.num_patches = patches_resolution[0] * patches_resolution[1]\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        if norm_layer is not None:\n",
    "            self.norm = norm_layer(embed_dim)\n",
    "        else:\n",
    "            self.norm = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        # FIXME look at relaxing size constraints\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)  # B Ph*Pw C\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self):\n",
    "        Ho, Wo = self.patches_resolution\n",
    "        flops = Ho * Wo * self.embed_dim * self.in_chans * (self.patch_size[0] * self.patch_size[1])\n",
    "        if self.norm is not None:\n",
    "            flops += Ho * Wo * self.embed_dim\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LuascylH1a-6"
   },
   "outputs": [],
   "source": [
    "class FLattenSwinTransformer(nn.Module):\n",
    "    r\"\"\" Swin Transformer\n",
    "        A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -\n",
    "          https://arxiv.org/pdf/2103.14030\n",
    "\n",
    "    Args:\n",
    "        img_size (int | tuple(int)): Input image size. Default 224\n",
    "        patch_size (int | tuple(int)): Patch size. Default: 4\n",
    "        in_chans (int): Number of input image channels. Default: 3\n",
    "        num_classes (int): Number of classes for classification head. Default: 1000\n",
    "        embed_dim (int): Patch embedding dimension. Default: 96\n",
    "        depths (tuple(int)): Depth of each Swin Transformer layer.\n",
    "        num_heads (tuple(int)): Number of attention heads in different layers.\n",
    "        window_size (int): Window size. Default: 7\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4\n",
    "        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float): Override default qk scale of head_dim ** -0.5 if set. Default: None\n",
    "        drop_rate (float): Dropout rate. Default: 0\n",
    "        attn_drop_rate (float): Attention dropout rate. Default: 0\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.1\n",
    "        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.\n",
    "        ape (bool): If True, add absolute position embedding to the patch embedding. Default: False\n",
    "        patch_norm (bool): If True, add normalization after patch embedding. Default: True\n",
    "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_size=32, patch_size=4, in_chans=3, num_classes=1000,\n",
    "                 embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n",
    "                 window_size=7, mlp_ratio=4., qkv_bias=True, qk_scale=None,\n",
    "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n",
    "                 norm_layer=nn.LayerNorm, ape=False, patch_norm=True,\n",
    "                 use_checkpoint=False,\n",
    "                 focusing_factor=3, kernel_size=5, attn_type='LLLL', **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = len(depths)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ape = ape\n",
    "        self.patch_norm = patch_norm\n",
    "        self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "\n",
    "        # split image into non-overlapping patches\n",
    "        self.patch_embed = PatchEmbed(\n",
    "            img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim,\n",
    "            norm_layer=norm_layer if self.patch_norm else None)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        patches_resolution = self.patch_embed.patches_resolution\n",
    "        self.patches_resolution = patches_resolution\n",
    "\n",
    "        # absolute position embedding\n",
    "        if self.ape:\n",
    "            self.absolute_pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
    "            trunc_normal_(self.absolute_pos_embed, std=.02)\n",
    "\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        # stochastic depth\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]  # stochastic depth decay rule\n",
    "\n",
    "        # build layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i_layer in range(self.num_layers):\n",
    "            layer = BasicLayer(dim=int(embed_dim * 2 ** i_layer),\n",
    "                               input_resolution=(patches_resolution[0] // (2 ** i_layer),\n",
    "                                                 patches_resolution[1] // (2 ** i_layer)),\n",
    "                               depth=depths[i_layer],\n",
    "                               num_heads=num_heads[i_layer],\n",
    "                               window_size=window_size,\n",
    "                               mlp_ratio=self.mlp_ratio,\n",
    "                               qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                               drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                               drop_path=dpr[sum(depths[:i_layer]):sum(depths[:i_layer + 1])],\n",
    "                               norm_layer=norm_layer,\n",
    "                               downsample=PatchMerging if (i_layer < self.num_layers - 1) else None,\n",
    "                               use_checkpoint=use_checkpoint,\n",
    "                               focusing_factor=focusing_factor,\n",
    "                               kernel_size=kernel_size,\n",
    "                               attn_type=attn_type[i_layer] + (attn_type[self.num_layers:] if attn_type[i_layer] == 'M' else ''))\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.norm = norm_layer(self.num_features)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'absolute_pos_embed'}\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay_keywords(self):\n",
    "        return {'relative_position_bias_table'}\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        if self.ape:\n",
    "            x = x + self.absolute_pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.norm(x)  # B L C\n",
    "        x = self.avgpool(x.transpose(1, 2))  # B C 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "    def flops(self):\n",
    "        flops = 0\n",
    "        flops += self.patch_embed.flops()\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            flops += layer.flops()\n",
    "        flops += self.num_features * self.patches_resolution[0] * self.patches_resolution[1] // (2 ** self.num_layers)\n",
    "        flops += self.num_features * self.num_classes\n",
    "        return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "CH3oe5YA1en5"
   },
   "outputs": [],
   "source": [
    "DATA_DIR='./data'\n",
    "\n",
    "IMAGE_SIZE = 32\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "NUM_WORKERS = 8\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CIG2Ai-N1rHK",
    "outputId": "4d641b02-cebf-4dd2-da65-46ad48144db5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4936866700842985690\n",
      "xla_global_id: -1\n",
      "]\n",
      "2.4.1+cu118\n",
      "11.8\n",
      "True\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)  # This will show the version of PyTorch\n",
    "print(torch.version.cuda)  # This will show the version of CUDA PyTorch is linked against\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c73u1cDN2wC4",
    "outputId": "ef5015da-5064-4dd4-d2fa-79d4631d2d7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float)\n",
    "])\n",
    "\n",
    "train_dset = datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=train_transform)\n",
    "test_dset = datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "KKpPWqWt2xoz"
   },
   "outputs": [],
   "source": [
    "def dataset_show_image(dset, idx):\n",
    "    X, Y = dset[idx]\n",
    "    title = \"Ground truth: {}\".format(dset.classes[Y])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(np.moveaxis(X.numpy(), 0, -1))\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "nL_w38GL3LeA",
    "outputId": "d173c5f6-0fe9-42f0-bd1f-98849ac90963"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_show_image(test_dset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWEj9CuI3Rjj",
    "outputId": "34daaffb-66fe-47a1-af42-101d1b24671e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Data loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),  # Swin Transformer expects 224x224 input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Attention window(4, 4) f2 kernel5\n",
      "Linear Attention window(4, 4) f2 kernel5\n",
      "Linear Attention window(4, 4) f2 kernel5\n",
      "Linear Attention window(4, 4) f2 kernel5\n",
      "Linear Attention window(2, 2) f2 kernel5\n",
      "Linear Attention window(2, 2) f2 kernel5\n",
      "Linear Attention window(2, 2) f2 kernel5\n",
      "Linear Attention window(2, 2) f2 kernel5\n",
      "Linear Attention window(2, 2) f2 kernel5\n",
      "Linear Attention window(2, 2) f2 kernel5\n",
      "Linear Attention window(1, 1) f2 kernel5\n",
      "Linear Attention window(1, 1) f2 kernel5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FLattenSwinTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.1, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): BasicLayer(\n",
       "      dim=96, input_resolution=(8, 8), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=96, input_resolution=(8, 8), num_heads=3, window_size=4, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=96, window_size=(4, 4), num_heads=3\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=96, input_resolution=(8, 8), num_heads=3, window_size=4, shift_size=2, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=96, window_size=(4, 4), num_heads=3\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.009)\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(8, 8), dim=96\n",
       "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicLayer(\n",
       "      dim=192, input_resolution=(4, 4), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=192, input_resolution=(4, 4), num_heads=6, window_size=4, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=192, window_size=(4, 4), num_heads=6\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.018)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=192, input_resolution=(4, 4), num_heads=6, window_size=4, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=192, window_size=(4, 4), num_heads=6\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.027)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(4, 4), dim=192\n",
       "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicLayer(\n",
       "      dim=384, input_resolution=(2, 2), depth=6\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(2, 2), num_heads=12, window_size=2, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=384, window_size=(2, 2), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.036)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(2, 2), num_heads=12, window_size=2, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=384, window_size=(2, 2), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.045)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(2, 2), num_heads=12, window_size=2, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=384, window_size=(2, 2), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.055)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(2, 2), num_heads=12, window_size=2, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=384, window_size=(2, 2), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.064)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(2, 2), num_heads=12, window_size=2, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=384, window_size=(2, 2), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.073)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SwinTransformerBlock(\n",
       "          dim=384, input_resolution=(2, 2), num_heads=12, window_size=2, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=384, window_size=(2, 2), num_heads=12\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.082)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(2, 2), dim=384\n",
       "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): BasicLayer(\n",
       "      dim=768, input_resolution=(1, 1), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          dim=768, input_resolution=(1, 1), num_heads=24, window_size=1, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=768, window_size=(1, 1), num_heads=24\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.091)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          dim=768, input_resolution=(1, 1), num_heads=24, window_size=1, shift_size=0, mlp_ratio=4.0\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): FocusedLinearAttention(\n",
       "            dim=768, window_size=(1, 1), num_heads=24\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.1, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dwc): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.100)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (head): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model instantiation\n",
    "model = FLattenSwinTransformer(\n",
    "    img_size=32,\n",
    "    patch_size=4,\n",
    "    in_chans=3,\n",
    "    num_classes=10,  # CIFAR-10 has 10 classes\n",
    "    embed_dim=96,\n",
    "    depths=[2, 2, 6, 2], # 2,2,6,2\n",
    "    num_heads=[3, 6, 12, 24],\n",
    "    window_size=4,\n",
    "    mlp_ratio=4.,\n",
    "    qkv_bias=True,\n",
    "    drop_rate=0.1,\n",
    "    attn_drop_rate=0.1,\n",
    "    drop_path_rate=0.1,\n",
    "    ape=False,\n",
    "    patch_norm=True,\n",
    "    use_checkpoint=False,\n",
    "    focusing_factor=2, # p=3\n",
    "    kernel_size=5,\n",
    "    attn_type='LLLL'\n",
    ")\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqpdKvMZ6RWm",
    "outputId": "21ff8c31-b326-4f89-f11a-e2633d8435fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 27,538,090\n"
     ]
    }
   ],
   "source": [
    "# Optimizer and loss function\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Initialize lists to store losses\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "4PmtkvvX7z53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Training Loss: 1.8348, Accuracy: 31.38%\n",
      "Test Loss: 1.5759, Test Accuracy: 40.43%\n",
      "Epoch [2/100], Training Loss: 1.4540, Accuracy: 46.45%\n",
      "Test Loss: 1.3969, Test Accuracy: 49.72%\n",
      "Epoch [3/100], Training Loss: 1.2813, Accuracy: 53.61%\n",
      "Test Loss: 1.2239, Test Accuracy: 55.63%\n",
      "Epoch [4/100], Training Loss: 1.1597, Accuracy: 58.16%\n",
      "Test Loss: 1.1453, Test Accuracy: 59.37%\n",
      "Epoch [5/100], Training Loss: 1.0713, Accuracy: 61.40%\n",
      "Test Loss: 1.0132, Test Accuracy: 63.63%\n",
      "Epoch [6/100], Training Loss: 1.0015, Accuracy: 64.33%\n",
      "Test Loss: 0.9902, Test Accuracy: 64.29%\n",
      "Epoch [7/100], Training Loss: 0.9473, Accuracy: 66.28%\n",
      "Test Loss: 0.9232, Test Accuracy: 67.42%\n",
      "Epoch [8/100], Training Loss: 0.9173, Accuracy: 67.41%\n",
      "Test Loss: 0.9134, Test Accuracy: 67.60%\n",
      "Epoch [9/100], Training Loss: 0.8552, Accuracy: 69.58%\n",
      "Test Loss: 0.9029, Test Accuracy: 68.14%\n",
      "Epoch [10/100], Training Loss: 0.8174, Accuracy: 70.92%\n",
      "Test Loss: 0.9921, Test Accuracy: 64.92%\n",
      "Epoch [11/100], Training Loss: 0.8026, Accuracy: 71.64%\n",
      "Test Loss: 0.8768, Test Accuracy: 69.55%\n",
      "Epoch [12/100], Training Loss: 0.7625, Accuracy: 73.21%\n",
      "Test Loss: 0.9300, Test Accuracy: 67.22%\n",
      "Epoch [13/100], Training Loss: 0.7372, Accuracy: 73.88%\n",
      "Test Loss: 0.8937, Test Accuracy: 68.90%\n",
      "Epoch [14/100], Training Loss: 0.7063, Accuracy: 74.96%\n",
      "Test Loss: 0.8469, Test Accuracy: 70.28%\n",
      "Epoch [15/100], Training Loss: 0.6844, Accuracy: 75.79%\n",
      "Test Loss: 0.8660, Test Accuracy: 70.13%\n",
      "Epoch [16/100], Training Loss: 0.6640, Accuracy: 76.57%\n",
      "Test Loss: 0.8140, Test Accuracy: 71.74%\n",
      "Epoch [17/100], Training Loss: 0.6413, Accuracy: 77.35%\n",
      "Test Loss: 0.7913, Test Accuracy: 72.88%\n",
      "Epoch [18/100], Training Loss: 0.6228, Accuracy: 77.98%\n",
      "Test Loss: 0.8363, Test Accuracy: 71.49%\n",
      "Epoch [19/100], Training Loss: 0.5994, Accuracy: 78.57%\n",
      "Test Loss: 0.8221, Test Accuracy: 72.01%\n",
      "Epoch [20/100], Training Loss: 0.5916, Accuracy: 78.99%\n",
      "Test Loss: 0.8585, Test Accuracy: 71.52%\n",
      "Epoch [21/100], Training Loss: 0.5592, Accuracy: 79.92%\n",
      "Test Loss: 0.8321, Test Accuracy: 71.87%\n",
      "Epoch [22/100], Training Loss: 0.5463, Accuracy: 80.66%\n",
      "Test Loss: 0.8283, Test Accuracy: 72.45%\n",
      "Epoch [23/100], Training Loss: 0.5439, Accuracy: 80.88%\n",
      "Test Loss: 0.8351, Test Accuracy: 72.11%\n",
      "Epoch [24/100], Training Loss: 0.5186, Accuracy: 81.58%\n",
      "Test Loss: 0.8543, Test Accuracy: 71.59%\n",
      "Epoch [25/100], Training Loss: 0.4940, Accuracy: 82.57%\n",
      "Test Loss: 0.8211, Test Accuracy: 73.15%\n",
      "Epoch [26/100], Training Loss: 0.4806, Accuracy: 82.88%\n",
      "Test Loss: 0.8490, Test Accuracy: 72.94%\n",
      "Epoch [27/100], Training Loss: 0.4653, Accuracy: 83.30%\n",
      "Test Loss: 0.8041, Test Accuracy: 73.49%\n",
      "Epoch [28/100], Training Loss: 0.4618, Accuracy: 83.53%\n",
      "Test Loss: 0.8702, Test Accuracy: 72.76%\n",
      "Epoch [29/100], Training Loss: 0.4352, Accuracy: 84.51%\n",
      "Test Loss: 0.8528, Test Accuracy: 72.73%\n",
      "Epoch [30/100], Training Loss: 0.4217, Accuracy: 85.13%\n",
      "Test Loss: 0.8273, Test Accuracy: 72.86%\n",
      "Epoch [31/100], Training Loss: 0.4138, Accuracy: 85.26%\n",
      "Test Loss: 0.8453, Test Accuracy: 73.01%\n",
      "Epoch [32/100], Training Loss: 0.4035, Accuracy: 85.74%\n",
      "Test Loss: 0.8957, Test Accuracy: 71.14%\n",
      "Epoch [33/100], Training Loss: 0.3849, Accuracy: 86.35%\n",
      "Test Loss: 0.8811, Test Accuracy: 72.57%\n",
      "Epoch [34/100], Training Loss: 0.3734, Accuracy: 86.79%\n",
      "Test Loss: 0.8680, Test Accuracy: 72.80%\n",
      "Epoch [35/100], Training Loss: 0.3572, Accuracy: 87.31%\n",
      "Test Loss: 0.8355, Test Accuracy: 73.89%\n",
      "Epoch [36/100], Training Loss: 0.3603, Accuracy: 87.26%\n",
      "Test Loss: 0.8421, Test Accuracy: 74.51%\n",
      "Epoch [37/100], Training Loss: 0.3365, Accuracy: 88.07%\n",
      "Test Loss: 0.8436, Test Accuracy: 73.72%\n",
      "Epoch [38/100], Training Loss: 0.3249, Accuracy: 88.43%\n",
      "Test Loss: 0.8682, Test Accuracy: 73.53%\n",
      "Epoch [39/100], Training Loss: 0.3160, Accuracy: 88.81%\n",
      "Test Loss: 0.8809, Test Accuracy: 73.59%\n",
      "Epoch [40/100], Training Loss: 0.2992, Accuracy: 89.43%\n",
      "Test Loss: 0.8945, Test Accuracy: 73.10%\n",
      "Epoch [41/100], Training Loss: 0.2932, Accuracy: 89.82%\n",
      "Test Loss: 0.9318, Test Accuracy: 73.13%\n",
      "Epoch [42/100], Training Loss: 0.2943, Accuracy: 89.54%\n",
      "Test Loss: 0.9039, Test Accuracy: 72.70%\n",
      "Epoch [43/100], Training Loss: 0.2680, Accuracy: 90.69%\n",
      "Test Loss: 0.9694, Test Accuracy: 73.03%\n",
      "Epoch [44/100], Training Loss: 0.2665, Accuracy: 90.57%\n",
      "Test Loss: 0.8790, Test Accuracy: 74.04%\n",
      "Epoch [45/100], Training Loss: 0.2502, Accuracy: 91.16%\n",
      "Test Loss: 0.9250, Test Accuracy: 73.29%\n",
      "Epoch [46/100], Training Loss: 0.2400, Accuracy: 91.53%\n",
      "Test Loss: 0.9312, Test Accuracy: 73.88%\n",
      "Epoch [47/100], Training Loss: 0.2313, Accuracy: 91.94%\n",
      "Test Loss: 1.0250, Test Accuracy: 72.33%\n",
      "Epoch [48/100], Training Loss: 0.2244, Accuracy: 92.03%\n",
      "Test Loss: 0.9715, Test Accuracy: 73.41%\n",
      "Epoch [49/100], Training Loss: 0.2136, Accuracy: 92.49%\n",
      "Test Loss: 0.9723, Test Accuracy: 73.14%\n",
      "Epoch [50/100], Training Loss: 0.2083, Accuracy: 92.62%\n",
      "Test Loss: 0.9220, Test Accuracy: 74.21%\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        #_, predicted = outputs.max(1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    train_accuracy = 100. * correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)  # Store average training loss\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Training Loss: {avg_train_loss:.4f}, \"\n",
    "          f\"Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            #_, predicted = outputs.max(1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    avg_val_loss = test_loss / len(test_loader)\n",
    "    val_losses.append(avg_val_loss)  # Store average validation loss\n",
    "    test_accuracy = 100. * correct / total\n",
    "    print(f\"Test Loss: {avg_val_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss', color='blue', marker='o')\n",
    "plt.plot(val_losses, label='Validation Loss', color='orange', marker='o')\n",
    "plt.title('Training and Validation Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
