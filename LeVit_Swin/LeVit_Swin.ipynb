{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b26b693b986946ddb6c0449d11bf72e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b502dae845364f0997321c947aee91ad",
              "IPY_MODEL_d062ea7b9573453ba9b38c66502b51b0",
              "IPY_MODEL_4a461e4c440740418bc2ffa3ecbbf00b"
            ],
            "layout": "IPY_MODEL_696c6ef7584d46a9882952885acaa665"
          }
        },
        "b502dae845364f0997321c947aee91ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a716eb6c12b40c6a76e727c79dc8df9",
            "placeholder": "​",
            "style": "IPY_MODEL_62f2692ff252405ebb578c8f9c5209fc",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "d062ea7b9573453ba9b38c66502b51b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_251495753346452a8cb009243f93eed9",
            "max": 76012429,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f5f13b256d34d2fa543d77a222d70db",
            "value": 76012429
          }
        },
        "4a461e4c440740418bc2ffa3ecbbf00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e497b168c3514e71881fa269d5d386fa",
            "placeholder": "​",
            "style": "IPY_MODEL_2b4f8e777c5141d7a38b13df04bfa0be",
            "value": " 76.0M/76.0M [00:01&lt;00:00, 75.5MB/s]"
          }
        },
        "696c6ef7584d46a9882952885acaa665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a716eb6c12b40c6a76e727c79dc8df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62f2692ff252405ebb578c8f9c5209fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "251495753346452a8cb009243f93eed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f5f13b256d34d2fa543d77a222d70db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e497b168c3514e71881fa269d5d386fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b4f8e777c5141d7a38b13df04bfa0be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b26b693b986946ddb6c0449d11bf72e8",
            "b502dae845364f0997321c947aee91ad",
            "d062ea7b9573453ba9b38c66502b51b0",
            "4a461e4c440740418bc2ffa3ecbbf00b",
            "696c6ef7584d46a9882952885acaa665",
            "4a716eb6c12b40c6a76e727c79dc8df9",
            "62f2692ff252405ebb578c8f9c5209fc",
            "251495753346452a8cb009243f93eed9",
            "5f5f13b256d34d2fa543d77a222d70db",
            "e497b168c3514e71881fa269d5d386fa",
            "2b4f8e777c5141d7a38b13df04bfa0be"
          ]
        },
        "id": "LMoOgsR_Fldz",
        "outputId": "bfcc6525-f563-4d94-e6b0-cd1e4c199eb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/76.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b26b693b986946ddb6c0449d11bf72e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stages): Sequential(\n",
            "    (0): LevitStage(\n",
            "      (downsample): Identity()\n",
            "      (blocks): Sequential(\n",
            "        (0): LevitBlock(\n",
            "          (attn): Attention(\n",
            "            (qkv): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (act): Hardswish()\n",
            "              (ln): LinearNorm(\n",
            "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path1): Identity()\n",
            "          (mlp): LevitMlp(\n",
            "            (ln1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (act): Hardswish()\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "            (ln2): LinearNorm(\n",
            "              (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (1): LevitBlock(\n",
            "          (attn): Attention(\n",
            "            (qkv): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (act): Hardswish()\n",
            "              (ln): LinearNorm(\n",
            "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path1): Identity()\n",
            "          (mlp): LevitMlp(\n",
            "            (ln1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (act): Hardswish()\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "            (ln2): LinearNorm(\n",
            "              (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (2): LevitBlock(\n",
            "          (attn): Attention(\n",
            "            (qkv): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (act): Hardswish()\n",
            "              (ln): LinearNorm(\n",
            "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path1): Identity()\n",
            "          (mlp): LevitMlp(\n",
            "            (ln1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (act): Hardswish()\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "            (ln2): LinearNorm(\n",
            "              (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (3): LevitBlock(\n",
            "          (attn): Attention(\n",
            "            (qkv): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (act): Hardswish()\n",
            "              (ln): LinearNorm(\n",
            "                (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "                (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path1): Identity()\n",
            "          (mlp): LevitMlp(\n",
            "            (ln1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (act): Hardswish()\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "            (ln2): LinearNorm(\n",
            "              (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): LevitStage(\n",
            "      (downsample): LevitDownsample(\n",
            "        (attn_downsample): AttentionDownsample(\n",
            "          (kv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=1280, bias=False)\n",
            "            (bn): BatchNorm1d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (q): Sequential(\n",
            "            (down): Downsample()\n",
            "            (ln): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (act): Hardswish()\n",
            "            (ln): LinearNorm(\n",
            "              (linear): Linear(in_features=1024, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (blocks): Sequential(\n",
            "        (0): LevitBlock(\n",
            "          (attn): Attention(\n",
            "            (qkv): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "              (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (act): Hardswish()\n",
            "              (ln): LinearNorm(\n",
            "                (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "                (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path1): Identity()\n",
            "          (mlp): LevitMlp(\n",
            "            (ln1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "              (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (act): Hardswish()\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "            (ln2): LinearNorm(\n",
            "              (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (1): LevitBlock(\n",
            "          (attn): Attention(\n",
            "            (qkv): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "              (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (act): Hardswish()\n",
            "              (ln): LinearNorm(\n",
            "                (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "                (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path1): Identity()\n",
            "          (mlp): LevitMlp(\n",
            "            (ln1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "              (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (act): Hardswish()\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "            (ln2): LinearNorm(\n",
            "              (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (2): LevitBlock(\n",
            "          (attn): Attention(\n",
            "            (qkv): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "              (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (act): Hardswish()\n",
            "              (ln): LinearNorm(\n",
            "                (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "                (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path1): Identity()\n",
            "          (mlp): LevitMlp(\n",
            "            (ln1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "              (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (act): Hardswish()\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "            (ln2): LinearNorm(\n",
            "              (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (3): LevitBlock(\n",
            "          (attn): Attention(\n",
            "            (qkv): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "              (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (act): Hardswish()\n",
            "              (ln): LinearNorm(\n",
            "                (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "                (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path1): Identity()\n",
            "          (mlp): LevitMlp(\n",
            "            (ln1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "              (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (act): Hardswish()\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "            (ln2): LinearNorm(\n",
            "              (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): LevitStage(\n",
            "      (downsample): LevitDownsample(\n",
            "        (attn_downsample): AttentionDownsample(\n",
            "          (kv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1920, bias=False)\n",
            "            (bn): BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (q): Sequential(\n",
            "            (down): Downsample()\n",
            "            (ln): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (act): Hardswish()\n",
            "            (ln): LinearNorm(\n",
            "              (linear): Linear(in_features=1536, out_features=512, bias=False)\n",
            "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=1024, bias=False)\n",
            "            (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.0, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=1024, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (blocks): Sequential(\n",
            "        (0): LevitBlock(\n",
            "          (attn): Attention(\n",
            "            (qkv): LinearNorm(\n",
            "              (linear): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (act): Hardswish()\n",
            "              (ln): LinearNorm(\n",
            "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "                (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path1): Identity()\n",
            "          (mlp): LevitMlp(\n",
            "            (ln1): LinearNorm(\n",
            "              (linear): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (act): Hardswish()\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "            (ln2): LinearNorm(\n",
            "              (linear): Linear(in_features=1024, out_features=512, bias=False)\n",
            "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (1): LevitBlock(\n",
            "          (attn): Attention(\n",
            "            (qkv): LinearNorm(\n",
            "              (linear): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (act): Hardswish()\n",
            "              (ln): LinearNorm(\n",
            "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "                (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path1): Identity()\n",
            "          (mlp): LevitMlp(\n",
            "            (ln1): LinearNorm(\n",
            "              (linear): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (act): Hardswish()\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "            (ln2): LinearNorm(\n",
            "              (linear): Linear(in_features=1024, out_features=512, bias=False)\n",
            "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (2): LevitBlock(\n",
            "          (attn): Attention(\n",
            "            (qkv): LinearNorm(\n",
            "              (linear): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (act): Hardswish()\n",
            "              (ln): LinearNorm(\n",
            "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "                (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path1): Identity()\n",
            "          (mlp): LevitMlp(\n",
            "            (ln1): LinearNorm(\n",
            "              (linear): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (act): Hardswish()\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "            (ln2): LinearNorm(\n",
            "              (linear): Linear(in_features=1024, out_features=512, bias=False)\n",
            "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (3): LevitBlock(\n",
            "          (attn): Attention(\n",
            "            (qkv): LinearNorm(\n",
            "              (linear): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (proj): Sequential(\n",
            "              (act): Hardswish()\n",
            "              (ln): LinearNorm(\n",
            "                (linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "                (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (drop_path1): Identity()\n",
            "          (mlp): LevitMlp(\n",
            "            (ln1): LinearNorm(\n",
            "              (linear): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (act): Hardswish()\n",
            "            (drop): Dropout(p=0.0, inplace=False)\n",
            "            (ln2): LinearNorm(\n",
            "              (linear): Linear(in_features=1024, out_features=512, bias=False)\n",
            "              (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=1000, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import timm\n",
        "\n",
        "# LeViT 모델 불러오기 (LeViT-256 예시)\n",
        "model = timm.create_model('levit_256', pretrained=True)\n",
        "\n",
        "# 모델 구조 출력\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-ignite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxH-oa14LdPY",
        "outputId": "2895ea6b-5733-4e03-edcf-520ae15af54f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.5.1-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: torch<3,>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (2.5.0+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.3->pytorch-ignite) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (3.0.2)\n",
            "Downloading pytorch_ignite-0.5.1-py3-none-any.whl (312 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/312.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m307.2/312.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.7/312.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "import ignite.metrics\n",
        "import ignite.contrib.handlers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NBrzU05J59X",
        "outputId": "0d4dff5d-b2e3-497f-a75c-63a705f33bc9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = './data'\n",
        "\n",
        "IMAGE_SIZE = 32\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "NUM_WORKERS = 8\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 1e-1\n",
        "\n",
        "validation_split = 0.1"
      ],
      "metadata": {
        "id": "vX_EkoUQLagR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"device:\", DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p86cMKcLhA8",
        "outputId": "e938ecb9-dc71-4c26-dec4-10407c8d9acc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.PILToTensor(),\n",
        "    transforms.ConvertImageDtype(torch.float)\n",
        "])"
      ],
      "metadata": {
        "id": "Ouw-fLAwLihO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dset = datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=train_transform)\n",
        "test_dset = datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w18OaGFoL8ZG",
        "outputId": "04a25247-23fc-43be-bc41-280d869a3a19"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 43.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                                           num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                                          num_workers=NUM_WORKERS, pin_memory=True)"
      ],
      "metadata": {
        "id": "pd9_UjEJL_JD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class swin_transformer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(swin_transformer, self).__init__()"
      ],
      "metadata": {
        "id": "zP5TY9kkUUcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ShrinkAttention(nn.Module):\n",
        "  def __init__(self, embded_dim, num_heads):\n",
        "    super(ShrinkAttention, self).__init__()\n",
        "    self.embded_dim = embded_dim\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = embded_dim // num_heads"
      ],
      "metadata": {
        "id": "XXuCXwd_FIal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNorm(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    super(ConvNorm, self).__init__()\n",
        "    self.linear = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "    self.norm = nn.BatchNorm2d(out_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = self.norm(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "EapqpOdOQU6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearNorm(nn.Module):\n",
        "  def __init__(self, in_features, out_features):\n",
        "    super(LinearNorm, self).__init__()\n",
        "    self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "    self.norm = nn.BatchNorm1d(out_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear(x)\n",
        "    x = self.norm(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "wbZNj5HjSuhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Downsample(nn.Module):\n",
        "  def forward(self,x):\n",
        "    return F.avg_pool2d(x, kernel_size=5, stride=5)\n",
        "class AttentionDownsample(nn.Module):\n",
        "  def __init__(self, in_features, out_features):\n",
        "    super(AttentionDownsample, self).__init__()\n",
        "    self.kv = LinearNorm(in_features, in_features*5)\n",
        "    self.q = nn.Sequential(\n",
        "        Downsample(),\n",
        "        LinearNorm(in_features, in_features),\n",
        "    )\n",
        "    self.proj = nn.Sequential(\n",
        "        nn.Hardswish(),\n",
        "        LinearNorm(out_features * 3, out_features)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    kv = self.kv(x)\n",
        "    q = self.q(x)\n",
        "    attention_output =\n",
        "    proj = self.proj(x)\n",
        "\n",
        "    return proj"
      ],
      "metadata": {
        "id": "24WrniWi4Rlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeViTMlp(nn.Module):\n",
        "  def __init__(self ,in_features, hidden_features):\n",
        "    super(LeViTMlp, self).__init__()\n",
        "    self.linear1 = LinearNorm(in_features, hidden_features)\n",
        "    self.linear2 = LinearNorm(hidden_features, in_features)\n",
        "    self.act = nn.Hardswish()\n",
        "    self.drop = nn.Dropout(p = 0.0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    x = self.act(x)\n",
        "    x = self.drop(x)\n",
        "    x = self.linear2(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "jTArPS49SfZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeViTBlock(nn.Module):\n",
        "  def __init__(self, in_features):\n",
        "    super(LeViTBlock, self).__init__()\n",
        "    self.drop_path1 = nn.Identity()\n",
        "    self.drop_path2 = nn.Identity()\n",
        "    self.mlp = LeViTMlp(in_features, in_features * 2)\n",
        "    self.attn = swin_transformer(in_features)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + self.drop_path1(self.attn(x))\n",
        "    x = x + self.drop_path2(self.mlp(x))\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "tNMKTQ9KR1lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeViT_swin(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeViT_swin, self).__init__()\n",
        "    self.stem == nn.Sequential(\n",
        "        ConvNorm(3, 32, kernel_size=3, stride=2, padding=1),\n",
        "        nn.Hardswish(),\n",
        "        ConvNorm(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "        nn.Hardswish(),\n",
        "        ConvNorm(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "        nn.Hardswish(),\n",
        "        ConvNorm(128, 256, kernel_size=3, stride=2, padding=1)\n",
        "    )\n",
        "\n",
        "    self.stages = nn.Sequential(\n",
        "        LeViTBlock(256),\n",
        "        LeViTBlock(256),\n",
        "        LeViTBlock(256),\n",
        "        LeViTBlock(256),\n",
        "    )"
      ],
      "metadata": {
        "id": "I8oXYVAcMBgi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}