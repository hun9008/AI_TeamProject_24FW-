{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxaDC-dR0GPE",
        "outputId": "f1aad417-ac89-44b0-cfa0-73020e9dd0e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m3x4ufxnz-3T"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_BJVoSY-z-3U"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)   # 입력 채널은 3\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 3)   # 출력 채널을 3으로 설정 (RGB 이미지)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "M68361j-z-3V"
      },
      "outputs": [],
      "source": [
        "class Residual(nn.Module):\n",
        "    def __init__(self, *layers):\n",
        "        super().__init__()\n",
        "        self.residual = nn.Sequential(*layers)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.gamma * self.residual(x)\n",
        "\n",
        "class GlobalAvgPool(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.mean(dim=-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EokVit6dz-3V"
      },
      "outputs": [],
      "source": [
        "class ShiftedWindowAttention(nn.Module):\n",
        "    def __init__(self, dim, head_dim, shape, window_size, shift_size=0):\n",
        "        super().__init__()\n",
        "        self.heads = dim // head_dim\n",
        "        self.head_dim = head_dim\n",
        "        self.scale = head_dim**-0.5\n",
        "\n",
        "        self.shape = shape\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, dim * 3)\n",
        "        self.unifyheads = nn.Linear(dim, dim)\n",
        "\n",
        "        self.pos_enc = nn.Parameter(torch.Tensor(self.heads, (2 * window_size - 1)**2))\n",
        "        self.register_buffer(\"relative_indices\", self.get_indices(window_size))\n",
        "\n",
        "        if shift_size > 0:\n",
        "            self.register_buffer(\"mask\", self.generate_mask(shape, window_size, shift_size))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        shift_size, window_size = self.shift_size, self.window_size\n",
        "\n",
        "        x = self.to_windows(x, self.shape, window_size, shift_size) # partition into windows\n",
        "\n",
        "        # self attention\n",
        "        qkv = self.to_qkv(x).unflatten(-1, (3, self.heads, self.head_dim)).transpose(-2, 1)\n",
        "        queries, keys, values = qkv.unbind(dim=2)\n",
        "\n",
        "        att = queries @ keys.transpose(-2, -1)\n",
        "\n",
        "        att = att * self.scale + self.get_rel_pos_enc(window_size) # add relative positon encoding\n",
        "\n",
        "        # masking\n",
        "        if shift_size > 0:\n",
        "            att = self.mask_attention(att)\n",
        "\n",
        "        att = F.softmax(att, dim=-1)\n",
        "\n",
        "        x = att @ values\n",
        "        x = x.transpose(1, 2).contiguous().flatten(-2, -1) # move head back\n",
        "        x = self.unifyheads(x)\n",
        "\n",
        "        x = self.from_windows(x, self.shape, window_size, shift_size) # undo partitioning into windows\n",
        "        return x\n",
        "\n",
        "\n",
        "    def to_windows(self, x, shape, window_size, shift_size):\n",
        "        x = x.unflatten(1, shape)\n",
        "        if shift_size > 0:\n",
        "            x = x.roll((-shift_size, -shift_size), dims=(1, 2))\n",
        "        x = self.split_windows(x, window_size)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def from_windows(self, x, shape, window_size, shift_size):\n",
        "        x = self.merge_windows(x, shape, window_size)\n",
        "        if shift_size > 0:\n",
        "            x = x.roll((shift_size, shift_size), dims=(1, 2))\n",
        "        x = x.flatten(1, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def mask_attention(self, att):\n",
        "        num_win = self.mask.size(1)\n",
        "        att = att.unflatten(0, (att.size(0) // num_win, num_win))\n",
        "        att = att.masked_fill(self.mask, float('-inf'))\n",
        "        att = att.flatten(0, 1)\n",
        "        return att\n",
        "\n",
        "\n",
        "    def get_rel_pos_enc(self, window_size):\n",
        "        indices = self.relative_indices.expand(self.heads, -1)\n",
        "        rel_pos_enc = self.pos_enc.gather(-1, indices)\n",
        "        rel_pos_enc = rel_pos_enc.unflatten(-1, (window_size**2, window_size**2))\n",
        "        return rel_pos_enc\n",
        "\n",
        "\n",
        "    # For explanation of mask regions see Figure 4 in the article\n",
        "    @staticmethod\n",
        "    def generate_mask(shape, window_size, shift_size):\n",
        "        region_mask = torch.zeros(1, *shape, 1)\n",
        "        slices = [slice(0, -window_size), slice(-window_size, -shift_size), slice(-shift_size, None)]\n",
        "\n",
        "        region_num = 0\n",
        "        for i in slices:\n",
        "            for j in slices:\n",
        "                region_mask[:, i, j, :] = region_num\n",
        "                region_num += 1\n",
        "\n",
        "        mask_windows = ShiftedWindowAttention.split_windows(region_mask, window_size).squeeze(-1)\n",
        "        diff_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
        "        mask = diff_mask != 0\n",
        "        mask = mask.unsqueeze(1).unsqueeze(0) # add heads and batch dimension\n",
        "        return mask\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def split_windows(x, window_size):\n",
        "        n_h, n_w = x.size(1) // window_size, x.size(2) // window_size\n",
        "        x = x.unflatten(1, (n_h, window_size)).unflatten(-2, (n_w, window_size)) # split into windows\n",
        "        x = x.transpose(2, 3).flatten(0, 2) # merge batch and window numbers\n",
        "        x = x.flatten(-3, -2)\n",
        "        return x\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def merge_windows(x, shape, window_size):\n",
        "        n_h, n_w = shape[0] // window_size, shape[1] // window_size\n",
        "        b = x.size(0) // (n_h * n_w)\n",
        "        x = x.unflatten(1, (window_size, window_size))\n",
        "        x = x.unflatten(0, (b, n_h, n_w)).transpose(2, 3) # separate batch and window numbers\n",
        "        x = x.flatten(1, 2).flatten(-3, -2) # merge windows\n",
        "        return x\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def get_indices(window_size):\n",
        "        x = torch.arange(window_size, dtype=torch.long)\n",
        "\n",
        "        y1, x1, y2, x2 = torch.meshgrid(x, x, x, x, indexing='ij')\n",
        "        indices = (y1 - y2 + window_size - 1) * (2 * window_size - 1) + x1 - x2 + window_size - 1\n",
        "        indices = indices.flatten()\n",
        "\n",
        "        return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6Me6aMKmz-3V"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Sequential):\n",
        "    def __init__(self, dim, mult=4):\n",
        "        hidden_dim = dim * mult\n",
        "        super().__init__(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8dspUcgkz-3V"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Sequential):\n",
        "    def __init__(self, dim, head_dim, shape, window_size, shift_size=0, p_drop=0.):\n",
        "        super().__init__(\n",
        "            Residual(\n",
        "                nn.LayerNorm(dim),\n",
        "                ShiftedWindowAttention(dim, head_dim, shape, window_size, shift_size),\n",
        "                nn.Dropout(p_drop)\n",
        "            ),\n",
        "            Residual(\n",
        "                nn.LayerNorm(dim),\n",
        "                FeedForward(dim),\n",
        "                nn.Dropout(p_drop)\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Wc9T8709z-3V"
      },
      "outputs": [],
      "source": [
        "class PatchMerging(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, shape):\n",
        "        super().__init__()\n",
        "        self.shape = shape\n",
        "        self.norm = nn.LayerNorm(4 * in_dim)\n",
        "        self.reduction = nn.Linear(4 * in_dim, out_dim, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unflatten(1, self.shape).movedim(-1, 1)\n",
        "        x = F.unfold(x, kernel_size=2, stride=2).movedim(1, -1)\n",
        "\n",
        "        x = self.norm(x)\n",
        "        x = self.reduction(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UTbDRrTvz-3W"
      },
      "outputs": [],
      "source": [
        "class Stage(nn.Sequential):\n",
        "    def __init__(self, num_blocks, in_dim, out_dim, head_dim, shape, window_size, p_drop=0.):\n",
        "        if out_dim != in_dim:\n",
        "            layers = [PatchMerging(in_dim, out_dim, shape)]\n",
        "            shape = (shape[0] // 2, shape[1] // 2)\n",
        "        else:\n",
        "            layers = []\n",
        "\n",
        "        shift_size = window_size // 2\n",
        "        layers += [TransformerBlock(out_dim, head_dim, shape, window_size, 0 if (num % 2 == 0) else shift_size,\n",
        "                                    p_drop) for num in range(num_blocks)]\n",
        "\n",
        "        super().__init__(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b-Iqq7U6z-3W"
      },
      "outputs": [],
      "source": [
        "class StageStack(nn.Sequential):\n",
        "    def __init__(self, num_blocks_list, dims, head_dim, shape, window_size, p_drop=0.):\n",
        "        layers = []\n",
        "        in_dim = dims[0]\n",
        "        for num, out_dim in zip(num_blocks_list, dims[1:]):\n",
        "            layers.append(Stage(num, in_dim, out_dim, head_dim, shape, window_size, p_drop))\n",
        "            if in_dim != out_dim:\n",
        "                shape = (shape[0] // 2, shape[1] // 2)\n",
        "                in_dim = out_dim\n",
        "\n",
        "        super().__init__(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vwjQoET8z-3W"
      },
      "outputs": [],
      "source": [
        "class ToPatches(nn.Module):\n",
        "    def __init__(self, in_channels, dim, patch_size):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        patch_dim = in_channels * patch_size**2\n",
        "        self.proj = nn.Linear(patch_dim, dim)\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.unfold(x, kernel_size=self.patch_size, stride=self.patch_size).movedim(1, -1)\n",
        "        x = self.proj(x)\n",
        "        x = self.norm(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "30En31ZNz-3W"
      },
      "outputs": [],
      "source": [
        "class AddPositionEmbedding(nn.Module):\n",
        "    def __init__(self, dim, num_patches):\n",
        "        super().__init__()\n",
        "        self.pos_embedding = nn.Parameter(torch.Tensor(num_patches, dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pos_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8ctIiZNyz-3W"
      },
      "outputs": [],
      "source": [
        "class ToEmbedding(nn.Sequential):\n",
        "    def __init__(self, in_channels, dim, patch_size, num_patches, p_drop=0.):\n",
        "        super().__init__(\n",
        "            ToPatches(in_channels, dim, patch_size),\n",
        "            AddPositionEmbedding(dim, num_patches),\n",
        "            nn.Dropout(p_drop)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "c9cFLWghz-3W"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Sequential):\n",
        "    def __init__(self, dim, classes, p_drop=0.):\n",
        "        super().__init__(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.GELU(),\n",
        "            GlobalAvgPool(),\n",
        "            nn.Dropout(p_drop),\n",
        "            nn.Linear(dim, classes)\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3kDzqy0jz-3W"
      },
      "outputs": [],
      "source": [
        "class SwinTransformer(nn.Sequential):\n",
        "    def __init__(self, classes, image_size, num_blocks_list, dims, head_dim, patch_size, window_size,\n",
        "                 in_channels=3, emb_p_drop=0., trans_p_drop=0., head_p_drop=0.):\n",
        "        reduced_size = image_size // patch_size\n",
        "        shape = (reduced_size, reduced_size)\n",
        "        num_patches = shape[0] * shape[1]\n",
        "\n",
        "        super().__init__(\n",
        "            ToEmbedding(in_channels, dims[0], patch_size, num_patches, emb_p_drop),\n",
        "            StageStack(num_blocks_list, dims, head_dim, shape, window_size, trans_p_drop),\n",
        "            Head(dims[-1], classes, head_p_drop)\n",
        "        )\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                nn.init.constant_(m.weight, 1.)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, AddPositionEmbedding):\n",
        "                nn.init.normal_(m.pos_embedding, mean=0.0, std=0.02)\n",
        "            elif isinstance(m, ShiftedWindowAttention):\n",
        "                nn.init.normal_(m.pos_enc, mean=0.0, std=0.02)\n",
        "            elif isinstance(m, Residual):\n",
        "                nn.init.zeros_(m.gamma)\n",
        "\n",
        "    def separate_parameters(self):\n",
        "        parameters_decay = set()\n",
        "        parameters_no_decay = set()\n",
        "        modules_weight_decay = (nn.Linear, )\n",
        "        modules_no_weight_decay = (nn.LayerNorm,)\n",
        "\n",
        "        for m_name, m in self.named_modules():\n",
        "            for param_name, param in m.named_parameters():\n",
        "                full_param_name = f\"{m_name}.{param_name}\" if m_name else param_name\n",
        "\n",
        "                if isinstance(m, modules_no_weight_decay):\n",
        "                    parameters_no_decay.add(full_param_name)\n",
        "                elif param_name.endswith(\"bias\"):\n",
        "                    parameters_no_decay.add(full_param_name)\n",
        "                elif isinstance(m, Residual) and param_name.endswith(\"gamma\"):\n",
        "                    parameters_no_decay.add(full_param_name)\n",
        "                elif isinstance(m, AddPositionEmbedding) and param_name.endswith(\"pos_embedding\"):\n",
        "                    parameters_no_decay.add(full_param_name)\n",
        "                elif isinstance(m, ShiftedWindowAttention) and param_name.endswith(\"pos_enc\"):\n",
        "                    parameters_no_decay.add(full_param_name)\n",
        "                elif isinstance(m, modules_weight_decay):\n",
        "                    parameters_decay.add(full_param_name)\n",
        "\n",
        "        # sanity check\n",
        "        assert len(parameters_decay & parameters_no_decay) == 0\n",
        "        assert len(parameters_decay) + len(parameters_no_decay) == len(list(self.parameters()))\n",
        "\n",
        "        return parameters_decay, parameters_no_decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "eLM38MITz-3X"
      },
      "outputs": [],
      "source": [
        "class Lewin(nn.Module):\n",
        "    def __init__(self, num_classes=37):\n",
        "        super(Lewin, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()  # Stem16 레이어 추가\n",
        "\n",
        "        # Swin Transformer 초기화\n",
        "        self.swin_transformer = SwinTransformer(\n",
        "            classes=num_classes,\n",
        "            image_size=224,\n",
        "            num_blocks_list=[4, 4],\n",
        "            dims=[128, 256, 512],\n",
        "            head_dim=32,\n",
        "            patch_size=4,\n",
        "            window_size=7,\n",
        "            emb_p_drop=0.0,\n",
        "            trans_p_drop=0.0,\n",
        "            head_p_drop=0.3\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)  # Stem16 레이어에서 출력을 변환\n",
        "        x = self.swin_transformer(x)  # Swin Transformer 레이어\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO8PvIw4z-3X",
        "outputId": "5d0084c9-beab-4a03-cf5f-875eb6722c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lewin(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (swin_transformer): SwinTransformer(\n",
            "    (0): ToEmbedding(\n",
            "      (0): ToPatches(\n",
            "        (proj): Linear(in_features=48, out_features=128, bias=True)\n",
            "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): AddPositionEmbedding()\n",
            "      (2): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): StageStack(\n",
            "      (0): Stage(\n",
            "        (0): PatchMerging(\n",
            "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
            "        )\n",
            "        (1): TransformerBlock(\n",
            "          (0): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): ShiftedWindowAttention(\n",
            "                (to_qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "                (unifyheads): Linear(in_features=256, out_features=256, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): FeedForward(\n",
            "                (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "                (1): GELU(approximate='none')\n",
            "                (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): TransformerBlock(\n",
            "          (0): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): ShiftedWindowAttention(\n",
            "                (to_qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "                (unifyheads): Linear(in_features=256, out_features=256, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): FeedForward(\n",
            "                (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "                (1): GELU(approximate='none')\n",
            "                (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): TransformerBlock(\n",
            "          (0): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): ShiftedWindowAttention(\n",
            "                (to_qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "                (unifyheads): Linear(in_features=256, out_features=256, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): FeedForward(\n",
            "                (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "                (1): GELU(approximate='none')\n",
            "                (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (4): TransformerBlock(\n",
            "          (0): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): ShiftedWindowAttention(\n",
            "                (to_qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "                (unifyheads): Linear(in_features=256, out_features=256, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): FeedForward(\n",
            "                (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "                (1): GELU(approximate='none')\n",
            "                (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): Stage(\n",
            "        (0): PatchMerging(\n",
            "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
            "        )\n",
            "        (1): TransformerBlock(\n",
            "          (0): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): ShiftedWindowAttention(\n",
            "                (to_qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "                (unifyheads): Linear(in_features=512, out_features=512, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): FeedForward(\n",
            "                (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "                (1): GELU(approximate='none')\n",
            "                (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): TransformerBlock(\n",
            "          (0): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): ShiftedWindowAttention(\n",
            "                (to_qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "                (unifyheads): Linear(in_features=512, out_features=512, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): FeedForward(\n",
            "                (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "                (1): GELU(approximate='none')\n",
            "                (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): TransformerBlock(\n",
            "          (0): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): ShiftedWindowAttention(\n",
            "                (to_qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "                (unifyheads): Linear(in_features=512, out_features=512, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): FeedForward(\n",
            "                (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "                (1): GELU(approximate='none')\n",
            "                (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (4): TransformerBlock(\n",
            "          (0): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): ShiftedWindowAttention(\n",
            "                (to_qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
            "                (unifyheads): Linear(in_features=512, out_features=512, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): Residual(\n",
            "            (residual): Sequential(\n",
            "              (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "              (1): FeedForward(\n",
            "                (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "                (1): GELU(approximate='none')\n",
            "                (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "              )\n",
            "              (2): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): Head(\n",
            "      (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (1): GELU(approximate='none')\n",
            "      (2): GlobalAvgPool()\n",
            "      (3): Dropout(p=0.3, inplace=False)\n",
            "      (4): Linear(in_features=512, out_features=37, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = Lewin()\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlQjcedUz-3X",
        "outputId": "a170205f-2019-496c-b85d-392aa831e2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================================================================================================================\n",
            "Layer (type:depth-idx)                                            Output Shape              Param #\n",
            "===================================================================================================================\n",
            "Lewin                                                             [32, 37]                  --\n",
            "├─Stem16: 1-1                                                     [32, 3, 224, 224]         --\n",
            "│    └─ConvNorm: 2-1                                              [32, 32, 224, 224]        --\n",
            "│    │    └─Conv2d: 3-1                                           [32, 32, 224, 224]        864\n",
            "│    │    └─BatchNorm2d: 3-2                                      [32, 32, 224, 224]        64\n",
            "│    └─Hardswish: 2-2                                             [32, 32, 224, 224]        --\n",
            "│    └─ConvNorm: 2-3                                              [32, 64, 224, 224]        --\n",
            "│    │    └─Conv2d: 3-3                                           [32, 64, 224, 224]        18,432\n",
            "│    │    └─BatchNorm2d: 3-4                                      [32, 64, 224, 224]        128\n",
            "│    └─Hardswish: 2-4                                             [32, 64, 224, 224]        --\n",
            "│    └─ConvNorm: 2-5                                              [32, 128, 224, 224]       --\n",
            "│    │    └─Conv2d: 3-5                                           [32, 128, 224, 224]       73,728\n",
            "│    │    └─BatchNorm2d: 3-6                                      [32, 128, 224, 224]       256\n",
            "│    └─Hardswish: 2-6                                             [32, 128, 224, 224]       --\n",
            "│    └─ConvNorm: 2-7                                              [32, 3, 224, 224]         --\n",
            "│    │    └─Conv2d: 3-7                                           [32, 3, 224, 224]         3,456\n",
            "│    │    └─BatchNorm2d: 3-8                                      [32, 3, 224, 224]         6\n",
            "├─SwinTransformer: 1-2                                            [32, 37]                  --\n",
            "│    └─ToEmbedding: 2-8                                           [32, 3136, 128]           --\n",
            "│    │    └─ToPatches: 3-9                                        [32, 3136, 128]           6,528\n",
            "│    │    └─AddPositionEmbedding: 3-10                            [32, 3136, 128]           401,408\n",
            "│    │    └─Dropout: 3-11                                         [32, 3136, 128]           --\n",
            "│    └─StageStack: 2-9                                            [32, 196, 512]            --\n",
            "│    │    └─Stage: 3-12                                           [32, 784, 256]            3,296,552\n",
            "│    │    └─Stage: 3-13                                           [32, 196, 512]            13,146,696\n",
            "│    └─Head: 2-10                                                 [32, 37]                  --\n",
            "│    │    └─LayerNorm: 3-14                                       [32, 196, 512]            1,024\n",
            "│    │    └─GELU: 3-15                                            [32, 196, 512]            --\n",
            "│    │    └─GlobalAvgPool: 3-16                                   [32, 512]                 --\n",
            "│    │    └─Dropout: 3-17                                         [32, 512]                 --\n",
            "│    │    └─Linear: 3-18                                          [32, 37]                  18,981\n",
            "===================================================================================================================\n",
            "Total params: 16,968,123\n",
            "Trainable params: 16,968,123\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 156.35\n",
            "===================================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 9787.94\n",
            "Params size (MB): 67.81\n",
            "Estimated Total Size (MB): 9875.02\n",
            "===================================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PAqRkbLBz-3X"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO4H9oy-z-3X",
        "outputId": "12c944b6-afd2-4113-ceda-f415bfca7cff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/pets/images.tar.gz to data/oxford-iiit-pet/images.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 792M/792M [00:22<00:00, 35.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/oxford-iiit-pet/images.tar.gz to data/oxford-iiit-pet\n",
            "Downloading https://thor.robots.ox.ac.uk/pets/annotations.tar.gz to data/oxford-iiit-pet/annotations.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19.2M/19.2M [00:01<00:00, 16.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/oxford-iiit-pet/annotations.tar.gz to data/oxford-iiit-pet\n"
          ]
        }
      ],
      "source": [
        "trainval_data = datasets.OxfordIIITPet(root=\"data\", split=\"trainval\", target_types=\"category\", download=True, transform=transform)\n",
        "test_data = datasets.OxfordIIITPet(root=\"data\", split=\"test\", target_types=\"category\", download=True, transform=transform)\n",
        "combined_data = ConcatDataset([trainval_data, test_data])\n",
        "\n",
        "train_size = int(0.7 * len(combined_data))\n",
        "val_size = int(0.15 * len(combined_data))\n",
        "test_size = len(combined_data) - train_size - val_size\n",
        "train_data, val_data, test_data = random_split(combined_data, [train_size, val_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WeJp_CJz-3X",
        "outputId": "f9c523d6-13f6-4a36-9c4a-bcac571e87f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 5144\n",
            "Validation set size: 1102\n",
            "Test set size: 1103\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ST2NvkU1z-3X"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4_6QutPaz-3X"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6cyqWBnRz-3X"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMFI0W09z-3X",
        "outputId": "1e9fe9cc-a154-45af-a6cc-0913fc0f60fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:50<00:00,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.7210, Train Accuracy: 3.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.5910, Validation Accuracy: 6.26%\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:49<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.5577, Train Accuracy: 5.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.4160, Validation Accuracy: 9.53%\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:49<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.4070, Train Accuracy: 9.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.3617, Validation Accuracy: 9.07%\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:49<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.3467, Train Accuracy: 9.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.3839, Validation Accuracy: 7.71%\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:49<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.3397, Train Accuracy: 9.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.3550, Validation Accuracy: 9.26%\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:49<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.2919, Train Accuracy: 10.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.2754, Validation Accuracy: 8.98%\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:49<00:00,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.3055, Train Accuracy: 10.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.2682, Validation Accuracy: 10.34%\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:49<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.2904, Train Accuracy: 10.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.3992, Validation Accuracy: 9.17%\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:49<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.2455, Train Accuracy: 11.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.3190, Validation Accuracy: 8.71%\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [00:49<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.2487, Train Accuracy: 11.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:06<00:00,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.3641, Validation Accuracy: 9.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device)\n",
        "    evaluate(model, val_loader, criterion, device, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1p-9Iu0z-3X",
        "outputId": "745e61a4-4e57-4f03-b101-ee2cc74fed8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 35/35 [00:07<00:00,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 3.3996, Test Accuracy: 9.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b6AdveTM0EJ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}