{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAbTR8w_2wEZ",
        "outputId": "58438b43-4acc-4986-cc90-753ffb939103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x7A1b0UV2wEa"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BGFsgnAU2wEa"
      },
      "outputs": [],
      "source": [
        "class Residual(nn.Module):\n",
        "    def __init__(self, *layers):\n",
        "        super().__init__()\n",
        "        self.residual = nn.Sequential(*layers)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.gamma * self.residual(x)\n",
        "\n",
        "class GlobalAvgPool(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.mean(dim=-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GHbC4wrM2wEb"
      },
      "outputs": [],
      "source": [
        "class ShiftedWindowAttention(nn.Module):\n",
        "    def __init__(self, dim, head_dim, shape, window_size, shift_size=0):\n",
        "        super().__init__()\n",
        "        self.heads = dim // head_dim\n",
        "        self.head_dim = head_dim\n",
        "        self.scale = head_dim**-0.5\n",
        "\n",
        "        self.shape = shape\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, dim * 3)\n",
        "        self.unifyheads = nn.Linear(dim, dim)\n",
        "\n",
        "        self.pos_enc = nn.Parameter(torch.Tensor(self.heads, (2 * window_size - 1)**2))\n",
        "        self.register_buffer(\"relative_indices\", self.get_indices(window_size))\n",
        "\n",
        "        if shift_size > 0:\n",
        "            self.register_buffer(\"mask\", self.generate_mask(shape, window_size, shift_size))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        shift_size, window_size = self.shift_size, self.window_size\n",
        "\n",
        "        x = self.to_windows(x, self.shape, window_size, shift_size) # partition into windows\n",
        "\n",
        "        # self attention\n",
        "        qkv = self.to_qkv(x).unflatten(-1, (3, self.heads, self.head_dim)).transpose(-2, 1)\n",
        "        queries, keys, values = qkv.unbind(dim=2)\n",
        "\n",
        "        att = queries @ keys.transpose(-2, -1)\n",
        "\n",
        "        att = att * self.scale + self.get_rel_pos_enc(window_size) # add relative positon encoding\n",
        "\n",
        "        # masking\n",
        "        if shift_size > 0:\n",
        "            att = self.mask_attention(att)\n",
        "\n",
        "        att = F.softmax(att, dim=-1)\n",
        "\n",
        "        x = att @ values\n",
        "        x = x.transpose(1, 2).contiguous().flatten(-2, -1) # move head back\n",
        "        x = self.unifyheads(x)\n",
        "\n",
        "        x = self.from_windows(x, self.shape, window_size, shift_size) # undo partitioning into windows\n",
        "        return x\n",
        "\n",
        "\n",
        "    def to_windows(self, x, shape, window_size, shift_size):\n",
        "        x = x.unflatten(1, shape)\n",
        "        if shift_size > 0:\n",
        "            x = x.roll((-shift_size, -shift_size), dims=(1, 2))\n",
        "        x = self.split_windows(x, window_size)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def from_windows(self, x, shape, window_size, shift_size):\n",
        "        x = self.merge_windows(x, shape, window_size)\n",
        "        if shift_size > 0:\n",
        "            x = x.roll((shift_size, shift_size), dims=(1, 2))\n",
        "        x = x.flatten(1, 2)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def mask_attention(self, att):\n",
        "        num_win = self.mask.size(1)\n",
        "        att = att.unflatten(0, (att.size(0) // num_win, num_win))\n",
        "        att = att.masked_fill(self.mask, float('-inf'))\n",
        "        att = att.flatten(0, 1)\n",
        "        return att\n",
        "\n",
        "\n",
        "    def get_rel_pos_enc(self, window_size):\n",
        "        indices = self.relative_indices.expand(self.heads, -1)\n",
        "        rel_pos_enc = self.pos_enc.gather(-1, indices)\n",
        "        rel_pos_enc = rel_pos_enc.unflatten(-1, (window_size**2, window_size**2))\n",
        "        return rel_pos_enc\n",
        "\n",
        "\n",
        "    # For explanation of mask regions see Figure 4 in the article\n",
        "    @staticmethod\n",
        "    def generate_mask(shape, window_size, shift_size):\n",
        "        region_mask = torch.zeros(1, *shape, 1)\n",
        "        slices = [slice(0, -window_size), slice(-window_size, -shift_size), slice(-shift_size, None)]\n",
        "\n",
        "        region_num = 0\n",
        "        for i in slices:\n",
        "            for j in slices:\n",
        "                region_mask[:, i, j, :] = region_num\n",
        "                region_num += 1\n",
        "\n",
        "        mask_windows = ShiftedWindowAttention.split_windows(region_mask, window_size).squeeze(-1)\n",
        "        diff_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
        "        mask = diff_mask != 0\n",
        "        mask = mask.unsqueeze(1).unsqueeze(0) # add heads and batch dimension\n",
        "        return mask\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def split_windows(x, window_size):\n",
        "        n_h, n_w = x.size(1) // window_size, x.size(2) // window_size\n",
        "        x = x.unflatten(1, (n_h, window_size)).unflatten(-2, (n_w, window_size)) # split into windows\n",
        "        x = x.transpose(2, 3).flatten(0, 2) # merge batch and window numbers\n",
        "        x = x.flatten(-3, -2)\n",
        "        return x\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def merge_windows(x, shape, window_size):\n",
        "        n_h, n_w = shape[0] // window_size, shape[1] // window_size\n",
        "        b = x.size(0) // (n_h * n_w)\n",
        "        x = x.unflatten(1, (window_size, window_size))\n",
        "        x = x.unflatten(0, (b, n_h, n_w)).transpose(2, 3) # separate batch and window numbers\n",
        "        x = x.flatten(1, 2).flatten(-3, -2) # merge windows\n",
        "        return x\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def get_indices(window_size):\n",
        "        x = torch.arange(window_size, dtype=torch.long)\n",
        "\n",
        "        y1, x1, y2, x2 = torch.meshgrid(x, x, x, x, indexing='ij')\n",
        "        indices = (y1 - y2 + window_size - 1) * (2 * window_size - 1) + x1 - x2 + window_size - 1\n",
        "        indices = indices.flatten()\n",
        "\n",
        "        return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6G1kJRHF2wEb"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Sequential):\n",
        "    def __init__(self, dim, mult=4):\n",
        "        hidden_dim = dim * mult\n",
        "        super().__init__(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Pb17rzvq2wEc"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Sequential):\n",
        "    def __init__(self, dim, head_dim, shape, window_size, shift_size=0, p_drop=0.):\n",
        "        super().__init__(\n",
        "            Residual(\n",
        "                nn.LayerNorm(dim),\n",
        "                ShiftedWindowAttention(dim, head_dim, shape, window_size, shift_size),\n",
        "                nn.Dropout(p_drop)\n",
        "            ),\n",
        "            Residual(\n",
        "                nn.LayerNorm(dim),\n",
        "                FeedForward(dim),\n",
        "                nn.Dropout(p_drop)\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9mx4UqXK2wEc"
      },
      "outputs": [],
      "source": [
        "class PatchMerging(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, shape):\n",
        "        super().__init__()\n",
        "        self.shape = shape\n",
        "        self.norm = nn.LayerNorm(4 * in_dim)\n",
        "        self.reduction = nn.Linear(4 * in_dim, out_dim, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unflatten(1, self.shape).movedim(-1, 1)\n",
        "        x = F.unfold(x, kernel_size=2, stride=2).movedim(1, -1)\n",
        "\n",
        "        x = self.norm(x)\n",
        "        x = self.reduction(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NVys79OW2wEc"
      },
      "outputs": [],
      "source": [
        "class Stage(nn.Sequential):\n",
        "    def __init__(self, num_blocks, in_dim, out_dim, head_dim, shape, window_size, p_drop=0.):\n",
        "        if out_dim != in_dim:\n",
        "            layers = [PatchMerging(in_dim, out_dim, shape)]\n",
        "            shape = (shape[0] // 2, shape[1] // 2)\n",
        "        else:\n",
        "            layers = []\n",
        "\n",
        "        shift_size = window_size // 2\n",
        "        layers += [TransformerBlock(out_dim, head_dim, shape, window_size, 0 if (num % 2 == 0) else shift_size,\n",
        "                                    p_drop) for num in range(num_blocks)]\n",
        "\n",
        "        super().__init__(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LcPfiiho2wEc"
      },
      "outputs": [],
      "source": [
        "class StageStack(nn.Sequential):\n",
        "    def __init__(self, num_blocks_list, dims, head_dim, shape, window_size, p_drop=0.):\n",
        "        layers = []\n",
        "        in_dim = dims[0]\n",
        "        for num, out_dim in zip(num_blocks_list, dims[1:]):\n",
        "            layers.append(Stage(num, in_dim, out_dim, head_dim, shape, window_size, p_drop))\n",
        "            if in_dim != out_dim:\n",
        "                shape = (shape[0] // 2, shape[1] // 2)\n",
        "                in_dim = out_dim\n",
        "\n",
        "        super().__init__(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yB6EczT82wEc"
      },
      "outputs": [],
      "source": [
        "class ToPatches(nn.Module):\n",
        "    def __init__(self, in_channels, dim, patch_size):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        patch_dim = in_channels * patch_size**2\n",
        "        self.proj = nn.Linear(patch_dim, dim)\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.unfold(x, kernel_size=self.patch_size, stride=self.patch_size).movedim(1, -1)\n",
        "        x = self.proj(x)\n",
        "        x = self.norm(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HFYbHrmg2wEc"
      },
      "outputs": [],
      "source": [
        "class AddPositionEmbedding(nn.Module):\n",
        "    def __init__(self, dim, num_patches):\n",
        "        super().__init__()\n",
        "        self.pos_embedding = nn.Parameter(torch.Tensor(num_patches, dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pos_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "L0AiPdgg2wEc"
      },
      "outputs": [],
      "source": [
        "class ToEmbedding(nn.Sequential):\n",
        "    def __init__(self, in_channels, dim, patch_size, num_patches, p_drop=0.):\n",
        "        super().__init__(\n",
        "            ToPatches(in_channels, dim, patch_size),\n",
        "            AddPositionEmbedding(dim, num_patches),\n",
        "            nn.Dropout(p_drop)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zlsEj4wc2wEc"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Sequential):\n",
        "    def __init__(self, dim, classes, p_drop=0.):\n",
        "        super().__init__(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.GELU(),\n",
        "            GlobalAvgPool(),\n",
        "            nn.Dropout(p_drop),\n",
        "            nn.Linear(dim, classes)\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1THL4jMt2wEc"
      },
      "outputs": [],
      "source": [
        "class SwinTransformer(nn.Sequential):\n",
        "    def __init__(self, classes, image_size, num_blocks_list, dims, head_dim, patch_size, window_size,\n",
        "                 in_channels=3, emb_p_drop=0., trans_p_drop=0., head_p_drop=0.):\n",
        "        reduced_size = image_size // patch_size\n",
        "        shape = (reduced_size, reduced_size)\n",
        "        num_patches = shape[0] * shape[1]\n",
        "\n",
        "        super().__init__(\n",
        "            ToEmbedding(in_channels, dims[0], patch_size, num_patches, emb_p_drop),\n",
        "            StageStack(num_blocks_list, dims, head_dim, shape, window_size, trans_p_drop),\n",
        "            Head(dims[-1], classes, head_p_drop)\n",
        "        )\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                nn.init.constant_(m.weight, 1.)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, AddPositionEmbedding):\n",
        "                nn.init.normal_(m.pos_embedding, mean=0.0, std=0.02)\n",
        "            elif isinstance(m, ShiftedWindowAttention):\n",
        "                nn.init.normal_(m.pos_enc, mean=0.0, std=0.02)\n",
        "            elif isinstance(m, Residual):\n",
        "                nn.init.zeros_(m.gamma)\n",
        "\n",
        "    def separate_parameters(self):\n",
        "        parameters_decay = set()\n",
        "        parameters_no_decay = set()\n",
        "        modules_weight_decay = (nn.Linear, )\n",
        "        modules_no_weight_decay = (nn.LayerNorm,)\n",
        "\n",
        "        for m_name, m in self.named_modules():\n",
        "            for param_name, param in m.named_parameters():\n",
        "                full_param_name = f\"{m_name}.{param_name}\" if m_name else param_name\n",
        "\n",
        "                if isinstance(m, modules_no_weight_decay):\n",
        "                    parameters_no_decay.add(full_param_name)\n",
        "                elif param_name.endswith(\"bias\"):\n",
        "                    parameters_no_decay.add(full_param_name)\n",
        "                elif isinstance(m, Residual) and param_name.endswith(\"gamma\"):\n",
        "                    parameters_no_decay.add(full_param_name)\n",
        "                elif isinstance(m, AddPositionEmbedding) and param_name.endswith(\"pos_embedding\"):\n",
        "                    parameters_no_decay.add(full_param_name)\n",
        "                elif isinstance(m, ShiftedWindowAttention) and param_name.endswith(\"pos_enc\"):\n",
        "                    parameters_no_decay.add(full_param_name)\n",
        "                elif isinstance(m, modules_weight_decay):\n",
        "                    parameters_decay.add(full_param_name)\n",
        "\n",
        "        # sanity check\n",
        "        assert len(parameters_decay & parameters_no_decay) == 0\n",
        "        assert len(parameters_decay) + len(parameters_no_decay) == len(list(self.parameters()))\n",
        "\n",
        "        return parameters_decay, parameters_no_decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQcaxmne2wEd",
        "outputId": "0b693574-0897-45b2-d8ec-99f0a1c1b782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SwinTransformer(\n",
            "  (0): ToEmbedding(\n",
            "    (0): ToPatches(\n",
            "      (proj): Linear(in_features=12, out_features=128, bias=True)\n",
            "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (1): AddPositionEmbedding()\n",
            "    (2): Dropout(p=0.0, inplace=False)\n",
            "  )\n",
            "  (1): StageStack(\n",
            "    (0): Stage(\n",
            "      (0): TransformerBlock(\n",
            "        (0): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): ShiftedWindowAttention(\n",
            "              (to_qkv): Linear(in_features=128, out_features=384, bias=True)\n",
            "              (unifyheads): Linear(in_features=128, out_features=128, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): FeedForward(\n",
            "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "              (1): GELU(approximate='none')\n",
            "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): TransformerBlock(\n",
            "        (0): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): ShiftedWindowAttention(\n",
            "              (to_qkv): Linear(in_features=128, out_features=384, bias=True)\n",
            "              (unifyheads): Linear(in_features=128, out_features=128, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): FeedForward(\n",
            "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "              (1): GELU(approximate='none')\n",
            "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): TransformerBlock(\n",
            "        (0): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): ShiftedWindowAttention(\n",
            "              (to_qkv): Linear(in_features=128, out_features=384, bias=True)\n",
            "              (unifyheads): Linear(in_features=128, out_features=128, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): FeedForward(\n",
            "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "              (1): GELU(approximate='none')\n",
            "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): TransformerBlock(\n",
            "        (0): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): ShiftedWindowAttention(\n",
            "              (to_qkv): Linear(in_features=128, out_features=384, bias=True)\n",
            "              (unifyheads): Linear(in_features=128, out_features=128, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): FeedForward(\n",
            "              (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "              (1): GELU(approximate='none')\n",
            "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): Stage(\n",
            "      (0): PatchMerging(\n",
            "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
            "      )\n",
            "      (1): TransformerBlock(\n",
            "        (0): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): ShiftedWindowAttention(\n",
            "              (to_qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "              (unifyheads): Linear(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): FeedForward(\n",
            "              (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "              (1): GELU(approximate='none')\n",
            "              (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): TransformerBlock(\n",
            "        (0): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): ShiftedWindowAttention(\n",
            "              (to_qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "              (unifyheads): Linear(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): FeedForward(\n",
            "              (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "              (1): GELU(approximate='none')\n",
            "              (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): TransformerBlock(\n",
            "        (0): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): ShiftedWindowAttention(\n",
            "              (to_qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "              (unifyheads): Linear(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): FeedForward(\n",
            "              (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "              (1): GELU(approximate='none')\n",
            "              (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (4): TransformerBlock(\n",
            "        (0): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): ShiftedWindowAttention(\n",
            "              (to_qkv): Linear(in_features=256, out_features=768, bias=True)\n",
            "              (unifyheads): Linear(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): Residual(\n",
            "          (residual): Sequential(\n",
            "            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (1): FeedForward(\n",
            "              (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "              (1): GELU(approximate='none')\n",
            "              (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "            )\n",
            "            (2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (2): Head(\n",
            "    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    (1): GELU(approximate='none')\n",
            "    (2): GlobalAvgPool()\n",
            "    (3): Dropout(p=0.3, inplace=False)\n",
            "    (4): Linear(in_features=256, out_features=37, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = SwinTransformer(37, 224,\n",
        "                        num_blocks_list=[4, 4], dims=[128, 128, 256],\n",
        "                        head_dim=32, patch_size=2, window_size=4,\n",
        "                        emb_p_drop=0., trans_p_drop=0., head_p_drop=0.3)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RnqebW62wEd",
        "outputId": "2f3b8560-ec65-4e8b-86ba-5b4c8f437f14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================================================================================================\n",
            "Layer (type:depth-idx)                                       Output Shape              Param #\n",
            "==============================================================================================================\n",
            "SwinTransformer                                              [32, 37]                  --\n",
            "├─ToEmbedding: 1-1                                           [32, 12544, 128]          --\n",
            "│    └─ToPatches: 2-1                                        [32, 12544, 128]          --\n",
            "│    │    └─Linear: 3-1                                      [32, 12544, 128]          1,664\n",
            "│    │    └─LayerNorm: 3-2                                   [32, 12544, 128]          256\n",
            "│    └─AddPositionEmbedding: 2-2                             [32, 12544, 128]          1,605,632\n",
            "│    └─Dropout: 2-3                                          [32, 12544, 128]          --\n",
            "├─StageStack: 1-2                                            [32, 3136, 256]           --\n",
            "│    └─Stage: 2-4                                            [32, 12544, 128]          --\n",
            "│    │    └─TransformerBlock: 3-3                            [32, 12544, 128]          198,470\n",
            "│    │    └─TransformerBlock: 3-4                            [32, 12544, 128]          198,470\n",
            "│    │    └─TransformerBlock: 3-5                            [32, 12544, 128]          198,470\n",
            "│    │    └─TransformerBlock: 3-6                            [32, 12544, 128]          198,470\n",
            "│    └─Stage: 2-5                                            [32, 3136, 256]           --\n",
            "│    │    └─PatchMerging: 3-7                                [32, 3136, 256]           132,096\n",
            "│    │    └─TransformerBlock: 3-8                            [32, 3136, 256]           790,154\n",
            "│    │    └─TransformerBlock: 3-9                            [32, 3136, 256]           790,154\n",
            "│    │    └─TransformerBlock: 3-10                           [32, 3136, 256]           790,154\n",
            "│    │    └─TransformerBlock: 3-11                           [32, 3136, 256]           790,154\n",
            "├─Head: 1-3                                                  [32, 37]                  --\n",
            "│    └─LayerNorm: 2-6                                        [32, 3136, 256]           512\n",
            "│    └─GELU: 2-7                                             [32, 3136, 256]           --\n",
            "│    └─GlobalAvgPool: 2-8                                    [32, 256]                 --\n",
            "│    └─Dropout: 2-9                                          [32, 256]                 --\n",
            "│    └─Linear: 2-10                                          [32, 37]                  9,509\n",
            "==============================================================================================================\n",
            "Total params: 5,704,165\n",
            "Trainable params: 5,704,165\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 13.32\n",
            "==============================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 29183.98\n",
            "Params size (MB): 22.81\n",
            "Estimated Total Size (MB): 29226.05\n",
            "==============================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rax_CHvV2wEd"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYdF25He2wEd",
        "outputId": "587a26f1-ae49-4d0e-b514-18b19e8719b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/pets/images.tar.gz to data/oxford-iiit-pet/images.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 792M/792M [00:38<00:00, 20.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/oxford-iiit-pet/images.tar.gz to data/oxford-iiit-pet\n",
            "Downloading https://thor.robots.ox.ac.uk/pets/annotations.tar.gz to data/oxford-iiit-pet/annotations.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19.2M/19.2M [00:01<00:00, 10.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/oxford-iiit-pet/annotations.tar.gz to data/oxford-iiit-pet\n"
          ]
        }
      ],
      "source": [
        "trainval_data = datasets.OxfordIIITPet(root=\"data\", split=\"trainval\", target_types=\"category\", download=True, transform=transform)\n",
        "test_data = datasets.OxfordIIITPet(root=\"data\", split=\"test\", target_types=\"category\", download=True, transform=transform)\n",
        "combined_data = ConcatDataset([trainval_data, test_data])\n",
        "\n",
        "train_size = int(0.7 * len(combined_data))\n",
        "val_size = int(0.15 * len(combined_data))\n",
        "test_size = len(combined_data) - train_size - val_size\n",
        "train_data, val_data, test_data = random_split(combined_data, [train_size, val_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTEp19Tp2wEd",
        "outputId": "d96a26e8-3db3-45c5-c5e9-7354a02483bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 5144\n",
            "Validation set size: 1102\n",
            "Test set size: 1103\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jBKyqq1x2wEd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mSFxy88X2wEd"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7twrPH6r2wEd"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnKDW0DT2wEd",
        "outputId": "aba56236-ca3b-4c93-9d0c-d10615427996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:37<00:00,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.6775, Train Accuracy: 3.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.5503, Validation Accuracy: 5.63%\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:37<00:00,  1.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.5836, Train Accuracy: 5.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.5018, Validation Accuracy: 6.81%\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:36<00:00,  1.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.5457, Train Accuracy: 5.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.4829, Validation Accuracy: 6.53%\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:37<00:00,  1.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.5003, Train Accuracy: 6.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.4824, Validation Accuracy: 7.08%\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:37<00:00,  1.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.4529, Train Accuracy: 7.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.4074, Validation Accuracy: 8.53%\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:37<00:00,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.3886, Train Accuracy: 8.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.3070, Validation Accuracy: 11.89%\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:37<00:00,  1.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.3045, Train Accuracy: 10.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.2842, Validation Accuracy: 10.44%\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:37<00:00,  1.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.2386, Train Accuracy: 11.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.2107, Validation Accuracy: 12.43%\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:37<00:00,  1.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.1806, Train Accuracy: 12.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.1727, Validation Accuracy: 12.70%\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:37<00:00,  1.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.1565, Train Accuracy: 12.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:10<00:00,  3.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.1546, Validation Accuracy: 12.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device)\n",
        "    evaluate(model, val_loader, criterion, device, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjRZG9yF2wEd",
        "outputId": "13ebda16-72d3-4810-8449-c07c15818f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 35/35 [00:10<00:00,  3.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 3.1781, Test Accuracy: 15.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10jPZiUg2wEd"
      },
      "source": [
        "# timm SWIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_8NDCSW2wEe",
        "outputId": "b67a90d5-a881-4dfa-ca5a-24a672b727b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "Layer (type:depth-idx)                             Output Shape              Param #\n",
            "====================================================================================================\n",
            "SwinTransformer                                    [32, 37]                  --\n",
            "├─PatchEmbed: 1-1                                  [32, 56, 56, 128]         --\n",
            "│    └─Conv2d: 2-1                                 [32, 128, 56, 56]         6,272\n",
            "│    └─LayerNorm: 2-2                              [32, 56, 56, 128]         256\n",
            "├─Sequential: 1-2                                  [32, 7, 7, 1024]          --\n",
            "│    └─SwinTransformerStage: 2-3                   [32, 56, 56, 128]         --\n",
            "│    │    └─Identity: 3-1                          [32, 56, 56, 128]         --\n",
            "│    │    └─Sequential: 3-2                        [32, 56, 56, 128]         397,896\n",
            "│    └─SwinTransformerStage: 2-4                   [32, 28, 28, 256]         --\n",
            "│    │    └─PatchMerging: 3-3                      [32, 28, 28, 256]         132,096\n",
            "│    │    └─Sequential: 3-4                        [32, 28, 28, 256]         1,582,224\n",
            "│    └─SwinTransformerStage: 2-5                   [32, 14, 14, 512]         --\n",
            "│    │    └─PatchMerging: 3-5                      [32, 14, 14, 512]         526,336\n",
            "│    │    └─Sequential: 3-6                        [32, 14, 14, 512]         56,791,584\n",
            "│    └─SwinTransformerStage: 2-6                   [32, 7, 7, 1024]          --\n",
            "│    │    └─PatchMerging: 3-7                      [32, 7, 7, 1024]          2,101,248\n",
            "│    │    └─Sequential: 3-8                        [32, 7, 7, 1024]          25,203,264\n",
            "├─LayerNorm: 1-3                                   [32, 7, 7, 1024]          2,048\n",
            "├─ClassifierHead: 1-4                              [32, 37]                  --\n",
            "│    └─SelectAdaptivePool2d: 2-7                   [32, 1024]                --\n",
            "│    │    └─FastAdaptiveAvgPool: 3-9               [32, 1024]                --\n",
            "│    │    └─Identity: 3-10                         [32, 1024]                --\n",
            "│    └─Dropout: 2-8                                [32, 1024]                --\n",
            "│    └─Linear: 2-9                                 [32, 37]                  37,925\n",
            "│    └─Identity: 2-10                              [32, 37]                  --\n",
            "====================================================================================================\n",
            "Total params: 86,781,149\n",
            "Trainable params: 86,781,149\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 5.74\n",
            "====================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 9248.45\n",
            "Params size (MB): 346.87\n",
            "Estimated Total Size (MB): 9614.59\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "timm_swin = timm.create_model('swin_base_patch4_window7_224', pretrained=False, num_classes=37)\n",
        "print(summary(timm_swin, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UDwJJdr2wEe",
        "outputId": "87527423-9ccf-4eda-d458-e14648b3359b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:06<00:00,  2.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.7397, Train Accuracy: 2.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:08<00:00,  4.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.6961, Validation Accuracy: 3.54%\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:06<00:00,  2.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.7452, Train Accuracy: 2.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:08<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.6961, Validation Accuracy: 3.54%\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:06<00:00,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.7394, Train Accuracy: 2.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:08<00:00,  4.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.6961, Validation Accuracy: 3.54%\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:06<00:00,  2.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.7425, Train Accuracy: 2.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:08<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.6961, Validation Accuracy: 3.54%\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:06<00:00,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.7431, Train Accuracy: 2.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:08<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.6961, Validation Accuracy: 3.54%\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:06<00:00,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.7440, Train Accuracy: 2.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:08<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.6961, Validation Accuracy: 3.54%\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:06<00:00,  2.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.7459, Train Accuracy: 2.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:08<00:00,  4.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.6961, Validation Accuracy: 3.54%\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:06<00:00,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.7381, Train Accuracy: 2.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:08<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.6961, Validation Accuracy: 3.54%\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:06<00:00,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.7387, Train Accuracy: 2.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.6961, Validation Accuracy: 3.54%\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 161/161 [01:05<00:00,  2.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 3.7445, Train Accuracy: 2.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 35/35 [00:07<00:00,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 3.6961, Validation Accuracy: 3.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(timm_swin, train_loader, criterion, optimizer, device)\n",
        "    evaluate(timm_swin, val_loader, criterion, device, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE5JNkXY2wEe",
        "outputId": "b90a9907-3ad1-434f-8fd6-6fa6b98410da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 35/35 [00:08<00:00,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 3.7442, Test Accuracy: 3.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(timm_swin, test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BUSJSqzc23fd"
      },
      "execution_count": 27,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}