{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "84cde6d5-1be0-4730-f09b-b3f09d05cd39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=9b10132ed7d391d50c9b2a3e087b73ed5d070b702ae22dd6e4970a775de23ac1\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "8f334781-6cbd-446d-8612-1eed58d1efb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-23 07:23:12--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.45.92, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-03-23 07:23:12--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  24.8MB/s    in 11m 48s \n",
            "\n",
            "2025-03-23 07:35:00 (15.8 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "ee649dea-af97-4776-9a1c-6798842c94f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "39b087eb-67ff-4447-c74c-a4a71aa53f9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "3d95efd0-3383-48ad-a229-6f823350da05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "314664e7-95e0-495d-bd04-b349d314a025"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation\n",
        "aug_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.75),\n",
        "    transforms.RandomVerticalFlip(p=0.75),\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "zja84HaiVhoh"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "#train_data = Subset(dataset, load_train_idx)\n",
        "#val_data = Subset(dataset, load_val_idx)\n",
        "#test_data = Subset(dataset, load_test_idx)\n",
        "\n",
        "dataset_train = datasets.ImageFolder(root=train_dir, transform=aug_transform)\n",
        "dataset_eval = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "\n",
        "train_data = Subset(dataset_train, load_train_idx)\n",
        "val_data = Subset(dataset_eval, load_val_idx)\n",
        "test_data = Subset(dataset_eval, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "b76be6ed-e28b-4453-b284-fa0c4d4eb031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "8ac49d11-83c6-40b3-e30f-003163702bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6678, Train Accuracy: 76.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3530, Validation Accuracy: 88.29%\n",
            "Balanced Accuracy: 0.8824\n",
            "New best model saved with Validation loss 0.3530 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3445, Train Accuracy: 87.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3030, Validation Accuracy: 89.57%\n",
            "Balanced Accuracy: 0.8893\n",
            "New best model saved with Validation loss 0.3030 at best_model.pth\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:59<00:00, 12.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2352, Train Accuracy: 91.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2349, Validation Accuracy: 91.37%\n",
            "Balanced Accuracy: 0.9075\n",
            "New best model saved with Validation loss 0.2349 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:59<00:00, 12.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1809, Train Accuracy: 93.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2092, Validation Accuracy: 93.05%\n",
            "Balanced Accuracy: 0.9325\n",
            "New best model saved with Validation loss 0.2092 at best_model.pth\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:59<00:00, 12.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1461, Train Accuracy: 95.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2037, Validation Accuracy: 92.91%\n",
            "Balanced Accuracy: 0.9278\n",
            "New best model saved with Validation loss 0.2037 at best_model.pth\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:59<00:00, 12.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1176, Train Accuracy: 95.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3489, Validation Accuracy: 88.03%\n",
            "Balanced Accuracy: 0.8759\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:59<00:00, 12.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0951, Train Accuracy: 96.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2400, Validation Accuracy: 92.19%\n",
            "Balanced Accuracy: 0.9235\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0757, Train Accuracy: 97.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4736, Validation Accuracy: 85.91%\n",
            "Balanced Accuracy: 0.8431\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0633, Train Accuracy: 97.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0544, Validation Accuracy: 98.11%\n",
            "Balanced Accuracy: 0.9799\n",
            "New best model saved with Validation loss 0.0544 at best_model.pth\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:59<00:00, 12.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0546, Train Accuracy: 98.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7854, Validation Accuracy: 77.95%\n",
            "Balanced Accuracy: 0.7589\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:59<00:00, 12.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0457, Train Accuracy: 98.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1298, Validation Accuracy: 95.71%\n",
            "Balanced Accuracy: 0.9522\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0407, Train Accuracy: 98.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1383, Validation Accuracy: 76.17%\n",
            "Balanced Accuracy: 0.7611\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:59<00:00, 12.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0343, Train Accuracy: 98.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0965, Validation Accuracy: 97.33%\n",
            "Balanced Accuracy: 0.9722\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0321, Train Accuracy: 98.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0951, Validation Accuracy: 97.29%\n",
            "Balanced Accuracy: 0.9715\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0292, Train Accuracy: 99.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1707, Validation Accuracy: 95.07%\n",
            "Balanced Accuracy: 0.9516\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0248, Train Accuracy: 99.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3840, Validation Accuracy: 89.27%\n",
            "Balanced Accuracy: 0.8884\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0256, Train Accuracy: 99.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2926, Validation Accuracy: 91.49%\n",
            "Balanced Accuracy: 0.9169\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0202, Train Accuracy: 99.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0448, Validation Accuracy: 98.45%\n",
            "Balanced Accuracy: 0.9833\n",
            "New best model saved with Validation loss 0.0448 at best_model.pth\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:01<00:00, 12.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0177, Train Accuracy: 99.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0674, Validation Accuracy: 98.21%\n",
            "Balanced Accuracy: 0.9825\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:01<00:00, 12.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0181, Train Accuracy: 99.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0688, Validation Accuracy: 97.82%\n",
            "Balanced Accuracy: 0.9777\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0197, Train Accuracy: 99.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0361, Validation Accuracy: 98.89%\n",
            "Balanced Accuracy: 0.9884\n",
            "New best model saved with Validation loss 0.0361 at best_model.pth\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0152, Train Accuracy: 99.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 18.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0735, Validation Accuracy: 97.61%\n",
            "Balanced Accuracy: 0.9759\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0161, Train Accuracy: 99.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0368, Validation Accuracy: 98.86%\n",
            "Balanced Accuracy: 0.9888\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0148, Train Accuracy: 99.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0388, Validation Accuracy: 98.96%\n",
            "Balanced Accuracy: 0.9896\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0139, Train Accuracy: 99.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0652, Validation Accuracy: 97.99%\n",
            "Balanced Accuracy: 0.9789\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:02<00:00, 12.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0126, Train Accuracy: 99.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0281, Validation Accuracy: 99.15%\n",
            "Balanced Accuracy: 0.9912\n",
            "New best model saved with Validation loss 0.0281 at best_model.pth\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:01<00:00, 12.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0121, Train Accuracy: 99.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0646, Validation Accuracy: 98.07%\n",
            "Balanced Accuracy: 0.9812\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:01<00:00, 12.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0126, Train Accuracy: 99.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0356, Validation Accuracy: 98.95%\n",
            "Balanced Accuracy: 0.9889\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0102, Train Accuracy: 99.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 18.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4774, Validation Accuracy: 88.32%\n",
            "Balanced Accuracy: 0.8766\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:00<00:00, 12.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0123, Train Accuracy: 99.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0851, Validation Accuracy: 97.81%\n",
            "Balanced Accuracy: 0.9791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wDDP-iS8z1Q",
        "outputId": "a063eae4-a399-4c85-9a90-421c32b2f5bf"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "57260a76-6165-4032-a627-c00e1bbced4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:24<00:00, 19.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0277, Test Accuracy: 99.05%\n",
            "Balanced Accuracy: 0.9902\n",
            "New best model saved with Test loss 0.0277 at best_model.pth\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "bfdf12d2-f8ba-428d-d22b-ffb027dc618f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 12.59 ms\n",
            "Standard Deviation: 1.13 ms\n",
            "Maximum Time: 18.61 ms\n",
            "Minimum Time: 11.73 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "81ee3c20-cfe2-48d5-bc07-cecd0c33a3c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.367ms        16.29%       1.367ms     170.833us             8  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     991.134us        11.82%     991.134us     123.892us             8  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     778.713us         9.28%     778.713us      97.339us             8  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     739.862us         8.82%     739.862us      15.414us            48  \n",
            "                        ampere_sgemm_64x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us     587.665us         7.01%     587.665us      73.458us             8  \n",
            "                                ampere_sgemm_128x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     536.592us         6.40%     536.592us     134.148us             4  \n",
            "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     502.511us         5.99%     502.511us      19.327us            26  \n",
            "void at::native::batch_norm_transform_input_channels...         0.00%       0.000us         0.00%       0.000us       0.000us     493.102us         5.88%     493.102us      14.503us            34  \n",
            "                                 ampere_sgemm_128x32_tn         0.00%       0.000us         0.00%       0.000us       0.000us     343.563us         4.10%     343.563us      85.891us             4  \n",
            "       _5x_cudnn_ampere_scudnn_128x64_relu_medium_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     307.850us         3.67%     307.850us     307.850us             1  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 14.944ms\n",
            "Self CUDA time total: 8.387ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4UchJcz1N6K",
        "outputId": "6bf63cfc-8b56-474d-e2fc-6a54877019a6"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:24<00:00, 19.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0277, Test Accuracy: 99.05%\n",
            "Overall - F1: 0.9904, Recall: 0.9902, Precision: 0.9905\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9987, Recall: 0.9981, Precision: 0.9994\n",
            "Class 1 - F1: 0.9991, Recall: 1.0000, Precision: 0.9981\n",
            "Class 2 - F1: 0.9887, Recall: 0.9884, Precision: 0.9890\n",
            "Class 3 - F1: 0.9983, Recall: 0.9977, Precision: 0.9988\n",
            "Class 4 - F1: 0.9899, Recall: 0.9895, Precision: 0.9902\n",
            "Class 5 - F1: 0.9911, Recall: 0.9906, Precision: 0.9916\n",
            "Class 6 - F1: 0.9810, Recall: 0.9802, Precision: 0.9817\n",
            "Class 7 - F1: 0.9786, Recall: 0.9764, Precision: 0.9808\n",
            "Class 8 - F1: 0.9879, Recall: 0.9912, Precision: 0.9847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "ZLcoSxfe1Qbt",
        "outputId": "db44c7e3-10e3-4d92-c6bc-f0a78219366a"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MOLSL09JxKdp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}