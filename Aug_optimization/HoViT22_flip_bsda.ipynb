{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "f835cbce-8367-458e-e23f-f2d32798cf7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=545f258c90aeed1a29ee4f173782710713c4471b79cb1f04123686cb1e9de3af\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n",
            "--2025-04-03 04:52:44--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.43.25, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-04-03 04:52:45--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  17.9MB/s    in 10m 46s \n",
            "\n",
            "2025-04-03 05:03:31 (17.3 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo\n",
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super().__init__()\n",
        "        self.stem = Stem16()\n",
        "        self.stage1 = LevitStage(256, 256, 4, 2, downsample=False)\n",
        "        self.stage2 = LevitStage(256, 384, 6, 2, downsample=True)\n",
        "        self.conv1x1 = nn.Sequential(nn.Conv2d(384, 512, 1), nn.BatchNorm2d(512), nn.ReLU(True))\n",
        "        self.head = NormLinear(512, num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(512, num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        H = W = int(x.shape[1] ** 0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "        x = self.conv1x1(x)\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        return self.head(x)\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        x = self.stem(x)\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        H = W = int(x.shape[1] ** 0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "        x = self.conv1x1(x)\n",
        "        return torch.mean(x, dim=(2, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "d8ec4683-fbed-414f-a3c2-edeb6532ba95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gNpMsNYAzLDF",
        "outputId": "6a2daa2d-165a-4092-96dd-ca3dc64c94ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 4,909,234\n",
            "Trainable params: 4,909,234\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.68\n",
            "Params size (MB): 19.61\n",
            "Estimated Total Size (MB): 936.56\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "13eb71ec-0547-42d0-b16c-45bccf19fe33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.68\n",
            "Params size (MB): 19.61\n",
            "Estimated Total Size (MB): 936.56\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.68\n",
            "Params size (MB): 19.61\n",
            "Estimated Total Size (MB): 936.56\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LUiqsuSdOgj0"
      },
      "outputs": [],
      "source": [
        "class BSDALayer(nn.Module):\n",
        "    def __init__(self, feature_dim, bsda_lambda=0.8) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.bsda_lambda = bsda_lambda\n",
        "\n",
        "        self.logvar = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "        )\n",
        "\n",
        "        self.d = nn.Dropout(p=self.bsda_lambda)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "    def modified_indicator_function(self, x):\n",
        "        return torch.where(x >= 0, torch.sign(x), -torch.sign(x))\n",
        "\n",
        "    def calc_a_tilde(self, a, m, multi=1):\n",
        "        a = a.repeat(multi, 1)\n",
        "        return a + self.d(m) * self.modified_indicator_function(a)\n",
        "\n",
        "    def reparameterize(self, mu, logvar, multi=1):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        std = std.repeat(multi, 1)\n",
        "        eps = torch.randn_like(std, device=std.device)\n",
        "        mu = mu.repeat(multi, 1)\n",
        "        return eps * std + mu\n",
        "\n",
        "    def forward(self, a, multi=1):\n",
        "        \"\"\"\n",
        "            a: (batch_size, feature_dim)\n",
        "            m: (batch_size, feature_dim)\n",
        "            mu: (batch_size, feature_dim)\n",
        "            logvar: (batch_size, feature_dim)\n",
        "        \"\"\"\n",
        "        x = self.encoder(a)\n",
        "\n",
        "        logvar = self.logvar(x)\n",
        "        mu = torch.zeros_like(logvar, device=logvar.device)\n",
        "\n",
        "        m = self.reparameterize(mu, logvar, multi)\n",
        "        a_hat = self.decoder(m)\n",
        "\n",
        "        return m, mu, logvar, a_hat\n",
        "\n",
        "    def calc_kl_loss(self, mu, logvar):\n",
        "\n",
        "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        return kl_loss\n",
        "\n",
        "    def calc_recon_loss(self, a, a_hat, multi=1):\n",
        "        recon_loss = torch.mean((a.repeat(multi, 1) - a_hat) ** 2) * 0.5\n",
        "        return recon_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "301f408e-a2f1-4a96-8e56-05ec8af1c54c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mAsRwMpISMIh"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "flip_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.75),\n",
        "    transforms.RandomVerticalFlip(p=0.75),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fnlxaQSs7NsL"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "dataset_train = datasets.ImageFolder(root=train_dir, transform=flip_transform)\n",
        "dataset_eval = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "\n",
        "train_data = Subset(dataset_train, load_train_idx)\n",
        "val_data = Subset(dataset_eval, load_val_idx)\n",
        "test_data = Subset(dataset_eval, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "05640c0d-8cf2-4bf8-db44-6ebb9675c7d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch,\n",
        "          use_bsda=False, bsda_layer=None, multi=10, bsda_alpha=0.5,\n",
        "          kl_weight=8e-4, recon_weight=1.0, use_ori=True, num_epochs=30):\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    ratio = min(bsda_alpha * (epoch / (num_epochs // 2)), bsda_alpha) if use_bsda else 0\n",
        "\n",
        "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        features = model.extract_features(inputs)\n",
        "        y_hat = model.head(features)\n",
        "\n",
        "        if use_bsda:\n",
        "            m, mu, logvar, a_hat = bsda_layer(features, multi=multi)\n",
        "            a_tilde = bsda_layer.calc_a_tilde(features, m, multi=multi)\n",
        "            y_hat_tilde = model.head(a_tilde)\n",
        "\n",
        "            loss_task = criterion(y_hat, labels)\n",
        "            loss_task_tilde = criterion(y_hat_tilde, labels.repeat(multi,))\n",
        "            loss_kl = bsda_layer.calc_kl_loss(mu, logvar)\n",
        "            loss_recon = bsda_layer.calc_recon_loss(features, a_hat, multi)\n",
        "            loss_bsda = kl_weight * loss_kl + recon_weight * loss_recon\n",
        "            loss = loss_task_tilde + loss_bsda\n",
        "            if use_ori:\n",
        "                loss = loss * ratio + loss_task\n",
        "        else:\n",
        "            loss = criterion(y_hat, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(y_hat, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Train Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100*correct/total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "d2a0a7e5-87c0-4fa6-faed-53b6f5e508a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 2188/2188 [02:31<00:00, 14.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5115, Accuracy: 82.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6840, Validation Accuracy: 86.64%\n",
            "Balanced Accuracy: 0.8576\n",
            "New best model saved with Validation loss 0.6840 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 2188/2188 [02:30<00:00, 14.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2995, Accuracy: 91.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5399, Validation Accuracy: 81.81%\n",
            "Balanced Accuracy: 0.8289\n",
            "New best model saved with Validation loss 0.5399 at best_model.pth\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 2188/2188 [02:31<00:00, 14.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2681, Accuracy: 94.06%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4708, Validation Accuracy: 81.46%\n",
            "Balanced Accuracy: 0.8125\n",
            "New best model saved with Validation loss 0.4708 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 2188/2188 [02:31<00:00, 14.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2574, Accuracy: 95.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2587, Validation Accuracy: 91.28%\n",
            "Balanced Accuracy: 0.9096\n",
            "New best model saved with Validation loss 0.2587 at best_model.pth\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 2188/2188 [02:29<00:00, 14.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2533, Accuracy: 96.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3349, Validation Accuracy: 88.24%\n",
            "Balanced Accuracy: 0.8805\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 2188/2188 [02:31<00:00, 14.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2549, Accuracy: 96.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4584, Validation Accuracy: 85.79%\n",
            "Balanced Accuracy: 0.8419\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 2188/2188 [02:31<00:00, 14.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2563, Accuracy: 97.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1033, Validation Accuracy: 96.66%\n",
            "Balanced Accuracy: 0.9654\n",
            "New best model saved with Validation loss 0.1033 at best_model.pth\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 2188/2188 [02:31<00:00, 14.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2615, Accuracy: 97.84%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2011, Validation Accuracy: 93.16%\n",
            "Balanced Accuracy: 0.9274\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 2188/2188 [02:31<00:00, 14.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2654, Accuracy: 98.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1377, Validation Accuracy: 95.31%\n",
            "Balanced Accuracy: 0.9560\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 2188/2188 [02:31<00:00, 14.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2741, Accuracy: 98.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1209, Validation Accuracy: 96.19%\n",
            "Balanced Accuracy: 0.9626\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 2188/2188 [02:31<00:00, 14.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2801, Accuracy: 98.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3943, Validation Accuracy: 88.61%\n",
            "Balanced Accuracy: 0.8763\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 2188/2188 [02:31<00:00, 14.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2891, Accuracy: 98.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0708, Validation Accuracy: 97.75%\n",
            "Balanced Accuracy: 0.9772\n",
            "New best model saved with Validation loss 0.0708 at best_model.pth\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 2188/2188 [02:31<00:00, 14.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2940, Accuracy: 98.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0471, Validation Accuracy: 98.29%\n",
            "Balanced Accuracy: 0.9824\n",
            "New best model saved with Validation loss 0.0471 at best_model.pth\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 2188/2188 [02:31<00:00, 14.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3103, Accuracy: 98.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0444, Validation Accuracy: 98.50%\n",
            "Balanced Accuracy: 0.9839\n",
            "New best model saved with Validation loss 0.0444 at best_model.pth\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 2188/2188 [02:31<00:00, 14.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3156, Accuracy: 99.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1039, Validation Accuracy: 96.75%\n",
            "Balanced Accuracy: 0.9662\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 2188/2188 [02:31<00:00, 14.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3285, Accuracy: 99.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0449, Validation Accuracy: 98.49%\n",
            "Balanced Accuracy: 0.9842\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 2188/2188 [02:31<00:00, 14.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3167, Accuracy: 99.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0451, Validation Accuracy: 98.55%\n",
            "Balanced Accuracy: 0.9854\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 2188/2188 [02:31<00:00, 14.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3106, Accuracy: 99.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0529, Validation Accuracy: 98.34%\n",
            "Balanced Accuracy: 0.9833\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 2188/2188 [02:31<00:00, 14.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3043, Accuracy: 99.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0784, Validation Accuracy: 97.67%\n",
            "Balanced Accuracy: 0.9763\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 2188/2188 [02:30<00:00, 14.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3047, Accuracy: 99.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0338, Validation Accuracy: 98.88%\n",
            "Balanced Accuracy: 0.9888\n",
            "New best model saved with Validation loss 0.0338 at best_model.pth\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 2188/2188 [02:31<00:00, 14.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2942, Accuracy: 99.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0413, Validation Accuracy: 98.74%\n",
            "Balanced Accuracy: 0.9873\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 2188/2188 [02:30<00:00, 14.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2943, Accuracy: 99.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0418, Validation Accuracy: 98.73%\n",
            "Balanced Accuracy: 0.9872\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 2188/2188 [02:31<00:00, 14.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2812, Accuracy: 99.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0290, Validation Accuracy: 99.19%\n",
            "Balanced Accuracy: 0.9921\n",
            "New best model saved with Validation loss 0.0290 at best_model.pth\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 2188/2188 [02:32<00:00, 14.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2886, Accuracy: 99.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0795, Validation Accuracy: 97.69%\n",
            "Balanced Accuracy: 0.9757\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 2188/2188 [02:32<00:00, 14.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2751, Accuracy: 99.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0454, Validation Accuracy: 98.75%\n",
            "Balanced Accuracy: 0.9874\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 2188/2188 [02:32<00:00, 14.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2808, Accuracy: 99.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0411, Validation Accuracy: 98.83%\n",
            "Balanced Accuracy: 0.9876\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 2188/2188 [02:31<00:00, 14.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2697, Accuracy: 99.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1506, Validation Accuracy: 95.92%\n",
            "Balanced Accuracy: 0.9613\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 2188/2188 [02:33<00:00, 14.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2741, Accuracy: 99.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0453, Validation Accuracy: 98.79%\n",
            "Balanced Accuracy: 0.9886\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 2188/2188 [02:31<00:00, 14.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2707, Accuracy: 99.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0498, Validation Accuracy: 98.42%\n",
            "Balanced Accuracy: 0.9840\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 2188/2188 [02:31<00:00, 14.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2640, Accuracy: 99.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0308, Validation Accuracy: 99.09%\n",
            "Balanced Accuracy: 0.9911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "bsda_layer = BSDALayer(feature_dim=512, bsda_lambda=0.8).to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch,\n",
        "          use_bsda=True,\n",
        "          bsda_layer=bsda_layer,\n",
        "          multi=10,\n",
        "          bsda_alpha=0.5,\n",
        "          kl_weight=8e-4,\n",
        "          recon_weight=1.0,\n",
        "          use_ori=True,\n",
        "          num_epochs=num_epochs)\n",
        "\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCGf9fvf2-qk",
        "outputId": "40b72040-12d7-49a5-b1ba-2561e3568dc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "e0587bba-77d9-4687-ead7-5468b763c39b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0308, Test Accuracy: 99.05%\n",
            "Balanced Accuracy: 0.9905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "5e511910-6260-4b9a-a5d2-8620ef530e30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 5.95 ms\n",
            "Standard Deviation: 0.22 ms\n",
            "Maximum Time: 7.87 ms\n",
            "Minimum Time: 5.69 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "6f73993f-7697-47ce-a98f-cd558cbca4a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul        17.57%       2.940ms        40.66%       6.805ms     283.537us       0.000us         0.00%       2.539ms     105.786us            24  \n",
            "                                           aten::linear         0.48%      79.842us        19.77%       3.308ms     194.607us       0.000us         0.00%       1.819ms     107.010us            17  \n",
            "                                               aten::mm         3.59%     601.596us        17.22%       2.882ms     180.094us       1.807ms        38.36%       1.807ms     112.920us            16  \n",
            "                                           aten::conv2d         1.02%     170.933us        10.20%       1.706ms     284.396us       0.000us         0.00%     721.375us     120.229us             6  \n",
            "                                      aten::convolution         0.31%      52.431us         9.17%       1.535ms     255.907us       0.000us         0.00%     721.375us     120.229us             6  \n",
            "                                     aten::_convolution         1.09%     182.323us         8.86%       1.483ms     247.169us       0.000us         0.00%     721.375us     120.229us             6  \n",
            "                                aten::cudnn_convolution         5.91%     989.157us         7.45%       1.248ms     207.927us     706.559us        15.00%     706.559us     117.760us             6  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     679.171us        14.42%     679.171us     169.793us             4  \n",
            "                                              aten::bmm         1.58%     263.797us         1.99%     333.803us      41.725us     568.864us        12.08%     568.864us      71.108us             8  \n",
            "                                       aten::batch_norm         0.74%     123.632us        33.20%       5.556ms     252.551us       0.000us         0.00%     544.160us      24.735us            22  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 16.736ms\n",
            "Self CUDA time total: 4.710ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    val_losses.append(epoch_loss)\n",
        "    val_accuracies.append(accuracy)\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubbBuFrU-GRd",
        "outputId": "f23b97cb-1049-4cc0-d372-03e407561b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:21<00:00, 22.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0308, Test Accuracy: 99.05%\n",
            "Overall - F1: 0.9903, Recall: 0.9905, Precision: 0.9901\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9987, Recall: 0.9994, Precision: 0.9981\n",
            "Class 1 - F1: 0.9991, Recall: 0.9994, Precision: 0.9987\n",
            "Class 2 - F1: 0.9836, Recall: 0.9902, Precision: 0.9771\n",
            "Class 3 - F1: 0.9986, Recall: 0.9988, Precision: 0.9983\n",
            "Class 4 - F1: 0.9876, Recall: 0.9888, Precision: 0.9865\n",
            "Class 5 - F1: 0.9924, Recall: 0.9911, Precision: 0.9936\n",
            "Class 6 - F1: 0.9867, Recall: 0.9894, Precision: 0.9841\n",
            "Class 7 - F1: 0.9760, Recall: 0.9713, Precision: 0.9807\n",
            "Class 8 - F1: 0.9899, Recall: 0.9860, Precision: 0.9939\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "3qaLb5c--H0Q",
        "outputId": "edbcdad2-da1a-4abd-80b1-990ce7c4b826"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "QCHdGKmbuw9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cff85e22-e244-4e5a-811f-d01175de922d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved to HoViT22_flip_bsda.pth\n"
          ]
        }
      ],
      "source": [
        "save_path = \"HoViT22_flip_bsda.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model weights saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2NMYNeV0Ly5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}