{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "eccafb48-460d-45aa-be2d-0c523bcf472b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=93c79d59cec91b45e4608426da61fe667dd35136b0cf65d6cd81b8d77ef5fadd\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "64f42bdc-075b-43cc-ec60-52971d66ac76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-24 01:55:58--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.43.25, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-03-24 01:55:59--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  5.02MB/s    in 36m 49s \n",
            "\n",
            "2025-03-24 02:32:48 (5.05 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "15fdc34e-2b29-4249-ca9f-10463b10ea92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "31ce70a9-c384-4a64-b7f0-8ae7fa58c404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "f427e1da-9b80-4d0a-e8bd-b37e30abf022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "4d956392-79b3-4315-ad82-952acb78e0c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.color import rgb2hed, hed2rgb\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "id": "_XOsreNaIoSQ"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# H:색조, S:채도, V:밝기\n",
        "class HSVShiftTransform:\n",
        "    def __init__(self, h_shift=10, s_shift=20, v_shift=30):\n",
        "        self.h_shift = h_shift\n",
        "        self.s_shift = s_shift\n",
        "        self.v_shift = v_shift\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = np.array(img)\n",
        "\n",
        "        # OpenCV expects BGR, so convert\n",
        "        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV).astype(np.int32)\n",
        "        hsv[:, :, 0] = (hsv[:, :, 0] + self.h_shift) % 180\n",
        "        hsv[:, :, 1] = np.clip(hsv[:, :, 1] + self.s_shift, 0, 255)\n",
        "        hsv[:, :, 2] = np.clip(hsv[:, :, 2] + self.v_shift, 0, 255)\n",
        "        hsv = hsv.astype(np.uint8)\n",
        "        shifted = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "\n",
        "        # np.array → PIL.Image\n",
        "        return Image.fromarray(shifted)"
      ],
      "metadata": {
        "id": "l7SJ75QtHrxa"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HEDShiftTransform:\n",
        "    def __init__(self, h_shift=0.05, e_shift=0.05, d_shift=0.05):\n",
        "        self.h_shift = h_shift\n",
        "        self.e_shift = e_shift\n",
        "        self.d_shift = d_shift\n",
        "\n",
        "    def __call__(self, img):\n",
        "        # 1. PIL.Image → NumPy (RGB), float32, 0~1 정규화\n",
        "        img = np.array(img).astype(np.float32) / 255.0\n",
        "\n",
        "        # 2. RGB → HED 색공간 변환\n",
        "        hed = rgb2hed(img)\n",
        "\n",
        "        # 3. 염색 성분별로 shift 적용\n",
        "        hed[:, :, 0] += self.h_shift  # Hematoxylin\n",
        "        hed[:, :, 1] += self.e_shift  # Eosin\n",
        "        hed[:, :, 2] += self.d_shift  # DAB\n",
        "\n",
        "        # 4. HED → RGB 복원\n",
        "        rgb = hed2rgb(hed)\n",
        "\n",
        "        # 5. 값 범위 정리 및 타입 변환\n",
        "        rgb = np.clip(rgb, 0, 1)                # 0~1 범위로 제한\n",
        "        rgb = (rgb * 255).astype(np.uint8)      # 다시 uint8로 변환\n",
        "\n",
        "        # 6. NumPy → PIL.Image 변환\n",
        "        return Image.fromarray(rgb)"
      ],
      "metadata": {
        "id": "nSBEWwNZKDJi"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    #transforms.ToTensor(),\n",
        "    #HSVShiftTransform(),\n",
        "    #HEDShiftTransform(),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.01),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "zja84HaiVhoh"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "YDaTgqOuPUej"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "train_dataset_full = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "test_dataset_full = datasets.ImageFolder(root=train_dir, transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "train_data = Subset(train_dataset_full, load_train_idx)\n",
        "val_data = Subset(test_dataset_full, load_val_idx)\n",
        "test_data = Subset(test_dataset_full, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "8311b8ca-8ee7-4c9c-a726-a40a292cb61f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "f982608e-a0cc-4335-cbf0-103c3bff3ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:20<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.7549, Train Accuracy: 73.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3857, Validation Accuracy: 86.05%\n",
            "Balanced Accuracy: 0.8541\n",
            "New best model saved with Validation loss 0.3857 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:21<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3552, Train Accuracy: 87.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5861, Validation Accuracy: 82.65%\n",
            "Balanced Accuracy: 0.8162\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:20<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2493, Train Accuracy: 91.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2560, Validation Accuracy: 91.04%\n",
            "Balanced Accuracy: 0.9066\n",
            "New best model saved with Validation loss 0.2560 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:22<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1968, Train Accuracy: 93.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5034, Validation Accuracy: 83.47%\n",
            "Balanced Accuracy: 0.8171\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:21<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1566, Train Accuracy: 94.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1873, Validation Accuracy: 93.93%\n",
            "Balanced Accuracy: 0.9351\n",
            "New best model saved with Validation loss 0.1873 at best_model.pth\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:21<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1238, Train Accuracy: 95.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6587, Validation Accuracy: 84.12%\n",
            "Balanced Accuracy: 0.8272\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:19<00:00,  3.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1023, Train Accuracy: 96.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2057, Validation Accuracy: 93.18%\n",
            "Balanced Accuracy: 0.9262\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:16<00:00,  3.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0810, Train Accuracy: 97.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1183, Validation Accuracy: 96.10%\n",
            "Balanced Accuracy: 0.9589\n",
            "New best model saved with Validation loss 0.1183 at best_model.pth\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:13<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0685, Train Accuracy: 97.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2490, Validation Accuracy: 93.00%\n",
            "Balanced Accuracy: 0.9275\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:14<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0559, Train Accuracy: 98.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.2063, Validation Accuracy: 77.04%\n",
            "Balanced Accuracy: 0.7424\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:14<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0460, Train Accuracy: 98.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1622, Validation Accuracy: 95.13%\n",
            "Balanced Accuracy: 0.9490\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:15<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0427, Train Accuracy: 98.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3245, Validation Accuracy: 91.51%\n",
            "Balanced Accuracy: 0.9074\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:13<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0372, Train Accuracy: 98.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0957, Validation Accuracy: 97.09%\n",
            "Balanced Accuracy: 0.9705\n",
            "New best model saved with Validation loss 0.0957 at best_model.pth\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:14<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0312, Train Accuracy: 98.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1547, Validation Accuracy: 95.87%\n",
            "Balanced Accuracy: 0.9555\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:14<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0282, Train Accuracy: 99.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1308, Validation Accuracy: 96.51%\n",
            "Balanced Accuracy: 0.9667\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:15<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0264, Train Accuracy: 99.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0575, Validation Accuracy: 98.33%\n",
            "Balanced Accuracy: 0.9834\n",
            "New best model saved with Validation loss 0.0575 at best_model.pth\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:15<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0245, Train Accuracy: 99.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3294, Validation Accuracy: 91.56%\n",
            "Balanced Accuracy: 0.9189\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:14<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0210, Train Accuracy: 99.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0649, Validation Accuracy: 98.22%\n",
            "Balanced Accuracy: 0.9822\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:14<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0200, Train Accuracy: 99.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0980, Validation Accuracy: 97.39%\n",
            "Balanced Accuracy: 0.9738\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:18<00:00,  3.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0195, Train Accuracy: 99.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0844, Validation Accuracy: 97.90%\n",
            "Balanced Accuracy: 0.9801\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:18<00:00,  3.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0195, Train Accuracy: 99.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0715, Validation Accuracy: 98.14%\n",
            "Balanced Accuracy: 0.9815\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:19<00:00,  3.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0165, Train Accuracy: 99.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0890, Validation Accuracy: 97.81%\n",
            "Balanced Accuracy: 0.9789\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:22<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0147, Train Accuracy: 99.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0694, Validation Accuracy: 98.19%\n",
            "Balanced Accuracy: 0.9830\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:20<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0158, Train Accuracy: 99.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4425, Validation Accuracy: 90.87%\n",
            "Balanced Accuracy: 0.9079\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:20<00:00,  3.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0134, Train Accuracy: 99.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0558, Validation Accuracy: 98.59%\n",
            "Balanced Accuracy: 0.9861\n",
            "New best model saved with Validation loss 0.0558 at best_model.pth\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:20<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0118, Train Accuracy: 99.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0879, Validation Accuracy: 97.65%\n",
            "Balanced Accuracy: 0.9768\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:18<00:00,  3.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0130, Train Accuracy: 99.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0702, Validation Accuracy: 98.18%\n",
            "Balanced Accuracy: 0.9816\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:18<00:00,  3.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0114, Train Accuracy: 99.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1638, Validation Accuracy: 95.07%\n",
            "Balanced Accuracy: 0.9485\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:19<00:00,  3.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0106, Train Accuracy: 99.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0652, Validation Accuracy: 98.44%\n",
            "Balanced Accuracy: 0.9844\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [09:17<00:00,  3.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0106, Train Accuracy: 99.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0668, Validation Accuracy: 98.45%\n",
            "Balanced Accuracy: 0.9840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "825b1235-52f1-4dc6-f172-6f09413709ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:23<00:00, 20.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0862, Test Accuracy: 98.03%\n",
            "Balanced Accuracy: 0.9800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "22b419dc-b75a-42da-f50d-66f2dbf4522c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 10.58 ms\n",
            "Standard Deviation: 0.47 ms\n",
            "Maximum Time: 13.55 ms\n",
            "Minimum Time: 9.95 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "9ae284e6-2a6c-4768-aa74-19ac470263ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         6.01%       1.289ms        36.88%       7.903ms     164.642us       0.000us         0.00%       5.050ms     105.203us            48  \n",
            "                                           aten::linear         0.90%     193.172us        25.65%       5.496ms     161.654us       0.000us         0.00%       3.619ms     106.444us            34  \n",
            "                                               aten::mm         5.25%       1.125ms        21.75%       4.662ms     145.680us       3.595ms        43.36%       3.595ms     112.355us            32  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.353ms        16.32%       1.353ms     169.123us             8  \n",
            "                                              aten::bmm         2.27%     485.483us         2.87%     615.744us      38.484us       1.133ms        13.67%       1.133ms      70.840us            16  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     988.089us        11.92%     988.089us     123.511us             8  \n",
            "                                       aten::batch_norm         1.10%     235.932us        31.28%       6.703ms     171.869us       0.000us         0.00%     864.635us      22.170us            39  \n",
            "                           aten::_batch_norm_impl_index        10.94%       2.344ms        30.18%       6.467ms     165.820us       0.000us         0.00%     864.635us      22.170us            39  \n",
            "                                            aten::copy_         3.80%     815.128us         8.99%       1.927ms      23.495us     798.590us         9.63%     798.590us       9.739us            82  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     772.605us         9.32%     772.605us      96.576us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 21.431ms\n",
            "Self CUDA time total: 8.291ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "xc2tPigjv6Is"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"HoViT44_withAug_7Ktest.pth\")\n",
        "#model.load_state_dict(torch.load(\"HoViT44_withAug_7Ktest.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbSpMMWGk3bf",
        "outputId": "2dbec2fb-b34a-45a8-92f6-1622a7a08ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-24 08:01:32--  https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.43.25, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 800276929 (763M) [application/octet-stream]\n",
            "Saving to: ‘CRC-VAL-HE-7K.zip’\n",
            "\n",
            "CRC-VAL-HE-7K.zip   100%[===================>] 763.20M  2.71MB/s    in 4m 55s  \n",
            "\n",
            "2025-03-24 08:06:29 (2.58 MB/s) - ‘CRC-VAL-HE-7K.zip’ saved [800276929/800276929]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O CRC-VAL-HE-7K.zip https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
        "!unzip -qq CRC-VAL-HE-7K.zip -d val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "rldaXFNXpT4r"
      },
      "outputs": [],
      "source": [
        "test_7k_dir = './val/CRC-VAL-HE-7K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "6oLIYyRG9dVi"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "Belqw8QytnZL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "test7k_dataset = datasets.ImageFolder(root=test_7k_dir, transform=test_transform)\n",
        "test7k_dataloader = DataLoader(test7k_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2y3cywDpjUQ",
        "outputId": "e6a7a5c4-515f-4b4f-ff7e-0deae19b674e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 225/225 [00:11<00:00, 19.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.4891, Test Accuracy: 90.71%\n",
            "Overall - F1: 0.8779, Recall: 0.8893, Precision: 0.8831\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9139, Recall: 0.8490, Precision: 0.9895\n",
            "Class 1 - F1: 0.9641, Recall: 1.0000, Precision: 0.9308\n",
            "Class 2 - F1: 0.8657, Recall: 0.9794, Precision: 0.7757\n",
            "Class 3 - F1: 0.9646, Recall: 0.9874, Precision: 0.9428\n",
            "Class 4 - F1: 0.9603, Recall: 0.9585, Precision: 0.9622\n",
            "Class 5 - F1: 0.7441, Recall: 0.8497, Precision: 0.6618\n",
            "Class 6 - F1: 0.9309, Recall: 0.9541, Precision: 0.9087\n",
            "Class 7 - F1: 0.6018, Recall: 0.4774, Precision: 0.8138\n",
            "Class 8 - F1: 0.9555, Recall: 0.9481, Precision: 0.9629\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test7k_dataloader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "p4pYjMPUpy2m",
        "outputId": "957398f3-f773-402b-d680-1eff5ca84f3f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}