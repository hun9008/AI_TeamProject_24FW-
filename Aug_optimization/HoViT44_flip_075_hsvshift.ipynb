{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "8bed0447-a0a7-4da6-be32-82c3aa0f1925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=3a94d93bd5ad5d8e1a0ed7122abaf309a9c807eb35a134ffd06c25c9aaf6f6bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "4707a0b8-f5c6-468a-c8df-39b5e8ea22e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-26 06:13:22--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.45.92, 188.185.43.25, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-03-26 06:13:22--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  25.8MB/s    in 7m 59s  \n",
            "\n",
            "2025-03-26 06:21:22 (23.3 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d051ba8-e1df-408c-f529-d990f740da5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNpMsNYAzLDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19ddd653-c578-4780-e1be-cedc5998c89e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61e0df6-1d91-4c93-ad5c-742e8e0ad91b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XJWJO0JTIMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "423712e0-7e9b-400e-e355-c308e3959fd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation\n",
        "aug_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.75),\n",
        "    transforms.RandomVerticalFlip(p=0.75),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.01),\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "zja84HaiVhoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "#train_data = Subset(dataset, load_train_idx)\n",
        "#val_data = Subset(dataset, load_val_idx)\n",
        "#test_data = Subset(dataset, load_test_idx)\n",
        "\n",
        "dataset_train = datasets.ImageFolder(root=train_dir, transform=aug_transform)\n",
        "dataset_eval = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "\n",
        "train_data = Subset(dataset_train, load_train_idx)\n",
        "val_data = Subset(dataset_eval, load_val_idx)\n",
        "test_data = Subset(dataset_eval, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8inM-bBnztEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00073f2d-d3b7-475f-d2c1-fa0b49e8c29c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "VXsiOTOO0GGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55243bb-49a9-4502-9744-8b97e61533f4"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:24<00:00,  4.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7849, Train Accuracy: 71.98%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.08it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.3820, Validation Accuracy: 86.41%\n",
            "Balanced Accuracy: 0.8587\n",
            "New best model saved with Validation loss 0.3820 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:18<00:00,  4.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3848, Train Accuracy: 86.44%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.10it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.3936, Validation Accuracy: 86.23%\n",
            "Balanced Accuracy: 0.8544\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:16<00:00,  5.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2636, Train Accuracy: 91.00%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.11it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.2448, Validation Accuracy: 91.39%\n",
            "Balanced Accuracy: 0.9108\n",
            "New best model saved with Validation loss 0.2448 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:17<00:00,  5.00it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2126, Train Accuracy: 92.78%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.20it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0173, Validation Accuracy: 71.53%\n",
            "Balanced Accuracy: 0.6921\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:19<00:00,  4.98it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1741, Train Accuracy: 94.04%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.28it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1334, Validation Accuracy: 95.65%\n",
            "Balanced Accuracy: 0.9558\n",
            "New best model saved with Validation loss 0.1334 at best_model.pth\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:20<00:00,  4.97it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1440, Train Accuracy: 95.13%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.17it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1087, Validation Accuracy: 96.41%\n",
            "Balanced Accuracy: 0.9625\n",
            "New best model saved with Validation loss 0.1087 at best_model.pth\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:20<00:00,  4.96it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1193, Train Accuracy: 95.95%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.0928, Validation Accuracy: 96.94%\n",
            "Balanced Accuracy: 0.9691\n",
            "New best model saved with Validation loss 0.0928 at best_model.pth\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:20<00:00,  4.97it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1000, Train Accuracy: 96.60%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1685, Validation Accuracy: 94.74%\n",
            "Balanced Accuracy: 0.9498\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:19<00:00,  4.98it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0876, Train Accuracy: 96.96%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.17it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1096, Validation Accuracy: 96.41%\n",
            "Balanced Accuracy: 0.9646\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:18<00:00,  4.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0719, Train Accuracy: 97.51%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1835, Validation Accuracy: 94.46%\n",
            "Balanced Accuracy: 0.9428\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:20<00:00,  4.97it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0653, Train Accuracy: 97.74%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.10it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1031, Validation Accuracy: 96.33%\n",
            "Balanced Accuracy: 0.9601\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:20<00:00,  4.96it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0559, Train Accuracy: 98.09%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.2407, Validation Accuracy: 94.41%\n",
            "Balanced Accuracy: 0.9357\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:20<00:00,  4.97it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0513, Train Accuracy: 98.24%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1226, Validation Accuracy: 96.03%\n",
            "Balanced Accuracy: 0.9552\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:18<00:00,  4.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0454, Train Accuracy: 98.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0420, Validation Accuracy: 98.61%\n",
            "Balanced Accuracy: 0.9857\n",
            "New best model saved with Validation loss 0.0420 at best_model.pth\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:20<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0427, Train Accuracy: 98.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1782, Validation Accuracy: 94.61%\n",
            "Balanced Accuracy: 0.9432\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:19<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0377, Train Accuracy: 98.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0646, Validation Accuracy: 97.89%\n",
            "Balanced Accuracy: 0.9795\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:19<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0340, Train Accuracy: 98.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0409, Validation Accuracy: 98.67%\n",
            "Balanced Accuracy: 0.9863\n",
            "New best model saved with Validation loss 0.0409 at best_model.pth\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:19<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0320, Train Accuracy: 98.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0682, Validation Accuracy: 97.54%\n",
            "Balanced Accuracy: 0.9737\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:20<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0297, Train Accuracy: 98.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0401, Validation Accuracy: 98.79%\n",
            "Balanced Accuracy: 0.9877\n",
            "New best model saved with Validation loss 0.0401 at best_model.pth\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:20<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0275, Train Accuracy: 99.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0585, Validation Accuracy: 98.15%\n",
            "Balanced Accuracy: 0.9810\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:19<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0254, Train Accuracy: 99.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0326, Validation Accuracy: 99.07%\n",
            "Balanced Accuracy: 0.9905\n",
            "New best model saved with Validation loss 0.0326 at best_model.pth\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:19<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0254, Train Accuracy: 99.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0583, Validation Accuracy: 98.29%\n",
            "Balanced Accuracy: 0.9823\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:19<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0228, Train Accuracy: 99.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0441, Validation Accuracy: 98.69%\n",
            "Balanced Accuracy: 0.9878\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:18<00:00,  4.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0206, Train Accuracy: 99.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0466, Validation Accuracy: 98.50%\n",
            "Balanced Accuracy: 0.9847\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:19<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0208, Train Accuracy: 99.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1308, Validation Accuracy: 96.17%\n",
            "Balanced Accuracy: 0.9583\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:19<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0200, Train Accuracy: 99.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0964, Validation Accuracy: 97.29%\n",
            "Balanced Accuracy: 0.9721\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:19<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0171, Train Accuracy: 99.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0355, Validation Accuracy: 98.96%\n",
            "Balanced Accuracy: 0.9898\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:26<00:00,  4.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0170, Train Accuracy: 99.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0459, Validation Accuracy: 98.60%\n",
            "Balanced Accuracy: 0.9862\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:24<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0172, Train Accuracy: 99.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0552, Validation Accuracy: 98.42%\n",
            "Balanced Accuracy: 0.9848\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [07:19<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0157, Train Accuracy: 99.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0372, Validation Accuracy: 98.99%\n",
            "Balanced Accuracy: 0.9895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ],
      "metadata": {
        "id": "4wDDP-iS8z1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5857315-c0c9-4f97-d40d-58970d8ebd16"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yq3Yxnau6V3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3b4948-1f51-433d-825d-92cf02d30467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:22<00:00, 20.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0380, Test Accuracy: 98.87%\n",
            "Balanced Accuracy: 0.9885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "1b3b4be9-7ce2-42b0-9aba-e72a45268f88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 9.86 ms\n",
            "Standard Deviation: 0.23 ms\n",
            "Maximum Time: 11.67 ms\n",
            "Minimum Time: 9.49 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "b91a6189-29bd-4967-d250-1009be350f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         6.86%       1.261ms        30.58%       5.624ms     117.160us       0.000us         0.00%       5.071ms     105.643us            48  \n",
            "                                           aten::linear         1.08%     199.262us        17.89%       3.289ms      96.736us       0.000us         0.00%       3.639ms     107.016us            34  \n",
            "                                               aten::mm         6.52%       1.200ms        13.43%       2.470ms      77.182us       3.616ms        43.65%       3.616ms     112.989us            32  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.359ms        16.41%       1.359ms     169.928us             8  \n",
            "                                              aten::bmm         2.64%     486.095us         3.33%     612.966us      38.310us       1.134ms        13.69%       1.134ms      70.888us            16  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     987.873us        11.93%     987.873us     123.484us             8  \n",
            "                                       aten::batch_norm         1.42%     260.768us        33.29%       6.121ms     156.958us       0.000us         0.00%     852.803us      21.867us            39  \n",
            "                           aten::_batch_norm_impl_index         9.37%       1.723ms        31.87%       5.861ms     150.272us       0.000us         0.00%     852.803us      21.867us            39  \n",
            "                                            aten::copy_         4.31%     791.919us        10.65%       1.958ms      23.879us     794.531us         9.59%     794.531us       9.689us            82  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     774.690us         9.35%     774.690us      96.836us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 18.388ms\n",
            "Self CUDA time total: 8.284ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4UchJcz1N6K",
        "outputId": "a22df1ef-fdb8-40f4-89ce-4009ed80cb65"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:23<00:00, 20.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0380, Test Accuracy: 98.87%\n",
            "Overall - F1: 0.9886, Recall: 0.9885, Precision: 0.9887\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9978, Recall: 0.9987, Precision: 0.9968\n",
            "Class 1 - F1: 0.9981, Recall: 0.9987, Precision: 0.9975\n",
            "Class 2 - F1: 0.9858, Recall: 0.9838, Precision: 0.9878\n",
            "Class 3 - F1: 0.9983, Recall: 0.9977, Precision: 0.9988\n",
            "Class 4 - F1: 0.9877, Recall: 0.9925, Precision: 0.9829\n",
            "Class 5 - F1: 0.9909, Recall: 0.9887, Precision: 0.9931\n",
            "Class 6 - F1: 0.9855, Recall: 0.9840, Precision: 0.9870\n",
            "Class 7 - F1: 0.9675, Recall: 0.9598, Precision: 0.9754\n",
            "Class 8 - F1: 0.9859, Recall: 0.9925, Precision: 0.9793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "ZLcoSxfe1Qbt",
        "outputId": "edf9a4a0-b7a1-42b8-df4c-8010bb3f5bef"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABTMAAAGkCAYAAADt4rEnAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAchRJREFUeJzt3XdUFNf/xvEHiIC9YAEUFStW7F2xoVhi7w1bjMbee++994ZGY40tmmY01hg7dhMTv0nsSrMhRZbfH+jqCljyU3DC+3XOnhxm74x38uHOnX2YmbWKjIyMFAAAAAAAAAB85KzjuwMAAAAAAAAA8DYIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAACA/5iKFSuqV69e5p+zZs2qWbNmxVt/3hfCTMTqyJEjsrGxUa1atSyW//XXX7KysjK/kidPrnz58qlr1666cuWKRVsfHx+lSpUqDnuNmLRt29aiZg4ODvLy8tLZs2ejtf38889lY2OjTZs2xbitP/74Q+3atVOmTJlkZ2cnV1dXNW/eXCdOnDC3sbKy0rZt28w/h4eHq3nz5sqYMaPOnz//3vcPr/dy/RMlSqQMGTLI09NTK1askMlkMrfLmjWrxe/J89ekSZMkRR/7tra2ypEjh8aNG6fIyMj42j3Eom3btqpXr54kKTQ0VPny5VOnTp2itRswYIBcXV318OFD+fj4yMrKSnny5InWbtOmTbKyslLWrFk/cM/xtp6P7c6dO0d7r2vXrrKyslLbtm0lRT+RfS6mefrBgwcaOnSo3NzcZG9vL0dHR1WtWlVbtmxhrMezD1Hz4OBgDR48WNmzZ5e9vb3SpUsnDw8Pbd++/QPtBV71vK7P59vntm3bJisrK/PPERERmjlzpgoUKCB7e3ulTp1aNWrU0OHDhy3We34st7KykrW1tZycnNS0aVP9888/Fu0qVqwY478rSbVq1ZKVlZVGjRr1/nYUb+XevXvq0qWLMmfOLDs7Ozk6Oqp69eoaP358jOdpL7/27dv31vVH/HhTDUeNGqV9+/bJyspKQUFB0dZ/NYh6vt6vv/5q0S40NFQODg7m3wt8ONeuXVP79u3l7OwsW1tbZcmSRT179pS/v398d+0/jTATsVq+fLm6d++uAwcO6ObNm9He/+mnn3Tr1i2dOXNGEyZM0KVLl+Tu7q49e/bEQ2/xJl5eXrp165Zu3bqlPXv26JNPPlHt2rUt2gQHB2v9+vUaMGCAVqxYEW0bJ06cUNGiRfX7779r8eLFunjxorZu3So3Nzf17ds3xn83ODhYderU0fHjx3Xo0CHlz5//g+wfXu95/f/66y999913qlSpknr27KnatWvr6dOn5nZjxowx/548f3Xv3t1iW8/H/pUrVzR69GiNHz8+xt8XfDzs7Oy0evVq+fj46IcffjAv//XXXzVz5kz5+PgoefLkkqSkSZPq7t27OnLkiMU2li9frsyZM8dpv/FmLi4uWr9+vZ48eWJeFhISoq+++upf1SsoKEhlypTR6tWrNXjwYJ06dUoHDhxQ06ZNNWDAAN2/f/99dh//wvuueefOnbVlyxbNnTtXly9f1vfff69GjRrxISyO2dvba/LkyQoMDIzx/cjISDVr1kxjxoxRz549denSJe3bt08uLi6qWLGixR+RJSlFihS6deuWbty4oa+//lq//fabGjduHG27Li4u8vHxsVh248YN7dmzR05OTu9r9/AOGjZsqNOnT2vVqlX6/ffftWPHDlWsWFEFChSwOD9r0qSJxfn9rVu3VKZMGUlvX3/EvZfrNWvWLHOtnr/69ev3ztt0cXHRypUrLZZt3bpVyZIle1/dRiyuXr2qYsWK6cqVK1q3bp3++OMPLVq0SHv27FHp0qUVEBDwwf7t8PDwD7ZtIyDMRIwePXqkDRs2qEuXLqpVq1a0kxxJcnBwkKOjo7Jly6a6devqp59+UsmSJdWhQwdFRETEfafxWs//suvo6KhChQpp0KBBunbtmu7du2dus2nTJuXNm1eDBg3SgQMHdO3aNfN7kZGRatu2rXLmzKmDBw+qVq1ayp49uwoVKqSRI0fGeAVHUFCQPD09dfPmTR06dEiurq5xsq+I7nn9M2bMqCJFimjIkCHavn27vvvuO4vxnTx5cvPvyfNX0qRJLbb1fOxnyZJFLVu2VNmyZXXq1Kk43iO8q6JFi2ro0KHq0KGDgoKCFBISonbt2ql79+7y8PAwt/vkk0/UokULi4D6+vXr2rdvn1q0aBEfXcdrFClSRC4uLtqyZYt52ZYtW5Q5c2YVLlz4nbc3ZMgQ/fXXXzp69Ki8vb2VN29e5cqVS5999pl8fX35YPQReN8137Fjh4YMGaKaNWsqa9asKlq0qLp376727du/z27jDapWrSpHR0dNnDgxxvc3btyozZs3a/Xq1erYsaNcXV3l7u6uJUuWqE6dOurYsaMeP35sbm9lZSVHR0c5OTmpTJky6tChg44dO6YHDx5YbLd27dry8/OzuLpz1apVqlatmtKnT/9hdhaxCgoK0sGDBzV58mRVqlRJWbJkUYkSJTR48GDVqVPH4vwsceLEFuf3jo6OsrW1lfT29Ufce7leKVOmNNfq+evfzLPe3t7R/si1YsUKeXt7v8+uIwZdu3aVra2tfvzxR3l4eChz5syqUaOGfvrpJ924cUNDhw7VkCFDVLJkyWjruru7a8yYMeafly1bpjx58sje3l5ubm5asGCB+b3nd8ht2LBBHh4esre319q1a+Xv72++AzJJkiQqUKCA1q1bFyf7Ht8IMxGjjRs3ys3NTblz51arVq20YsWKN95aZm1trZ49e+rvv//WyZMn46in+DcePXqkNWvWKEeOHHJwcDAvX758uVq1aqWUKVOqRo0aFiGXr6+vLly4oL59+8raOvqh49XbFG/fvm0OSPbv3y9HR8cPsi/49ypXrix3d3eLD8Tv6sSJEzp58mSMEzQ+PkOHDpWjo6N69OihYcOGycrKShMmTIjWrn379tq4caOCg4MlRd2y6OXlpQwZMsR1l/EW2rdvb3FFxooVK9SuXbt33o7JZNL69evVsmVLOTs7R3s/WbJk+uSTT/5ffcX78b5qLkV9sP7222/18OHD99U9/As2NjaaMGGC5s6dq+vXr0d7/6uvvlKuXLn06aefRnuvb9++8vf31+7du2Pc9t27d7V161bZ2NjIxsbG4j1bW1u1bNnS4vfJx8eHMDueJEuWTMmSJdO2bdsUGhr6Xrb5uvrjv6Fo0aLKmjWrvv76a0nSP//8owMHDqh169bx3LP/toCAAP3www/64osvlDhxYov3HB0d1bJlS23YsEEtW7bUsWPH9Oeff5rfv3Dhgs6ePWu+UGDt2rUaMWKExo8fr0uXLmnChAkaPny4Vq1aZbHdQYMGma/Or169ukJCQlS0aFHt2rVL58+fV6dOndS6dWsdO3bsw/8PiGeEmYjR81BLiro99f79+9q/f/8b13Nzc5MU9ZcDfFx27txpPkFKnjy5duzYoQ0bNpiDyStXrujXX39V06ZNJUmtWrXSypUrzSH28+ehPq/xm/Ts2VNhYWHavXs3z039iLm5uVmM14EDB5p/T56/Dh48aLFOmTJllCxZMtna2qp48eJq0qSJ2rRpE8c9x7/xySefaPXq1dq0aZPmzp2r1atXy97ePlq7woULK1u2bNq8ebMiIyP5YPuRa9WqlQ4dOqS///5bf//9tw4fPmyew9+Fn5+fAgMD3/o4j/jzvmouSUuWLNEvv/wiBwcHFS9eXL179472DEbEjfr165vveHnV77//HuPzjCWZl//+++/mZffv31eyZMmUNGlSZciQQT///LO6du0a7W4L6cUfsB4/fqwDBw7o/v370R5FhLjxySefyMfHR6tWrVKqVKlUtmxZDRkyJMbn3L/Ou9Qf/w3t27c331Xj4+OjmjVrKl26dPHcq/+2K1euKDIy8rXH5sDAQKVLl07u7u766quvzO+tXbtWJUuWVI4cOSRJI0eO1PTp09WgQQO5urqqQYMG6t27txYvXmyxzV69epnbODk5KWPGjOrXr58KFSqkbNmyqXv37vLy8tLGjRs/3I5/JAgzEc1vv/2mY8eOqXnz5pKiJtWmTZtq+fLlb1z3efD18sPK8XGoVKmSfH195evrq2PHjql69eqqUaOG/v77b0lRV3VUr15dadOmlSTVrFlT9+/f1969eyXpnb/0oXbt2uZna+LjFRkZaTFe+/fvb/49ef4qVqyYxTobNmyQr6+vzpw5o40bN2r79u0aNGhQXHcd/1LevHnVsGFDeXp6Rqvty55f+bV//349fvxYNWvWjMNe4l2kS5fO/EiYlStXqlatWuZj+bvgy32M433VXJIqVKigq1evas+ePWrUqJEuXLig8uXLa+zYse+513gbkydP1qpVq3Tp0qVo773LGE2ePLl8fX114sQJTZ8+XUWKFNH48eNjbOvu7q6cOXNq8+bNWrFihVq3bs1V2PGoYcOGunnzpnbs2CEvLy/t27dPRYoUifGxX7F5l/rjv6FVq1Y6cuSIrl69yh+h49jbHJtbtmxpDjMjIyO1bt06tWzZUpL0+PFj/fnnn+rQoYPFBSXjxo2zuJpTUrRz94iICI0dO1YFChRQmjRplCxZMv3www8J4gu/mKUQzfLly/X06VOLW8wiIyNlZ2enefPmvXbd5ydePBvx45M0aVLzX36kqGdypEyZUkuXLtXo0aO1atUq3b592+LkNSIiQitWrFCVKlWUK1cuSdLly5ff6plcrVu3Vp06ddS+fXtFRkaqT58+73+n8P926dIli/GaNm1ai9+TmLi4uJjb5MmTR3/++aeGDx+uUaNGxXiVHz4+n3zyyRs/qLZs2VIDBgzQqFGj+GBrAO3bt1e3bt0kSfPnz4/2fooUKWL88p6goCClTJlSUlRAlipVKl2+fPnDdhbvxfuo+XOJEiVS+fLlVb58eQ0cOFDjxo3TmDFjNHDgQPMz+BA3KlSooOrVq2vw4MHmb6aXpFy5csUYcEovzr+fn6tJUY9/enWu7tKli7788ssYt9G+fXvNnz9fFy9eTBC3J37s7O3t5enpKU9PTw0fPlwdO3bUyJEjLX4nXudd64+PS4oUKSRFXWH76h1uMR3Dpahn2teuXVsdOnRQSEiIatSoweNDPrAcOXLIyspKly5dUv369aO9f+nSJaVOnVrp0qVT8+bNNXDgQJ06dUpPnjzRtWvXzHdEPnr0SJK0dOnSaI/uevXREK9eXT116lTNnj1bs2bNUoECBZQ0aVL16tVLYWFh73NXP0pcmQkLT58+1erVqzV9+nSLK7POnDkjZ2fn1z5M1mQyac6cOXJ1df1XD6BH3LKyspK1tbWePHliflbW6dOnLeq+bt06bdmyRUFBQSpUqJDy5s2r6dOny2QyRdteUFBQtGXe3t7y8fHRgAEDNG3atDjYK7yLvXv36ty5c2rYsOH/azs2NjZ6+vRpgpg0E5I0adKoTp062r9/P3/dNwAvLy+FhYUpPDxc1atXj/Z+7ty5Y/yirlOnTpkDEGtrazVr1kxr167VzZs3o7V99OiRnj59+v47j3/lfdQ8Nnnz5tXTp08VEhLy3vqLtzdp0iR98803OnLkiHlZs2bNdOXKFX3zzTfR2k+fPl0ODg7y9PSMdZuDBg3Shg0bYv3CvhYtWujcuXPKnz+/8ubN+//fCbxXefPmtfiCp3f1pvrj45IzZ05ZW1tH+x6Kq1ev6v79+7Eew9u3b699+/apTZs2PB81Djw/7i5YsMDiy5ekqO+PWLt2rZo2bSorKytlypRJHh4eWrt2rdauXStPT0/zl6xlyJBBzs7Ounr1qnLkyGHxetNFYocPH1bdunXVqlUrubu7K1u2bBaPHPkv4zILWNi5c6cCAwPVoUOHaH/xadiwoZYvXy4vLy9Jkr+/v27fvq3g4GCdP39es2bN0rFjx7Rr1y4Onh+h0NBQ3b59W5IUGBioefPm6dGjR/r00081a9Ys1apVS+7u7hbr5M2bV71799batWvVtWtXrVy5UlWrVlX58uU1dOhQubm56dGjR/rmm2/0448/xvhc1datW8va2lre3t6KjIxU//7942R/Yel5/SMiInTnzh19//33mjhxomrXrm3xvMuHDx+af0+eS5IkifkvxNKLsf/06VOdO3dOs2fPVqVKlSza4ONw//59+fr6Wix7+Uu/3sTHx0cLFix4p3UQP2xsbMxXZ8U0B3fp0kXz5s1Tjx491LFjR9nZ2WnXrl1at26dRTgyfvx47du3TyVLltT48eNVrFgxJUqUSAcPHtTEiRN1/PhxnoP8kXhfNa9YsaKaN2+uYsWKycHBQRcvXtSQIUM4rsejAgUKqGXLlpozZ455WbNmzbRp0yZ5e3tr6tSpqlKlih48eKD58+drx44d2rRp02ufh+ji4qL69etrxIgR2rlzZ7T3U6dOrVu3bilRokQfZJ/wdvz9/dW4cWO1b99eBQsWVPLkyXXixAlNmTJFdevW/dfbfVP98XFJnjy5OnbsqL59++qTTz5RgQIFdO3aNQ0cOFClSpVSmTJlYlzPy8tL9+7d49gdh+bNm6cyZcqoevXqGjdunFxdXXXhwgX1799fGTNmtHi8Q8uWLTVy5EiFhYVp5syZFtsZPXq0evTooZQpU8rLy0uhoaE6ceKEAgMDX3uH4/NHhPzyyy9KnTq1ZsyYoTt37iSIP0oRZsLC8uXLVbVq1RgvXW/YsKGmTJmiBw8eSJKqVq0qKSroyJIliypVqqQlS5a88RZVxI/vv/9eTk5OkqImSDc3N23atEl58uTRrl27LB5I/Jy1tbXq16+v5cuXq2vXripRooROnDih8ePH67PPPpOfn5+cnJxUpkwZzZo1K9Z/u2XLlrK2tlbr1q1lMpk0cODAD7WbiMXz+n/yySdKnTq13N3dNWfOHHl7e1t8O/2IESM0YsQIi3U///xzLVq0yPzz87FvY2MjJycn1axZk+cwfaT27dsX7Ur5Dh06vPX6iRMnjvbtjPh4ve7DS7Zs2XTgwAENHTpUVatWVVhYmHkeeP5HSinqitxff/1VkyZN0rhx4/T3338rderUKlCggKZOnRrj+QHiz/uoefXq1bVq1SoNGTJEwcHBcnZ2Vu3ataPNBYhbY8aM0YYNG8w/W1lZaePGjZo1a5ZmzpypL774Qvb29ipdurT27dunsmXLvnGbvXv3VunSpXXs2DGVKFEi2vv8oSL+JUuWTCVLltTMmTP1559/Kjw8XC4uLvrss880ZMiQ/9e231R/fFxmz56tSZMmaeDAgfr777/l6OgoT09PjR8/Ptbvp7CysvrXz0/Gv5MzZ06dOHFCI0eOVJMmTRQQECBHR0fVq1dPI0eOVJo0acxtGzVqpG7dusnGxkb16tWz2E7Hjh2VJEkSTZ06Vf3791fSpElVoEAB9erV67X//rBhw3T16lVVr15dSZIkUadOnVSvXr0YHzPzX2MVydPeAQAAAAAAABgAz8wEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgz8a+FhoZq1KhRCg0Nje+uIA5Q74SFeics1Dthod4JC/VOWKh3wkK9ExbqnbBQ79ezioyMjIzvTsCYHjx4oJQpU+r+/ftKkSJFfHcHHxj1Tliod8JCvRMW6p2wUO+EhXonLNQ7YaHeCQv1fj2uzAQAAAAAAABgCISZAAAAAAAAAAzhk/juwH+ByWTSzZs3lTx5cllZWcV3d+LMgwcPLP6L/zbqnbBQ74SFeics1Dthod4JC/VOWKh3wkK9E5aEWu/IyEg9fPhQzs7OsraO/fpLnpn5Hly/fl0uLi7x3Q0AAAAAAADA0K5du6ZMmTLF+j5XZr4HyZMnlySt+nqPkiRNFs+9QZzgbwAJSvIMGeK7C4hDD+/cie8uIA4lTpsuvruAOBQWFh7fXUAcSprYLr67gDiU15kvyEhIzt+8H99dQBwKDzfFdxcQR4IfPVSzKoXNOVtsCDPfg+e3lidJmowwM6EgzExQkr7hQIr/lohHj+O7C4hDSZIxvhOSRISZCUrSJISZCQnf9puwJH1AuJWQEGYmPG96hCNfAAQAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGZCknTe94RGD/xCretVVK3y+XTkwJ43rnP29DH1aN9IdSsXUsdmXtr97dZobXZu+UrtGnuqXpXC6t2pmX67ePZDdB/v6LzvCY0e1FWt61dSrQr5deTgW9a7Q2PVrVJYHZvX0O7vtkVrs3PLOrVrUk31qhZR78+b67eL5z5A7/FvbFmzXI0rFlaVfBnVqWE1XTxzKta2T8PDtXLuVDWtXExV8mVU2089dPSVY0Lwo4eaM26oGnkUUpX8mdSlSQ1dOhv7NhF3GN8Jz9a1y9WsSlFVc3dRl6Zerx2LT8PDtWr+NLWsVlzV3F3UoV5FHTu416JN8ONHmjdhmJpVLqLqhTKrW/Oaunzu9IfeDbylHet91KZGSdUunk09WtZ+bW2ehodrzaKZalurjGoXz6bOjavq+OGfLdoEP36khVNGqLVXCX1aIrt6tamj3877fuC9wNv6es1yNapYWJXzZdRnbzl/N6lcTJXzZZT3px76NYb5e/a4oWroUUiV82dSZ+bvj8rSRQtUwC2H0qdOpsoVyujk8WOxtg0PD9fkCePkni+30qdOprIli+inH3+waFPALYdSJkkU7dW3V/cPvSt4C1vWLFeTSkVUNX8mfd6o+hvHt8+8aWpWpbiq5s+kdp9WjOH8/JHmjB+qxhULq2oBF3VpWlOXzjJ/fyy2fbVCLTyLyatwZnVt5qXLbzhfW71gulp5lZBX4cz6rH6lGM/X5k8cpuZVi6pGkSzq3rJWgjpf+8+HmW3btpWVlVW01x9//KEDBw7o008/lbOzs6ysrLRt27b47m68CQl5ItccudWlz7C3an/75nWNGvCFChYpobkrvlbdxq01Z8pInTx6yNzmwJ7vtHTeFLVo+4XmLNsk1xy5Nbzv5woK9P9Qu4G3FBLyRK7Zc6tL76Fv1f72zesaNbCrChYuobnLN6tuo2f1PnbY3ObAnu+0dP4UtWjb5UW9+1Hvj8GeXVs1b8Jwte3WX8u27VWOPPnUt31jBfrfi7H90pkTtGPDKvUaMVFffndYdZt5a8gX3vr9wos/Rkwe2kvHD+/TsKkLtGrXARUvV1G9vRvq3u1bcbVbiAXjO2HZ++02LZw8Ut5d+2nJ1z8pe+58GvBZ01jH9/LZE7Vz42p1HzpRPjsPqk5Tbw3v3lZXXgqnpw7rrRO/7NfgyfO1Yvs+FStbUf3aN9K9O4zv+Lbv++1aMm20Wn7eR/PXf69sufNqaJeWCvL3i7G9z7wp+nbzGn0xaKyWbv1ZtRq31pjeHfXHpfPmNjNH9dOpIwc1YPwcLdr8k4qW9tCgz5vJj3rHu+fzd7tu/bX82fzd5zXz95KZE7R9wyr1fjZ/14th/p70bP4ePnWBVj+bv3sxf38Uvt68UUMG9dfAIcN04Jdjyl+goOrXraV7d+/G2H7s6BFauXyppk6fpaOnzqpdh05q2ayRzvi+CDN+PnhEv1+9Zn5t2/m9JKleg0Zxsk+I3Z5dWzV/4gi17dZPy7btUQ63fOrXoUns5+ezJmrH+lXqOXyCVn97SHWbe2to17b6/aLl+fmJw/s1dOp8+ezcr+JlK6pPW8b3x+Dn77Zp0ZSRavNFXy3atFvZc+fTwM+bxVrvFXMmaeem1eo+ZIJW7DigT5t6a2TPdrpy6cX52vQRvXXyyAENnjRPy7buU7EyFTWgY+MEc772nw8zJcnLy0u3bt2yeLm6uurx48dyd3fX/Pnz47uL8a5YqfJq81lPlalQ9a3af7t9gxydMqpjtwHKnDW7Pm3YUuU8qmnbxtXmNls3rJLXp43kWau+MrvmULd+I2Vvb68fd235ULuBtxRV7x7vUO+Nz+rd/1m9W6ich6dlvTeullftRvKsWV+Zs2ZXt74jntU7+hW7iFsbVizUp01bq1ajFnLNmVv9xkyXfeLE2rX5qxjb/7B9o1p37q3SFT3lnDmr6rdsr9IeVbV+xQJJUmjIE+3/Yae6DBipQiXKKFOWbGrfY6AyZnHVtq9WxuWuIQaM74Rl06pFqtW4lWo0aK6sOXKrz6ipsrdPrO+2rIux/e4dm9SiU0+V8qgqZ5esqtu8nUpWqKKNPi/G94HdO/V5vxFyL15aGbNkU9tuA+Sc2VU71vnE4Z4hJlu+XCqvBi1UvV5TZcmeSz2GTZKdfWL9sG19jO337PpazTp2V4nyVeSUKYs+beKt4uUq6+vViyVF1fvQnm/VsfdQFShaShkzu6p1l75ydsmqnZtWx7hNxJ31r8zf/Z/N3zvfYv7O+Jr5+4uX5u8Oz+bvrczf8W7+nFnybtdBrdq0lVuevJo1d4GSJE6iL1f7xNh+w1dr1bf/QFXzqiFX12zq2KmzPKvX0Lw5M81t0qZLpwyOjubXD9/tkmu27CpXvkIc7RVis3HlItVu0ko1G7ZQ1hy51XfMNNnbx35+/uP2jWrVuZf5/Lxei3Yq5VFFG1YslPRs/v5xp7r0H6FCxZ+fnw+IOj9fx/iOb5tXLVLNRq3kVT/qfK3XyKmys0+s72M5X/vpm01q8VlPlawQdb5Wp1lblSxfRZt8Xqr37l3q1He4ChYrrYxZXOXdtb+cM7vqm/U+cbhn8SdBhJl2dnZydHS0eNnY2KhGjRoaN26c6tevH99dNJzLF86oULFSFsuKlCiryxfOSJLCw8P0x+8XVahoafP71tbWKlSslLkNjOPyhTMqVPR19Q6PqvdLvxPW1tYqVJR6x7fwsDD9fuGMipbxMC+ztrZWsTIeunD6eKzr2NrZWSyztbfXuZNHJUkRT58qIiJCtnb2Fm3s7BPr7Mlf3/Me4ENjfBuXeXyXfvGh1NraWkVKV9AF3xOxrhN97Nrr3MmoWxkjIiJkioiIdgyws7fXuVNH3/Me4F2Eh4fpyqWzKlKqvHmZtbW1Cpcqp4tnT8a8TliobG1fqaWdvS74vqHedvaxzhGIG8/Hd7F3nL/tYhi7Z5m/P3phYWHyPX1KFStVMS+ztrZWxcqVdfxozLUJDQuVnb1lLRMnttevv/wS67+xYf1XatUm6s5FxJ/YxnfRMm+av18d34lfOj+PiHl82704h0f8CA8L0+8Xz6pIacv5u0ipCrp4JuZ6h8Xyeez8qTfP3+dPx/54iv+SBBFmvm+hoaF68OCBxSuhCfT3U6rUaS2WpUrjoODHjxQaGqIH94NkiohQqjQOlm1SOygwlluh8PEKDPCLsZYv6h0YVe/Ur7RJ46DAAOodn+4H+isiIkJp0qazWJ7aIZ3878V821KJcpW0YcVCXfvrT5lMJh0/tE8Hftwl/7t3JElJkiVX/sLFtWr+NPnduaWIiAj9sH2jLpw+Lv97dz74PuH9Ynwb1/2gAJkiIpTaIfr4DvCLeXwXK1dJm3wW6fpfV2UymXTi8D4d3P2tAp6N3SRJkylfoWL6cuEM+d29rYiICO3esUkXfU+Y2yB+PAiMqncqB8vzr9QO6RToF/NtakXLVNTXXy7Rjb+j6n3yyAEd3vutAp4d/5MkTaY87kX11ZLZ8n9W7z07v9alsyepdzyLbf5O84b5e/0r8/f+GOZvH+bvj46/n58iIiKUPkN6i+Xp0mfQnTu3Y1ynStVqmj93tv7844pMJpP27vlJ32zfptux3FK885vtuh8UpJat2rz3/uPd3A8MUEREhFK/Or7Tpjcfn19VolwlbVy56MX4Pvzq+Xky5StcXKsWTJffnajj+Y/bN+mC7wnGdzz7N+drxctW1OZVi3X92fx94pf9OvST5fla3kLFtGbRzBfna99s1sUzCafeCSLM3Llzp5IlS2Z+NW7c+P+1vYkTJyplypTml4uLy3vqKQDEvx7DJihT1mxqVb20Kud10swxA1WzYXNZWb+YMoZNXaDIyEjVL1dAVfI56+vVS1WldgNZWyWIaQUwrO5DxilTVld51yojz4IZNWfcYHnVb2YxvgdPnq/IyEg19iioau6ZtGXNMlWuVd+iDYyhy4AxypjFVR3reahWsaxaMHGoqtVtalHLAePnKDIyUi08i6p2cVdt+2qFKnrVo94G1HPYBLlkzaaW1UurUl4nzYhh/h4+dYEUGal65Qqocj5nbV69VFWZvw1p8tQZyp49h4oVyq+0KZOof5+eatnaW9axjN0vV62UZzUvOTk7x3FP8T70GDZembJkU2uvMqqSz1mzxgxSjQbNXjk/j5q/G5QvoKr5M2rzs/NzK8a34XQdPE4Zs7iqXe2yql4ok+aOH6zq9V45X5sYVe+mldzlVdhFW9csVaWa9WM9BvzXfBLfHYgLlSpV0sKFC80/J02a9P+1vcGDB6tPnz7mnx88eJDgAs3UDmkVFGh5RU5QgL+SJE0mOzt7WVtby9rGRkEBll8OERTor9SvXFGAj1/qNGljrOWLettE1fuVLwMJCvBX6jTUOz6lTO0gGxsbBbxy1U6g/z05pEsf4zqpHdJq4sIvo67KCwxU2gyOWjR1jJxdspjbZMziqnlffaMnwY/1+NFDpU3vqJE9O8jppTYwBsa3caVMlUbWNjbRHh4f6H9PadLGPL5TpUmrcfNWKyw0RPeDApU2vaOWTB8rp0wvje/Mrpr95XY9CX6s4EeP5JA+g0b3/syiDeJeitRR9X71y34C/e9Fu7rnuVRpHDRq1gqFhYboQVCgHNI7avmsCXLMmNncxtklq6at+FohwcF6/PihHNJl0Pj+neWUKXOM20TciG3+DnjH+XvhW8zfI3p2sGiDuOeQNq1sbGx0947lVVr37t5RhgyOMa6TNl06fbXxa4WEhCjA319Ozs4aOXyIsrpmi9b2n3/+1r69e7Rm3aYP0n+8m5Sp08jGxibaVfUBfneVJpbxnSpNWk1YuNry/HzaWMvxndlVc9fueOX8vCPjO5792/O1sXNXWZyvLZ0xzuJczDlzVs1ctS3qfO3xIzmky6CxfRPO+VqCiGyTJk2qHDlymF9OTk7/r+3Z2dkpRYoUFq+Exi2fu3xfefbG6RO/yC2fuyQpUSJb5ciVV74vPX/HZDLJ9+RRcxsYR8z1PvJSvRM9q/eLNiaTSb6nqHd8S2Rrq1z53HXyyAHzMpPJpJO/HFC+wsVfu66dnb3SOTop4ulT7f9hp8pVrRGtTeIkSZU2vaMe3g/SsYM/q3wMbfBxY3wb1/PxferXg+ZlJpNJp349qHyFir12XVs7e6XLEDW+D+zeqbJVvKK1SZwkqRzSZ9DD+0E6fvjnGNsg7iRKZKuceQrq9NFD5mUmk0m+Rw8pb8Gir13X1s5eaZ/V+9Ceb1W6UrVobeyTJJFDugx6+CBIJ4/sV+mK1d/7PuDtvc/5O6a5+fn8/eDZ/B3THI+4Y2trq0KFi2j/vr3mZSaTSft//lnFS5Z6zZqSvb29nDNm1NOnT7Vj21bVrPVptDZrV69SunTpVb1Gzffed7y72Mb3qSNvnr9fHt8HfvhG5WKZv5+fnx8/9LPKVWF8x6dEtrbKlbegTr9yvnb66EHldX/787WDu3eqTOXoc3PiJEmj5u/7QTp+eJ/KVEoY83eCuDITb/Yk+LFu3vjH/PPtW9f155VLSp4ipdJncJbPopny97urvsMmSpJq1m2qnVvWacWCafKs1UBnTh3VwZ9/0KjJC8zbqN/UWzMmDFFOt3zKlaeAtm/6UiFPnsizJl+4FN+eBAe/Uu8b+vPK5Wf1dpLP4mf1Hvq83k20c+s6rVg4XZ416+vMqWPR692kjWZMHKqcufMpV5782r5pzbN614vr3cMrmrbvogkDusktfyHlKVhEm3wW6cmTYNVs2FySNK7/F0qbwUmd+w2XJF3wPSm/O7eUM09+3btzSyvmTpHJZFKLz7qbt3n04F4pMlIurjl04+//acHkUcqcLadqNmwRL/uIFxjfCUtj786aNLi7cuV3V54CRbR59WKFPAmWV/1mkqQJA7sqXQYnfdZnmCTp4pmo8Z0jT3753bktn/lTFWkyqXmHbuZtHju0V4qUXFyz68bf/9OiaaOV2TWnatRvHi/7iBcatP5M04b3Vq58BZU7f2FtXbNUIU+eqFq9ppKkKUN7KG16J7XvOViSdPnsKfndva3sbvnkd/e21iycrkiTSU3afmHe5onD+xSpSLlkya4b1/7Ssplj5ZI1u6rVbRov+4gXmrXvovEvzd8bn83ftZ7N32P7f6F0MczfUeM79vk7MjJSmZ/N3/Ofzd+1mL/jXdcevdTls/YqXKSoihYrrgXz5uhx8GO1au0tSfq8Y1s5OWfUqDHjJUknjh3VzZs3VcDdXbdu3tTE8WNkMpnUs08/i+2aTCat/XKVmrdqrU8+4eP/x6JJu86aOLC7cj8/P1+12OL8fHz/rkqbwVGfPxvfF8+c1L3bL87PV86dKpMpUs1fGt/Hno1vF9ccuvHP/7TQfH7O/B3fGnl31uQhPZQrXyG5FSisr79copAnwar+7Hxt0uBuSpveUR17R52vXTp7Un53Xszfq+dPVWSkSc3avzhfO37o52f1zq4b//ylJdNGK7NrDnklkPO1BH00e/Tokf744w/zz//73//k6+urNGnSKHPmhHVrzZXfLmhwj3bmn5fNmyJJquJVV32GTlCA/z3du/PiYdKOzpk0asoCLZ07Wds3r1HadI7qMWC0ipYsZ25ToUoN3Q8K0Jrl8xQY4KdsOdw0Ztpibkv8CFz57bwG92xv/tmi3kPGK8DfL3q9J8/X0nlTntU7Q1S9S5Q1t4mqd6DWrHi53ouo90egSq36Cgrw1/LZkxRw765y5Mmvacs3mm9ruHPzusWzdMJCQ7R05gTduva3EidNqlIeVTV86gIlT5HS3ObxwwdaPG2c7t2+qeSpUqli9U/1WZ+h+iRRojjfP1hifCcslWvW0/1Af/nMmaIAv7vKnie/Ji9Zbx7fd2/dsHh2UlhoqFbMmaSb1/5W4iRJVbJCFQ2ZPF/JLMb3Qy2bOU73bt9S8pSpVKFabXXoNYTx/RGo6FVX9wMDtHrBNAX63VO23Pk0fsEa85cK3Lt907LeYaFaNX+Kbl3/R4mTJFHxcpU1YPwcy3o/eqCVcybJ705UvctWqal23QdS74/A8/l72Uvz9/RX5m/rGObvm6+Zvx+9NH+nSJVKHtU/VSfm749Cw0ZN5H/vniaMHa07d26rQEF3bdm2U+kzZJAkXb92zWJ8h4SGatyYkfrrf1eVNFkyVavupSXLfJQqVSqL7f68d4+uXftHrdu0jcO9wZs8H98r5kx+6fx8w4vxfeu6rKxffOt8WGiIls2aGHV+niRqfA+LYXwvmT7efH7uUa025+cfiUo16ul+gL985k1RoN9dZXfLp0mL11mcr1l+Hos6X7t1/cX52qBJ86PN38tmjZffs/O18p611b7n4ARTb6vIyMjI+O7Eh9S2bVsFBQVp27Zt0d7bt2+fKlWqFG25t7e3fHx83vrfePDggVKmTKlN3x9VkqTJ/h+9hWH8t4cNXpHCKeZnFeG/6cGtmL81FP9NSWJ5NhX+m8LCwuO7C4hDSZPYxXcXEIcKZEz55kb4zzhzPSi+u4A4FB5uiu8uII48fvRQdUrm0P3791/7SMf//JWZrwslK1asqP94lgsAAAAAAAD8ZySILwACAAAAAAAAYHyEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABjCJ/Hdgf8Ua5uoF/77TKb47gHi0NOn1DtBiaTeCUmSxIniuwuIQ08eh8R3FxCHnkZExncXEIf8n4TFdxcQh1Ils4vvLiAO3Qt8Et9dwEeGKzMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAED76MNPKykrbtm17721h6bzvcY0e0Fmt65RXrbJuOnLgpzeuc/bUUfVo10B1KxZQxybVtHvXlmhtdn69Vu0aVla9SgXV+7Mm+u3i2Q/Rfbyj874nNHrgF2pdz0O1yud9u3qfPqYe7RuqbmV3dWxWXbu/3Rqtzc4tX6ld46qqV6WQendqSr0/IlvXLlezKkVVzd1FXZp66dLZU7G2fRoerlXzp6llteKq5u6iDvUq6tjBvRZtgh8/0rwJw9SschFVL5RZ3ZrX1OVzpz/0buAtnD9zQqMHdVPrBlVUy6OgjrxSu5icPX1cPTo2Ud2qRdWxRS3t/m57tDY7t65Xu6ZequdZTL07t9Bvl859iO7jX9i0eqnqlS2o8rkc1b5uVV3wPRlr26fh4Vo2e4oaVCis8rkc1dKrnI7ss5wDIiIitGj6eNUr564KuZ3UoEJhLZ8zVZGRkR96V/AWvtm4Sm0/LaO6ZXKql3cd/XbeN9a2T5+G66uls9S+bjnVLZNTXZtX14lf9lm0CX78SIunj5J37dKqVzan+ravr98vnPmwO4G3tnXtcjWtXESeBTOpS5PqbzV/t/AsLs+CmdShbkUdPbjHok3wo0eaO2GomlYurGruLurajPn7Y7J62WKVL5RHbs5pVN/TQ2dOnoi1bXh4uOZMnaiKRfPLzTmNalYoqf17frRoExERoRkTxqhC4bzKk9FBFYvm19xpkziefyTWr1wirxL5Vcw1nVrUqqRzp19f70UzJqlm6YIq5ppOjaqW0aGfd1u0iYiI0LwpY+VVsoCKZ0uvmqULavHMydT7I7HtqxVq4VlMXoUzq2szL11+w/F89YLpauVVQl6FM+uz+pVi/Dw2f+IwNa9aVDWKZFH3lrUS1PH8ncLMtm3bysrKSlZWVrK1tVWOHDk0ZswYPX369EP1T7du3VKNGjXee1tYCnnyRK453NSl74i3an/75nWN6t9ZBYuU0FyfbarbpI3mTB6uk0cPmtsc+OlbLZ07SS3ad9WcFVvkmiO3hvfpqKBA/w+1G3hLISHBcs2RW136DH+r9rdvXteoAV2i6r1ii+o2bqM5U0bo5NFD5jYH9nynpfMmq0XbLzRn2Wa55nDT8L6dqPdHYO+327Rw8kh5d+2nJV//pOy582nAZ00V6H8vxvbLZ0/Uzo2r1X3oRPnsPKg6Tb01vHtbXbn4IryaOqy3TvyyX4Mnz9eK7ftUrGxF9WvfSPfu3Iqr3UIsoo7nudWl15C3an/71nWNGtRVBQuX0Nxlm1S3USvNmTpKJ48dNrc5sPd7LZ0/VS28O2vO0g1yzZ5bw/t1Znx/BHZ/s0Wzxw1Th54DtWrXPuXIm1892zRUgF/M43vRtHHa9pWP+o6erPU//aoGLdtp4Oet9dv5F398+nLRLG1Zs0L9xkzR+p+OquugUVqzeI42+iyJq91CLPb/uENLZ45Vi896ae6aXcqWK4+Gd2+loAC/GNuvXjBV321Zqy79x2jRxp9Us2Erjev/mf68fN7cZva4ATp99KD6jZmlBet3q3DJ8hryRQv53b0dV7uFWOz9dqsWTBqhtl37aemWPcqeO5/6d2zy2vn7mw2r1GPYBK3adUh1mnlreLe2uvLSH5enDu+lk7/s15DJ87Vix34VK1tRfds1ZP7+COzculkThg9Sj/6D9c3ew8qTv4C8G9eV3727MbafPn601vks18hJ0/TjLyfVom1HdW7TXBfO+prbLJo9Q2tXLtOoyTO0+8gpDRg5VkvmzNSqJQvjaK8Qm++3f62po4eoc59B2vDDQeXOW0CdWzSQfyzz97zJY7V5zUoNHjdV2/YdU+PW7dW7Q0tdOvfij08r5s/UxlXLNWT8VG3bf1y9ho7RygWz9dXyRXG1W4jFz99t06IpI9Xmi75atGm3sufOp4GfN4v1eL5iziTt3LRa3YdM0IodB/RpU2+N7NlOV166mGD6iN46eeSABk+ap2Vb96lYmYoa0LFxgjmev/OVmV5eXrp165auXLmivn37atSoUZo6dWq0dmFhYe+lg46OjrKzs3vvbWGpWOkKatOpl8p4eL5V+2+3rZejUyZ17D5ImbNm16eNWqlcxeratmGVuc3WDT7y+rSxPGs1VGbXHOrWf7Ts7ez1486vP9Ru4C0VK1VBbT7rqTIVqr5V+2+3b5CjU0Z17DYwqt4NW6qcRzVt27ja3OZFvRtE1bvfSNnb2+vHGK7YRdzatGqRajVupRoNmitrjtzqM2qq7O0T67st62Jsv3vHJrXo1FOlPKrK2SWr6jZvp5IVqmijzwJJUmjIEx3YvVOf9xsh9+KllTFLNrXtNkDOmV21Y51PHO4ZYlKsVHm16dhdZSpUeav2327fFDW+u/ZT5qzZ9GmD5irn4altm740t9m6cbW8ajeUZ816ypw1u7r1HS57+8T68dttH2gv8LbWLVugus3a6NMmLZUtp5sGjZ8h+8RJ9M3GNTG2/27rRnl37a2ylaopY+asati6g0pX8tRXy+aZ25w9eUwVPGuqXOXqcnbJrCo166pE+Uq6eCb2Kz4RN7auXSaves1VrU4TZc6WS90GT5SdfWL9uGNDjO33frtFTdp1U/FyleWUKYtqNWqtYmUqa8vapZKk0JAQHd77ndr3GKICRUrK2SWrWn3eR84uWbRr85cxbhNxZ5PPs/m7YYuo+Xv0NNnbJ9a3X38VY/sft29Uy897qZSHp3n+LlWhijasjAquQkOeaP+Pz+fvMsqUJZvadR+gjJldtX3dyrjcNcRg+YK5atq6nRq3bKOcbnk0bvocJU6cWJvWro6x/baN69Sld39V8vRS5qyuatX+M1WsWl3L5s8xtzl1/FdVrVFLlat5KVPmLKpZp77KVaqiM6divwIQcWP1knlq2MJb9Zq1UvZcbho+eZYSJ06sbetiPvbu/Hq9Onbvq/JVqitTFlc19e6ocpWrafXiueY2Z04cVaXqtVShqpcyumRRtdr1VNqjss6/5o4NxI3NqxapZqNW8qof9Xms18ipsrNPrO9j+Tz20zeb1OKznipZIerzWJ1mbVWyfBVt8nlxPD+we5c69R2ugsVKK2MWV3l37S/nzK76Zr1PHO5Z/HnnMNPOzk6Ojo7KkiWLunTpoqpVq2rHjh1q27at6tWrp/Hjx8vZ2Vm5c+eWJF27dk1NmjRRqlSplCZNGtWtW1d//fWXxTZXrFihfPnyyc7OTk5OTurWrZv5vZdvHQ8LC1O3bt3k5OQke3t7ZcmSRRMnToyxrSSdO3dOlStXVuLEieXg4KBOnTrp0aNH5vef93natGlycnKSg4ODunbtqvDw8Hf935LgXD7vq0LFSlssK1KyrC4/u9UpPDxMf/x2QYWKlzG/b21trULFSpvbwDguX4ih3iXK6vIFX0nP6v37RRUqWsr8vrnez9ogfoSHhen3C2dUtHQF8zJra2sVKV1BF3xjPpENDwuTrZ29xTI7e3udO3lMUtQtLKaICNm+8scjO3t7nTt19D3vAT60yxfOWIxdSSpSvIwuX4i6kic8PFx//H4p+vguWlKXuRU1XoWHhenyeV+VKFvRvMza2lrFy3ro3KnjMa4TFhYqu1fGt729vc4c/9X8c8GiJXTi8H79c/UPSdLvF8/pzIlfVbri2/0BDB9GeHiY/rh8ToVKljMvs7a2VqES5WK9VS08PEy2ttGP1Rd8o34/IiKeRh3PX2lja2evi74x/w4hboSHhem3C2dUtIyHeZm1tbWKlq6gi6+dv1+ppX1inTsZNTdHPH0+f9u/0sbe3AbxIywsTOfPnFZZj0rmZdbW1irrUUmnjx+LdR07++jH8xNHj5h/LlK8lH45sE9X/7giSbp0/qxOHP1FHlWrfYC9wNsKDwvTpbO+KlXest4ly1fUmZOx1Ts02ti1t7fX6WMv5m/3YiV19NB+/fVnVL1/u3BOp48dUbnKb3fBEj6M8LAw/X7xrIqULm9eZm1trSKlKujimZiP52ExHs/tdf7UGz6P2dnr/OmYf4f+a/7fz8xMnDix+SrMPXv26LffftPu3bu1c+dOhYeHq3r16kqePLkOHjyow4cPK1myZPLy8jKvs3DhQnXt2lWdOnXSuXPntGPHDuXIkSPGf2vOnDnasWOHNm7cqN9++01r165V1qxZY2z7+PFjVa9eXalTp9bx48e1adMm/fTTTxZBqST9/PPP+vPPP/Xzzz9r1apV8vHxkY+Pz2v3OTQ0VA8ePLB4JTSBAfeUKo2DxbJUqdMq+PEjhYaG6EFQoEwREdHbpEmrwFhuhcLHK9DfT6lSv1pLhxf1vh/0rN5pLdukdlCgP/WOT/eDAmSKiFBqh3QWy1M7pFOAX8y3LRUrV0mbfBbp+l9XZTKZdOLwPh3c/a0C7t2RJCVJmkz5ChXTlwtnyO/ubUVERGj3jk266HvC3AbGERjg/4bx/ex4/mqb1A4cz+NZUKC/IiIilCat5fhOky6dAmK5LbFUhcr6atkC/fO/P2UymXT04M/6+fud8ntp7Lbp0luenzZQkyolVCZHOrWp5aFm7TrLq16TD7o/eL0Hz4/nr861adIqIJbb1IqU8tDWr5bqxj//k8lk0qlfD+iXvd+Zj/9JkiZTnoJFtW7ZHPnfizqe7/12iy6fOxXrHIG4cT8wqt5pXp2/06aPtTbFzfP3ny/N37tezN/JkilfoeJavWC6/O5E1ftH5u+PQqB/1PE8bfr0FsvTpk+ve3djrk35ylW0YsFc/e/PP2QymXTw5z36YdcO3bvz4hERXXr1Ve36jeRZqrByZUip2hXLqN3nXVWvcbMPuj94vcCAqHo7pLMc3w5p01vMxy8r41FFXy6Zp7+vRtX7yP692vPtN7r30iNBOnTrI6+6DVW3QjEVyZxGTaqVU6vPvlCtBk0/6P7g9f7N57HiZStq86rFuv73s89jv+zXoZ8sP4/lLVRMaxbNfPF57JvNunjmhPwTyPH8X4eZkZGR+umnn/TDDz+ocuXKkqSkSZNq2bJlypcvn/Lly6cNGzbIZDJp2bJlKlCggPLkyaOVK1fqn3/+0b59+yRJ48aNU9++fdWzZ0/lypVLxYsXV69evWL8N//55x/lzJlT5cqVU5YsWVSuXDk1b948xrZfffWVQkJCtHr1auXPn1+VK1fWvHnz9OWXX+rOnRfFTZ06tebNmyc3NzfVrl1btWrV0p49e2Lc5nMTJ05UypQpzS8XF5d3/x8IAB+p7kPGKVNWV3nXKiPPghk1Z9xgedVvJivrF1PG4MnzFRkZqcYeBVXNPZO2rFmmyrXqW7QB8PHpM3KSXLJmU9MqJVQuZ3pNGzlAtRu3kLXVi7H7086t+n77Jo2ZvVSrd+7TiOkLtHbpPO3aHPOtUPh4de43Ss4urvq8USXVKZ1dC6eMUNU6TWRtbWVu02/MTEUqUq1rlFDdMjm0Y/1KeVSvK2uO54bTfeh4ZcySTW1qllHVAs6aPXaQajSwnL+HTJkvRUaqkUcBeRbMqC1fLlXlWg2Yvw1oxISpypotuzxLFVZux1QaNbCvGjVvbVHLXdu+1o7NGzRryUrt+Pmwps1fomXz5+jrdTE/igQfr4Fjpyiza3bVrVBMRbM4aMLQfqrbtKXFsfqHHVu0a8tGTZq/XOt/OKhxsxdp1aI52r5xbTz2HP9G18HjlDGLq9rVLqvqhTJp7vjBql7vlc9jE6M+jzWt5C6vwi7aumapKtWsn2Dm70/edYWdO3cqWbJkCg8Pl8lkUosWLTRq1Ch17dpVBQoUkK2trbntmTNn9Mcffyh58uQW2wgJCdGff/6pu3fv6ubNm6pS5e2e69W2bVt5enoqd+7c8vLyUu3atVWtWsyXyF+6dEnu7u5KmjSpeVnZsmVlMpn022+/KUOGDJKkfPnyycbGxtzGyclJ5869/htaBw8erD59+ph/fvDgQYILNFOnSaegAMsvfggK9FOSpMlkZ2cv61TWsraxid4mwC/aFQX4+KV2SBvtiz6CAvxf1Nv6eb0tr9IKCvRXagfqHZ9SpkojaxubaA+XDvS/pzRp08e4Tqo0aTVu3mqFhYboflCg0qZ31JLpY+WUKYu5TcbMrpr95XY9CX6s4EeP5JA+g0b3/syiDYwhdRqHN4xvm6jx/WqbQH+O5/EsVWoH2djYRPuyn4B795QmXczjO7VDWk1dulahISG6HxSgdBmcNH/SKDlnzmpuM3fiCLXp0kvV6jSUJOVwy6fbN65r1YKZqtUo5j8i48NL8fx4/upcG+AX7eq951KmdtCI6csU9uwuCod0GbRy7kQ5ZsxsbuOUKaumLNmkkCfBCn78UGnSZtDEwV9YtEHcS5k6qt6vXnUb6Hf3tfP3+PmrzXdJPZ+/nV1emb/X7Hg2fz+UQ3pHje7d0aIN4l5qh6jjud9dy6u0/O7eVbr0GWJcxyFtOi1es0GhISEKDAhQBicnTR49XJmzuJrbTBo5VJ/37KtPGzSWJLnlza8b165p4azpati81YfbIbxW6jRR9fa/Zzm+/f3uKm26mOudxiGtZq9cp9CQEAUFBii9o5NmjR+pTC/N3zPGDleHbr1Vo14jSVKuPPl06/o1LZ87Q3WbtPxg+4PX+7efx8bOXWXxeWzpjHEWn7WcM2fVzFXboo7njx/JIV0Gje2bcD6PvXNkW6lSJfn6+urKlSt68uSJVq1aZQ4MXw4OJenRo0cqWrSofH19LV6///67WrRoocSJE7/Tv12kSBH973//09ixY/XkyRM1adJEjRo1etddsJAoUSKLn62srGQymV67jp2dnVKkSGHxSmjc8heS78kjFstOH/9FbvkLSZISJbJVjtz55HviRRuTySTfk7+a28A43PIVku/JXy2WnT5xRG75Ckl6Vu9ceS3amOv9rA3iRyJbW+XK565Tvx40L4u61fCg8hUq9tp1be3slS6DkyKePtWB3TtVtopXtDaJkySVQ/oMeng/SMcP/xxjG3zc3PK5y/eVZ6VFje+CkqLmyRy58li0MZlM8j11VG753OO0r7CUyNZWbvkL6fgv+83LTCaTjv9yQAWKFH/tunb29krv6KyIp0/18/ffqIJnDfN7IU+eWFypKUU928kU+frzI3xYiRLZKodbAZ05dti8zGQyyff4YbkVLPLadW3t7JU2vaMiIp7q8N7vVMoj+sUA9omTKE3aDHr4IEinjhxQqbf8Ukh8GIlsbZU7n7tOHTlgXmYymXTy14PK+4b52+6l+Xv/j9+obOXY5m9HPbwfpGOHflbZyjVi2BLiiq2trfK7F9YvB/aZl5lMJv1yYJ8KFy/x2nXt7O3l6Oysp0+f6oed21W1Ri3ze0+ePIl2lZa1Dcfz+JbI1lZ5ChbS0UP7zMtMJpOOHtov96JvrncGp6h6//TtdlWs/qLeISHB0a6ytraxUST1jleJbG2VK29BnX7l89jpoweV1/3tP48d3L1TZSpXj9YmcZKkckj3/PPYPpWpFL3Nf9E7X5mZNGnSWJ9p+aoiRYpow4YNSp8+fayBX9asWbVnzx5VqlQpxvdflSJFCjVt2lRNmzZVo0aN5OXlpYCAAKVJk8aiXZ48eeTj46PHjx+bQ9bDhw/L2tra/OVEeOFJ8GPdvP6P+efbN6/rz98vKXmKlErv6CyfhdPl73dXfYdPliTVrNdMO79eqxXzp8qzdkOdOfmrDu79XqOmLjJvo37TtpoxfpByuuVXrrwFtX3jKoWEPJFnrQZxvn+w9CT4sW7eeKnet27ozyvP6p3BWT6LZkTVe9gkSVLNuk21c8tXWrFgmjxrNdCZU0d18OfvNWryQvM26jdtqxkTBkfVO08Bbd+0WiFPnsizZv043z9YauzdWZMGd1eu/O7KU6CINq9erJAnwfKqH/W8pAkDuypdBid91meYJOnimZPyu3NLOfLkl9+d2/KZP1WRJpOad3jxzOFjh/ZKkZKLa3bd+Pt/WjRttDK75lSN+ly1Fd+eBAfHML4vPxvfTvJZMlv+9+6o79AJkqSadRtr59Z1WrFwhjxr1o8a3/t+1KhJL77dun6TNpoxcZhyuuVVLrcC2r55TdT4rlEvrncPr2je8QuN6fuF8hQorLyFimj98oUKCX6s2o2jrsAY1aez0mVwUteBIyVJ50+f0L07t5QrbwHdvX1Ty2ZNlslkUuvPe5q3Wb6Kl1bOn6EMGTMpW848+v3CWa1bvkCfNuaqjvhWv2VHzRjVVznzFlCufIW0/avlCn0SLM9Po55nOm1ELzmkd1S7boMkSZfPn5b/3dvKliuv/O/d1tolMxUZaVKjNp3N2zx5ZL8iIyOVKUs23bz2l1bMmaBMWbPLsw7PSI1vjdt21sRB3ZU7fyHlKVhEm1dFzd81GkTNtRMGdlXa9I7q1He4pFfn71vymTdVkaZINevY3bzNYwf3KlKRyuyaQzf+/p8WTh2lzNlymreJ+NPhi+7q17WTChQqLPcixbRy8XwFBwerUYvWkqS+XToqg5OzBowYI0nyPXFct2/dVN4CBXX71k3NnjxeJpNJn/fobd5mleo1tGDGFDlnclEutzy6cPaMViycZ94m4k+bTt00rFdn5XUvrAKFi2nN0gV6Ehyses2irpgd0qOTMjg6q+eQUZKks6eO6+7tW3LLV0B3bt/SwukTZTJFqt0XL+ZvD88aWjpnmpwyZlL23Hl0+fxZfbl4nuo1o97xrZF3Z00e0kO58hWSW4HC+vrLJQp5Eqzqzz6PTRrcTWnTO6pj76jPY5fOnpTfndvK7pZPfndva/X8qYqMNKlZ+xefx44f+lmRkZFRn8f++UtLpo1WZtcc8kogn8feOcx8Fy1bttTUqVNVt25djRkzRpkyZdLff/+tLVu2aMCAAcqUKZNGjRqlzp07K3369KpRo4YePnyow4cPq3v37tG2N2PGDDk5Oalw4cKytrbWpk2b5OjoqFSpUsX4b48cOVLe3t4aNWqU7t27p+7du6t169bmW8zxwpXL5zW4u7f552Vzo0KsKjXqqc+wSQrwv6d7d26a33d0zqRRUxdp6ZxJ2r5ptdKmc1SPgWNVtOSLb+iqULWm7gcFaM2yuQoMuKdsOfNozPSl3Jb4Ebjy2wUN7tHW/POyeVEhdRWveuozdIIC/P10784t8/uOzpk0aspCLZ07Sds3fxlV7wFjVPSlb1StUKVGVL2Xz1VggJ+y5XDTmGmLqfdHoHLNerof6C+fOVMU4HdX2fPk1+Ql6823Ndy9dcPir/ZhoaFaMWeSbl77W4mTJFXJClU0ZPJ8JUuR0tzm8cOHWjZznO7dvqXkKVOpQrXa6tBriD555Wp3xL0rv13Q4F4dzD8vmz9VklTFq476DB4XdTx/6WHxjk6ZNGrSfC2dN1Xbv16rtOkyqEf/USpaoqy5TYXKXrofFKg1KxY8G9+5NWbqQqV+5UveEPc8P22goAA/LZk5Qf737ipXngKatWqzHJ7dZn7nxnWLqyzDQkO1aNp43fznLyVOmlRlKnlq1MxFSp7yxfjuO3qyFk+foKnD+ynQz09pMziqfou26tBjQJzvHyx5VKujB4EB+nLRDAX631O2XHk1Zu6X5i8VuHf7psXxPDw0VKsXTtXtG9eUOHESFStbSf3GzFKy5C8dzx89kM+8yfK7e1vJU6RU2co15d21vz75hON5fKtcs76CAvy1cu5kBdy7qxx58mvK0g3m+fvOzeuysnrx/NOw0BAtnz3RPH+X8qiqIZMXKHkKy3ovnTFe927fVPJUqVTBs7Y69h7K/P0RqF2/kQL8/DRz0jj53b2jPPkLymfjNvNt5jdvXLcY36GhIZoxYYz++ft/Spo0mSpWraYZC5crRcpU5jYjJ03XjIljNKJ/L/n73VMGRyc1926v7v0Hx/Xu4RVedRsq0N9PC6ZOkN+9O8qdr4AWrv3aPH/ffqXeYaGhmjd5rK7/85eSJEmqclWqacKcJRb1HjxuquZNGafxg/sqwP+e0mVwVKPW7dS596C43j28olKNerof4C+feVMU6HdX2d3yadLidRafx6yson8eu3X9xeexQZNe+Tz26IGWzRovv2efx8p71lb7noMTzPHcKjIyMvJtG7dt21ZBQUHatm3bW793+/ZtDRw4UN9++60ePnyojBkzqkqVKpo2bZr5as3Fixdr5syZunr1qtKmTatGjRppzpw5UR20stLWrVtVr149LV26VAsWLNCVK1dkY2Oj4sWLa+rUqSpcuHC0tpJ07tw59ezZU0eOHFGSJEnUsGFDzZgxQ8mSJYu1z7169ZKvr6/5C4rexoMHD5QyZUpt+vGEkiRN9tbrwcDe8CgC/LckSUsgm5AEvxT04b8vbZaE9czrhM7f72F8dwFxKEmyd3ukFYwtc7ok8d0FxKFHoRHx3QXEoXuBT+K7C4gjjx89VJ2SOXT//v3XPtLxncJMxIwwMwEizExQCDMTFsLMhIUwM2EhzExYCDMTFsLMhIUwM2EhzEw43jbMTBjf2Q4AAAAAAADA8AgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMIRP4rsD/ylPw6JeAP5T7O05VCYkwdY28d0FxKEA/0fx3QXEIbvEdvHdBcQhO1uO5wlJ5lRJ4rsLiEO7fa/HdxcQh2ztbeO7C/jIcGUmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhpiQrKytt27ZNkvTXX3/JyspKvr6+8dqnuHb+zAmNHtRNrRtUUS2PgjpycO8b1zl7+rh6dGyiulWLqmOLWtr93fZobXZuXa92Tb1Uz7OYenduod8unfsQ3cc7ot4Jz+bVy1S/nLs8cjupQ72quuB7Mta2T8PDtXzOFDXyKCKP3E5qXaO8juz/yaJNRESEFk8frwblC8nDzVmNPIpoxZypioyM/NC7gjc473tCowd+odb1KqpW+Xw6cmDPG9c5e/qYerRvpLqVC6ljMy/t/nZrtDY7t3yldo09Va9KYfXu1Ey/XTz7IbqPf+GbjT7yrl1adUrnUK82n+q386djbfs0PFxrl8xSuzplVad0Dn3RrJpO/PKzRZvgx4+0aNooedcqpbplcqhPu3r67YLvB94LvK1tX61QC89i8iqcWV2beeny2VOxtn0aHq7VC6arlVcJeRXOrM/qV9KxV+b84MePNH/iMDWvWlQ1imRR95a1dPlc7L9DiFubVy9T/fLu8nBzUof6VXXhzFvM3xWLyMPNSa1rxjJ/zxivBhUKySOPsxpVLKIVc5m/PxYLFsxX9mxZlTSJvUqXLqljx47F2jY8PFxjx45RrpzZlTSJvYoUdtf3338frd2NGzfUpnUrpU/noGRJE6uQewGdOHHiQ+4G3hLzd8LC/P1+xXuY2bZtW1lZWcnKykqJEiWSq6urBgwYoJCQkPjuWoIS8uSJXHPkVpdeQ96q/e1b1zVqUFcVLFxCc5dtUt1GrTRn6iidPHbY3ObA3u+1dP5UtfDurDlLN8g1e24N79dZQYH+H2o38Jaod8Ly084tmjN+mDr0HCCfnT8rZ5786u3dSAF+92Jsv3j6eG37apX6jJqsr3YfUf2W7TTo8zb67cKL8OrLRbO1de1K9R09Ret/+lVfDByptUvmapPPkrjaLcQiJOTZ+O4z7K3a3755XaMGfKGCRUpo7oqvVbdxa82ZMlInjx4ytzmw5zstnTdFLdp+oTnLNsk1R24N7/s54/sjsP/HHVoyY6xaduqluWu/lWuuvBrWrbWCAvxibL9q4VR9t2WNugwYq8Wb9qhmw1Ya2+8z/XH5vLnN7LH9dfroQfUbO0sLN+xWkVIVNKRLC/ndvRVXu4VY/PzdNi2aMlJtvuirRZt2K3vufBr4eTMF+sd8PF8xZ5J2blqt7kMmaMWOA/q0qbdG9mynKy/9sXH6iN46eeSABk+ap2Vb96lYmYoa0LGx7t2h3vHtp51bNGfCMHXoMUA+37zl/L1ulfqMnKyvfjyi+i3aaVDnWObvUVO0fvev+mLAs/l7FfN3fNu4YYP69e2j4cNH6viJU3Iv6K6aNarr7t27MbYfPnyYli5ZrFmz5+rc+Yvq1KmzGjWsr9OnX4QZgYGBqlC+rBIlSqSdu77TufMXNWXqdKVOnTqudguxYP5OWJi/3794DzMlycvLS7du3dLVq1c1c+ZMLV68WCNHjozvbiUoxUqVV5uO3VWmQpW3av/t9k1ydMqojl37KXPWbPq0QXOV8/DUtk1fmtts3bhaXrUbyrNmPWXOml3d+g6XvX1i/fjttg+0F3hb1DthWbdsgeo0baPajVvKNaebBoyfIbvESbRz09oY23+/daO8v+itMpU8lTFzVjVo1V5lKlXVuqXzzW3OnTqm8p41VLZyNTllyqzKNeuqRPmKungm9r8wIm4UK1VebT7rqTIVqr5V+2+3b4ga390GKHPW7Pq0YUuV86imbRtXm9ts3bBKXp82kmet+srsmkPd+o2Uvb29fty15UPtBt7S1jVLVaN+c1Wr01RZsuVS9yETZWdvrx+3b4ix/d5dX6tp+24qUa6ynDJlUe3GbVS8bGVtWRMVZISGPNGhvd+pQ48hKlCklJxdXNXq8z5ydsmqXZu/jHGbiDubVy1SzUat5FW/ubLmyK1eI6fKzj6xvt+yLsb2P32zSS0+66mSFarK2SWr6jRrq5Llq2iTz0JJUfU+sHuXOvUdroLFSitjFld5d+0v58yu+ma9TxzuGWKybvkr8/e4N8zf2zbKu8sr83fFqlq37JX5u+or83c55u+PwcxZM9Sx42dq266d8ubNqwULFylJkiRauXJFjO3XrvlSgwYPUc2aNZUtWzZ17tJFNWrU1MwZ081tpkyZrEwuLlq+YqVKlCghV1dXVatWTdmzZ4+r3UIsmL8TFubv9++jCDPt7Ozk6OgoFxcX1atXT1WrVtXu3bslSSaTSRMnTpSrq6sSJ04sd3d3bd682WL9CxcuqHbt2kqRIoWSJ0+u8uXL688//5QkHT9+XJ6enkqbNq1SpkwpDw8PnTrFZP3/dfnCGRUqWspiWZHiZXT52V9+w8PD9cfvlyzaWFtbq1DRkrp84Uyc9hX/f9TbuMLDwvTb+TMqXs7DvMza2lrFy3ro/KnjMa4TFhYqWzs7i2V2dol15sSv5p8LFCmhE4cP6J+rf0iSrlw8rzPHj6p0xbcL0PDxuHzhjAoVe2V8lyhrHrvh4WH64/eLKlS0tPl9a2trFSpWivEdz8LDw3Tl8jkVKlHOvMza2lqFSpTXpXMx34oaHh4mW1t7i2W2dva64Bt1PIiIiJApIkKJXjkGvNwG8SM8LEy/XzyrIqXLm5dZW1urSKkKungm5ltGw8LCoh3Pbe3tdf5U1K2rz+sd/Zhvr/OnY7+9FR+eef4uG8P8ffod5m/7GObvX16avy+d15kTR1Xag/k7PoWFhenUyZOqUuVFHaytrVWlSlX9euRIjOuEhobK3s7yeJ44cWIdPvzizoqd3+xQ0aLF1LRJYzk5plexooW1bOnSD7MTeGvM3wkL8/eH8VGEmS87f/68fvnlF9na2kqSJk6cqNWrV2vRokW6cOGCevfurVatWmn//v2Sop4BUqFCBdnZ2Wnv3r06efKk2rdvr6dPn0qSHj58KG9vbx06dEi//vqrcubMqZo1a+rhw4f/uo+hoaF68OCBxSuhCQzwV6rUDhbLUqVxUPDjRwoNDdGD+4EyRUREb5PaQYGxXDqPjxf1Nq6gQH9FREQoTdp0FsvTpE0n/3t3YlynZIXKWr98ga7970+ZTCYdO/iz9v2w06J9my695PlpAzWrWlLlcqaXd20PNW3fWdXrNf6g+4P3L9DfT6lSp7VYZjm+g6LGd5oYxrc/4zs+PQgKkCkiQqkdLMd3aoe0CozlNtSipTy0Ze1S3fjnfzKZTDr16wH9svc7BfhF3caYJGky5SlYVOuWzZb/vduKiIjQ3m+36PK5k+Y2iB/3Y613ulhrU7xsRW1etVjX/74qk8mkE7/s16GfvlXAs+N5kqTJlLdQMa1ZNFN+d6Pqvfubzbp45kSscwTixr+av8tX1voVbzF/126gZp4lVS7Xs/m7HfN3fPPz81NERITSZ8hgsTx9hgy6fed2jOtUq1Zds2bN0JUrV2QymbR7925t3bpFt269uMX06tWrWrxooXLkzKlvv/tBn3/eRb169dDqVas+6P7g9Zi/Exbm7w/jk/jugCTt3LlTyZIl09OnTxUaGipra2vNmzdPoaGhmjBhgn766SeVLh11RUi2bNl06NAhLV68WB4eHpo/f75Spkyp9evXK1GiRJKkXLlymbdduXJli39ryZIlSpUqlfbv36/atWv/q/5OnDhRo0eP/pd7CwAft94jJmrS4F5qVrWkrKyslDGzq2o1amFxW9ueXVv1w/ZNGj17iVxz5tGVi+c0a+wQpc3gqFoNm8dj7wG8zuf9R2vO2AHq1LCiZGUlp0xZ5FmniX7c8eK2tn5jZmnmmH5q5VVc1jY2yuGWXx7V6+oPvtTNcLoOHqfpI/uqXe2ykpWVnF2yqnq9Zvp+64vb2gZPnK+pw3upaSV3WdvYKGeeAqpUs76u8CVfhtN7xERNGtJLzTzfMH/v2KTRs57N35eYv41q5qzZ+rzTZ8qX101WVlbKnj272rZtZ3FbuslkUtFixTR+/ARJUuHChXXhwnktXrJIbby946vr+BeYvxMW5u83+yjCzEqVKmnhwoV6/PixZs6cqU8++UQNGzbUhQsXFBwcLE9PT4v2YWFhKly4sCTJ19dX5cuXNweZr7pz546GDRumffv26e7du4qIiFBwcLD++eeff93fwYMHq0+fPuafHzx4IBcXl3+9PSNKncYh2hc/BAX4K0nSZLKzs5e1tY2sbWyitwn0V+o0llcA4eNHvY0rVWoH2djYRPuygAC/e3JIlyHGdVI7pNXkJWsUGhqi+4EBSpfBSQsmj1bGzFnMbeZNHKnWnXvJ89OGkqQcbnl1+8Y1rV4wiw9DBpPaIa2CAi2vsLQc39ZR4zsghvHtwPiOTylSpZG1jU20h8cH+vsp9StXcz2XKrWDRsxYrrBnV9U7pHPUirkT5Zjxxfh2dsmqqUs3K+RJsIIfPVSadBk0cVAXOWbM/EH3B6+XMtZ631OatOljXCdVmrQaO3eVwkJDdD8oUGnTO2rpjHFyyvRSvTNn1cxV2/Qk+LGCHz+SQ7oMGtv3M4s2iHv/ev5e/Ib5e9JItf48hvl7IfN3fEqbNq1sbGx0947lFVV379yRYwbHGNdJly6dtmzdppCQEPn7+8vZ2VmDBw9StmzZzG2cnJyUN09ei/Xc3PJoy5av3/9O4K0xfycszN8fxkdxm3nSpEmVI0cOubu7a8WKFTp69KiWL1+uR48eSZJ27dolX19f8+vixYvm52YmTpz4tdv29vaWr6+vZs+erV9++UW+vr5ycHBQWFjYv+6vnZ2dUqRIYfFKaNzyucv35FGLZadPHJFbvoKSpESJEilHrjwWbUwmk3xPHZVbPvc47Sv+/6i3cSWytVXu/O46cfiAednzWxXyFyn+2nXt7OyV3tFZEU+f6ufvv1F5z5rm90KePJG1teUUYm1jo0iT6f3uAD64mMf3L+axmyiRrXLkyivfky+euWYymeR7kvEd3xIlslVOtwLyPX7YvMxkMsn3+CHlKVD0teva2tkrbXonRTx9qsN7vlVpD89obewTJ1GadBn08EGQTh45oFIVq733fcDbS2Rrq1x5C+r0rwfNy0wmk04fPai87sVeu66tnb3SZYiq98HdO1WmcvVobRInSSqHdBn08H6Qjh/epzKVordB3DHP37/EMH8Xfof5+4dvVL7qG+Zva+bv+GZra6siRYtq79495mUmk0l79+5RqdKlX7OmZG9vr4wZM+rp06fauuVrfVqnrvm9MmXK6rfff7No//uV35U5S8IIOz5WzN8JC/P3h/FRXJn5Mmtraw0ZMkR9+vTR77//Ljs7O/3zzz/y8PCIsX3BggW1atUqhYeHx3h15uHDh7VgwQLVrBk1iV+7dk1+fjzj61VPgoN188aLq1Vv37qhP69cVvIUKZU+g5N8lsyW/7076js06haFmnUba+fWdVqxcIY8a9bXmVNHdXDfjxo1aZ55G/WbtNGMicOU0y2vcrkV0PbNaxTy5Ik8a9SL693DK6h3wtK84xca27er3AoWUj73Ilq/YpFCgoNVu1ELSdLoPl2UztFJXwwYIUm6cPqE7t25pZx5C+je7VtaNnuyIk0mtfq8h3mb5ap4yWf+dGVwzqRsudz024WzWr98gWo3bhkv+4gXngQ/fmV8X9efVy49G9/O8lk0U/5+d9V32ERJUs26TbVzyzqtWDBNnrUaRI3vn3/QqMkLzNuo39RbMyYMUU63fMqVp4C2b/oyanzXrB/n+wdL9Vt9pukj+yhnnoLKnb+Qtn21XKFPnsizThNJ0rQRveSQzlHtug+SJF0+d1r+924rW6688r93W2sWz1RkZKQaeXcxb/PkL/sUqUhlypJdN6/9peWzxytT1uyq9mmTeNlHvNDIu7MmD+mhXPkKya1AYX395RKFPAlW9frNJEmTBndT2vSO6th7mCTp0tmT8rtzW9nd8snv7m2tnj9VkZEmNWvfzbzN44d+VmRkpFxcs+vGP39pybTRyuyaQ171uUovvjXv8IXG9usqtwLP5u+Vr8zffbsoXYaX5m/fE7p3+y3m7wWvzN8rFqh2I+bv+Na7Vx+1a+etokWLqXiJEpoze5YeP36stm3bSZLaereRc8aMmjAhav4+evSobt64IfdChXTjxg2NGTNKJpNJ/fsPMG+zZ6/eKl+ujCZOnKDGjZvo+LFjWrZ0iRYtWhIPe4iXMX8nLMzf799HF2ZKUuPGjdW/f38tXrxY/fr1U+/evWUymVSuXDndv39fhw8fVooUKeTt7a1u3bpp7ty5atasmQYPHqyUKVPq119/VYkSJZQ7d27lzJlTX375pYoVK6YHDx6of//+b7yaMyG68tsFDe7VwfzzsvlTJUlVvOqoz+BxCvC/p3t3Xzx82tEpk0ZNmq+l86Zq+9drlTZdBvXoP0pFS5Q1t6lQ2Uv3gwK1ZsUCBQb4KVuO3BozdaFSv/IlEoh71DthqVq7gQL9/bVsxkT5+91Vzjz5NdNnk9Kki7qt4c7N6xZXaYSGhmrx9PG6+c/fSpw0qUpX9NTIGQuVPEVKc5s+oyZpyYwJmja8nwL8/ZQug6PqNW+r9j36x/n+wdKV3y5ocI925p+XzZsiSariVVd9hk6IGt93Xnw5gKNzJo2askBL507W9s1rlDado3oMGK2iJV98w2aFKjV0PyhAa5bPeza+3TRm2mIeI/ER8KhWR/cDA7Rm0XQF+N9T9lx5NXbul+aHzN+9fUNWVlbm9mFhIVq1YKpu3/hHiRMnUfFyldV/7CwlS/5ifD9+9FAr502S393bSp4ilcpVqSHvLwbok1ge6YO4U6lGPd0P8JfPvCkK9Lur7G75NGnxOvNtandv3ZCV1YvjeVhoqFbMmaRb1/9W4iRJVbJCFQ2aNF/JUrxc7wdaNmu8/G7fUvKUqVTes7ba9xxMvT8CVWs3UGCAv5bNfIf5e8Yb5u+Rz+bvEa/M392Zv+Nbk6ZNdc/vnkaNGqHbt2/LvVAh7fr2e2V49qVA/1z7x6LeISEhGjFimK5evapkyZKpRo2aWrXqS6VKlcrcpnjx4tr89VYNGzpY48aOkaurq2bMmKUWLQmv4xvzd8LC/P3+WUVGRkbGZwfatm2roKAgbdu2zWL5pEmTNGPGDP3vf//TsmXLtHDhQl29elWpUqVSkSJFNGTIEFWoUEGSdPbsWfXv31+HDh2SjY2NChUqJB8fH2XLlk2nT59Wp06ddP78ebm4uGjChAnq16+fevXqpV69ekmSrKystHXrVtWrV09//fWXXF1ddfr0aRUqVOit9uHBgwdKmTKlNn37i5IkTfYe/+8A+BikyZwpvruAOBRw/dabG+E/wzpJwntUTEJma28b311AHEqSOGF8oEOU4llSx3cXEId2+16P7y4gDjF/JxyPHz1UnZI5dP/+/dc+0jHew8z/AsJM4L+NMDNhIcxMWAgzExY+DCUshJkJC2FmwkKYmbAwfyccbxtmfhRfAAQAAAAAAAAAb0KYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAM4ZP47sB/QWRkpCQpOPhxPPcEwIdg9/BBfHcBcSj48aP47gLikJXJKr67gDgU/tQ2vruAOBT5lI86CcmDBzbx3QXEocePHsZ3FxCHmL8TjuBnY/t5zhYbq8g3tcAbXb9+XS4uLvHdDQAAAAAAAMDQrl27pkyZMsX6PmHme2AymXTz5k0lT55cVlYJ5wqPBw8eyMXFRdeuXVOKFCniuzv4wKh3wkK9ExbqnbBQ74SFeics1Dthod4JC/VOWBJqvSMjI/Xw4UM5OzvL2jr2J2Ny78V7YG1t/drE+L8uRYoUCWpwJXTUO2Gh3gkL9U5YqHfCQr0TFuqdsFDvhIV6JywJsd4pU6Z8Yxu+AAgAAAAAAACAIRBmAgAAAAAAADAEwkz8a3Z2dho5cqTs7OziuyuIA9Q7YaHeCQv1Tliod8JCvRMW6p2wUO+EhXonLNT79fgCIAAAAAAAAACGwJWZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAj/B8C8jWAHFBmUAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('best_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cecCHgEViSGR",
        "outputId": "08b757c6-3624-458c-ca59-8f1fa6b00a83"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_597c4199-648a-4987-8104-579f96b5cbef\", \"best_model.pth\", 33606709)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MqGI7P64iUGm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}