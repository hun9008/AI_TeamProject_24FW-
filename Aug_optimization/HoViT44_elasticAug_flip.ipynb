{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "2e5f5308-9d27-42e5-8b80-62eca1a9eba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=5266a9a12f8ad579b87b5703687a1298f304227b032d08de3d03ecd802db55fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "61abc8ff-cd27-4ed6-e581-ee76c088e85a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-25 10:46:15--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.45.92, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-03-25 10:46:16--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  12.0MB/s    in 16m 34s \n",
            "\n",
            "2025-03-25 11:02:50 (11.2 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "c69e8da9-39c4-4c01-ba32-2c7c8f210f6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "996c0706-2906-42ea-d55a-f69da0be98a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "e5b403d8-a807-4670-8cba-3b2c910522a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "48463c25-d6c6-427d-e290-302666b0633b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def elastic_transform(image, alpha, sigma):\n",
        "    \"\"\"탄성 변형 적용\"\"\"\n",
        "\n",
        "    if isinstance(image, torch.Tensor):\n",
        "        image_np = image.permute(1, 2, 0).numpy()\n",
        "    else:\n",
        "        image_np = np.array(image)\n",
        "\n",
        "    shape = image_np.shape[:2]\n",
        "\n",
        "    ksize = 2 * int(sigma) + 1\n",
        "\n",
        "    dx = cv2.GaussianBlur((np.random.rand(*shape) * 2 - 1), (ksize, ksize), sigma) * alpha\n",
        "    dy = cv2.GaussianBlur((np.random.rand(*shape) * 2 - 1), (ksize, ksize), sigma) * alpha\n",
        "    x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
        "\n",
        "    indices = np.stack((y + dy, x + dx), axis=-1).astype(np.float32)\n",
        "    distorted_image = cv2.remap(image_np, indices, None, cv2.INTER_LINEAR)\n",
        "\n",
        "    return distorted_image"
      ],
      "metadata": {
        "id": "YytQAVpEWmF-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation\n",
        "aug_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Lambda(lambda x: elastic_transform(x, alpha=10, sigma=4)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.75),\n",
        "    transforms.RandomVerticalFlip(p=0.75),\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "zja84HaiVhoh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "#train_data = Subset(dataset, load_train_idx)\n",
        "#val_data = Subset(dataset, load_val_idx)\n",
        "#test_data = Subset(dataset, load_test_idx)\n",
        "\n",
        "dataset_train = datasets.ImageFolder(root=train_dir, transform=aug_transform)\n",
        "dataset_eval = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "\n",
        "train_data = Subset(dataset_train, load_train_idx)\n",
        "val_data = Subset(dataset_eval, load_val_idx)\n",
        "test_data = Subset(dataset_eval, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "2b92e233-781f-47f3-c80f-b116f67f3589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "2916015b-d089-4916-dae5-c95bf04a65d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [06:07<00:00,  5.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6921, Train Accuracy: 75.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5543, Validation Accuracy: 81.10%\n",
            "Balanced Accuracy: 0.8021\n",
            "New best model saved with Validation loss 0.5543 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [06:05<00:00,  5.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3621, Train Accuracy: 87.22%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3190, Validation Accuracy: 89.33%\n",
            "Balanced Accuracy: 0.8917\n",
            "New best model saved with Validation loss 0.3190 at best_model.pth\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [06:04<00:00,  6.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2491, Train Accuracy: 91.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2854, Validation Accuracy: 90.27%\n",
            "Balanced Accuracy: 0.9036\n",
            "New best model saved with Validation loss 0.2854 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [06:03<00:00,  6.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1989, Train Accuracy: 93.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5643, Validation Accuracy: 81.85%\n",
            "Balanced Accuracy: 0.8226\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [06:04<00:00,  6.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1626, Train Accuracy: 94.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3718, Validation Accuracy: 88.08%\n",
            "Balanced Accuracy: 0.8747\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [06:02<00:00,  6.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1328, Train Accuracy: 95.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1789, Validation Accuracy: 93.93%\n",
            "Balanced Accuracy: 0.9364\n",
            "New best model saved with Validation loss 0.1789 at best_model.pth\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [06:04<00:00,  6.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1083, Train Accuracy: 96.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1466, Validation Accuracy: 94.85%\n",
            "Balanced Accuracy: 0.9483\n",
            "New best model saved with Validation loss 0.1466 at best_model.pth\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [06:04<00:00,  6.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0894, Train Accuracy: 96.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3522, Validation Accuracy: 88.85%\n",
            "Balanced Accuracy: 0.8903\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [06:05<00:00,  5.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0717, Train Accuracy: 97.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1959, Validation Accuracy: 93.33%\n",
            "Balanced Accuracy: 0.9293\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [06:03<00:00,  6.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0631, Train Accuracy: 97.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0930, Validation Accuracy: 96.92%\n",
            "Balanced Accuracy: 0.9707\n",
            "New best model saved with Validation loss 0.0930 at best_model.pth\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [06:01<00:00,  6.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0543, Train Accuracy: 98.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1591, Validation Accuracy: 95.51%\n",
            "Balanced Accuracy: 0.9518\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:57<00:00,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0451, Train Accuracy: 98.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3710, Validation Accuracy: 89.31%\n",
            "Balanced Accuracy: 0.8920\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:53<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0394, Train Accuracy: 98.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1640, Validation Accuracy: 94.61%\n",
            "Balanced Accuracy: 0.9455\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:53<00:00,  6.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0359, Train Accuracy: 98.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1402, Validation Accuracy: 95.46%\n",
            "Balanced Accuracy: 0.9527\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:54<00:00,  6.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0314, Train Accuracy: 98.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3683, Validation Accuracy: 90.97%\n",
            "Balanced Accuracy: 0.9059\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:54<00:00,  6.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0297, Train Accuracy: 98.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1815, Validation Accuracy: 94.82%\n",
            "Balanced Accuracy: 0.9446\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:53<00:00,  6.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0288, Train Accuracy: 99.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2604, Validation Accuracy: 92.99%\n",
            "Balanced Accuracy: 0.9307\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:53<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0238, Train Accuracy: 99.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1474, Validation Accuracy: 96.55%\n",
            "Balanced Accuracy: 0.9619\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:54<00:00,  6.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0245, Train Accuracy: 99.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3056, Validation Accuracy: 91.22%\n",
            "Balanced Accuracy: 0.9061\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:53<00:00,  6.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0200, Train Accuracy: 99.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0475, Validation Accuracy: 98.53%\n",
            "Balanced Accuracy: 0.9847\n",
            "New best model saved with Validation loss 0.0475 at best_model.pth\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:54<00:00,  6.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0198, Train Accuracy: 99.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0502, Validation Accuracy: 98.56%\n",
            "Balanced Accuracy: 0.9852\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:54<00:00,  6.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0191, Train Accuracy: 99.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9876, Validation Accuracy: 79.43%\n",
            "Balanced Accuracy: 0.7822\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:53<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0189, Train Accuracy: 99.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1923, Validation Accuracy: 95.17%\n",
            "Balanced Accuracy: 0.9555\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:53<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0156, Train Accuracy: 99.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1238, Validation Accuracy: 96.75%\n",
            "Balanced Accuracy: 0.9670\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:54<00:00,  6.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0154, Train Accuracy: 99.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1443, Validation Accuracy: 96.11%\n",
            "Balanced Accuracy: 0.9580\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:54<00:00,  6.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0144, Train Accuracy: 99.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0375, Validation Accuracy: 98.91%\n",
            "Balanced Accuracy: 0.9895\n",
            "New best model saved with Validation loss 0.0375 at best_model.pth\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:54<00:00,  6.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0139, Train Accuracy: 99.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0640, Validation Accuracy: 98.13%\n",
            "Balanced Accuracy: 0.9820\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:54<00:00,  6.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0142, Train Accuracy: 99.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0661, Validation Accuracy: 98.09%\n",
            "Balanced Accuracy: 0.9824\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:53<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0129, Train Accuracy: 99.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0475, Validation Accuracy: 98.59%\n",
            "Balanced Accuracy: 0.9854\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:53<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0114, Train Accuracy: 99.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1872, Validation Accuracy: 95.07%\n",
            "Balanced Accuracy: 0.9519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wDDP-iS8z1Q",
        "outputId": "9d327d53-26fa-4ea6-b062-a57413230cba"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "711593aa-ecb1-4936-abf1-549a4b19abc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:23<00:00, 20.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0444, Test Accuracy: 98.61%\n",
            "Balanced Accuracy: 0.9865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "7cf87bdb-2624-4155-cfee-43a5277e0593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 10.02 ms\n",
            "Standard Deviation: 0.38 ms\n",
            "Maximum Time: 14.95 ms\n",
            "Minimum Time: 9.55 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "aab0f000-2afe-4adb-c084-0583c7b9fd7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul        17.49%       4.364ms        44.69%      11.155ms     232.386us       0.000us         0.00%       5.047ms     105.144us            48  \n",
            "                                           aten::linear         0.70%     174.680us        22.76%       5.681ms     167.096us       0.000us         0.00%       3.615ms     106.315us            34  \n",
            "                                               aten::mm         4.45%       1.111ms        19.71%       4.920ms     153.750us       3.591ms        43.23%       3.591ms     112.217us            32  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.352ms        16.28%       1.352ms     169.001us             8  \n",
            "                                              aten::bmm         1.91%     475.521us         2.43%     607.242us      37.953us       1.134ms        13.66%       1.134ms      70.886us            16  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     987.559us        11.89%     987.559us     123.445us             8  \n",
            "                                       aten::batch_norm         0.92%     230.618us        30.06%       7.503ms     192.397us       0.000us         0.00%     860.866us      22.073us            39  \n",
            "                           aten::_batch_norm_impl_index        13.03%       3.252ms        29.14%       7.273ms     186.483us       0.000us         0.00%     860.866us      22.073us            39  \n",
            "                                            aten::copy_         3.43%     856.191us         7.79%       1.944ms      23.705us     800.518us         9.64%     800.518us       9.762us            82  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     768.005us         9.25%     768.005us      96.001us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 24.961ms\n",
            "Self CUDA time total: 8.306ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4UchJcz1N6K",
        "outputId": "c3e4eed6-00cb-4e28-d42f-5a365a348fea"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:23<00:00, 19.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0444, Test Accuracy: 98.61%\n",
            "Overall - F1: 0.9860, Recall: 0.9865, Precision: 0.9855\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9965, Recall: 0.9994, Precision: 0.9936\n",
            "Class 1 - F1: 0.9994, Recall: 0.9994, Precision: 0.9994\n",
            "Class 2 - F1: 0.9852, Recall: 0.9820, Precision: 0.9883\n",
            "Class 3 - F1: 0.9974, Recall: 0.9971, Precision: 0.9977\n",
            "Class 4 - F1: 0.9762, Recall: 0.9835, Precision: 0.9690\n",
            "Class 5 - F1: 0.9865, Recall: 0.9916, Precision: 0.9815\n",
            "Class 6 - F1: 0.9852, Recall: 0.9856, Precision: 0.9848\n",
            "Class 7 - F1: 0.9676, Recall: 0.9726, Precision: 0.9627\n",
            "Class 8 - F1: 0.9799, Recall: 0.9674, Precision: 0.9928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "ZLcoSxfe1Qbt",
        "outputId": "e37eeae8-dd49-4d1b-c285-a08f7b319ed3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"HoViT_44_elasticAug_flip.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model weights saved to {save_path}\")"
      ],
      "metadata": {
        "id": "MOLSL09JxKdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce9a4379-7656-499a-eb28-20d54cf3c882"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved to HoViT_44_elasticAug_flip.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KFlriCIkXHOr"
      },
      "execution_count": 40,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}