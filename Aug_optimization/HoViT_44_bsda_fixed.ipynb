{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "c9da953b-841d-48e2-8e9f-84ee33c3c4cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=1d4f25a11e80eb8a3607c2200ca3e366b1230352fe067c99d800d8b7fb8db313\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n",
            "--2025-03-28 08:33:31--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.43.25, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-03-28 08:33:32--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  24.1MB/s    in 10m 54s \n",
            "\n",
            "2025-03-28 08:44:26 (17.1 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo\n",
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super().__init__()\n",
        "        self.stem = Stem16()\n",
        "        self.stage1 = LevitStage(256, 256, 4, 4, downsample=False)\n",
        "        self.stage2 = LevitStage(256, 384, 6, 4, downsample=True)\n",
        "        self.conv1x1 = nn.Sequential(nn.Conv2d(384, 512, 1), nn.BatchNorm2d(512), nn.ReLU(True))\n",
        "        self.head = NormLinear(512, num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(512, num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        H = W = int(x.shape[1] ** 0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "        x = self.conv1x1(x)\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        return self.head(x)\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        x = self.stem(x)\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        H = W = int(x.shape[1] ** 0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "        x = self.conv1x1(x)\n",
        "        return torch.mean(x, dim=(2, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "fec67ec7-bd2e-499e-8d2f-b45ae4e7a3e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gNpMsNYAzLDF",
        "outputId": "46511e46-982f-4526-dc01-401d8114507f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.22\n",
            "Params size (MB): 33.32\n",
            "Estimated Total Size (MB): 1444.80\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "98c94185-5076-49bf-a8d6-29e0d2ad32cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.22\n",
            "Params size (MB): 33.32\n",
            "Estimated Total Size (MB): 1444.80\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.22\n",
            "Params size (MB): 33.32\n",
            "Estimated Total Size (MB): 1444.80\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LUiqsuSdOgj0"
      },
      "outputs": [],
      "source": [
        "class BSDALayer(nn.Module):\n",
        "    def __init__(self, feature_dim, bsda_lambda=0.8) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.bsda_lambda = bsda_lambda\n",
        "\n",
        "        self.logvar = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "        )\n",
        "\n",
        "        self.d = nn.Dropout(p=self.bsda_lambda)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "    def modified_indicator_function(self, x):\n",
        "        return torch.where(x >= 0, torch.sign(x), -torch.sign(x))\n",
        "\n",
        "    def calc_a_tilde(self, a, m, multi=1):\n",
        "        a = a.repeat(multi, 1)\n",
        "        return a + self.d(m) * self.modified_indicator_function(a)\n",
        "\n",
        "    def reparameterize(self, mu, logvar, multi=1):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        std = std.repeat(multi, 1)\n",
        "        eps = torch.randn_like(std, device=std.device)\n",
        "        mu = mu.repeat(multi, 1)\n",
        "        return eps * std + mu\n",
        "\n",
        "    def forward(self, a, multi=1):\n",
        "        \"\"\"\n",
        "            a: (batch_size, feature_dim)\n",
        "            m: (batch_size, feature_dim)\n",
        "            mu: (batch_size, feature_dim)\n",
        "            logvar: (batch_size, feature_dim)\n",
        "        \"\"\"\n",
        "        x = self.encoder(a)\n",
        "\n",
        "        logvar = self.logvar(x)\n",
        "        mu = torch.zeros_like(logvar, device=logvar.device)\n",
        "\n",
        "        m = self.reparameterize(mu, logvar, multi)\n",
        "        a_hat = self.decoder(m)\n",
        "\n",
        "        return m, mu, logvar, a_hat\n",
        "\n",
        "    def calc_kl_loss(self, mu, logvar):\n",
        "\n",
        "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        return kl_loss\n",
        "\n",
        "    def calc_recon_loss(self, a, a_hat, multi=1):\n",
        "        recon_loss = torch.mean((a.repeat(multi, 1) - a_hat) ** 2) * 0.5\n",
        "        return recon_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "a5c3b2b9-1dd0-458a-ec6c-0beffc4ee86f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mAsRwMpISMIh"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fnlxaQSs7NsL"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "train_data = Subset(dataset, load_train_idx)\n",
        "val_data = Subset(dataset, load_val_idx)\n",
        "test_data = Subset(dataset, load_test_idx)\n",
        "\n",
        "# dataset_train = datasets.ImageFolder(root=train_dir, transform=aug_transform)\n",
        "# dataset_eval = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "\n",
        "# train_data = Subset(dataset_train, load_train_idx)\n",
        "# val_data = Subset(dataset_eval, load_val_idx)\n",
        "# test_data = Subset(dataset_eval, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "6143c7de-4069-440b-badc-58b63d300a1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch,\n",
        "          use_bsda=False, bsda_layer=None, multi=10, bsda_alpha=0.5,\n",
        "          kl_weight=8e-4, recon_weight=1.0, use_ori=True, num_epochs=30):\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    ratio = min(bsda_alpha * (epoch / (num_epochs // 2)), bsda_alpha) if use_bsda else 0\n",
        "\n",
        "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        features = model.extract_features(inputs)\n",
        "        y_hat = model.head(features)\n",
        "\n",
        "        if use_bsda:\n",
        "            m, mu, logvar, a_hat = bsda_layer(features, multi=multi)\n",
        "            a_tilde = bsda_layer.calc_a_tilde(features, m, multi=multi)\n",
        "            y_hat_tilde = model.head(a_tilde)\n",
        "\n",
        "            loss_task = criterion(y_hat, labels)\n",
        "            loss_task_tilde = criterion(y_hat_tilde, labels.repeat(multi,))\n",
        "            loss_kl = bsda_layer.calc_kl_loss(mu, logvar)\n",
        "            loss_recon = bsda_layer.calc_recon_loss(features, a_hat, multi)\n",
        "            loss_bsda = kl_weight * loss_kl + recon_weight * loss_recon\n",
        "            loss = loss_task_tilde + loss_bsda\n",
        "            if use_ori:\n",
        "                loss = loss * ratio + loss_task\n",
        "        else:\n",
        "            loss = criterion(y_hat, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(y_hat, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Train Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100*correct/total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "b7973c66-c93f-4cae-8e1f-18fb804f9ad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 2188/2188 [02:45<00:00, 13.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1727, Accuracy: 93.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0085, Validation Accuracy: 63.78%\n",
            "Balanced Accuracy: 0.6398\n",
            "New best model saved with Validation loss 1.0085 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 2188/2188 [02:45<00:00, 13.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1893, Accuracy: 95.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.7275, Validation Accuracy: 46.14%\n",
            "Balanced Accuracy: 0.4629\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 2188/2188 [02:45<00:00, 13.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1976, Accuracy: 96.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7751, Validation Accuracy: 70.51%\n",
            "Balanced Accuracy: 0.7022\n",
            "New best model saved with Validation loss 0.7751 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 2188/2188 [02:46<00:00, 13.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2051, Accuracy: 96.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.6014, Validation Accuracy: 57.18%\n",
            "Balanced Accuracy: 0.5865\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 2188/2188 [02:46<00:00, 13.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2056, Accuracy: 97.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1819, Validation Accuracy: 93.67%\n",
            "Balanced Accuracy: 0.9372\n",
            "New best model saved with Validation loss 0.1819 at best_model.pth\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 2188/2188 [02:46<00:00, 13.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2117, Accuracy: 97.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.2322, Validation Accuracy: 63.55%\n",
            "Balanced Accuracy: 0.6060\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 2188/2188 [02:46<00:00, 13.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2168, Accuracy: 98.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0973, Validation Accuracy: 96.57%\n",
            "Balanced Accuracy: 0.9633\n",
            "New best model saved with Validation loss 0.0973 at best_model.pth\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 2188/2188 [02:46<00:00, 13.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2268, Accuracy: 98.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1255, Validation Accuracy: 95.59%\n",
            "Balanced Accuracy: 0.9588\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 2188/2188 [02:45<00:00, 13.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2363, Accuracy: 98.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0665, Validation Accuracy: 97.80%\n",
            "Balanced Accuracy: 0.9771\n",
            "New best model saved with Validation loss 0.0665 at best_model.pth\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 2188/2188 [02:46<00:00, 13.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2373, Accuracy: 98.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0450, Validation Accuracy: 98.66%\n",
            "Balanced Accuracy: 0.9863\n",
            "New best model saved with Validation loss 0.0450 at best_model.pth\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 2188/2188 [02:46<00:00, 13.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2514, Accuracy: 99.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0631, Validation Accuracy: 97.97%\n",
            "Balanced Accuracy: 0.9793\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 2188/2188 [02:47<00:00, 13.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2547, Accuracy: 99.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2949, Validation Accuracy: 89.79%\n",
            "Balanced Accuracy: 0.8896\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 2188/2188 [02:47<00:00, 13.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2708, Accuracy: 99.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0504, Validation Accuracy: 98.33%\n",
            "Balanced Accuracy: 0.9828\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 2188/2188 [02:46<00:00, 13.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2767, Accuracy: 99.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1475, Validation Accuracy: 95.53%\n",
            "Balanced Accuracy: 0.9560\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 2188/2188 [02:47<00:00, 13.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2937, Accuracy: 99.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0407, Validation Accuracy: 98.75%\n",
            "Balanced Accuracy: 0.9880\n",
            "New best model saved with Validation loss 0.0407 at best_model.pth\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 2188/2188 [02:46<00:00, 13.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3022, Accuracy: 99.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0457, Validation Accuracy: 98.49%\n",
            "Balanced Accuracy: 0.9844\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 2188/2188 [02:47<00:00, 13.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2919, Accuracy: 99.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0552, Validation Accuracy: 98.38%\n",
            "Balanced Accuracy: 0.9827\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 2188/2188 [02:48<00:00, 12.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2882, Accuracy: 99.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0400, Validation Accuracy: 98.91%\n",
            "Balanced Accuracy: 0.9893\n",
            "New best model saved with Validation loss 0.0400 at best_model.pth\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 2188/2188 [02:47<00:00, 13.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2803, Accuracy: 99.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1090, Validation Accuracy: 96.98%\n",
            "Balanced Accuracy: 0.9686\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 2188/2188 [02:47<00:00, 13.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2839, Accuracy: 99.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0927, Validation Accuracy: 73.45%\n",
            "Balanced Accuracy: 0.7087\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 2188/2188 [02:47<00:00, 13.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2694, Accuracy: 99.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0579, Validation Accuracy: 79.15%\n",
            "Balanced Accuracy: 0.7906\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 2188/2188 [02:48<00:00, 13.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2702, Accuracy: 99.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2219, Validation Accuracy: 93.75%\n",
            "Balanced Accuracy: 0.9349\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 2188/2188 [02:48<00:00, 12.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2662, Accuracy: 99.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0525, Validation Accuracy: 98.54%\n",
            "Balanced Accuracy: 0.9848\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 2188/2188 [02:47<00:00, 13.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2637, Accuracy: 99.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0854, Validation Accuracy: 97.69%\n",
            "Balanced Accuracy: 0.9786\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 2188/2188 [02:47<00:00, 13.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2674, Accuracy: 99.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0434, Validation Accuracy: 98.87%\n",
            "Balanced Accuracy: 0.9881\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 2188/2188 [02:47<00:00, 13.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2502, Accuracy: 99.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3019, Validation Accuracy: 93.26%\n",
            "Balanced Accuracy: 0.9388\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 2188/2188 [02:48<00:00, 13.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2620, Accuracy: 99.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0476, Validation Accuracy: 98.81%\n",
            "Balanced Accuracy: 0.9878\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 2188/2188 [02:47<00:00, 13.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2537, Accuracy: 99.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0336, Validation Accuracy: 99.21%\n",
            "Balanced Accuracy: 0.9921\n",
            "New best model saved with Validation loss 0.0336 at best_model.pth\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 2188/2188 [02:46<00:00, 13.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2544, Accuracy: 99.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0493, Validation Accuracy: 98.85%\n",
            "Balanced Accuracy: 0.9875\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 2188/2188 [02:46<00:00, 13.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2490, Accuracy: 99.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0563, Validation Accuracy: 98.67%\n",
            "Balanced Accuracy: 0.9869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "bsda_layer = BSDALayer(feature_dim=512, bsda_lambda=0.8).to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch,\n",
        "          use_bsda=True,\n",
        "          bsda_layer=bsda_layer,\n",
        "          multi=10,\n",
        "          bsda_alpha=0.5,\n",
        "          kl_weight=8e-4,\n",
        "          recon_weight=1.0,\n",
        "          use_ori=True,\n",
        "          num_epochs=num_epochs)\n",
        "\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCGf9fvf2-qk",
        "outputId": "27e37a84-d912-4d4d-9b86-c031fd222102"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "61904e16-4a20-47f4-ee95-2c4f5e4a448d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:22<00:00, 20.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0457, Test Accuracy: 98.99%\n",
            "Balanced Accuracy: 0.9900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "c12f543c-917f-4334-986d-29d84be2c153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 10.05 ms\n",
            "Standard Deviation: 0.47 ms\n",
            "Maximum Time: 13.45 ms\n",
            "Minimum Time: 9.53 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "36f58fb6-1949-4eeb-cdb9-d5d4fe9f0879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         7.67%       1.446ms        32.56%       6.139ms     127.899us       0.000us         0.00%       5.099ms     106.223us            48  \n",
            "                                           aten::linear         0.91%     172.471us        18.02%       3.397ms     102.939us       0.000us         0.00%       3.646ms     110.488us            33  \n",
            "                                               aten::mm         7.07%       1.334ms        14.28%       2.693ms      84.149us       3.634ms        43.57%       3.634ms     113.556us            32  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.366ms        16.38%       1.366ms     170.747us             8  \n",
            "                                              aten::bmm         3.00%     565.485us         3.75%     706.093us      44.131us       1.141ms        13.68%       1.141ms      71.317us            16  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     993.528us        11.91%     993.528us     124.191us             8  \n",
            "                                       aten::batch_norm         1.51%     283.772us        30.48%       5.746ms     151.204us       0.000us         0.00%     856.668us      22.544us            38  \n",
            "                           aten::_batch_norm_impl_index         7.73%       1.457ms        28.97%       5.462ms     143.736us       0.000us         0.00%     856.668us      22.544us            38  \n",
            "                                            aten::copy_         4.42%     833.748us        10.51%       1.982ms      24.473us     805.918us         9.66%     805.918us       9.950us            81  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     778.842us         9.34%     778.842us      97.355us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 18.853ms\n",
            "Self CUDA time total: 8.341ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    val_losses.append(epoch_loss)\n",
        "    val_accuracies.append(accuracy)\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubbBuFrU-GRd",
        "outputId": "b5cf68b6-e0e3-4e0d-90ab-c8a029bcfdd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:23<00:00, 19.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0457, Test Accuracy: 98.99%\n",
            "Overall - F1: 0.9898, Recall: 0.9900, Precision: 0.9895\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9984, Recall: 0.9981, Precision: 0.9987\n",
            "Class 1 - F1: 1.0000, Recall: 1.0000, Precision: 1.0000\n",
            "Class 2 - F1: 0.9878, Recall: 0.9861, Precision: 0.9895\n",
            "Class 3 - F1: 0.9980, Recall: 0.9983, Precision: 0.9977\n",
            "Class 4 - F1: 0.9881, Recall: 0.9955, Precision: 0.9808\n",
            "Class 5 - F1: 0.9894, Recall: 0.9842, Precision: 0.9945\n",
            "Class 6 - F1: 0.9825, Recall: 0.9817, Precision: 0.9832\n",
            "Class 7 - F1: 0.9755, Recall: 0.9770, Precision: 0.9739\n",
            "Class 8 - F1: 0.9884, Recall: 0.9893, Precision: 0.9874\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "3qaLb5c--H0Q",
        "outputId": "6db48402-a7a5-4e2d-c244-faf5dc66b658"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29ACr21nOjBW",
        "outputId": "a58dd2b9-64b5-40b8-c469-33471708e149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved to HoViT_44_bsda_fixed.pth\n"
          ]
        }
      ],
      "source": [
        "save_path = \"HoViT_44_bsda_fixed.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model weights saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCHdGKmbuw9W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2NMYNeV0Ly5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}