{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "9b14b9cf-0f91-4fe5-cf3b-9015a55a2f63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=f442f387a0f792bb495513eadecaf4662f6b0895c2e88b8f74226dbd5b71bdab\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n",
            "--2025-03-27 05:44:10--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.45.92, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-03-27 05:44:11--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  17.7MB/s    in 14m 6s  \n",
            "\n",
            "2025-03-27 05:58:17 (13.2 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo\n",
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "87e8b27c-f78a-4c0c-883e-9e97b134e929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "2129d1b4-e17f-49e3-824b-5b1b884f8dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDELjYy2zP90",
        "outputId": "11d7c057-4c67-4d86-bb16-d7132026f2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BSDALayer(nn.Module):\n",
        "    def __init__(self, feature_dim, bsda_lambda=0.8) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.bsda_lambda = bsda_lambda\n",
        "\n",
        "        self.logvar = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "        )\n",
        "\n",
        "        self.d = nn.Dropout(p=self.bsda_lambda)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "    def modified_indicator_function(self, x):\n",
        "        return torch.where(x >= 0, torch.sign(x), -torch.sign(x))\n",
        "\n",
        "    def calc_a_tilde(self, a, m, multi=1):\n",
        "        a = a.repeat(multi, 1)\n",
        "        return a + self.d(m) * self.modified_indicator_function(a)\n",
        "\n",
        "    def reparameterize(self, mu, logvar, multi=1):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        std = std.repeat(multi, 1)\n",
        "        eps = torch.randn_like(std, device=std.device)\n",
        "        mu = mu.repeat(multi, 1)\n",
        "        return eps * std + mu\n",
        "\n",
        "    def forward(self, a, multi=1):\n",
        "        \"\"\"\n",
        "            a: (batch_size, feature_dim)\n",
        "            m: (batch_size, feature_dim)\n",
        "            mu: (batch_size, feature_dim)\n",
        "            logvar: (batch_size, feature_dim)\n",
        "        \"\"\"\n",
        "        x = self.encoder(a)\n",
        "\n",
        "        logvar = self.logvar(x)\n",
        "        mu = torch.zeros_like(logvar, device=logvar.device)\n",
        "\n",
        "        m = self.reparameterize(mu, logvar, multi)\n",
        "        a_hat = self.decoder(m)\n",
        "\n",
        "        return m, mu, logvar, a_hat\n",
        "\n",
        "    def calc_kl_loss(self, mu, logvar):\n",
        "\n",
        "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        return kl_loss\n",
        "\n",
        "    def calc_recon_loss(self, a, a_hat, multi=1):\n",
        "        recon_loss = torch.mean((a.repeat(multi, 1) - a_hat) ** 2) * 0.5\n",
        "        return recon_loss\n"
      ],
      "metadata": {
        "id": "LUiqsuSdOgj0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BSDAWarp(nn.Module):\n",
        "    def __init__(self, backbone, num_classes, info, feature_dim=None, fc_name=None, bsda_kl_weight=8e-4, bsda_recon_weight=1) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = backbone\n",
        "\n",
        "        self.feature_dim = 512\n",
        "        self.backbone.head = nn.Identity()\n",
        "        self.backbone.head_dist = nn.Identity()\n",
        "\n",
        "\n",
        "        self.multi = info['bsda_multi']\n",
        "        self.use_ori = info['bsda_use_ori']\n",
        "        self.bsda_lambda = info['bsda_lambda']\n",
        "        self.n_channels = info['n_channels']\n",
        "        # self.train_eval = info['train_evaluator']\n",
        "        # self.val_eval = info['val_evaluator']\n",
        "        # self.test_eval = info['test_evaluator']\n",
        "\n",
        "\n",
        "        self.linear = nn.Linear(self.feature_dim, num_classes)\n",
        "        self.bsda_layer = BSDALayer(self.feature_dim, self.bsda_lambda)\n",
        "\n",
        "\n",
        "        self.linear = self.linear.to(next(self.backbone.parameters()).device)\n",
        "        self.bsda_layer = self.bsda_layer.to(next(self.backbone.parameters()).device)\n",
        "\n",
        "\n",
        "        self.bsda_kl_weight = bsda_kl_weight\n",
        "        self.bsda_recon_weight = bsda_recon_weight\n",
        "\n",
        "\n",
        "    def get_loss(self, outputs, targets, criterion, logger=None, writer=None, epoch=None, is_train=False, bsda_alpha=0.5, task=''):\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.float()\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "        if not is_train:\n",
        "            # print(outputs.shape)\n",
        "            # print(targets.shape)\n",
        "            return criterion(outputs, targets)\n",
        "\n",
        "        (y_hat, y_hat_tilde), (a, a_tilde, a_hat, m, mu, logvar)= outputs\n",
        "\n",
        "        loss_task = criterion(y_hat, targets)\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            loss_task_tilde = criterion(y_hat_tilde, targets.repeat(self.multi, 1))\n",
        "        else:\n",
        "            loss_task_tilde = criterion(y_hat_tilde, targets.repeat(self.multi, ))\n",
        "\n",
        "        loss_bsda_kl = self.bsda_layer.calc_kl_loss(mu, logvar)\n",
        "        loss_bsda_recon = self.bsda_layer.calc_recon_loss(a, a_hat, self.multi)\n",
        "\n",
        "        loss_bsda = loss_bsda_kl * self.bsda_kl_weight + loss_bsda_recon * self.bsda_recon_weight\n",
        "\n",
        "        loss = loss_task_tilde + loss_bsda\n",
        "\n",
        "        if self.use_ori:\n",
        "            loss = loss * bsda_alpha + loss_task\n",
        "\n",
        "\n",
        "        if logger is not None and writer is not None and epoch is not None:\n",
        "            if epoch % 10 == 0:\n",
        "                logger.info(f'loss: {loss.item():.4f}, loss_task: {loss_task.item():.4f}, loss_task_tilde: {loss_task_tilde.item():.4f}, loss_bsda: {loss_bsda.item():.4f}, loss_bsda_kl: {loss_bsda_kl.item():.4f}, loss_bsda_recon: {loss_bsda_recon.item():.4f}, bsda_alpha:{bsda_alpha}')\n",
        "            writer.add_scalar('loss_task', loss_task.item(), epoch)\n",
        "            writer.add_scalar('loss_task_tilde', loss_task_tilde.item(), epoch)\n",
        "            writer.add_scalar('loss_bsda_kl', loss_bsda_kl.item(), epoch)\n",
        "            writer.add_scalar('loss_bsda_recon', loss_bsda_recon.item(), epoch)\n",
        "            writer.add_scalar('loss_bsda', loss_bsda.item(), epoch)\n",
        "            writer.add_scalar('loss', loss.item(), epoch)\n",
        "            writer.add_scalar('bsda_alpha', bsda_alpha, epoch)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x, is_train=False):\n",
        "        \"\"\"\n",
        "            all signature accrording to the bsda paper on arxiv\n",
        "\n",
        "            x: (batch_size, n_channels, height, width)\n",
        "            a: (batch_size, feature_dim)\n",
        "            y_hat: (batch_size, num_classes)\n",
        "            y_hat_tilde: (batch_size, num_classes)\n",
        "            a_tilde: (batch_size, feature_dim)\n",
        "            a_hat: (batch_size, feature_dim)\n",
        "            m: (batch_size, feature_dim)\n",
        "            mu: (batch_size, feature_dim)\n",
        "            logvar: (batch_size, feature_dim)\n",
        "        \"\"\"\n",
        "        a = self.backbone(x)\n",
        "        y_hat = self.linear(a)\n",
        "\n",
        "        if not is_train:\n",
        "            return y_hat\n",
        "\n",
        "        m, mu, logvar, a_hat = self.bsda_layer(a, multi=self.multi)\n",
        "\n",
        "        a_tilde = self.bsda_layer.calc_a_tilde(a, m, multi=self.multi)\n",
        "        y_hat_tilde = self.linear(a_tilde)\n",
        "\n",
        "        return (y_hat, y_hat_tilde), (a, a_tilde, a_hat, m, mu, logvar)\n"
      ],
      "metadata": {
        "id": "N4TN1T6UOXKP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4c2b991c"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Your script description')\n",
        "\n",
        "\n",
        "parser.add_argument('--resize', action='store_true', help='Resize images')\n",
        "parser.add_argument('--bsda', action='store_true', help='Use BSDA')\n",
        "parser.add_argument('--bsda_lambda', type=float, default=0.8, help='BSDA lambda value')\n",
        "parser.add_argument('--bsda_multi', type=int, default=10, help='BSDA multi value')\n",
        "parser.add_argument('--bsda_use_ori', action='store_true', help='Use original images in BSDA')\n",
        "parser.add_argument('--bsda_alpha', type=float, default=0.5, help='BSDA alpha value')\n",
        "parser.add_argument('--model_name', type=str, default='resnet18', help='Model name')\n",
        "args_list = \"--resize --bsda --bsda_lambda 0.8 --bsda_multi 10 --bsda_use_ori --bsda_alpha 0.5 --model_name resnet18\".split()\n",
        "\n",
        "args = parser.parse_args(args_list)\n",
        "\n",
        "\n",
        "data_info = {\n",
        "        'n_channels': 1,\n",
        "        'bsda_lambda': args.bsda_lambda,\n",
        "        'bsda_multi': args.bsda_multi,\n",
        "        'bsda_use_ori': args.bsda_use_ori,\n",
        "}\n",
        "model = model\n",
        "bsda_warp = BSDAWarp(model, num_classes=9, info=data_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "a85d22b6-455f-413a-8b75-12e6568ac223"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): Identity()\n",
              "  (head_dist): Identity()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.color import rgb2hed, hed2rgb\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "id": "Jv3bwCkSIP4o"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mAsRwMpISMIh"
      },
      "outputs": [],
      "source": [
        "# Augmentation\n",
        "aug_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.75),\n",
        "    transforms.RandomVerticalFlip(p=0.75),\n",
        "    transforms.GaussianBlur(kernel_size=3, sigma=(0.5, 0.5)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "fnlxaQSs7NsL"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "#train_data = Subset(dataset, load_train_idx)\n",
        "#val_data = Subset(dataset, load_val_idx)\n",
        "#test_data = Subset(dataset, load_test_idx)\n",
        "\n",
        "dataset_train = datasets.ImageFolder(root=train_dir, transform=aug_transform)\n",
        "dataset_eval = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "\n",
        "train_data = Subset(dataset_train, load_train_idx)\n",
        "val_data = Subset(dataset_eval, load_val_idx)\n",
        "test_data = Subset(dataset_eval, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "899e79f8-1736-447d-9a32-6496050c51a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch, bsda_warp=None, num_epochs=None):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "\n",
        "    ratio = min(0.5 * (epoch / (num_epochs // 2)), 0.5) if bsda_warp and num_epochs else 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if bsda_warp:\n",
        "            outputs = bsda_warp(inputs, is_train=True)\n",
        "            loss = bsda_warp.get_loss(outputs, labels, criterion, bsda_alpha=ratio, is_train=True)\n",
        "        else:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "15797513-c8f5-42e3-efc0-54a15a41a39d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:33<00:00,  6.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.8045, Train Accuracy: 77.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.3640, Validation Accuracy: 86.59%\n",
            "Balanced Accuracy: 0.8625\n",
            "New best model saved with Validation loss 1.3640 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:33<00:00,  6.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.9757, Train Accuracy: 88.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5676, Validation Accuracy: 89.87%\n",
            "Balanced Accuracy: 0.8941\n",
            "New best model saved with Validation loss 0.5676 at best_model.pth\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4666, Train Accuracy: 92.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6447, Validation Accuracy: 86.43%\n",
            "Balanced Accuracy: 0.8545\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2814, Train Accuracy: 94.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7389, Validation Accuracy: 80.93%\n",
            "Balanced Accuracy: 0.7911\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:33<00:00,  6.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1901, Train Accuracy: 95.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7015, Validation Accuracy: 85.03%\n",
            "Balanced Accuracy: 0.8368\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1380, Train Accuracy: 96.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5296, Validation Accuracy: 82.86%\n",
            "Balanced Accuracy: 0.8203\n",
            "New best model saved with Validation loss 0.5296 at best_model.pth\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:33<00:00,  6.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1070, Train Accuracy: 97.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3567, Validation Accuracy: 89.85%\n",
            "Balanced Accuracy: 0.8930\n",
            "New best model saved with Validation loss 0.3567 at best_model.pth\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0850, Train Accuracy: 97.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3642, Validation Accuracy: 91.61%\n",
            "Balanced Accuracy: 0.9104\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0716, Train Accuracy: 98.06%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1433, Validation Accuracy: 95.99%\n",
            "Balanced Accuracy: 0.9580\n",
            "New best model saved with Validation loss 0.1433 at best_model.pth\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0612, Train Accuracy: 98.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2219, Validation Accuracy: 93.97%\n",
            "Balanced Accuracy: 0.9388\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:30<00:00,  6.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0501, Train Accuracy: 98.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2825, Validation Accuracy: 92.12%\n",
            "Balanced Accuracy: 0.9174\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0435, Train Accuracy: 98.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2831, Validation Accuracy: 91.45%\n",
            "Balanced Accuracy: 0.9086\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0395, Train Accuracy: 98.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1723, Validation Accuracy: 95.27%\n",
            "Balanced Accuracy: 0.9489\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0345, Train Accuracy: 98.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0992, Validation Accuracy: 96.75%\n",
            "Balanced Accuracy: 0.9644\n",
            "New best model saved with Validation loss 0.0992 at best_model.pth\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0332, Train Accuracy: 99.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1290, Validation Accuracy: 95.81%\n",
            "Balanced Accuracy: 0.9555\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0278, Train Accuracy: 99.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3425, Validation Accuracy: 91.17%\n",
            "Balanced Accuracy: 0.9013\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0284, Train Accuracy: 99.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0373, Validation Accuracy: 98.83%\n",
            "Balanced Accuracy: 0.9876\n",
            "New best model saved with Validation loss 0.0373 at best_model.pth\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0232, Train Accuracy: 99.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0402, Validation Accuracy: 98.79%\n",
            "Balanced Accuracy: 0.9870\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:30<00:00,  6.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0227, Train Accuracy: 99.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7687, Validation Accuracy: 83.95%\n",
            "Balanced Accuracy: 0.8220\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0205, Train Accuracy: 99.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1653, Validation Accuracy: 95.12%\n",
            "Balanced Accuracy: 0.9482\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0194, Train Accuracy: 99.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0640, Validation Accuracy: 98.00%\n",
            "Balanced Accuracy: 0.9794\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0186, Train Accuracy: 99.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0546, Validation Accuracy: 98.42%\n",
            "Balanced Accuracy: 0.9829\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0166, Train Accuracy: 99.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0317, Validation Accuracy: 98.94%\n",
            "Balanced Accuracy: 0.9890\n",
            "New best model saved with Validation loss 0.0317 at best_model.pth\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:30<00:00,  6.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0154, Train Accuracy: 99.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0541, Validation Accuracy: 98.41%\n",
            "Balanced Accuracy: 0.9839\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0159, Train Accuracy: 99.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0516, Validation Accuracy: 98.34%\n",
            "Balanced Accuracy: 0.9827\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0137, Train Accuracy: 99.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0415, Validation Accuracy: 98.71%\n",
            "Balanced Accuracy: 0.9857\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0134, Train Accuracy: 99.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1052, Validation Accuracy: 97.21%\n",
            "Balanced Accuracy: 0.9705\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0126, Train Accuracy: 99.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0492, Validation Accuracy: 98.51%\n",
            "Balanced Accuracy: 0.9852\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0130, Train Accuracy: 99.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0399, Validation Accuracy: 98.81%\n",
            "Balanced Accuracy: 0.9881\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0107, Train Accuracy: 99.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1516, Validation Accuracy: 95.65%\n",
            "Balanced Accuracy: 0.9545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCGf9fvf2-qk",
        "outputId": "d768ed81-6485-4750-cbd3-f81282770265"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "b55eed5e-88c1-453e-992d-ca882667a8c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:23<00:00, 20.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0402, Test Accuracy: 98.78%\n",
            "Balanced Accuracy: 0.9874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "adc5604d-ec62-435a-b09e-66385ff94ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 10.01 ms\n",
            "Standard Deviation: 0.70 ms\n",
            "Maximum Time: 16.59 ms\n",
            "Minimum Time: 9.43 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "54da519b-35cf-4da0-cbac-cedf7ca48ee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul        24.35%       9.870ms        55.82%      22.622ms     471.289us       0.000us         0.00%       5.049ms     105.188us            48  \n",
            "                                           aten::linear         0.42%     172.047us        28.12%      11.397ms     356.142us       0.000us         0.00%       3.595ms     112.344us            32  \n",
            "                                               aten::mm         2.84%       1.152ms        26.64%      10.797ms     337.410us       3.595ms        43.68%       3.595ms     112.344us            32  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.353ms        16.44%       1.353ms     169.168us             8  \n",
            "                                              aten::bmm         1.21%     491.246us         1.54%     622.873us      38.930us       1.134ms        13.78%       1.134ms      70.874us            16  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     987.489us        12.00%     987.489us     123.436us             8  \n",
            "                                       aten::batch_norm         0.55%     223.611us        27.93%      11.318ms     305.893us       0.000us         0.00%     830.115us      22.436us            37  \n",
            "                           aten::_batch_norm_impl_index        17.70%       7.173ms        27.38%      11.094ms     299.850us       0.000us         0.00%     830.115us      22.436us            37  \n",
            "                                            aten::copy_         2.04%     828.433us         4.67%       1.894ms      23.675us     782.207us         9.50%     782.207us       9.778us            80  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     770.818us         9.37%     770.818us      96.352us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 40.527ms\n",
            "Self CUDA time total: 8.231ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    val_losses.append(epoch_loss)\n",
        "    val_accuracies.append(accuracy)\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubbBuFrU-GRd",
        "outputId": "2cc5604b-5815-4658-9804-f6e17f7e0955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:23<00:00, 19.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0402, Test Accuracy: 98.78%\n",
            "Overall - F1: 0.9878, Recall: 0.9874, Precision: 0.9883\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9987, Recall: 0.9987, Precision: 0.9987\n",
            "Class 1 - F1: 1.0000, Recall: 1.0000, Precision: 1.0000\n",
            "Class 2 - F1: 0.9782, Recall: 0.9861, Precision: 0.9704\n",
            "Class 3 - F1: 0.9991, Recall: 0.9988, Precision: 0.9994\n",
            "Class 4 - F1: 0.9873, Recall: 0.9895, Precision: 0.9851\n",
            "Class 5 - F1: 0.9880, Recall: 0.9926, Precision: 0.9834\n",
            "Class 6 - F1: 0.9870, Recall: 0.9802, Precision: 0.9938\n",
            "Class 7 - F1: 0.9666, Recall: 0.9521, Precision: 0.9816\n",
            "Class 8 - F1: 0.9854, Recall: 0.9884, Precision: 0.9824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "3qaLb5c--H0Q",
        "outputId": "8e2c81e3-1d31-4fc1-e339-ae5981c944b0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29ACr21nOjBW",
        "outputId": "37d788dc-dfdd-46ee-9c68-d251ffeb43b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved to HoViT_44_bsda_flip_Gaussian.pth\n"
          ]
        }
      ],
      "source": [
        "save_path = \"HoViT_44_bsda_flip_Gaussian.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model weights saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QCHdGKmbuw9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2NMYNeV0Ly5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}