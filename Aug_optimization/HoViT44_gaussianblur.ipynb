{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "827ae611-ba43-4298-c3a1-7fb52d5adbba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=980a767068d636acd90a0f5e81a2211e1155192ae4dba24bad720ccb21dba8f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "8773d76c-5318-4e75-ebb2-5d9ca803a0f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-24 10:25:40--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.48.194, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-03-24 10:25:41--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  20.6MB/s    in 25m 4s  \n",
            "\n",
            "2025-03-24 10:50:45 (7.41 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "ee214488-a001-442e-a849-164e18f60570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "fd281beb-059d-4ef3-9784-3e3e25e9bc62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "cb6935f0-8c7e-49b1-e424-f48f2bc0e263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "e4bf8d50-30bc-4c94-e70d-acb59dc196d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.color import rgb2hed, hed2rgb\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "id": "_XOsreNaIoSQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nkbdj8q8sSAn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    #transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.01),\n",
        "    transforms.GaussianBlur(kernel_size=(3), sigma=(0.1, 1)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "zja84HaiVhoh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "YDaTgqOuPUej"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "train_dataset_full = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "test_dataset_full = datasets.ImageFolder(root=train_dir, transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "train_data = Subset(train_dataset_full, load_train_idx)\n",
        "val_data = Subset(test_dataset_full, load_val_idx)\n",
        "test_data = Subset(test_dataset_full, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "1f4577d4-c76b-4af7-f57f-173ea2324515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "b5e3db7d-139f-4963-8e6b-a65fe7302dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:27<00:00,  6.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6829, Train Accuracy: 75.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3386, Validation Accuracy: 87.89%\n",
            "Balanced Accuracy: 0.8770\n",
            "New best model saved with Validation loss 0.3386 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:27<00:00,  6.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3422, Train Accuracy: 87.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2647, Validation Accuracy: 90.93%\n",
            "Balanced Accuracy: 0.9089\n",
            "New best model saved with Validation loss 0.2647 at best_model.pth\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:26<00:00,  6.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2305, Train Accuracy: 92.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2616, Validation Accuracy: 90.89%\n",
            "Balanced Accuracy: 0.9012\n",
            "New best model saved with Validation loss 0.2616 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:26<00:00,  6.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1836, Train Accuracy: 93.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5993, Validation Accuracy: 80.23%\n",
            "Balanced Accuracy: 0.7912\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:25<00:00,  6.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1464, Train Accuracy: 95.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9805, Validation Accuracy: 71.27%\n",
            "Balanced Accuracy: 0.6927\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:28<00:00,  6.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1195, Train Accuracy: 95.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4984, Validation Accuracy: 85.12%\n",
            "Balanced Accuracy: 0.8488\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:26<00:00,  6.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0939, Train Accuracy: 96.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2373, Validation Accuracy: 92.37%\n",
            "Balanced Accuracy: 0.9160\n",
            "New best model saved with Validation loss 0.2373 at best_model.pth\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:27<00:00,  6.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0754, Train Accuracy: 97.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5716, Validation Accuracy: 84.68%\n",
            "Balanced Accuracy: 0.8401\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:28<00:00,  6.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0600, Train Accuracy: 97.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2013, Validation Accuracy: 93.30%\n",
            "Balanced Accuracy: 0.9287\n",
            "New best model saved with Validation loss 0.2013 at best_model.pth\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:30<00:00,  6.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0515, Train Accuracy: 98.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.4768, Validation Accuracy: 70.96%\n",
            "Balanced Accuracy: 0.7121\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:29<00:00,  6.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0460, Train Accuracy: 98.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2842, Validation Accuracy: 91.99%\n",
            "Balanced Accuracy: 0.9106\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:30<00:00,  6.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0360, Train Accuracy: 98.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2572, Validation Accuracy: 92.82%\n",
            "Balanced Accuracy: 0.9301\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:27<00:00,  6.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0338, Train Accuracy: 98.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3092, Validation Accuracy: 91.71%\n",
            "Balanced Accuracy: 0.9074\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:28<00:00,  6.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0264, Train Accuracy: 99.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.2136, Validation Accuracy: 73.65%\n",
            "Balanced Accuracy: 0.7356\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:28<00:00,  6.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0249, Train Accuracy: 99.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2320, Validation Accuracy: 93.87%\n",
            "Balanced Accuracy: 0.9343\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:27<00:00,  6.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0253, Train Accuracy: 99.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4095, Validation Accuracy: 93.42%\n",
            "Balanced Accuracy: 0.9274\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:28<00:00,  6.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0197, Train Accuracy: 99.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1858, Validation Accuracy: 94.99%\n",
            "Balanced Accuracy: 0.9453\n",
            "New best model saved with Validation loss 0.1858 at best_model.pth\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:28<00:00,  6.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0191, Train Accuracy: 99.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0870, Validation Accuracy: 97.50%\n",
            "Balanced Accuracy: 0.9722\n",
            "New best model saved with Validation loss 0.0870 at best_model.pth\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:28<00:00,  6.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0172, Train Accuracy: 99.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2583, Validation Accuracy: 93.91%\n",
            "Balanced Accuracy: 0.9433\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:28<00:00,  6.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0161, Train Accuracy: 99.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0575, Validation Accuracy: 98.33%\n",
            "Balanced Accuracy: 0.9824\n",
            "New best model saved with Validation loss 0.0575 at best_model.pth\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:28<00:00,  6.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0162, Train Accuracy: 99.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 4.0242, Validation Accuracy: 49.21%\n",
            "Balanced Accuracy: 0.4662\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:28<00:00,  6.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0153, Train Accuracy: 99.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0843, Validation Accuracy: 97.66%\n",
            "Balanced Accuracy: 0.9748\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:28<00:00,  6.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0125, Train Accuracy: 99.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0752, Validation Accuracy: 97.99%\n",
            "Balanced Accuracy: 0.9797\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:28<00:00,  6.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0147, Train Accuracy: 99.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0872, Validation Accuracy: 97.47%\n",
            "Balanced Accuracy: 0.9760\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:28<00:00,  6.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0112, Train Accuracy: 99.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0758, Validation Accuracy: 97.87%\n",
            "Balanced Accuracy: 0.9797\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:28<00:00,  6.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0114, Train Accuracy: 99.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0379, Validation Accuracy: 98.85%\n",
            "Balanced Accuracy: 0.9886\n",
            "New best model saved with Validation loss 0.0379 at best_model.pth\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:29<00:00,  6.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0113, Train Accuracy: 99.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0758, Validation Accuracy: 97.77%\n",
            "Balanced Accuracy: 0.9761\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0107, Train Accuracy: 99.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0503, Validation Accuracy: 98.55%\n",
            "Balanced Accuracy: 0.9853\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:29<00:00,  6.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0087, Train Accuracy: 99.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0856, Validation Accuracy: 97.91%\n",
            "Balanced Accuracy: 0.9790\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:29<00:00,  6.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0109, Train Accuracy: 99.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0481, Validation Accuracy: 98.71%\n",
            "Balanced Accuracy: 0.9873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "c5cd5192-0bf5-4ea7-a3b1-582c4ddfc1ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:23<00:00, 19.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0589, Test Accuracy: 98.58%\n",
            "Balanced Accuracy: 0.9860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "bc0b9a21-57fc-49d8-fc0b-7878ffe3f8b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 10.30 ms\n",
            "Standard Deviation: 0.35 ms\n",
            "Maximum Time: 12.89 ms\n",
            "Minimum Time: 9.81 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "4f7ee211-2947-40c6-f9af-9031b447a0ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         8.77%       1.577ms        33.10%       5.953ms     124.022us       0.000us         0.00%       5.053ms     105.280us            48  \n",
            "                                           aten::linear         1.02%     182.963us        17.99%       3.235ms      95.146us       0.000us         0.00%       3.625ms     106.608us            34  \n",
            "                                               aten::mm         6.05%       1.089ms        13.62%       2.449ms      76.534us       3.601ms        43.35%       3.601ms     112.522us            32  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.353ms        16.29%       1.353ms     169.183us             8  \n",
            "                                              aten::bmm         2.77%     498.717us         3.59%     645.821us      40.364us       1.133ms        13.64%       1.133ms      70.814us            16  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     986.618us        11.88%     986.618us     123.327us             8  \n",
            "                                       aten::batch_norm         1.35%     242.749us        30.54%       5.492ms     140.823us       0.000us         0.00%     864.990us      22.179us            39  \n",
            "                           aten::_batch_norm_impl_index         6.73%       1.211ms        29.19%       5.249ms     134.598us       0.000us         0.00%     864.990us      22.179us            39  \n",
            "                                            aten::copy_         4.48%     805.926us        10.85%       1.950ms      23.785us     793.185us         9.55%     793.185us       9.673us            82  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     771.454us         9.29%     771.454us      96.432us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 17.984ms\n",
            "Self CUDA time total: 8.306ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xc2tPigjv6Is"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"HoViT44_withAug_7Ktest.pth\")\n",
        "#model.load_state_dict(torch.load(\"HoViT44_withAug_7Ktest.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbSpMMWGk3bf",
        "outputId": "b3d9f23d-9351-48a1-d8b7-6e7c84120ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-24 14:06:06--  https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.48.194, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 800276929 (763M) [application/octet-stream]\n",
            "Saving to: ‘CRC-VAL-HE-7K.zip’\n",
            "\n",
            "CRC-VAL-HE-7K.zip   100%[===================>] 763.20M  16.1MB/s    in 12m 18s \n",
            "\n",
            "2025-03-24 14:18:24 (1.03 MB/s) - ‘CRC-VAL-HE-7K.zip’ saved [800276929/800276929]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O CRC-VAL-HE-7K.zip https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
        "!unzip -qq CRC-VAL-HE-7K.zip -d val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "rldaXFNXpT4r"
      },
      "outputs": [],
      "source": [
        "test_7k_dir = './val/CRC-VAL-HE-7K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "6oLIYyRG9dVi"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Belqw8QytnZL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "test7k_dataset = datasets.ImageFolder(root=test_7k_dir, transform=test_transform)\n",
        "test7k_dataloader = DataLoader(test7k_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2y3cywDpjUQ",
        "outputId": "dfd03479-d622-4880-a0dc-18add80fa7c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 225/225 [00:11<00:00, 19.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.0912, Test Accuracy: 89.42%\n",
            "Overall - F1: 0.8526, Recall: 0.8664, Precision: 0.8660\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9418, Recall: 0.8954, Precision: 0.9934\n",
            "Class 1 - F1: 0.9947, Recall: 1.0000, Precision: 0.9895\n",
            "Class 2 - F1: 0.6687, Recall: 0.9587, Precision: 0.5134\n",
            "Class 3 - F1: 0.9387, Recall: 0.9543, Precision: 0.9237\n",
            "Class 4 - F1: 0.9281, Recall: 0.9604, Precision: 0.8979\n",
            "Class 5 - F1: 0.7402, Recall: 0.7314, Precision: 0.7491\n",
            "Class 6 - F1: 0.9318, Recall: 0.9028, Precision: 0.9626\n",
            "Class 7 - F1: 0.5836, Recall: 0.4561, Precision: 0.8101\n",
            "Class 8 - F1: 0.9460, Recall: 0.9384, Precision: 0.9538\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test7k_dataloader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "p4pYjMPUpy2m",
        "outputId": "b525382b-ef18-49c4-fa6e-820642602ec5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}