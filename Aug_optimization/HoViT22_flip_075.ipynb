{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "eeb6fe07-d079-4c88-b897-03bbfddbd430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=c0ca570665d4f6f3cf5ab97131eda1106f6a2f77b9e19031d76dc63a9855d07e\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "70fa0b21-bcfc-4223-c715-2fc31fa063ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-01 15:39:19--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.43.25, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-04-01 15:39:20--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  17.9MB/s    in 10m 42s \n",
            "\n",
            "2025-04-01 15:50:02 (17.4 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=2, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=2, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "8f89372d-4fe8-4dbb-cf94-39c5d74df8aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "422a2476-264a-4987-f73b-7c44f5f3f289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 4,909,234\n",
            "Trainable params: 4,909,234\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.82\n",
            "Params size (MB): 19.64\n",
            "Estimated Total Size (MB): 936.72\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "2234d5d6-1edf-402e-ed5d-85e617abcb46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.82\n",
            "Params size (MB): 19.64\n",
            "Estimated Total Size (MB): 936.72\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.82\n",
            "Params size (MB): 19.64\n",
            "Estimated Total Size (MB): 936.72\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "2252c32c-d406-4920-dd1b-f4370df79410"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation\n",
        "aug_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.75),\n",
        "    transforms.RandomVerticalFlip(p=0.75),\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "zja84HaiVhoh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "#train_data = Subset(dataset, load_train_idx)\n",
        "#val_data = Subset(dataset, load_val_idx)\n",
        "#test_data = Subset(dataset, load_test_idx)\n",
        "\n",
        "dataset_train = datasets.ImageFolder(root=train_dir, transform=aug_transform)\n",
        "dataset_eval = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "\n",
        "train_data = Subset(dataset_train, load_train_idx)\n",
        "val_data = Subset(dataset_eval, load_val_idx)\n",
        "test_data = Subset(dataset_eval, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "34ec7477-91a5-4dd3-c142-e44570b4d7e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "18398e3f-2827-456b-e129-eb91b89d0a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:24<00:00, 15.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4992, Train Accuracy: 82.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4491, Validation Accuracy: 84.44%\n",
            "Balanced Accuracy: 0.8443\n",
            "New best model saved with Validation loss 0.4491 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2326, Train Accuracy: 91.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2552, Validation Accuracy: 90.78%\n",
            "Balanced Accuracy: 0.9108\n",
            "New best model saved with Validation loss 0.2552 at best_model.pth\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1653, Train Accuracy: 94.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0032, Validation Accuracy: 74.11%\n",
            "Balanced Accuracy: 0.7091\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1260, Train Accuracy: 95.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3249, Validation Accuracy: 88.57%\n",
            "Balanced Accuracy: 0.8790\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1011, Train Accuracy: 96.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0291, Validation Accuracy: 74.45%\n",
            "Balanced Accuracy: 0.7344\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0821, Train Accuracy: 97.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2086, Validation Accuracy: 92.92%\n",
            "Balanced Accuracy: 0.9296\n",
            "New best model saved with Validation loss 0.2086 at best_model.pth\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0712, Train Accuracy: 97.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7668, Validation Accuracy: 79.87%\n",
            "Balanced Accuracy: 0.7821\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:21<00:00, 15.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0582, Train Accuracy: 98.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1057, Validation Accuracy: 96.50%\n",
            "Balanced Accuracy: 0.9622\n",
            "New best model saved with Validation loss 0.1057 at best_model.pth\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0515, Train Accuracy: 98.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2582, Validation Accuracy: 91.68%\n",
            "Balanced Accuracy: 0.9206\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:21<00:00, 15.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0426, Train Accuracy: 98.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4020, Validation Accuracy: 89.93%\n",
            "Balanced Accuracy: 0.8927\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:21<00:00, 15.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0387, Train Accuracy: 98.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1161, Validation Accuracy: 96.64%\n",
            "Balanced Accuracy: 0.9663\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0365, Train Accuracy: 98.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0658, Validation Accuracy: 98.00%\n",
            "Balanced Accuracy: 0.9802\n",
            "New best model saved with Validation loss 0.0658 at best_model.pth\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0314, Train Accuracy: 98.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0548, Validation Accuracy: 98.34%\n",
            "Balanced Accuracy: 0.9827\n",
            "New best model saved with Validation loss 0.0548 at best_model.pth\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0307, Train Accuracy: 98.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2722, Validation Accuracy: 92.39%\n",
            "Balanced Accuracy: 0.9134\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0261, Train Accuracy: 99.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1694, Validation Accuracy: 94.95%\n",
            "Balanced Accuracy: 0.9482\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0232, Train Accuracy: 99.22%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1603, Validation Accuracy: 95.28%\n",
            "Balanced Accuracy: 0.9470\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0229, Train Accuracy: 99.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1453, Validation Accuracy: 95.77%\n",
            "Balanced Accuracy: 0.9550\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0227, Train Accuracy: 99.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1719, Validation Accuracy: 95.43%\n",
            "Balanced Accuracy: 0.9511\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0202, Train Accuracy: 99.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.5008, Validation Accuracy: 67.68%\n",
            "Balanced Accuracy: 0.6517\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0172, Train Accuracy: 99.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2193, Validation Accuracy: 94.30%\n",
            "Balanced Accuracy: 0.9394\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0165, Train Accuracy: 99.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0598, Validation Accuracy: 98.22%\n",
            "Balanced Accuracy: 0.9818\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:23<00:00, 15.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0165, Train Accuracy: 99.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0520, Validation Accuracy: 98.29%\n",
            "Balanced Accuracy: 0.9830\n",
            "New best model saved with Validation loss 0.0520 at best_model.pth\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0151, Train Accuracy: 99.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0337, Validation Accuracy: 98.97%\n",
            "Balanced Accuracy: 0.9899\n",
            "New best model saved with Validation loss 0.0337 at best_model.pth\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:23<00:00, 15.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0138, Train Accuracy: 99.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0254, Validation Accuracy: 99.21%\n",
            "Balanced Accuracy: 0.9920\n",
            "New best model saved with Validation loss 0.0254 at best_model.pth\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0134, Train Accuracy: 99.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0380, Validation Accuracy: 98.87%\n",
            "Balanced Accuracy: 0.9881\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0126, Train Accuracy: 99.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0502, Validation Accuracy: 98.69%\n",
            "Balanced Accuracy: 0.9866\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0117, Train Accuracy: 99.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0703, Validation Accuracy: 98.06%\n",
            "Balanced Accuracy: 0.9792\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:21<00:00, 15.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0132, Train Accuracy: 99.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0265, Validation Accuracy: 99.23%\n",
            "Balanced Accuracy: 0.9919\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0094, Train Accuracy: 99.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0568, Validation Accuracy: 98.53%\n",
            "Balanced Accuracy: 0.9865\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:22<00:00, 15.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0130, Train Accuracy: 99.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2711, Validation Accuracy: 93.80%\n",
            "Balanced Accuracy: 0.9323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wDDP-iS8z1Q",
        "outputId": "eef21893-2575-4b6e-c8dd-0455c1f78832"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "15b9e843-a24c-445d-f37a-028c547af72e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:21<00:00, 22.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0315, Test Accuracy: 99.08%\n",
            "Balanced Accuracy: 0.9905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "d4384244-416b-49e0-cad7-59a9080c559f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 6.26 ms\n",
            "Standard Deviation: 0.35 ms\n",
            "Maximum Time: 9.48 ms\n",
            "Minimum Time: 5.80 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "16c1d9a7-5af6-44ca-bf71-a969ef21303d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul        10.17%       1.816ms        42.58%       7.600ms     316.671us       0.000us         0.00%       2.520ms     104.989us            24  \n",
            "                                           aten::linear         0.76%     136.350us        28.03%       5.003ms     277.927us       0.000us         0.00%       1.819ms     101.047us            18  \n",
            "                                               aten::mm         4.02%     717.239us        24.64%       4.397ms     274.842us       1.795ms        38.15%       1.795ms     112.208us            16  \n",
            "                                           aten::conv2d         0.94%     166.916us        11.64%       2.077ms     346.171us       0.000us         0.00%     722.593us     120.432us             6  \n",
            "                                      aten::convolution         0.42%      75.049us        10.70%       1.910ms     318.351us       0.000us         0.00%     722.593us     120.432us             6  \n",
            "                                     aten::_convolution         1.72%     306.119us        10.28%       1.835ms     305.843us       0.000us         0.00%     722.593us     120.432us             6  \n",
            "                                aten::cudnn_convolution         6.43%       1.148ms         8.23%       1.469ms     244.855us     707.232us        15.03%     707.232us     117.872us             6  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     676.062us        14.37%     676.062us     169.015us             4  \n",
            "                                              aten::bmm         1.86%     332.473us         2.36%     421.510us      52.689us     565.788us        12.02%     565.788us      70.724us             8  \n",
            "                                       aten::batch_norm         0.90%     159.921us        25.94%       4.629ms     201.250us       0.000us         0.00%     545.851us      23.733us            23  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 17.847ms\n",
            "Self CUDA time total: 4.706ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4UchJcz1N6K",
        "outputId": "fa3feded-159f-4d86-f369-5726f2306fa5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:21<00:00, 21.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0315, Test Accuracy: 99.08%\n",
            "Overall - F1: 0.9906, Recall: 0.9905, Precision: 0.9908\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9965, Recall: 0.9994, Precision: 0.9936\n",
            "Class 1 - F1: 0.9987, Recall: 0.9987, Precision: 0.9987\n",
            "Class 2 - F1: 0.9904, Recall: 0.9902, Precision: 0.9907\n",
            "Class 3 - F1: 0.9983, Recall: 0.9971, Precision: 0.9994\n",
            "Class 4 - F1: 0.9880, Recall: 0.9835, Precision: 0.9924\n",
            "Class 5 - F1: 0.9911, Recall: 0.9921, Precision: 0.9902\n",
            "Class 6 - F1: 0.9855, Recall: 0.9848, Precision: 0.9863\n",
            "Class 7 - F1: 0.9786, Recall: 0.9789, Precision: 0.9783\n",
            "Class 8 - F1: 0.9886, Recall: 0.9898, Precision: 0.9875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "ZLcoSxfe1Qbt",
        "outputId": "69bf70b4-e745-415e-ca9e-725b14d6b0cf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABTMAAAGkCAYAAADt4rEnAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAfYxJREFUeJzs3XdUFFcfxvEHjIJiF6QYOyKiCGLvvfeeWLHGXmNv2HvvNWqiiZqoMaa8MfbesaWZblSkCKIiRZb3D3R1BYxJFJzw/ZzDyWH2t+udXO6dvc/OzFrFxcXFCQAAAAAAAABec9Yp3QAAAAAAAAAAeBGEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAADAf0y1atU0aNAg8+/58uXTggULUqw9LwthJpJ0/PhxpUmTRg0bNrTY/ttvv8nKysr8kylTJhUtWlR9+/bV1atXLWrXr1+vrFmzJmOrkRhfX1+LPsuRI4fq1aunixcvJqh95513lCZNGm3bti3R1/rpp5/UpUsXvfnmm7KxsVH+/Pn19ttv68yZM+YaKysr7dy50/x7TEyM3n77beXKlUuXL19+6fuH53u6/9OmTStHR0fVrl1b69atk8lkMtfly5fP4u/k8c+MGTMkJRz76dKlk6urq6ZMmaK4uLiU2j0kwdfXV82aNZMkRUVFqWjRourZs2eCuuHDhyt//vy6e/eu1q9fLysrKxUpUiRB3bZt22RlZaV8+fK94pbjRT0e27169UrwWN++fWVlZSVfX19JCd/IPpbYcTo8PFxjxoyRu7u7bG1t5eTkpFq1amn79u2M9RT2Kvo8IiJCo0aNUsGCBWVraysHBwdVrVpVn3766SvaCzzrcb8+Pt4+tnPnTllZWZl/j42N1fz58+Xp6SlbW1tly5ZN9evX19GjRy2e93gut7KykrW1tZydndW2bVv98ccfFnXVqlVL9N+VpIYNG8rKykp+fn4vb0fxQoKCgtS7d2/lyZNHNjY2cnJyUt26dTV16tRE36c9/XPgwIEX7n+kjL/qQz8/Px04cEBWVlYKCwtL8Pxng6jHzztx4oRFXVRUlHLkyGH+u8Crc+3aNXXt2lUuLi5Kly6d8ubNq4EDByokJCSlm/afRpiJJK1du1b9+/fXoUOHdOPGjQSPf/PNN7p586YuXLigadOm6bvvvpOXl5f27t2bAq3FX6lXr55u3rypmzdvau/evXrjjTfUqFEji5qIiAh99NFHGj58uNatW5fgNc6cOaOSJUvqxx9/1MqVK/Xtt99qx44dcnd319ChQxP9dyMiItSkSROdPn1aR44cUbFixV7J/uH5Hvf/b7/9pi+//FLVq1fXwIED1ahRIz18+NBcN2nSJPPfyeOf/v37W7zW47F/9epVTZw4UVOnTk307wWvDxsbG23cuFHr16/X//73P/P2EydOaP78+Vq/fr0yZcokSbKzs1NgYKCOHz9u8Rpr165Vnjx5krXd+Gu5c+fWRx99pAcPHpi3RUZGavPmzf+ov8LCwlShQgVt3LhRo0aN0rlz53To0CG1bdtWw4cP1507d15m8/EPvOw+79Wrl7Zv367Fixfr+++/11dffaVWrVqxCEtmtra2mjlzpkJDQxN9PC4uTm+99ZYmTZqkgQMH6rvvvtOBAweUO3duVatWzeJDZEnKnDmzbt68qevXr+uTTz7RDz/8oNatWyd43dy5c2v9+vUW265fv669e/fK2dn5Ze0e/oaWLVvq/Pnz2rBhg3788Uft2rVL1apVk6enp8X7szZt2li8v79586YqVKgg6cX7H8nv6f5asGCBua8e/7z77rt/+zVz586t9957z2Lbjh07lDFjxpfVbCThl19+UalSpXT16lV9+OGH+umnn7RixQrt3btX5cuX1+3bt1/Zvx0TE/PKXtsICDORqHv37mnLli3q3bu3GjZsmOBNjiTlyJFDTk5OKlCggJo2bapvvvlGZcuWVbdu3RQbG5v8jcZzPf5k18nJSd7e3ho5cqSuXbumoKAgc822bdvk4eGhkSNH6tChQ7p27Zr5sbi4OPn6+qpQoUI6fPiwGjZsqIIFC8rb21sTJkxI9AyOsLAw1a5dWzdu3NCRI0eUP3/+ZNlXJPS4/3PlyiUfHx+NHj1an376qb788kuL8Z0pUybz38njHzs7O4vXejz28+bNq/bt26tixYo6d+5cMu8R/q6SJUtqzJgx6tatm8LCwhQZGakuXbqof//+qlq1qrnujTfeULt27SwC6j///FMHDhxQu3btUqLpeA4fHx/lzp1b27dvN2/bvn278uTJoxIlSvzt1xs9erR+++03nTx5Up07d5aHh4fc3NzUo0cP+fv7szB6DbzsPt+1a5dGjx6tBg0aKF++fCpZsqT69++vrl27vsxm4y/UqlVLTk5Omj59eqKPb926VR9//LE2btyo7t27K3/+/PLy8tKqVavUpEkTde/eXffv3zfXW1lZycnJSc7OzqpQoYK6deumU6dOKTw83OJ1GzVqpODgYIuzOzds2KA6deooZ86cr2ZnkaSwsDAdPnxYM2fOVPXq1ZU3b16VKVNGo0aNUpMmTSzen6VPn97i/b2Tk5PSpUsn6cX7H8nv6f7KkiWLua8e//yT42znzp0TfMi1bt06de7c+WU2HYno27ev0qVLp6+//lpVq1ZVnjx5VL9+fX3zzTe6fv26xowZo9GjR6ts2bIJnuvl5aVJkyaZf1+zZo2KFCkiW1tbubu7a9myZebHHl8ht2XLFlWtWlW2trbatGmTQkJCzFdAZsiQQZ6envrwww+TZd9TGmEmErV161a5u7urcOHC6tChg9atW/eXl5ZZW1tr4MCB+v3333X27Nlkain+iXv37umDDz6Qq6urcuTIYd6+du1adejQQVmyZFH9+vUtQi5/f39duXJFQ4cOlbV1wqnj2csUAwICzAHJwYMH5eTk9Er2Bf9cjRo15OXlZbEg/rvOnDmjs2fPJnqAxutnzJgxcnJy0oABAzR27FhZWVlp2rRpCeq6du2qrVu3KiIiQlL8JYv16tWTo6NjcjcZL6Br164WZ2SsW7dOXbp0+duvYzKZ9NFHH6l9+/ZycXFJ8HjGjBn1xhtv/Ku24uV4WX0uxS+sv/jiC929e/dlNQ//QJo0aTRt2jQtXrxYf/75Z4LHN2/eLDc3NzVu3DjBY0OHDlVISIj27NmT6GsHBgZqx44dSpMmjdKkSWPxWLp06dS+fXuLv6f169cTZqeQjBkzKmPGjNq5c6eioqJeyms+r//x31CyZEnly5dPn3zyiSTpjz/+0KFDh9SxY8cUbtl/2+3bt/W///1Pffr0Ufr06S0ec3JyUvv27bVlyxa1b99ep06d0s8//2x+/MqVK7p48aL5RIFNmzZp/Pjxmjp1qr777jtNmzZN48aN04YNGyxed+TIkeaz8+vWravIyEiVLFlSn3/+uS5fvqyePXuqY8eOOnXq1Kv/H5DCCDORqMehlhR/eeqdO3d08ODBv3yeu7u7pPhPDvB62b17t/kNUqZMmbRr1y5t2bLFHExevXpVJ06cUNu2bSVJHTp00HvvvWcOsR/fD/VxH/+VgQMHKjo6Wnv27OG+qa8xd3d3i/E6YsQI89/J45/Dhw9bPKdChQrKmDGj0qVLp9KlS6tNmzbq1KlTMrcc/8Qbb7yhjRs3atu2bVq8eLE2btwoW1vbBHUlSpRQgQIF9PHHHysuLo6F7WuuQ4cOOnLkiH7//Xf9/vvvOnr0qPkY/ncEBwcrNDT0hed5pJyX1eeStGrVKh07dkw5cuRQ6dKlNXjw4AT3YETyaN68ufmKl2f9+OOPid7PWJJ5+48//mjedufOHWXMmFF2dnZydHTU/v371bdv3wRXW0hPPsC6f/++Dh06pDt37iS4FRGSxxtvvKH169drw4YNypo1qypWrKjRo0cnep/75/k7/Y//hq5du5qvqlm/fr0aNGggBweHFG7Vf9vVq1cVFxf33Lk5NDRUDg4O8vLy0ubNm82Pbdq0SWXLlpWrq6skacKECZo7d65atGih/Pnzq0WLFho8eLBWrlxp8ZqDBg0y1zg7OytXrlx699135e3trQIFCqh///6qV6+etm7d+up2/DVBmIkEfvjhB506dUpvv/22pPiDatu2bbV27dq/fO7j4Ovpm5Xj9VC9enX5+/vL399fp06dUt26dVW/fn39/vvvkuLP6qhbt67s7e0lSQ0aNNCdO3e0b98+SfrbX/rQqFEj87018fqKi4uzGK/Dhg0z/508/ilVqpTFc7Zs2SJ/f39duHBBW7du1aeffqqRI0cmd9PxD3l4eKhly5aqXbt2gr592uMzvw4ePKj79++rQYMGydhK/B0ODg7mW8K89957atiwoXku/zv4ch/jeFl9LklVqlTRL7/8or1796pVq1a6cuWKKleurMmTJ7/kVuNFzJw5Uxs2bNB3332X4LG/M0YzZcokf39/nTlzRnPnzpWPj4+mTp2aaK2Xl5cKFSqkjz/+WOvWrVPHjh05CzsFtWzZUjdu3NCuXbtUr149HThwQD4+Pone9ispf6f/8d/QoUMHHT9+XL/88gsfQiezF5mb27dvbw4z4+Li9OGHH6p9+/aSpPv37+vnn39Wt27dLE4omTJlisXZnJISvHePjY3V5MmT5enpqezZsytjxoz63//+lyq+8IujFBJYu3atHj58aHGJWVxcnGxsbLRkyZLnPvfxGy/ujfj6sbOzM3/yI8XfkyNLlixavXq1Jk6cqA0bNiggIMDizWtsbKzWrVunmjVrys3NTZL0/fffv9A9uTp27KgmTZqoa9euiouL05AhQ17+TuFf++677yzGq729vcXfSWJy585trilSpIh+/vlnjRs3Tn5+fome5YfXzxtvvPGXC9X27dtr+PDh8vPzY2FrAF27dlW/fv0kSUuXLk3weObMmRP98p6wsDBlyZJFUnxAljVrVn3//fevtrF4KV5Gnz+WNm1aVa5cWZUrV9aIESM0ZcoUTZo0SSNGjDDfgw/Jo0qVKqpbt65GjRpl/mZ6SXJzc0s04JSevP9+/F5Nir/907PH6t69e+v9999P9DW6du2qpUuX6ttvv00Vlye+7mxtbVW7dm3Vrl1b48aNU/fu3TVhwgSLv4nn+bv9j9dL5syZJcWfYfvsFW6JzeFS/D3tGzVqpG7duikyMlL169fn9iGvmKurq6ysrPTdd9+pefPmCR7/7rvvlC1bNjk4OOjtt9/WiBEjdO7cOT148EDXrl0zXxF57949SdLq1asT3Lrr2VtDPHt29ezZs7Vw4UItWLBAnp6esrOz06BBgxQdHf0yd/W1xJmZsPDw4UNt3LhRc+fOtTgz68KFC3JxcXnuzWRNJpMWLVqk/Pnz/6Mb0CN5WVlZydraWg8ePDDfK+v8+fMW/f7hhx9q+/btCgsLk7e3tzw8PDR37lyZTKYErxcWFpZgW+fOnbV+/XoNHz5cc+bMSYa9wt+xb98+Xbp0SS1btvxXr5MmTRo9fPgwVRw0U5Ps2bOrSZMmOnjwIJ/uG0C9evUUHR2tmJgY1a1bN8HjhQsXTvSLus6dO2cOQKytrfXWW29p06ZNunHjRoLae/fu6eHDhy+/8fhHXkafJ8XDw0MPHz5UZGTkS2svXtyMGTP02Wef6fjx4+Ztb731lq5evarPPvssQf3cuXOVI0cO1a5dO8nXHDlypLZs2ZLkF/a1a9dOly5dUrFixeTh4fHvdwIvlYeHh8UXPP1df9X/eL0UKlRI1tbWCb6H4pdfftGdO3eSnMO7du2qAwcOqFOnTtwfNRk8nneXLVtm8eVLUvz3R2zatElt27aVlZWV3nzzTVWtWlWbNm3Spk2bVLt2bfOXrDk6OsrFxUW//PKLXF1dLX7+6iSxo0ePqmnTpurQoYO8vLxUoEABi1uO/JdxmgUs7N69W6GhoerWrVuCT3xatmyptWvXql69epKkkJAQBQQEKCIiQpcvX9aCBQt06tQpff7550yer6GoqCgFBARIkkJDQ7VkyRLdu3dPjRs31oIFC9SwYUN5eXlZPMfDw0ODBw/Wpk2b1LdvX7333nuqVauWKleurDFjxsjd3V337t3TZ599pq+//jrR+6p27NhR1tbW6ty5s+Li4jRs2LBk2V9Yetz/sbGxunXrlr766itNnz5djRo1srjf5d27d81/J49lyJDB/Amx9GTsP3z4UJcuXdLChQtVvXp1ixq8Hu7cuSN/f3+LbU9/6ddfWb9+vZYtW/a3noOUkSZNGvPZWYkdg3v37q0lS5ZowIAB6t69u2xsbPT555/rww8/tAhHpk6dqgMHDqhs2bKaOnWqSpUqpbRp0+rw4cOaPn26Tp8+zX2QXxMvq8+rVaumt99+W6VKlVKOHDn07bffavTo0czrKcjT01Pt27fXokWLzNveeustbdu2TZ07d9bs2bNVs2ZNhYeHa+nSpdq1a5e2bdv23Psh5s6dW82bN9f48eO1e/fuBI9ny5ZNN2/eVNq0aV/JPuHFhISEqHXr1uratauKFy+uTJky6cyZM5o1a5aaNm36j1/3r/ofr5dMmTKpe/fuGjp0qN544w15enrq2rVrGjFihMqVK6cKFSok+rx69eopKCiIuTsZLVmyRBUqVFDdunU1ZcoU5c+fX1euXNGwYcOUK1cui9s7tG/fXhMmTFB0dLTmz59v8ToTJ07UgAEDlCVLFtWrV09RUVE6c+aMQkNDn3uF4+NbhBw7dkzZsmXTvHnzdOvWrVTxoRRhJiysXbtWtWrVSvTU9ZYtW2rWrFkKDw+XJNWqVUtSfNCRN29eVa9eXatWrfrLS1SRMr766is5OztLij9Auru7a9u2bSpSpIg+//xzixsSP2Ztba3mzZtr7dq16tu3r8qUKaMzZ85o6tSp6tGjh4KDg+Xs7KwKFSpowYIFSf7b7du3l7W1tTp27CiTyaQRI0a8qt1EEh73/xtvvKFs2bLJy8tLixYtUufOnS2+nX78+PEaP368xXPfeecdrVixwvz747GfJk0aOTs7q0GDBtyH6TV14MCBBGfKd+vW7YWfnz59+gTfzojX1/MWLwUKFNChQ4c0ZswY1apVS9HR0ebjwOMPKaX4M3JPnDihGTNmaMqUKfr999+VLVs2eXp6avbs2Ym+P0DKeRl9XrduXW3YsEGjR49WRESEXFxc1KhRowTHAiSvSZMmacuWLebfraystHXrVi1YsEDz589Xnz59ZGtrq/Lly+vAgQOqWLHiX77m4MGDVb58eZ06dUplypRJ8DgfVKS8jBkzqmzZspo/f75+/vlnxcTEKHfu3OrRo4dGjx79r177r/ofr5eFCxdqxowZGjFihH7//Xc5OTmpdu3amjp1apLfT2FlZfWP75+Mf6ZQoUI6c+aMJkyYoDZt2uj27dtycnJSs2bNNGHCBGXPnt1c26pVK/Xr109p0qRRs2bNLF6ne/fuypAhg2bPnq1hw4bJzs5Onp6eGjRo0HP//bFjx+qXX35R3bp1lSFDBvXs2VPNmjVL9DYz/zVWcdztHQAAAAAAAIABcM9MAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwE/9YVFSU/Pz8FBUVldJNQTKgv1MX+jt1ob9TF/o7daG/Uxf6O3Whv1MX+jt1ob+fzyouLi4upRsBYwoPD1eWLFl0584dZc6cOaWbg1eM/k5d6O/Uhf5OXejv1IX+Tl3o79SF/k5d6O/Uhf5+Ps7MBAAAAAAAAGAIhJkAAAAAAAAADOGNlG7Af4HJZNKNGzeUKVMmWVlZpXRzkk14eLjFf/HfRn+nLvR36kJ/py70d+pCf6cu9HfqQn+nLvR36pJa+zsuLk53796Vi4uLrK2TPv+Se2a+BH/++ady586d0s0AAAAAAAAADO3atWt68803k3ycMzNfgkyZMkmSNn5+UhnsMqZwa5Ac4iLvp3QTkIzs33RM6SYgGQXfCErpJiAZ5S/gnNJNQDK6ExGT0k1AMsqV1Talm4Bk5JCJ/k5NrgaxHktNIqIfpnQTkEzu37urxuWKmXO2pBBmvgSPLy3PYJdRGTI+/384/hvi0qSe2wlAypiJb49LTSLsHqR0E5CMGN+py8M0hJmpSabMhFupSWbCzFQlY2SalG4CkpE1YWaq81e3cOQLgAAAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkxIki6dOym/wV3UoV4pNSiVR8cO/O8vn3PxzHH1b99ATcq7qluzytrz2bYENZ9t3SDfxhXUtEIhDercRD9c9n8Frcffddn/jCaO6KOOzaqqYWUPHT/0zV8+5+L5UxrQtaWa1vBS97fqas8XOxLU7N6+WV1a11Kzmt4a3LOtfvj24qtoPv6BrRtWq0nF4qro5iTfprV0xf9skrUPY2K0euEsNatcQhXdnNSuXiUdO2D5N3L/3l3NnThKjSt4qpKbs7o2r6MrF8696t3AC7jsf1oTh/dSxyaV1bCi+4uN73MnNaBLCzWt5qnubepoz+fbE9Ts/mSTurSsoWbVi2twjzaM79fIpnWrVKNUURXPY6829arr4rkzSdbGxMRo6dwZql2muIrnsVfT6uV1eN8ei5p79+5q2tgRqlHSQ155HfRWw5q6dD7pOQPJ6+ONa9SskpeqFHZW12Z/PZ+vXTRLLav6qEphZ3WoX1nHDyacz+dPGqVmFYurqruLerSsq2+Zz18b61evUFlPdxVwzKZGNavo/NnTSdbGxMRo/sxpquBdVAUcs6lWxbLa/83XFjX37t7V+JHDVKZYYRV0yq4mdarL/zlzBpLXsmVL5VogvzJmSK8K5cvp1KlTSdbGxMRoyuRJKlzIVRkzpJdPCW/976uvLGpiY2M1Yfw4FSpYQJnsMqhwIVdNnTJZcXFxr3pX8AI+fG+V6pQuKp989nq7QXVdOv/84/fyeTNUr1xx+eSzV4ua5XXkmeP3/Xt3NWPcCNUu5aGS+R3UvnFNXXrOMQLJa9uG1WpasbgquTmpywusx9YsnKXmlUuo0qP12PFE1mPzJo5SkwqequzmrG7N66Sq4/d/Psz09fWVlZVVgp+ffvpJhw4dUuPGjeXi4iIrKyvt3LkzpZubYiIfRCh/IQ/1GTHlheoDrv+hCYN8VbxUeS3Z/KWavd1NC6cM19njB801B7/epdXzJ6tdj0Fa/MHnKuBWROP6d1DY7eBXtRt4QZGREcrvWli9h4x7ofqAG3/Kb3hvFfcpo8Xrtqtp605aNGu8zp48Yq45tPdLrV4yU+18+2jRmo+V39Vd44b2VFhoyKvaDbygrz/brgVTxqr7wBF6f/cBFSpSTP07ttTt4KBE65fPmaIdm9Zr2MSZ2vLNCbVo30XDe3bUD5efhFdTRgzUycMHNHH+Cn349VGVq1JDfds3U2DAjWTaKyQl8sED5Xd1V++h41+oPuDGn/Ib1it+fK/fqaZtOmnRzHE6e/KwuebQN19o9eIZate1rxat2678roU1bkh3xvdr4Iudn2jGhFHqO3Sktu85osJFi6n7W80VEpT4+F44Y5K2bFynsdNm6/NDp/VW527q16Wdvr10wVwzbnA/HTu0TzOXrNKuAydUsVpNdWndRLduMr5T2p7d27Vw6lh1HzhcG3bvV6EixTSoc6sk5/MVc6dq5+YNGuo3Ux/uOa7m7bto5Dud9MOVJ/P5tJEDderIAU2Yt0IffHVEZSpXV/+OzZnPXwOfbv9YE8eM1JARo/XVwWPyKOap9i2aKjgoMNH6WVMm6oP1azV51lztP3lOHbt2U/cOb+nyBX9zzbsD+ujwgX1atHKtvjl2WlWr19RbzRrp5o3rybRXSMrWLVs0bOhQjR03XqfOnFXx4sXVsH49BQYm3t/jx43V6lWrtGDhIl28fEU9e76jVi1b6Pz58+aa2bNmauWKFVq4aLEuXflW06bP0JzZs7VkyeLk2i0k4ctPP9Esv1HqPXSktv3viAp7FNM7bzdXSBLz+eKZk7Tt/XUaPXW2Pj14Wm06ddPAbu303VPH7/FD++n4oX2avniVduw7oQpVa6pHG47fr4M9T63HNj5ajw14gfXYu89Zj019tB7zm79Cm78+qrKpbD1mFfcf/1jG19dXt27d0nvvvWex3cHBQV9//bWOHj2qkiVLqkWLFtqxY4eaNWv2t/+N8PBwZcmSRR8fuKIMGTO9pJannAal8mjsnNWqUK1ukjXrFk3T6SP7tHzrk08HZozqq/v3wjV58fuSpEGdm8jNw0t9RkyWJJlMJnVuWFaN2/qqjW/fV7sTr1jcg3sp3YSXpmFlD42dukjlq9RKsmbd8rk6c/yglm3cZd42c8JQ3bt3V5PnrpIkDe7ZVm5FPNV78FhJ8f3t27KGGrVsrzYderzanXjFcuZxTukm/Cu+TWvJo3gJDZ88W1J83zQqV0xtfHvIt8/gBPX1SxdRl35D1Kbzk34b/k4n2djaavLCVYqMfKBqHrk1Z/UmVar5ZJ7o2LCaKlSrpd7Dxr76nXqFAv+8ldJNeGkaVnTX2OlLnj++l83RmWMHteyDz8zbZo4fonv3wjV53hpJ0uAebeTmXswckJpMJvk2r6ZGrTqoTceer3QfXrWCrrlSugn/Spt61VWshI/GT58rKb5vqpVwV4du76jngKEJ6isXL6Reg4apfdcn/da/a3vZ2qbX7GVrFPnggUoWdNbSDR+pWu165poWtSurSo3aGjTqxULy11VYRExKN+Ff6dqsljyK++jdSbMkxfd30wqeat25hzr1HpSgvlFZD/n2HaJWnbqbt43s3Uk2Nuk1ccFKRUY+UM1ieTRr1SZVrFHHXNO5cXWVr1pLvd4d88r36VXKnc02pZvwrzSqWUVePiU1dfZ8SfH9XbpoIXXp2Vv9Br+boN7HvYAGDB0u3x69zNt6dHxbtunTa/GqdXrw4IEKv5lT6zZvVa269c019apWUPXadTRirN8r36dXKWcmY/d3hfLlVKpUKS1avERSfH/nz5tHffv10/ARIxPU53kzl0aOHq0+fZ6sq9q0aiXb9Om18f349VjTxo2V0zGnVq9Zm2SNUf0QeD+lm/CvvN2guop5+2jMtCfH71ol3dWu6zvq3j/h8bu6dyH1HDhMb3d5cvwe1K29bGzTa+bS+ON32ULOWrT+I1Wt9eT43aZOZVWqUVsDRhr7+B0R/TClm/CvdHm0Hhv21Hqs8aP1WOdE1mMNHq3HWj+1HhvxaD026dF6rLpHbs1+Zj3WqWE1lTf4euze3XDVKJZXd+7cUebMmZOs+8+fmSlJNjY2cnJysvhJkyaN6tevrylTpqh58+Yp3UTD+e7SOXmXrWSxzad8VX13Mf605piYaP30/SWLGmtra3mXqaTvL6aeU5//K76/4i/vUuUttvmUqajvr/hLetTfP34r75LlzI9bW1vLu1R5cw1SRkx0tL6/5K8ylaqZt1lbW6tMpaq6dC7xS9VioqNkY2O5ILCxtdWFMyckSbEPHyo2NlbpEqnxf1QD4/j+ciLju2xFff/otiAxMdH66Ycr8i5dwfy4eXxz65AUFR0drSsXz6tC5WrmbdbW1ipfpZr8zyR+aWJ0dJRsbGwsttnaptfZU8clSQ9j48f3s3OAra2tuQYpIyY6Wj9cvqDSlaqat1lbW6t0xaTn8+joKKV7pr9tbNInMp8/U/PUnI+UER0drYv+51W5anXzNmtra1WqWkNnT51M9DlRUdEJx2769Dp1/JikJ/1tY5uw5vRxxndKio6O1rmzZ1Wz5pMPH62trVWjZi2dOJ74WIyKipJtIv197OiTK6fKVyiv/fv26ccff5QkXbhwQUePHlG9evWElBMTHa1vL55XuWeO3+UqV9OFs0kfvxPO1el1/tGxOTaJ47eNra3OcfxOUY/XY6WfWY+Vfs56LL6//9l6LLUcv1NFmPmyRUVFKTw83OIntQkNCVLW7PYW27Jlt1fE/buKioxUeNhtmWJjle2ZmqzZ7XU7JPFTqfH6Cg0JVtZsOSy2Zc2eQxH37ykqKlLhd8Jkio1N8DeRNVsOhYZwW4GUFBYaotjYWGW3d7DYnt3eQSFJXKZWrkoNbVqzTH/8+rNMJpNOHt6v/V/tVnBg/BmLdhkzydOntNYunq2gWzcVGxurL7Zv0aVzp801MI7Q20HKmv2Z8Z3N/sn4Dgt9NL6fnQPsFcptQ1JU6O348Z3DIafFdnuHnApO4rLEStVqaf3KJfrtl59kMpl09OA+7flil4JuBUiSMmbMJO9SZbRs/kzdCogf37s+/kj+Z06Za5AykprPs9k7KCQo8bm3XJUa+nCt5Xx+4H+7zfWP5/N1i+eY5/Mvd2zV5XOnFcJ8nqJuhwQrNjZW9jkdLbY75MypoCT6plrNWlq1bLF++Tl+fB/av1dffPapAh+P70yZVLJMWS2cNUMBN28oNjZWn2z5UGdPndQtxneKCg6O7++cjpb97eiYUwFJ9E2dOnW1cMF8Xb16VSaTSd/s2aOdO7br5s2b5prhI0aqTdu2KuZRROlt0ql0SR8NGDhQ7dq3f6X7g+dL6vid4znH74rVamnjyiX6/dHx+9jBfdr7xS4FBcb/fdhlzCSvUmW0Yv5MBT46fn/28Ue6cPaUggMZ3ynpn67HNr/AemzdU+uxL1PZeixVhJm7d+9WxowZzT+tW7f+V683ffp0ZcmSxfyTO3ful9RSAEh5Q/1mKE/+Ampdo4wquObUrPHD1bh1O1lbPTlkTFqwUnFxcWpQxkMVCzlqy/pVqtOkpUUNgNfPmCkzlTd/QTWoWFKeb2bX5FFD1eKtDrK2fjJ2Zy1drbi4OFX1clPx3Dn0/uoVati8tUUNjGHw+OnKna+g3qpVVpXdHDV3wgg1amU5n0+Yt0KKi1PjckVVpbCTtq1fpdqNW8rK2ioFW45/YtKM2cpfoKCqlvZWPocsGjNsiNq272gxdhetXKu4uDiVLOKq/Dmzat3KZWrWqg3j24DmLVggV9dCKuZRRBlsbTRwQH919vW16MttW7fqw82b9f4Hm3TqzFmte2+95s2dq40bNqRgy/FPjJwUf/xuXLmkSuTJrmljhqrZM8fv6YtXS3FxqlHCTT55c2jT2hWq36y1rHh/bjhD/WYod/4CalOjjCq65tTsRNZjEx+txxqW8VClVLgeeyOlG5AcqlevruXLl5t/t7Oz+1evN2rUKA0ZMsT8e3h4eKoLNLPlcEjwRT6ht4OVwS6TbGxtZZ0mu6zTpElw1k7Y7WBlz2H5iQRef9ly2Cf4oo+w2yHKYJdRNja2sra2lnWaNAn+JsJCQ5Qth+XZmkheWbPlUJo0aRLcXPp2cFCCT4Mfy5bDXnNWb1JUZKTuhN2Wg6Ozlszwk0uefOaaN/Pm16qtn+tBxH3dv3tX9o5OGtW3q3LlyfsqdwevQLbsDgq7/cz4Dg1+Mr6zPh7fz84BwQnOvkfyypY9fnw/+6l+cFCg7HMmPr6z2zto6YaPFBUZqbDQ28rp5Ky5U8Yrd9585po8+Qrog51fKeL+fd27d1c5HZ00uEdnixokv6Tm89DgIOVwcEz0Odly2GvWqg8UFRWpO6Hx8/nSmRPl8tRc/Wbe/Fq+ZXf8fH7vruxzOmlMv67K9dScj+SXPYe90qRJk+AMm6DAQDnkTLy/c9g7aN3mrYqMjFTo7RA5Obtomt845cmX31yTL38BffLF14q4f19374bL0clZvbp0VJ58+V7l7uAv2NvH93fgLcv+vnUrUE6OTok+x8HBQZ/s2KHIyEiFhITIxcVFo0eNVIECBcw1I0cM17ARI9T2rbckSZ6envrjj981a+YMderc+dXtEJ4rqeN3yF8cvxettzx+z586Xm8+NVfnyVdA63d8pYhH788dHJ009J3OepPjd4p6leuxlc+sx0anovVYqohs7ezs5Orqav5xdv53X+ZhY2OjzJkzW/ykNkU8feR/6qjFtvMnD6tIcR9JUtq06eTq7qkLT9WYTCb5nz4q90c1MA73ot7yP2t5743zZ47Lvai3pEf97eZhUWMymeR/9oS5Bikjbbp0cvf01umjB83bTCaTTh89JE+f0s99ro2trXI6uSj24UPt+/IzVa1TP0FN+gx2snd0UvidMJ04tFdV6jR46fuAV8u9mLf8z1reS+n86WNyL+Yt6dH4LlxU/mee1JjH96MapIx06dKpaPESOn7YcnyfOHxQ3qXKPPe5Nra2cnR20cOHD/X17l2qUbdhgpoMdnbK6eikO2GhOnJgb6I1SD5p06VT4WJeOn30kHmbyWTS6WMH/3o+t3kynx/46jNVqZ1wrk6fwU72OePn85OH9qlKrYRzPpJPunTpVNy7hI4cPGDeZjKZdOTQfpUsU/a5z7W1tZWzSy49fPhQX+zaqToNEh/fjk7OCgsL1cG936hug0YvexfwN6RLl04+JUtq37695m0mk0n79+1VufLlnvPM+P7OlSu+v3ds367GTZqYH4uIiEhwllaaNGlkMple7g7gb0mbLp08ipfQySOWx++TRw7Kq+SLH7/3fL5L1RM7fmewk8Oj4/cxjt8pLqn12Jm/uR7bz3rMQqo4MxN/7UHEfd249pv591vXr+nnH64oU5asyumUS+8tmaGQwAC9O2mBJKlByw76bOsGrV04VXWattWF08d0+Jvdmrhgvfk1mrfvrnl+Q1XIw1NuRb316ea1inoQodqN2yTvziGBBxH3deP6H+bfA25e189Xv1OmzFmU09FF61fMU0hwoIaOnSFJatC0rXZv36x1y+aodsMWunDupA7v/0p+M5+c8dy8ra/mTRulQu7F5FbEU59u26jIBw9UuwFfsJXS2nXvo4lD+6hI8RIq6uWjD9ct14OI+2rcOv5+SRMG95KDk7P6jZggSbp8/owCA27KrainggJuaNX8mTKZTOr0zkDzax4/uFdxcXHKW6CQ/vz9Fy2cNl75CrqpSWvuwZTSHkTc140/nxrfN/7Uzz8+Gt9OLlq/fG78+B43U5LUoNlb2v3JJq1bOlu1G7XUhbMndHjfV/KbvcL8Gs3b+mre1JHx49ujuD7dukGRkQ9Uu2GLZN8/WPLt1U8jB7yjYt4lVLxESW1YtUwPIiLU4q2OkqQR/Xoqp5Ozho6dKEm6cPa0bgXcUJGixXUr4IaWzJ4uk8mk7v0GmV/z8P5vpLg45S9YSL//9otmTxyrAq6F1OLtjimxi3jK2937aPLQvipS3FseXj7asm6FIiMi1LBVO0nSxCG95eDkrD7D47+19vL5Mwq6dVNuHp4KCripNQvj5/MO7wwwv+aJg3sVp/j5/Npvv2jJ9AnKW7CQGjGfp7gefQdocO8eKl7CRyVKltLq5Uv04H6E2raPH4sD3ukuZxcXjZowSZJ07swpBdy4oaLFvRRw44bmzpgqk8mkPgOeXFF2YO8excXFqaCrm3779WdNHjdaBd3c1LZ9pxTZRzwxaNBgde3iq5IlS6l0mTJatHCB7t+/r86+XSRJvp07K1cuF02dNl2SdPLkSd24fl1e3t66cf26Jk2aKJPJpHeHDTe/ZsNGjTVj+jTlyZNHHkWLyv/8eS2YP1++XbqkyD7iiU7v9NOYge+oqFcJFfMuqQ9Wxx+/mz06fo/qH3/8Hjwm/vh98dxp3bp5Q+7Fiivw5g0tmztdcSaTuvYdZH7No/u/UVxcnPK5FtIfv/6iuZPHKr9rIfNrIuU8ux776NF6rNFT67GcTs7q+9R6LOjReiww4IZWP1qPdXxmPaa4OOV5tB5b9Gg91jiVHL9TdZh57949/fTTT+bff/31V/n7+yt79uzKkydPCrYs+V399qJG9mpr/n31/Pg3RbUatdIQv3kKDQ5UUMAN8+NOufJo4oL1WjVvkj796D3Z53TSwLGzVLL8k2/YrFqnicJDb+v9FfMUGhKkAm4emrT4fWXjMvMUd/WHKxo1wNf8+5ol8aFGzXrNNGTMNN0OCVbQrSc3D3dyeVN+s5Zr9eIZ+vTj92Xv4KQBwyep5FPfVl+lZn3dCbutD9YuVujtYBVwddekOSu5DPU1UKdxC4WFBGvlvGkKCQqUm4enFm382HxZQ8CNP2X11P12oqKitGLOVF2/9pvSZ7BTxeq1NWnBCmXKksVcc+9uuJbOnKTAgBvKnCWbatRvrD7DxuqNtGmTff9g6er3lzWq/5NLx9Ysjv9Qomb9ZhoydoZuhwQp6NZT87nLm/KbvUKrF83Qp9s2xo/vEZNVsmxlc02VWg3ix/eaxQq9HaQChYpo0tzVjO/XQINmLXU7JFiLZ01VUOAtFSlaXKs/3G6+TO3G9WsW9z6MiorSwhmTde3335TBzk5Va9bVzKWrlTlLVnPNvfBwzZvqp4Cb15U1azbVbtRUg0eNV1rGd4qr3aiFwkJCtHredIUEB6pQkWKav35bkvN5dFSUVs6dqht//K70dnaqUK22JsxbrkyZLefz5bMnm+fz6vUaq9e7zOevg6YtWul2cJDmTJusoMBbKupZXB98stN8mfmNP69Z3C8vKjJKs6ZO0h+//aoMdhlVo3ZdLVq5RlmyZjXXhIeHa8bE8bp547qyZsumBk2aacRYP8b3a6BN27YKCg7SRL8JCggIkJe3t3Z/8aUcH30p0LVrfzzT35GaMH6cfvnlF2XMmFH16jfQ+g0blfWp/l64aJEmjB+n/v36KjAwUC4uLurRs6fGjhuf3LuHZ9Rv2lKhIcFaMmuqgoNuyb1oca3YvF32j+bzm9evyfrp43dklBbPnKw///hNGTLYqXLNupq+2PL4ffduuBZM89Otm9eVJWs21W7YVANGcvx+HdRu3EKhIcFa9dR6bOFT67FbN/60GN/Rz6zHKlSvrYmJrMeWPbMe652K1mNWcXFxcSndiFfJ19dXYWFh2rlzZ4LHDhw4oOrVqyfY3rlzZ61fv/6F/43w8HBlyZJFHx+4ogwZM/2L1sIo4h7cS+kmIBnlzPPvbk0BYwn8M3V8AyDiFXTNldJNQDIKi4hJ6SYgGeXOZpvSTUAyypmJ/k5Nfgi8n9JNQDKKiH6Y0k1AMrl3N1w1iuXVnTt3nntLx//8mZnPCyWrVaum/3iWCwAAAAAAAPxnpIovAAIAAAAAAABgfISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGMIbKd2A/xKbDDayzWCT0s1AMnjw4F5KNwHJKC4upVuAZPUwOqVbgGQUeCcypZuAZJTBNm1KNwHJ6KGJA3hqYiWrlG4CkpHNG/R3anI/KqVbgOTyomtvzswEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQ3jtw0wrKyvt3LnzpdcioZ2b1+ntWqVU1zuP+rStp+8unkuy9mFMjDYum6v2dcuorncedW9eXacO77Ooibh/T0umj9VbNUuqXom86teuob6/dP5V7wZewGX/M5o4oo86NquqhpU9dPzQN3/5nIvnT2lA15ZqWsNL3d+qqz1f7EhQs3v7ZnVpXUvNanprcM+2+uHbi6+i+fgHtm1craYVi6uSm5O6NK2lK/5nk6x9GBOjNQtnqXmVEqrk5qR29Srp+AHLv5H79+5q3sRRalLRU5ULO6tbizr69kLScwaSz+ULZzRxZD91bFFTDasW1/Fn5ubEXDx/WgO6t1HTWiXVvV1D7fny0wQ1u3d8pC5t66lZ7VIa3Kudfvju0qtoPv6B7R+sVZvqPqpV7E2906ruc8fiw5gYrV8yR2/VLK1axd5Ul8bVdPLQXouaiHv3tGjqGLWuVkK1PHOrd9sG+u4ix+/XxdYNq9W4gqcqFHJU5yY1dfkv5vPVC2aqaSVvVSjkqLfrVtSxRObzuX4j1ah8MVUs5KSuzevoCvP5a2PDmpWq6FVEbs7Z1bRWVfmfPZNkbUxMjBbOmq7KPsXk5pxd9SqX1YFvvraouXf3riaOGqYKxd3l5pJDzevW0IVzSf8NIXktW7ZUBQvkk10GW5UvX1anTp1KsjYmJkaTJ0+SW6GCsstgK58SXvrqq68samJjYzV+/Di5FsyvjHbp5VaooKZMmay4uLhXvSt4AR+sXalqPh4q+mYOtaxbTRfOPX98L54zXTVKe6romznUuFo5Hdq7x6Lm3r27mjJmuKqWKKJiue3VpkFNXTzP+H5dbNu4Ws0qFldlNyd1fcH1WIsqJVTZzUntn7Mea1rRU1UKO6t7KluP/a0w09fXV1ZWVrKyslK6dOnk6uqqSZMm6eHDh6+qfbp586bq16//0mthaf+XO7V85gR16jNUKz/eo4LuRTWi51sKDQlKtH7dohn6bOtG9R89Te99dkiN23bW+AFddPXbJ4vbOeMG6+yxQxo1c4nW7jygUhWqaVi31gq6dTO5dgtJiIyMUH7Xwuo9ZNwL1Qfc+FN+w3uruE8ZLV63XU1bd9KiWeN19uQRc82hvV9q9ZKZaufbR4vWfKz8ru4aN7SnwkJDXtVu4AXt+Wy7FkwZq+4DR2jj5wdUyKOYBnRqqdvBiY/v5XOmaMfm9Xp34kxt+eaEWrTvouHvdNQPl5+E01NHDNTJIwfkN2+FNv/vqMpWrqG+HZopMOBGcu0WkhD54EH8+B40+oXqA27+Kb+RfVW8RBktXrNNTVt10KLZfjp76qi55tC+r7R66Wy169xLi1ZvUf6ChTXu3V6M79fA3s93aOn08fLt967W7NwrV/eierdbmySP36sXTNeujzZo4Lhp2vjFETV9u7PG9PXVj099+DRzzCCdOXpQY2Yv1frdB1W6YjUN8W2poACO3ynt613bNX/yGPUYNEIffH5QbkWKqX+HFknO58tmT9H2Tes1bNIsbf3mpFp26KphPTro+8sXzDVThg/QycMHNGnBSn2055jKVq6uPu2Yz18Hn23/WFPGjtTA4aO0e/9RFSnmqY6tmio4KDDR+jlTJ2rThrWaOHOOvjl+Vu27dFfPTm/r8kV/c82IgX11+MB+zV+xRl8fOaUq1WuqffNGCrhBf6e0rVu26N2hQzRu3ASdPnNOXsW91KB+XQUGJt7f48aN1epVK7Vg4WJduvytevbspVYtm+v8+ScfPs2aNVMrVyzXwkVLdPnKd5o+fabmzJ6lJUsWJ9duIQmf7/hY08aPUr93R2nn3iMqUrSYurZpppAkxvf86ZO0ZcM6jZ82R18eOaO3OndTH9+3deXik/l8zKC+Onpwn2YvXa3PD55UpWo11LllYwXcZHyntD2fbdfCKWPVbeAIbfj8gFw9imngc9ZjK+ZM0c7N6zV04kx99Gg9NuKZ9di0EQN16tF6bNOj9Vi/VLQes4r7Gx/L+Pr66tatW3rvvfcUFRWlL774Qn379tXUqVM1atQoi9ro6GilS5fupTf4dRQeHq4sWbLos1M/yS5jppRuzj/Sp209FfYsoYFjp0uSTCaT2tYooebtu6ldjwEJ6ltXLa727wxSs3ZdzdsmDOwqGxtbjZ61TFGRD9SwdEFNWbJB5arWNte806q2ylSuoW4DRyV4TSN5EPLfWcA3rOyhsVMXqXyVWknWrFs+V2eOH9SyjbvM22ZOGKp79+5q8txVkqTBPdvKrYineg8eKyn+b8i3ZQ01atlebTr0eLU78Yo55HZO6Sb8K12a1pKHVwkNmzRbUnzfNC5fTG0691DnPoMT1DcoU0Rd+g1R605P+m1Er06ysbXVpAWrFBn5QNWL5tbs1ZtUqUZdc02nRtVUvlot9X537KvfqVco6PdrKd2El6Zh1eIaO2WByleukWTNuhXzdebEIS1b/+Rs65kTh+vevXBNnr1CkjS4Vzu5uRczB6Qmk0m+reuoUYu31aZ9t1e7E69YJmdjj+93WtWVu6e3Bk+YKSm+b1pV8VKLjt3V4Z2BCeqbVyqmjr0Gq0WHJ/02tp+vbGzTa9yc5YqKfKB6JfJr2rKNKl+9jrmme/OaKlulpnoMfrGQ/HWVwTZtSjfhX+ncpKY8vHw0YvKT+bxh2aJq69tTvn0Tzuf1Srmra/+hatP5yXw+7J2OsrVNr8kL4+fzqkXe1Nw1m1Wp5pP5vEODqqpQvbb6DDP2fO6Q0dj93bRWVRX3KanJs+ZJiu/vcp5u8u3RS30GvZugvrRHQfUbMlydu79j3vZOp3ayTW+rhSvXKfLBA3nkcdTqTVtVs049c03D6hVVrVYdDRsz4dXv1CuUK0uGlG7Cv1K+fFmVLlVaixYvkRTf3/ny5lbffv01YsTIBPW533TRqNFj1KdPX/O21q1aKn369Nr4/geSpCaNG8nR0VGr16xNssaofr19P6Wb8K+0rFtNxb19NGHmk/FdxauwOnbvpXcGDk1QX7GYq3oPHqYO3Z6M776+7WSbPr3mLl+ryAcP5J3fScs3blH1p8Z3s5qVVKVmbQ0Zbezxfft+TEo34V/p2rSWijyzHmtSvphaJ7Eea1imiHwTWY/Z2tpq4qP1WI2iuTUrkfVYhWq11MvA67F7d8NV0zOv7ty5o8yZMydZ97cvM7exsZGTk5Py5s2r3r17q1atWtq1a5d8fX3VrFkzTZ06VS4uLipcuLAk6dq1a2rTpo2yZs2q7Nmzq2nTpvrtt98sXnPdunUqWrSobGxs5OzsrH79+pkfe/rS8ejoaPXr10/Ozs6ytbVV3rx5NX369ERrJenSpUuqUaOG0qdPrxw5cqhnz566d++e+fHHbZ4zZ46cnZ2VI0cO9e3bVzExxh4of1dMdLR+/PaiSparbN5mbW2tkuWr6Fv/xE91j4mOVjobG4ttNja2unQu/lKI2NhYmWJjlS7dMzW2trp8LunLJfB6+v6Kv7xLlbfY5lOmor6/4i9JiomJ1k8/fivvkuXMj1tbW8u7VHlzDVJGTHS0vr/sr9IVq5m3WVtbq3TFqrp07nSiz4mOjlI6G1uLbTa2trpw+oQkKfbhQ8XGxj63Bsbx/ZULFmNXknxKV9D3V+I/+Y2JidFPP36XcHyXLKvvr1wQUk5MdLR+vHJBpSpUNW+ztrZWyQpVdOXvHL9t0+vS2ZOSpNiHsYmPbxtbcw1SRkx0tL6/5K+ylSz7u0ylqrqYxHurmOioBP1ta5te/qePS3refP6kBikjOjpaly6cV6Wq1c3brK2tValqdZ07nXh/R0dFy+aZvrRNb6szJ+L78uGj/rZJ5G/icQ1SRnR0tM6dPauaNZ+cXGBtba2aNWvpxPHE+yYqKkq2z/R3+vTpdfTokyunyleooH379urHH3+UJF24cEFHjx5RvXpczZiSoqOjdeXCeVV4ZnxXqFJd588kMb6jExvf6XX25KPxHftofNsmHN+Pa5AyHq/HyvzN9ViC/k5kPfZsTWpaj/3re2amT59e0dHRkqS9e/fqhx9+0J49e7R7927FxMSobt26ypQpkw4fPqyjR48qY8aMqlevnvk5y5cvV9++fdWzZ09dunRJu3btkqura6L/1qJFi7Rr1y5t3bpVP/zwgzZt2qR8+fIlWnv//n3VrVtX2bJl0+nTp7Vt2zZ98803FkGpJO3fv18///yz9u/frw0bNmj9+vVav379c/c5KipK4eHhFj9Gdifstkyxscpm72CxPVsOB90OTvw091KVqmnb+pX687dfZDKZdObYQR3+5gvdDrolScpgl1Ee3qX0/or5Cg4MUGxsrPbs+ljf+p9RyKMaGEdoSLCyZsthsS1r9hyKuH9PUVGRCr8TJlNsrLJmt7esyZZDoSHBydlUPCMsNESxsbHK/sz4zu7gkORlLOWq1NDmNcv0x68/y2Qy6eTh/dr/1W4FPxq7dhkzydOntNYtmq2gWzcVGxurL3ds0aVzp801MI7Q2yF/Mb5D48f3szXZcij0NuM7Jd0Jva3YRI7f2e1z6nYS47tMpera+t4KXfstfnyfPnpAh77+XCGBj47fGTOqaInS2rBsroJvxR+/v/50m65w/E5xYbcfz+c5LbZnt8+Z9HxetaY2r34yn584tF/7vvxMwYFP5vPiJctozaJZCgqIn8+/2L5Fl86dMtcgZYSGxPe3vYNlf9s75FTQrcT7pkqNmlqzbLF+/fknmUwmHd6/V1/t3qXAWwGSpIyZMsmndFktnjNTt27G9/f2rR/q3OmT5hqkjODgYMXGxiqno6PF9pyOjgpIom/q1KmrBQvm6erVqzKZTNqzZ4927Niumzef3BJkxIiRatP2LRX1cJetTVqVKllCAwYOUrv27V/p/uD5Qm8nPr5z5MypoCTm3krVa2rdisX67dH4PnJgn77+/KnxnTGTSpQuq6VzZ+rWo/n8020f6fyZk0nOGUgez1uPJfV+7Z+uxy6novXYPw4z4+Li9M033+h///ufatSIv3zNzs5Oa9asUdGiRVW0aFFt2bJFJpNJa9askaenp4oUKaL33ntPf/zxhw4cOCBJmjJlioYOHaqBAwfKzc1NpUuX1qBBgxL9N//44w8VKlRIlSpVUt68eVWpUiW9/fbbidZu3rxZkZGR2rhxo4oVK6YaNWpoyZIlev/993XrqcGcLVs2LVmyRO7u7mrUqJEaNmyovXv3Jvqaj02fPl1ZsmQx/+TOnfvv/w80uH6jpujNvPnl26ii6ni9qUVTRqle87dkZf3kT2rUjKWKi4tTm2pequudW9s3rVaNBs1lbf3af+8UkKoNnTBDufMVUJuaZVSxUE7NnjBcjVu3k7XVk7E7cf5KxcXFqWFZD1Vyc9SW9atUp0lLixoAr58BY6fqzbwF1LFeBdUs6qIFk0aqfgvL4/fY2fHH7xaVPVWrWC59vHG1ajZqISvGt+G86zdDufMXUKvqpVW+oINmjR+mJm3aW8zVk+avlOLiVL9MEVVwzamP3lupuk1b8X7NgPymz1b+ggVVo2wJuTpm1fgRQ9W6XUeL8b1gxRrFxcWpTFFXFXLKpvWrlqtJy9aMbwOav2ChXF0LqaiHu9LbptPAAf3k69vFYuxu27pVH27epA8+2KzTZ87pvfc2aN7cOdq4YUMKthz/xNips5SvgKvqVvCRh0s2TRo5VC3f6mDR37OXrlZcXJwqeRZS0VzZtXH1cjVq0VpW1lYp2HL8E0Mercfa1iyjSoVyas6E4Wr0zHrM79F6rFFZD1V2c9TWVLYee+PvPmH37t3KmDGjYmJiZDKZ1K5dO/n5+alv377y9PS0uE/mhQsX9NNPPylTJsv7SEZGRurnn39WYGCgbty4oZo1a77Qv+3r66vatWurcOHCqlevnho1aqQ6deokWvvdd9/Jy8tLdnZ25m0VK1aUyWTSDz/8IMdHn3oVLVpUadKkMdc4Ozvr0qXnf0PrqFGjNGTIEPPv4eHhhg40s2TNLus0aRT6zM1nQ0OCEnz6/1jW7PaavGSDoqMidScsVPY5nbR63hQ5v5nXXJMrTz4t2LhTDyLuK+L+PeVwcNSkIT0samAM2XLYJ/iij7DbIcpgl1E2NraytraWdZo0CnvmLK2w0BBly2F5tiaSV9ZsOZQmTZoEN5e+HRSkHA6Jj+9sOew1Z/UmRUVG6k7YbTk4OmvJDD+55Mlnrnkzb36t3Pq5HkTc1/17d2Wf00mj+3ZVrjyMb6PJlj3HX4zvNPHj+9ma0BBly874TklZsmVXmkSO37eDA5U9ifGdNbu9pi3fGH/WbWio7B2dtGLOZLnkfvr4nV+LN+2yGN8TBna3qEHyy5r98XxueRbH7eDA587nc9dstpjPF0/3U66n5/N8+bVq2xfx/X33ruwdnTSqTxeLGiS/bDni+/vZL/sJDgqUwzNn7z2Ww95Bqz/YosjISIXdvi1HZ2fNmDhOefLmN9fkzV9AW3f/TxH37+vu3XA5Ojmrb9dOypPE1W5IHvb29kqTJo0CnzmDLvDWLTk5OiX6HAcHB23fsVORkZEKCQmRi4uLRo0aqQIFCphrRowYpuEjRqrtW29Jkjw9PfX7H79r5szp6tS586vbITxXtuyJj++QwEA55Ex6fC/f+JGiIiMVGnpbjk7Omj15vHLnzWeuyZu/gDbvih/f9+7eVU4nJw3s3km5n5oDkPyetx5L6v1athz2mv3MemxpIuuxFc+sx8b07SqXVLIe+9uRbfXq1eXv76+rV6/qwYMH2rBhgzkwfDo4lKR79+6pZMmS8vf3t/j58ccf1a5dO6VPn/5v/ds+Pj769ddfNXnyZD148EBt2rRRq1at/u4uWEib1vLG4FZWVjKZTM99jo2NjTJnzmzxY2Rp06WTm0dxnTtx2LzNZDLp3InD8vAu9dznprOxlYOjs2IfPtShr3er4lM3n30sfQY75XBw1N07YTp99ECiNXi9uRf1lv9Zy3tvnD9zXO5FvSVJadOmk6ubh0WNyWSS/9kT5hqkjLTp0sm9mLdOHzto3hZ/a4hD8vQp/dzn2tjaKqeTi2IfPtT+rz5T1doJ76+UPoOd7HM6KfxOmE4c2qsqtRu89H3Aq+Ve1Ev+z9wLMX58F5cUf5x0dStiUWMymeR/7qTci3ola1thKW26dHIr6qWzxw+Zt5lMJp07flhF/+L4bWNjKwenR8fv/32mSjXrJah5PL7v3gnT6SP7Vakm91hLSWnTpZO7p7dOHbWcz08fPaTiPmWe+9yn5/N9X+5S1ToJ5+r0Gexk7+ik8LAwHT+0V1WZz1NUunTp5OlVQkcPHTBvM5lMOnrwgHxKP7+/bW1t5eTioocPH+rLzz5VnQYNE9RksLOTo5Oz7oSF6tC+b1SnfqOXvQv4G9KlSyefkiW1b9+TKwRNJpP27durcuXLP+eZ8f2dK1cuPXz4UDu2f6LGTZqaH4uIiEhwllaaNGn+cr2LVytdunQq6lVCx58Z38cOH1CJUn89nzs5x4/v/332qWrVSzh2M9jZKaeTk+6Eherw/r2qVT/hHIDkk9R67PQ/WI9VYT1m9rfPzLSzs0vynpbP8vHx0ZYtW5QzZ84kA798+fJp7969ql69eqKPPytz5sxq27at2rZtq1atWqlevXq6ffu2smfPblFXpEgRrV+/Xvfv3zeHrEePHpW1tbX5y4nwRGvfXpoxaoAKF/OWu2cJfbJxlSIfRKhe8/hP8aaP7Cf7nE7qMST+W7G+u3BWQYEBcnUvquBbAdqwdLbi4kx6q9uTe5KePrJfcXFxyp2/oK7/8ZtWzp6oPPldVa954rcGQPJ5EHFfN67/Yf494OZ1/Xz1O2XKnEU5HV20fsU8hQQHaujYGZKkBk3bavf2zVq3bI5qN2yhC+dO6vD+r+Q3c7n5NZq39dW8aaNUyL2Y3Ip46tNtGxX54IFqN2ie7PsHS+2699HEoX1UxLOEinr76KO1y/Ug4r4atY6/X9KEIb2U09FZfUfEf8vh5fNnFHTrptw8PBUYcEOrF8yUyWRSx6e+Gfn4wb1SXJzyFCykP3/7RYumjVe+gm5q3Jp7MKW0BxERiYzv7x+Nb2etX7VQIUG3NHTMNElSg6attXvHh1q3fJ5qN2geP74PfC2/GUvMr9G8TSfNmz5Whdw95ObuqU8//iB+fNdvlty7h2e06dJL00f0V+Fi3ipS3EfbNqzUgwcRatAy/lg7dVhf2Ts66Z13x0mSvr1wVkEBN1WoSDEF3bqp9xbPlskUp7d79De/5qnD+x4dv111/Y9ftXymn/IUKGR+TaSc9t37ym9ob3l4llBR75La/Gg+b9wmfu4dP+gd5XRyUb+RT+bzwIAbcvMorqCAG1o1f4biTCZ16jXA/JrHD+5VXFyc8hZw1bXfftWiaeOUr6CbmrRhPk9p3fv019C+PVXcu4S8fEpp3YqlioiIUOt2HSVJg3t3l5Ozi0aMnyRJOn/mtAJu3lBRz+IKuHlD82dOlclk0jsDnnxT7sG9exQXF6cChdz0+y8/a9qEMSpYyE2t23dMkX3EE4MHDVGXLp1VsmQplS5TRosWLtD9+/fl69tFkuTbuZNccuXStGnxX4B78uRJ3bh+XV7e3rp+/bomTfKTyWTSsGHDza/ZqFFjTZ8+Vbnz5FHRokXlf/68FsyfJ98uXVNgD/G0rr36aXj/d1TM20fFfUpq/cqlehARoZZvd5AkDevbQ45OLnp33ERJkv/Z07p184aKFCuuWzdvaPHsaTLFmdSj/yDzax7e943i4uKU37WQfv/1F830G6MChdzU8m3Gd0p7u3sfTXq0HvN4tB6LfGo95jeklxyesx5bk8h67MTj43fBQrr22y9aPG288qai9djfDjP/jvbt22v27Nlq2rSpJk2apDfffFO///67tm/fruHDh+vNN9+Un5+fevXqpZw5c6p+/fq6e/eujh49qv79+yd4vXnz5snZ2VklSpSQtbW1tm3bJicnJ2XNmjXRf3vChAnq3Lmz/Pz8FBQUpP79+6tjx47mS8zxRPX6zRR2O0TvLZ6l0OBAFXQvqpkrPzRfZh5487rF/Tiio6P03sIZuvHn70qfwU5lq9TUqJlLlTFzFnPN/bvhWr1gqoIDbipTlqyqXKeRug0cpTeeORsWye/qD1c0aoCv+fc1S2ZKkmrWa6YhY6bpdkiwgm49uXm4k8ub8pu1XKsXz9CnH78vewcnDRg+SSXLVjLXVKlZX3fCbuuDtYsVejtYBVzdNWnOSi5DfQ3UbtxCobeDtWr+NIUEBcqtiKcWbvjYfFniret/WnxqHx0VpRVzpur6H78pvZ2dKlSvrYnzVyhTlifj+97dcC2bNUmBATeUOUs21ajfWL3fHcv4fg1c/eGKRg3qZv59zdLZkqSa9ZpoyKgpuh0SpKDAJ18m4OT8pvxmLNXqJbP16SebZO/gqAHD/FSyTEVzTZUa9XQnLFQfrFv2aHwX1qTZy5Utu+WXAiH51WzYXGG3Q7Ru0UzdDgqUa5FimrN2i/n4fevmnxb3yoqOitSaBdN181r88btc1VoaO3uZMmW2HN+r5k5VUMANZcqaVVXrNFKPIWMY36+BOk3i5/MV8x7N5x6eWvz+J+b5PODGnxbv16KiIrV89lRdv/ab0mewU8XqtTVpwUplypLVXHMvPFxLZk58Mp83aKK+w5jPXweNW7RSSEiw5k2foqDAW/IoVlwbt+00X4Z648+E/T1n6iRd+/1XZbDLqOq162jB8rXK8lR/3w0P18zJExRw47qyZMum+o2badjYCQmuVkPya9O2rYKCg+TnN14BAQHy8vbW5198ZV67/nHtD4v+joyM1PjxY/XLL78oY8aMql+/gTZseN9ibbxw0WJNGD9O/fv1UWBgoFxcXNSj5zsaN258cu8entGweSvdDgnWwpnx47tIseJau2WH7M3j+5rFvWyjIiM1f/okXfv9N9nZ2alqrbqavWyNMluM7zuaM9VPATeuK2vWbKrbqKmGjGF8vw5qN26hsGfWYwteYD1246n1mN9frMeqp7L1mFVcXFzcixb7+voqLCxMO3fufOHHAgICNGLECH3xxRe6e/eucuXKpZo1a2rOnDnmszVXrlyp+fPn65dffpG9vb1atWqlRYsWxTfQyko7duxQs2bNtHr1ai1btkxXr15VmjRpVLp0ac2ePVslSpRIUCtJly5d0sCBA3X8+HFlyJBBLVu21Lx585QxY8Yk2zxo0CD5+/ubv6DoRYSHhytLliz67NRPssuY6a+fAMN7EBLy10X4z3DI7ZzSTUAyCvr9Wko3AckokzPjOzXJYJs63uAjnkNG+js1yZUlQ0o3Acno19v3U7oJSEa378ekdBOQTO7dDVdNz7y6c+fOc2/p+LfCTCSOMDP1IcxMXQgzUxfCzNSFMDN1IcxMXQgzUxfCzNSFMDN1IcxMPV40zEwd39kOAAAAAAAAwPAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADCEN1K6Af8lkcGBsn4QkdLNQHKwZuikJtbWVindBCQn20wp3QIko2IuWVK6CUhG3waEp3QTkIxs0timdBOQjExxcSndBCSju5GxKd0EJCOWY6nHi/Y1Z2YCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmSrKystLOnTslSb/99pusrKzk7++fom1KbpcvnNHEkf3UsUVNNaxaXMcP7/vL51w8f1oDurdR01ol1b1dQ+358tMENbt3fKQubeupWe1SGtyrnX747tKraD7+psv+ZzRxRB91bFZVDSt76Pihb/7yORfPn9KAri3VtIaXur9VV3u+2JGgZvf2zerSupaa1fTW4J5t9cO3F19F8/EPbN2wWo0reKpCIUd1blJTl/3PJln7MCZGqxfMVNNK3qpQyFFv162oYwcs/0bu37uruX4j1ah8MVUs5KSuzevoyoVzr3o38AIunz+piUO7qWPDsmpYNr+OH/z6L59z8ewJDejUSE0rFVb3ltW0Z/fHCWp2b9uoLs0qqVnlwhrctZl+uOL/ClqPf2LNyuXy8igk5xyZVKtaRZ09czrJ2piYGM2aPkU+nu5yzpFJlcuV1Dd7/mdRExsbq6mTJsi7qJtc7DPLx9Nds2dMVVxc3KveFbyAT95fq1ZVS6iGRy71aFlH3z5n7n0YE6P3Fs9Wm+qlVMMjlzo3qqoTB/da1ETcu6uFU8aoZRVv1Sj6pnq1rq/vLjKfvy7WrV6hUp5uypszi+rXqKxzZ58/vufOnKqyXkWUN2cW1ahYWvu+sTwGxMbGauYUP5X2LKx8jllV1quI5s2axvh+TSxftlSFCuZXJrv0qli+nE6fOpVkbUxMjKZMniR3N1dlskuvkj7e+t9XX1nUxMbGasL4cXJzLaDMGTPI3c1VU6dMpr9fE1vWr1bD8p4q55pTnRrX0OXzSb8/j4mJ0aoFM9WkopfKueZU2zoVdXR/wvfns/1GqkG5Yirv6ijfZrV15Tnv+ZG8tm5YrSYVi6uim5N8m9Z6bt88jInR6oWz1KxyCVV0c1K7epUSX49NHKXGFTxVyc051a3HUjzM9PX1lZWVlaysrJQ2bVrlz59fw4cPV2RkZEo3LVWJfPBA+V0Lq/eg0S9UH3DzT/mN7KviJcpo8ZptatqqgxbN9tPZU0fNNYf2faXVS2erXedeWrR6i/IXLKxx7/ZSWGjIq9oNvKDIyIj4/h4y7oXqA278Kb/hvVXcp4wWr9uupq07adGs8Tp78oi55tDeL7V6yUy18+2jRWs+Vn5Xd40b2pP+fg18vWu75k8eox6DRuiDzw/KrUgx9e/QQreDgxKtXzZ7irZvWq9hk2Zp6zcn1bJDVw3r0UHfX75grpkyfIBOHj6gSQtW6qM9x1S2cnX1addMgQE3kmmvkJTIBw+Uv1AR9R426YXqA25ck9+QripespwWv/+5mr7VRYumjdTZEwfNNYf27NbqhVPVrttALdqwW/ldi2jcwM4Kux38qnYDL2j7x1s1dtQwDR81VvuPnFSxYsXVqllDBQUGJlo/ddJ4bVi3RjPnzNfxMxfUpVtPdXq7tS5eOG+uWThvtt5bs0qz5i7QibMXNWHSVC1eMFerli9Nrt1CEvZ+vkNLpo1Tl/7DtPbTfXJ1L6ohXVorNCTx+XzV/Gn69KMNGjxhut7/6qiavd1Zo/t01o9XnnzYOGP0IJ0+ckDj5izTxs8PqXSlahrUqaWCAm4m124hCTs/2Sa/0cM1dMQYfX3ohIoW89TbzRsrKCjx8T1jsp/ef2+tps6er0Mnz6tTlx7q2r6NLl3wN9csmT9HG9au1rQ5C3TolL/GTpyqpQvnae3KZcm0V0jK1q1bNOzdoRo7brxOnj6r4l7F1bBBPQUmMZ+PHzdWa1av0vwFi3Th0hX17PmOWrdqofPnn8zns2fN1KqVK7Rg4WJdvPytpk6foblzZmvpksXJtVtIwv92faJ5k0er56AR2vzFIRXyKKa+HZs/5/35ZH3ywXsaPnm2Pt57Uq06dNG7PdpbvD+fNKy/Th7er8kLVmrLnmMqV6WGerdrpsCbvD9PaV9/tl0LpoxV94Ej9P7uAypUpJj6d2yZZH8vnzNFOzat17CJM7XlmxNq0b6LhvfsqB8uPzl+TxkxUCcPH9DE+Sv04ddHVa5KDfVtn3rWY1ZxKfyxjK+vr27duqX33ntPMTExOnv2rDp37qxevXpp5syZydIGKysr7dixQ82aNdNvv/2m/Pnz6/z58/L29n6h54eHhytLliza9sUxZbDL+GobmwwaVi2usVMWqHzlGknWrFsxX2dOHNKy9U/Ozps5cbju3QvX5NkrJEmDe7WTm3sxc0BqMpnk27qOGrV4W23ad3u1O/GqWb+R0i14aRpW9tDYqYtUvkqtJGvWLZ+rM8cPatnGXeZtMycM1b17dzV57ipJ0uCebeVWxFO9B4+V9Ki/W9ZQo5bt1aZDj1e7E6+YY16XlG7Cv9K5SU15ePloxOTZkuL7pmHZomrr21O+fQcnqK9Xyl1d+w9Vm85P+m3YOx1la5tekxeuUmTkA1Ut8qbmrtmsSjXrmms6NKiqCtVrq8+wsa9+p16hWzdDU7oJL03Dsvk1dtZKla9aJ8madUtm6MzR/Vr24ZOz82aO6R8/ny/cIEka3LWZ3IoUNwekJpNJvk0qqFHrzmrTufer3YlXrHzRXCndhH+lVrWK8vEppVnzFkqK7xvPwgXUo1cfDRo6PEG9h2teDRk2Ut3fedJvndq1Ufr06bVybXx/v9WqmRxy5tTiZauSrDGqbwPCU7oJ/0qPlnVUxLOEhvjFv0c2mUxqUbm4WnbsoY69Biaob1qhqDr1HqKWHZ+87xrT11c2NrYaP2+FoiIfqI5XPk1f8b4qVH8yT3RtWkPlqtZSzyEv9iH368rVwdjvy+vXqCxvn5KaPmeBpPj+9vFwVbeevdV/yLAE9V6F82vguyPUtUcv87ZuHd6SbXpbLV29XpLUoU1zOTjk1PylK5OsMarsdulSugn/SsXy5VSqdCktXLREUnx/F8iXR3369tPwESMT1OfNnUsjR41W7z59zdvatG6l9OnTa8PG9yVJzZo0Vk7HnFq1em2SNUZ1+ebdlG7Cv9KpcQ15ePlo5JQ5kuL7u34ZD73Vpae69B2SoL5OycLq1v9dtfV98v783Z4dZGObXlMXrVbkgweqXCSX5q39UJWfen/erkEVVaxWW32Hv9hJLK+rWJMppZvwr/g2rSWP4iU0/Kn1WKNyxdTGt4d8+yRcj9UvXURd+g2xWI8Nf6eTbGxtzeuxah65NWf1Jov1WMeG1VShWi31NvB67N7dcFUvlld37txR5syZk6xL8TMzJcnGxkZOTk7KnTu3mjVrplq1amnPnj2S4jt5+vTpyp8/v9KnTy8vLy99/LHl5W9XrlxRo0aNlDlzZmXKlEmVK1fWzz//LEk6ffq0ateuLXt7e2XJkkVVq1bVuXOp59TbV+X7KxfkXbKcxTaf0hX0/aNP+mNiYvTTj99Z1FhbW8u7ZFl9f+WCYCzfX/GXd6nyFtt8ylTU948uM42JidZPP36bsL9LlTfXIGXEREfr+0v+KlupqnmbtbW1ylSqqovnEr90KSY6SulsbCy22dqml//p45Kk2IcPFRsbq3Q2thY1Nk/VwDi+v3RO3qUrWmzzKVdF31+KP7MjJiZaP31/Wd5lKpkft7a2lnfpivr+EsfTlBQdHa0L58+pavUnHz5aW1uravUaOn3qRKLPiYqOko2t5dhNnz69Thw/Zv69TNlyOnRgv366+qMk6fKlCzp5/Jhq1akrpJyY6Gj9ePmCSlW0nM9LVaiqK+cTv/Q4JjpaNs/M5zY2trp49qSk58/nF88k/jeE5BEdHa2L/udUpZrl+K5crbrOnD6Z+HOiomT77PE7va1OnngyvkuXKafDh/br55+uSpKuXLqokyeOqUZtxndKio6O1rlzZ1Wj5pOTC6ytrVWjZi2dOJHEfB4VJdtE5vNjR59cOVWufHnt37dPP/4YP59fuHBBx44eUd169V7BXuBFxURH67tL/ipbqZp5m7W1tcpWrqaLSdxKIiY6Sja2z8zntunlfzr+7yM29vF8nth7eObzlPR4PVbmmf4uU6mqLp17Tn8nODbb6sKjY3PSx29b+aeS4/drEWY+7fLlyzp27JjSpYv/ZG369OnauHGjVqxYoStXrmjw4MHq0KGDDh6Mv/zt+vXrqlKlimxsbLRv3z6dPXtWXbt21cOHDyVJd+/eVefOnXXkyBGdOHFChQoVUoMGDXT37j//JCcqKkrh4eEWP6lN6O0QZc2Ww2Jb1uw5FHH/nqKiIhV+J1Sm2NiENdlyKJTLEg0nNCT4L/o7LL6/s9tb1mTLodAQ+jslhd0OUWxsrLLb57TYnt0+p0KSuEytXNWa2rx6mf749WeZTCadOLRf+778TMGBtyRJdhkzqXjJMlqzaJaCAm4qNjZWX2zfokvnTplrYByhIUEJx252e0Xcv6uoyEiFh4UmPr6z2yv0duKXxiB5hIQEKzY2Vg45HS22O+TMqVu3Eh+LNWrW1rLFC/TzT1dlMpm0f9832r1rp249dUnxoKHD1aJVa5X18VTOrBlUtUIZ9erbX63btnul+4PnuxP6aD7P4WCxPbu9g0KCE5/Py1Suro/WLde13+Ln89NHDujg158r5NFcnSFjJhUrUVrrl8xR8K34+fx/O7fqyvnTCgliPk9Jt83j2/L47eDgqMAkxne1mrW0Yuki/fLzTzKZTDq47xt98dmnCgwIMNf0HzJMzVq0UaVSxfVmjoyqVbmsevbup5Zt3n6l+4PnCw6O72/HZ+bznDlz6tZT/fe02nXqasGC+bp6NX4+/2bPHu3csV03bz6Zz4ePGKnWbdrKs2gRZbBNpzKlfNR/wEC1a9f+le4Pns/8/tzh2ffnDknOveWr1tQHq5c+9f58n/Z/+ZmCA+P/PszvzxfONr8//3z7Fl08e8pcg5QR9vj4bZ/I8Tup9ViVGtq05sl67OTh/dr/1W6L9ZinT2mtXTxbQbeeXo+dTjXrsdcizNy9e7cyZswoW1tbeXp6KjAwUMOGDVNUVJSmTZumdevWqW7duipQoIB8fX3VoUMHrVwZf2nE0qVLlSVLFn300UcqVaqU3Nzc1KVLFxUuXFiSVKNGDXXo0EHu7u4qUqSIVq1apYiICHMY+k9Mnz5dWbJkMf/kzp37pfx/AIDXwbt+M5Q7fwG1ql5a5Qs6aNb4YWrSpr2srZ4cMibNXynFxal+mSKq4JpTH723UnWbtpK19WtxWAGQhOmz5qmgq6vK+njKMZudRgwdqHYdOluM3R2fbNO2LR9p1bqNOnDkpJatWqsli+brw00bU7Dl+CcGjp2m3PkKqH2d8qpexFnzJo5Qg5Zvy+qp/h43Z5kUF6dmFT1Vw8NFH29crVqNWjCfG9DkmXNVoKCrKpUqrtz2mTR62GC1bd/Joi93bf9Y27d9qOVrNmjPoRNatGKNli9eoC2bjX3JcWo0b/4CuboWkmfRIrJLb6OBA/urs6+vRX9v27ZVH324WRs/2KSTp89q7XvrNX/eXG3caOxbhqRGwybOVJ58BdWiWimVLWCvmeOGqfEz788nL1ipuLg41S3trnIFHfTRuhWq27SVxZwPYxjqN0N58hdQ6xplVME1p2aNH67GrdtZrsce9XeDMh6qWMhRW9avUp0mLS1q/steixv/Va9eXcuXL9f9+/c1f/58vfHGG2rZsqWuXLmiiIgI1a5d26I+OjpaJUqUkCT5+/urcuXKSps2baKvfevWLY0dO1YHDhxQYGCgYmNjFRERoT/++OMft3fUqFEaMuTJfSzCw8NTXaCZLXuOBF/sEnY7RBnsMsrGxlbW1mlknSZNwprQEGV75uwevP6y5bD/i/62ju/vZ866DQsNUbYc9HdKypo9h9KkSaPbz5y1czs4UDme+TT4sWw57DV3zWZFRUbqTthtOTg6a/F0P+XKk89c82a+/Fq17Qs9iLiv+3fvyt7RSaP6dLGogTFky+GQcOzeDlYGu0yysbWVdZokxvftYGXLbvkJM5JXjhz2SpMmjYKe+QQ+KDBQjo6OiT7H3sFBH3z0iSIjI3X7doicnV00cfxo5c2X31wzYewoDRoyTC1bt5UkeRTz1LU//tCCObP0dvtOr26H8FxZsj2az5/5sp/bwUHKYZ/0fD59xfvxV1GEhsre0UnLZ0+SS+685ppcefNryYefxc/n9+7KPqeTxg/oZlGD5JfdPL4tj99BQbeUM6nxbe+g9Zu3KTIyUqG3Q+Tk7KIpE8Yqz1Pje9L4Ueo3eJiatWojSSpStJj+vPaHFs+brbbtOr66HcJz2dvH9/etZ+bzwMBAOTo5JfocBwcHfbJ9hyIjIxUSEiIXFxeNHjVS+QsUMNeMGjFcw4aPUNu2b0mSPD099cfvv2vWzBnq1Knzq9shPJf5/XnQs+/Pg5TDIfHxnS2HveatffT+PPS2HJyctWj6BOXKm89ckztfAa35OP79+b27d+Xg6KQRvX31Ju/PU1TWx8fv4ESO389Zj81ZvcliPbZkhp9cnl6P5c2vVVs/t1yP9e2qXHlSx/H7tYhs7ezs5OrqKi8vL61bt04nT57U2rVrde/ePUnS559/Ln9/f/PPt99+a75vZvr06Z/72p07d5a/v78WLlyoY8eOyd/fXzly5FB0dPQ/bq+NjY0yZ85s8ZPauBf1kv9Zy/v1nD9zXO5Fi0uS0qZNK1e3IhY1JpNJ/udOyr2oV7K2Ff+ee1Fv+Z+1vPdGfH97S5LSpk0nVzcPixqTyST/syfMNUgZadOlk7unt04dfXI2uslk0umjh1Tcp8xzn2tja6ucTi6KffhQ+77cpap1GiSoSZ/BTvaOTgoPC9PxQ3tVtXbCGrze3D195H/mmMW286eOyN0z/kPDtGnTydW9mPxPHzU/bjKZ5H/6mNw9fZK1rbCULl06eZXw0aED+83bTCaTDh7Yr9Jlyj3nmZKtra1cXHLp4cOH+uzTnWrQqLH5sQcPIhKclZcmTRqZ4ox9832jS5sundyKeenssUPmbSaTSWePHVLREqWf+1wbG1s5ODkr9uFDHfxqtyrXqp+gJn0GO9nndFL4nTCdOrxflRKpQfJJly6dinv76PBBy/F95OABlSpd9rnPtbW1lfOj8f35rh2q16CR+bEHEQ8SnLWTxjqNTAb/cg2jS5cunXx8Smr/vr3mbfG3AtmrcuX+ej7PlSu+v3fu2K7GjZuYH4uISGI+p79TVNp06VQkkffnp44cVPGSfzGf29oqp7OLHj58qL1f7Er0vXf6DHZycHRSeFiojh/al+h7eCSfx+ux04msxzx9XqC/zeuxz1S1ThLHb8f44/eJQ3tVJZX092txZubTrK2tNXr0aA0ZMkQ//vijbGxs9Mcff6hq1aqJ1hcvXlwbNmxQTExMomdnHj16VMuWLVODBvEdeu3aNQUHcw+/Zz2IiNCN60/OVg24eV0/X/1emTJnUU5HZ61ftVAhQbc0dMw0SVKDpq21e8eHWrd8nmo3aK4L507q8IGv5Tdjifk1mrfppHnTx6qQu4fc3D316ccfKPLBA9Wu3yy5dw/PeBBxP5H+/u5Rf7to/Yp5CgkO1NCxMyRJDZq21e7tm7Vu2RzVbtgivr/3fyW/mcvNr9G8ra/mTRulQu7F5FbEU59u2xjf3w2aJ/v+wVL77n3lN7S3PDxLqKh3SW1eu1wPIu6rcZv4+yWNH/SOcjq5qN/ICZKky+fPKDDghtw8iiso4IZWzZ+hOJNJnXoNML/m8YN7FRcXp7wFXHXtt1+1aNo45SvopiZtuAdTSnsQcV83/vzd/HvAjWv6+cdv48e3Uy6tXzpLIUEBGuo3T5LUoEV77d62UesWT1ftxm104cwxHd77ufzmPfnm0+Zvd9e8SUNVqEhxuXl46dOP1ikyMkK1G7VK9v2DpT79BqrvO93k7eMjn5KltWLpYkVE3Fe7DvFn3PTu0UXOLi4aP3GqJOnM6VO6eeO6PIt76eaNG5o5bbJMJpMGDHrX/Jr16jfU3Nkz9Gbu3HIv4qGLF/y1bPFCtecsnhT3Vtfemjqsn9w9vVWkuI+2rl+hBw8i1LBV/P0OJ7/bRw6Ozuo1LP5ba6/4n1XwrZtyLVJMwbduat2iWTLFmdSuZ3/za548tE9xcXHKU8BV13//VUtn+ilPgUJq2JJ7pKa0d/oO0MDe3eVVwkclSpbW6mWLFXH/vt7qEH+GdL93usrZ2UVj/KZIks6dOaWbN26omGdx3bx5Q3OmT5HJZFLfgUPNr1m7fgMtnDtTuXLnVmH3Irp88YJWLF2ktzswvlPawMGD1a2Lr3xKllLp0mW0eNEC3b9/X519u0iSuvh2louLi6ZOmy5JOnXypK7fuC4vL2/duH5dkydNlMlk0rvDhptfs2GjxpoxfZpy584jj6JF5e9/XgsXzDe/JlJO+x59NWFIb3kUf/z+fJkePLivJm06SJLGDXpHOZ2c1X+knyTp0qP354U9PBUYcFMr509XXJxJvr0Hml/z2IFvFBcn5Svoqmu//aIFU8crX8FC5tdEymnXvY8mDu2jIsVLqKiXjz5c92g91jp+7TRhcC85ODmr34in12M35VbU89F6bKZMJpM6vfOkv5+sxwrpz99/0cJp4+PXY61Tx3rstQszJal169YaNmyYVq5cqXfffVeDBw+WyWRSpUqVdOfOHR09elSZM2dW586d1a9fPy1evFhvvfWWRo0apSxZsujEiRMqU6aMChcurEKFCun9999XqVKlFB4ermHDhv3l2Zyp0dUfrmjUoG7m39csnS1JqlmviYaMmqLbIUEKeurGwU7Ob8pvxlKtXjJbn36ySfYOjhowzE8lyzz5RtwqNerpTlioPli3TKG3g1XAtbAmzV6ubNktv0gGye/qD1c0aoCv+fc1S2ZKkmrWa6YhY6bpdkiwgm49uXm4k8ub8pu1XKsXz9CnH78vewcnDRg+SSXLPvl24yo16+tO2G19sHbxo/5216Q5K7mtwGugTpMWCr0drBXzpikkKFBuHp5a/P4n5ssaAm78afGpfVRUpJbPnqrr135T+gx2qli9tiYtWKlMWbKaa+6Fh2vJzIkKDLihzFmyqUaDJuo7bKzeSOKWH0g+V7+7pFF9nnyRw5oF8Yvcmg1basj4ObodEqigWzfMjzu55JbfvHVavWCyPt2yXvY5nTRg9AyVLPfkQ8QqtRvpTliIPlg1T6EhwSrgVkSTFqxXthxcZp7SWrRqo5DgYE2fMkmBtwJUrLiXtu3Ybb4M9c9r1yzHd2Skpk6aoN9/+1V2dhlVu249LV/znrJkzWqumTFngaZN9tO7gwcoOChQTs4u8u3aXcNGjU3u3cMzajZsrrCQEK1ZMEO3gwLl6lFMc9dtNX/J261n5vPoqEitnjdNN679rvR2dipXtZbGzVmmTJmzmGvu3Q3XyjlTFBRwQ5mzZlXVuo3Vc+gY5vPXQLOWrRUSEqxZ0yYp6NYtFfX00ofbd5m/9Ov6n5bjOzIyUjOm+OmPR+O7Rp26WrJqncX4njZrvmZOnaiRQwcoJChIjk7O6tSlm4aMGJPcu4dntGnTVsFBQZrkN0EBAQHy8vLW7s+/NN825NoffyTo7wnjx+nXX35RxowZVa9+A723YaOyPtXfCxYukt+EcRrQv68CAwPl4uKi7j16auy48cm9e3hG3SYtFXo7RMvnTlNI0C0V9vDUkve3P3l/fv1Pi7OooyMjtWz2FF3/4zdlyGCnijXqaMqCVZbvz++Ga8mMiboVcENZsmZTjfpN1Hf4uCRvyYfkU6dxC4WFBGvlU+uxRRs/tliPWVmsx6K0Ys6z67EVypTF8vi9dOakJ+ux+o3VJxWtx6zi4uLiUrIBvr6+CgsL086dOy22z5gxQ/PmzdOvv/6qNWvWaPny5frll1+UNWtW+fj4aPTo0apSpYok6eLFixo2bJiOHDmiNGnSyNvbW+vXr1eBAgV0/vx59ezZU5cvX1bu3Lk1bdo0vfvuuxo0aJAGDRokSbKystKOHTvUrFkz/fbbb8qfP7/Onz8vb2/vF9qH8PBwZcmSRdu+OKYMdhlf4v8dvLasX8vPAfCKOOZ1SekmIBnduhma0k1AMipfNFdKNwHJ6NuA8JRuApKRqwPvy1OT7HbpUroJSEaXb95N6SYgGcVya4RU497dcFUvlld37tx57i0dUzzM/C8gzEyFCDNTFcLM1IUwM3UhzExdCDNTF8LM1IUwM3UhzExdCDNTjxcNM1+LLwACAAAAAAAAgL9CmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAgP+3d8e6iYNBFEYHK1pXmB7hZ+VhjXgAG+iCt9ktCdIq61+TOacNxUhXRuJTElIQMwEAAACAFMRMAAAAACAFMRMAAAAASEHMBAAAAABSEDMBAAAAgBTETAAAAAAgBTETAAAAAEhBzAQAAAAAUhAzAQAAAIAUxEwAAAAAIAUxEwAAAABIQcwEAAAAAFIQMwEAAACAFMRMAAAAACAFMRMAAAAASEHMBAAAAABSEDMBAAAAgBTETAAAAAAghY/WB/wE67pGRMTjcW98CZvpPDqV3Ja59Qls6HFbWp/AhubZ813JffF8V7L0z9YnsKGPz1+tT2BDN+/npXw+vZ9Xcf/zWexvZ3tlt757BW9dLpcYx7H1GQAAAACQ2jRNcTqdXv5czPwGz+czrtdr7Pf72O12rc/ZzDzPMY5jTNMUwzC0Pof/zN612LsWe9di71rsXYu9a7F3Lfaupere67rGsixxPB6j617/Z0x/K/sNuq77shj/dMMwlHq4qrN3Lfauxd612LsWe9di71rsXYu9a6m49+FwePsaXwAEAAAAAKQgZgIAAAAAKYiZ/LO+7+N8Pkff961PYQP2rsXetdi7FnvXYu9a7F2LvWuxdy32/povAAIAAAAAUvCbmQAAAABACmImAAAAAJCCmAkAAAAApCBmAgAAAAApiJkAAAAAQApiJgAAAACQgpgJAAAAAKQgZgIAAAAAKfwGmiJXByvPT4MAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MOLSL09JxKdp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}