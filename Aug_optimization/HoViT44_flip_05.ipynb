{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "36b28934-6528-4b80-a337-b832f3a0aa56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=756fc9e7aca4e7534fe916e81dfd369857d5d9d670666d7bbf506e976176029d\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "1a7fef8d-028e-44c1-86c0-6bc054666bed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-21 14:30:59--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.45.92, 188.185.43.25, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.45.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-03-21 14:31:00--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  24.7MB/s    in 7m 40s  \n",
            "\n",
            "2025-03-21 14:38:40 (24.2 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "6b7ad874-d874-43be-b9db-7c92b643c55b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "d758fb51-9f4b-4394-9ea5-d0b636f1893d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "69651ed3-12cf-4d92-fd00-ac5c1e2b4a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "2f20793e-2296-4fc4-d326-65f7c7e28ed2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "])"
      ],
      "metadata": {
        "id": "zja84HaiVhoh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "train_data = Subset(dataset, load_train_idx)\n",
        "val_data = Subset(dataset, load_val_idx)\n",
        "test_data = Subset(dataset, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "ce4c2d85-843b-4b16-d291-8ad023099208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "569d2bfc-245e-4698-fdb4-c56c248e8c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:47<00:00, 13.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6988, Train Accuracy: 74.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3818, Validation Accuracy: 86.97%\n",
            "Balanced Accuracy: 0.8668\n",
            "New best model saved with Validation loss 0.3818 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3623, Train Accuracy: 87.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4592, Validation Accuracy: 83.99%\n",
            "Balanced Accuracy: 0.8297\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2508, Train Accuracy: 91.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1799, Validation Accuracy: 93.92%\n",
            "Balanced Accuracy: 0.9399\n",
            "New best model saved with Validation loss 0.1799 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1920, Train Accuracy: 93.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.2198, Validation Accuracy: 68.51%\n",
            "Balanced Accuracy: 0.6805\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1522, Train Accuracy: 94.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2515, Validation Accuracy: 91.54%\n",
            "Balanced Accuracy: 0.9098\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1218, Train Accuracy: 95.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3586, Validation Accuracy: 88.39%\n",
            "Balanced Accuracy: 0.8773\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0990, Train Accuracy: 96.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4472, Validation Accuracy: 86.33%\n",
            "Balanced Accuracy: 0.8645\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0822, Train Accuracy: 97.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1321, Validation Accuracy: 95.59%\n",
            "Balanced Accuracy: 0.9570\n",
            "New best model saved with Validation loss 0.1321 at best_model.pth\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0670, Train Accuracy: 97.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0816, Validation Accuracy: 97.20%\n",
            "Balanced Accuracy: 0.9700\n",
            "New best model saved with Validation loss 0.0816 at best_model.pth\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0575, Train Accuracy: 97.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2512, Validation Accuracy: 91.55%\n",
            "Balanced Accuracy: 0.9074\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0481, Train Accuracy: 98.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1083, Validation Accuracy: 96.47%\n",
            "Balanced Accuracy: 0.9664\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0432, Train Accuracy: 98.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1303, Validation Accuracy: 95.79%\n",
            "Balanced Accuracy: 0.9556\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0372, Train Accuracy: 98.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1932, Validation Accuracy: 94.58%\n",
            "Balanced Accuracy: 0.9446\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0326, Train Accuracy: 98.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0972, Validation Accuracy: 77.39%\n",
            "Balanced Accuracy: 0.7686\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0318, Train Accuracy: 98.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0340, Validation Accuracy: 98.91%\n",
            "Balanced Accuracy: 0.9887\n",
            "New best model saved with Validation loss 0.0340 at best_model.pth\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0260, Train Accuracy: 99.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1070, Validation Accuracy: 96.77%\n",
            "Balanced Accuracy: 0.9648\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0234, Train Accuracy: 99.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1294, Validation Accuracy: 96.47%\n",
            "Balanced Accuracy: 0.9625\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0234, Train Accuracy: 99.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0678, Validation Accuracy: 98.04%\n",
            "Balanced Accuracy: 0.9808\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0210, Train Accuracy: 99.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.6603, Validation Accuracy: 67.25%\n",
            "Balanced Accuracy: 0.6629\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0186, Train Accuracy: 99.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3137, Validation Accuracy: 92.15%\n",
            "Balanced Accuracy: 0.9134\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0189, Train Accuracy: 99.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0409, Validation Accuracy: 98.70%\n",
            "Balanced Accuracy: 0.9864\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0160, Train Accuracy: 99.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0476, Validation Accuracy: 98.63%\n",
            "Balanced Accuracy: 0.9867\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0163, Train Accuracy: 99.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.1865, Validation Accuracy: 66.88%\n",
            "Balanced Accuracy: 0.6528\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0145, Train Accuracy: 99.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0325, Validation Accuracy: 99.01%\n",
            "Balanced Accuracy: 0.9904\n",
            "New best model saved with Validation loss 0.0325 at best_model.pth\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0146, Train Accuracy: 99.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4441, Validation Accuracy: 91.35%\n",
            "Balanced Accuracy: 0.9060\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0113, Train Accuracy: 99.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0676, Validation Accuracy: 98.19%\n",
            "Balanced Accuracy: 0.9835\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0132, Train Accuracy: 99.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0819, Validation Accuracy: 97.75%\n",
            "Balanced Accuracy: 0.9762\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0125, Train Accuracy: 99.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0309, Validation Accuracy: 99.17%\n",
            "Balanced Accuracy: 0.9917\n",
            "New best model saved with Validation loss 0.0309 at best_model.pth\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0115, Train Accuracy: 99.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0643, Validation Accuracy: 98.08%\n",
            "Balanced Accuracy: 0.9801\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0116, Train Accuracy: 99.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0596, Validation Accuracy: 98.32%\n",
            "Balanced Accuracy: 0.9828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wDDP-iS8z1Q",
        "outputId": "7c037b54-d55b-4a4a-c065-7d25c1f62342"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "0136fac7-06f4-40c3-c5df-156c694cf300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:24<00:00, 19.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0287, Test Accuracy: 99.09%\n",
            "Balanced Accuracy: 0.9909\n",
            "New best model saved with Test loss 0.0287 at best_model.pth\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "1c269a67-431f-49d4-db3c-419368c7be3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 10.39 ms\n",
            "Standard Deviation: 0.72 ms\n",
            "Maximum Time: 15.81 ms\n",
            "Minimum Time: 9.72 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "5e5f690b-096a-4387-d773-02b3317a432a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         8.84%       1.584ms        32.66%       5.853ms     121.931us       0.000us         0.00%       5.065ms     105.524us            48  \n",
            "                                           aten::linear         0.99%     176.823us        17.69%       3.170ms      93.243us       0.000us         0.00%       3.627ms     106.688us            34  \n",
            "                                               aten::mm         6.51%       1.167ms        13.29%       2.381ms      74.394us       3.603ms        43.12%       3.603ms     112.602us            32  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.356ms        16.22%       1.356ms     169.489us             8  \n",
            "                                              aten::bmm         2.84%     508.321us         3.62%     648.510us      40.532us       1.134ms        13.57%       1.134ms      70.888us            16  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     988.516us        11.83%     988.516us     123.565us             8  \n",
            "                                       aten::batch_norm         1.35%     242.245us        30.26%       5.422ms     139.022us       0.000us         0.00%     885.124us      22.695us            39  \n",
            "                           aten::_batch_norm_impl_index         6.23%       1.117ms        28.91%       5.180ms     132.810us       0.000us         0.00%     885.124us      22.695us            39  \n",
            "                                            aten::copy_         4.52%     810.032us        10.67%       1.912ms      23.322us     825.924us         9.88%     825.924us      10.072us            82  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     771.399us         9.23%     771.399us      96.425us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 17.918ms\n",
            "Self CUDA time total: 8.357ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4UchJcz1N6K",
        "outputId": "a84e22c0-eea0-4b31-ccd5-931246b3e2ed"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:25<00:00, 18.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0294, Test Accuracy: 99.08%\n",
            "Overall - F1: 0.9907, Recall: 0.9907, Precision: 0.9908\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9987, Recall: 0.9994, Precision: 0.9981\n",
            "Class 1 - F1: 0.9994, Recall: 0.9994, Precision: 0.9994\n",
            "Class 2 - F1: 0.9925, Recall: 0.9925, Precision: 0.9925\n",
            "Class 3 - F1: 0.9960, Recall: 0.9977, Precision: 0.9943\n",
            "Class 4 - F1: 0.9883, Recall: 0.9843, Precision: 0.9924\n",
            "Class 5 - F1: 0.9903, Recall: 0.9847, Precision: 0.9960\n",
            "Class 6 - F1: 0.9851, Recall: 0.9802, Precision: 0.9900\n",
            "Class 7 - F1: 0.9792, Recall: 0.9911, Precision: 0.9676\n",
            "Class 8 - F1: 0.9872, Recall: 0.9874, Precision: 0.9870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "ZLcoSxfe1Qbt",
        "outputId": "7aeab2f5-da58-4643-fd41-f61f7f23ff50"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbSpMMWGk3bf",
        "outputId": "52ae78c0-bc9b-4951-b0eb-761af1fef1c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-21 16:18:32--  https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.45.92, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 800276929 (763M) [application/octet-stream]\n",
            "Saving to: ‘CRC-VAL-HE-7K.zip’\n",
            "\n",
            "CRC-VAL-HE-7K.zip   100%[===================>] 763.20M  23.9MB/s    in 32s     \n",
            "\n",
            "2025-03-21 16:19:05 (23.7 MB/s) - ‘CRC-VAL-HE-7K.zip’ saved [800276929/800276929]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O CRC-VAL-HE-7K.zip https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
        "!unzip -qq CRC-VAL-HE-7K.zip -d val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "rldaXFNXpT4r"
      },
      "outputs": [],
      "source": [
        "test_7k_dir = './val/CRC-VAL-HE-7K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "6oLIYyRG9dVi"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Belqw8QytnZL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "test7k_dataset = datasets.ImageFolder(root=test_7k_dir, transform=test_transform)\n",
        "test7k_dataloader = DataLoader(test7k_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2y3cywDpjUQ",
        "outputId": "8a8eaf12-e034-49ba-8b8e-bcc97b496482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 225/225 [00:11<00:00, 19.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.7022, Test Accuracy: 89.47%\n",
            "Overall - F1: 0.8596, Recall: 0.8727, Precision: 0.8555\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9644, Recall: 0.9507, Precision: 0.9785\n",
            "Class 1 - F1: 0.9538, Recall: 1.0000, Precision: 0.9117\n",
            "Class 2 - F1: 0.7981, Recall: 0.9676, Precision: 0.6791\n",
            "Class 3 - F1: 0.9434, Recall: 0.9984, Precision: 0.8941\n",
            "Class 4 - F1: 0.9055, Recall: 0.8425, Precision: 0.9787\n",
            "Class 5 - F1: 0.7215, Recall: 0.6740, Precision: 0.7763\n",
            "Class 6 - F1: 0.8972, Recall: 0.9015, Precision: 0.8930\n",
            "Class 7 - F1: 0.6083, Recall: 0.5772, Precision: 0.6429\n",
            "Class 8 - F1: 0.9439, Recall: 0.9424, Precision: 0.9455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test7k_dataloader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "p4pYjMPUpy2m",
        "outputId": "ed442f96-f656-4a54-ebc0-680cb0cd4503"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MOLSL09JxKdp"
      },
      "execution_count": 44,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}