{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "84cde6d5-1be0-4730-f09b-b3f09d05cd39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=9b10132ed7d391d50c9b2a3e087b73ed5d070b702ae22dd6e4970a775de23ac1\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "8f334781-6cbd-446d-8612-1eed58d1efb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-23 07:23:12--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.45.92, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-03-23 07:23:12--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  24.8MB/s    in 11m 48s \n",
            "\n",
            "2025-03-23 07:35:00 (15.8 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "f706bf6f-3031-4ffa-86d8-7d03168fc5bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "7cd211b1-011f-480a-9c56-87cd28efc345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "0de24170-cc98-4992-eac1-73bb06595bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "05a147f8-5748-46c7-d03b-1d60d443ccfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation\n",
        "aug_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "zja84HaiVhoh"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "#train_data = Subset(dataset, load_train_idx)\n",
        "#val_data = Subset(dataset, load_val_idx)\n",
        "#test_data = Subset(dataset, load_test_idx)\n",
        "\n",
        "dataset_train = datasets.ImageFolder(root=train_dir, transform=aug_transform)\n",
        "dataset_eval = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "\n",
        "train_data = Subset(dataset_train, load_train_idx)\n",
        "val_data = Subset(dataset_eval, load_val_idx)\n",
        "test_data = Subset(dataset_eval, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "f7c144d0-ff8a-470a-f66a-76cfa8512412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "5f0c1419-04f0-4e2c-d19f-0fbca355e91f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:59<00:00, 12.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6988, Train Accuracy: 74.95%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.3804, Validation Accuracy: 86.97%\n",
            "Balanced Accuracy: 0.8680\n",
            "New best model saved with Validation loss 0.3804 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:58<00:00, 12.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.3634, Train Accuracy: 87.22%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.63it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.2924, Validation Accuracy: 90.13%\n",
            "Balanced Accuracy: 0.8971\n",
            "New best model saved with Validation loss 0.2924 at best_model.pth\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:57<00:00, 12.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2507, Train Accuracy: 91.27%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.64it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.3616, Validation Accuracy: 88.01%\n",
            "Balanced Accuracy: 0.8805\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1921, Train Accuracy: 93.45%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.60it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 2.5636, Validation Accuracy: 49.62%\n",
            "Balanced Accuracy: 0.5070\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:57<00:00, 12.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1550, Train Accuracy: 94.71%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.54it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.2380, Validation Accuracy: 91.89%\n",
            "Balanced Accuracy: 0.9177\n",
            "New best model saved with Validation loss 0.2380 at best_model.pth\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:57<00:00, 12.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1216, Train Accuracy: 95.82%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.60it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.3993, Validation Accuracy: 87.05%\n",
            "Balanced Accuracy: 0.8685\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:57<00:00, 12.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1000, Train Accuracy: 96.64%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.2527, Validation Accuracy: 91.57%\n",
            "Balanced Accuracy: 0.9131\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0822, Train Accuracy: 97.11%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.59it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.1868, Validation Accuracy: 73.61%\n",
            "Balanced Accuracy: 0.7098\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0682, Train Accuracy: 97.65%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.2278, Validation Accuracy: 74.17%\n",
            "Balanced Accuracy: 0.7216\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0560, Train Accuracy: 98.12%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.65it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.8038, Validation Accuracy: 81.59%\n",
            "Balanced Accuracy: 0.8194\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.39it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0508, Train Accuracy: 98.30%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.9759, Validation Accuracy: 78.64%\n",
            "Balanced Accuracy: 0.7693\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:57<00:00, 12.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0448, Train Accuracy: 98.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.67it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.1881, Validation Accuracy: 94.29%\n",
            "Balanced Accuracy: 0.9396\n",
            "New best model saved with Validation loss 0.1881 at best_model.pth\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0367, Train Accuracy: 98.74%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.62it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.9067, Validation Accuracy: 61.16%\n",
            "Balanced Accuracy: 0.6041\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0327, Train Accuracy: 98.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0869, Validation Accuracy: 97.39%\n",
            "Balanced Accuracy: 0.9731\n",
            "New best model saved with Validation loss 0.0869 at best_model.pth\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:57<00:00, 12.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0312, Train Accuracy: 98.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1177, Validation Accuracy: 96.31%\n",
            "Balanced Accuracy: 0.9607\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0268, Train Accuracy: 99.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5607, Validation Accuracy: 85.27%\n",
            "Balanced Accuracy: 0.8509\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:57<00:00, 12.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0237, Train Accuracy: 99.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2740, Validation Accuracy: 91.88%\n",
            "Balanced Accuracy: 0.9167\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:57<00:00, 12.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0247, Train Accuracy: 99.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0522, Validation Accuracy: 98.43%\n",
            "Balanced Accuracy: 0.9838\n",
            "New best model saved with Validation loss 0.0522 at best_model.pth\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:57<00:00, 12.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0188, Train Accuracy: 99.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0604, Validation Accuracy: 98.06%\n",
            "Balanced Accuracy: 0.9797\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:57<00:00, 12.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0194, Train Accuracy: 99.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3429, Validation Accuracy: 91.38%\n",
            "Balanced Accuracy: 0.9050\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0188, Train Accuracy: 99.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0292, Validation Accuracy: 99.05%\n",
            "Balanced Accuracy: 0.9901\n",
            "New best model saved with Validation loss 0.0292 at best_model.pth\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0162, Train Accuracy: 99.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3296, Validation Accuracy: 92.41%\n",
            "Balanced Accuracy: 0.9212\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0165, Train Accuracy: 99.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0621, Validation Accuracy: 98.39%\n",
            "Balanced Accuracy: 0.9842\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0150, Train Accuracy: 99.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0315, Validation Accuracy: 99.06%\n",
            "Balanced Accuracy: 0.9900\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0152, Train Accuracy: 99.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0270, Validation Accuracy: 99.18%\n",
            "Balanced Accuracy: 0.9916\n",
            "New best model saved with Validation loss 0.0270 at best_model.pth\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:56<00:00, 12.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0127, Train Accuracy: 99.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0489, Validation Accuracy: 98.51%\n",
            "Balanced Accuracy: 0.9856\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:57<00:00, 12.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0124, Train Accuracy: 99.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3986, Validation Accuracy: 89.69%\n",
            "Balanced Accuracy: 0.8869\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:57<00:00, 12.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0133, Train Accuracy: 99.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0747, Validation Accuracy: 97.95%\n",
            "Balanced Accuracy: 0.9799\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:57<00:00, 12.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0121, Train Accuracy: 99.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0411, Validation Accuracy: 98.81%\n",
            "Balanced Accuracy: 0.9880\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:57<00:00, 12.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0105, Train Accuracy: 99.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0388, Validation Accuracy: 98.97%\n",
            "Balanced Accuracy: 0.9888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wDDP-iS8z1Q",
        "outputId": "75cd5585-8b72-4975-84a2-aec70e708790"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "53e56078-39ba-45d0-b24a-374572a60d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:23<00:00, 19.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0322, Test Accuracy: 99.03%\n",
            "Balanced Accuracy: 0.9900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "2a0ce66e-1c8d-49a9-e62f-0a7153028005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 12.34 ms\n",
            "Standard Deviation: 0.64 ms\n",
            "Maximum Time: 20.65 ms\n",
            "Minimum Time: 11.68 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "928095a9-6988-494d-f219-9c3d504fef2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         2.70%     381.746us        27.02%       3.824ms      79.676us       0.000us         0.00%       5.078ms     105.783us            48  \n",
            "                                           aten::linear         1.38%     194.982us        16.72%       2.367ms      69.606us       0.000us         0.00%       3.636ms     106.927us            34  \n",
            "                                               aten::mm         7.75%       1.097ms        11.34%       1.604ms      50.134us       3.612ms        43.26%       3.612ms     112.864us            32  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.360ms        16.29%       1.360ms     170.033us             8  \n",
            "                                              aten::bmm         3.22%     456.013us         4.25%     601.847us      37.615us       1.138ms        13.64%       1.138ms      71.152us            16  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     989.382us        11.85%     989.382us     123.673us             8  \n",
            "                                       aten::batch_norm         1.60%     225.748us        29.64%       4.195ms     107.566us       0.000us         0.00%     870.823us      22.329us            39  \n",
            "                           aten::_batch_norm_impl_index         2.31%     326.741us        28.05%       3.969ms     101.778us       0.000us         0.00%     870.823us      22.329us            39  \n",
            "                                            aten::copy_         5.42%     766.808us        13.10%       1.854ms      22.604us     822.854us         9.86%     822.854us      10.035us            82  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     773.029us         9.26%     773.029us      96.629us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 14.152ms\n",
            "Self CUDA time total: 8.348ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4UchJcz1N6K",
        "outputId": "663cf92a-2e25-41b6-957d-06673ebed10c"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:24<00:00, 19.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0322, Test Accuracy: 99.03%\n",
            "Overall - F1: 0.9901, Recall: 0.9900, Precision: 0.9902\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9981, Recall: 0.9974, Precision: 0.9987\n",
            "Class 1 - F1: 0.9997, Recall: 0.9994, Precision: 1.0000\n",
            "Class 2 - F1: 0.9851, Recall: 0.9959, Precision: 0.9745\n",
            "Class 3 - F1: 0.9988, Recall: 0.9988, Precision: 0.9988\n",
            "Class 4 - F1: 0.9884, Recall: 0.9888, Precision: 0.9880\n",
            "Class 5 - F1: 0.9922, Recall: 0.9966, Precision: 0.9878\n",
            "Class 6 - F1: 0.9860, Recall: 0.9901, Precision: 0.9819\n",
            "Class 7 - F1: 0.9711, Recall: 0.9547, Precision: 0.9881\n",
            "Class 8 - F1: 0.9911, Recall: 0.9884, Precision: 0.9939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "ZLcoSxfe1Qbt",
        "outputId": "ebf38826-3df3-4319-b4c5-1e4908f18458"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MOLSL09JxKdp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}