{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "b2f28946-263d-4ad4-af63-d6145591dcbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=6d7d8094dd898f0669d9fb0020f4501465e48fd1b66ba6431f12d9ad15f96950\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n",
            "--2025-03-28 06:19:17--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.45.92, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-03-28 06:19:18--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  17.6MB/s    in 11m 11s \n",
            "\n",
            "2025-03-28 06:30:29 (16.6 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo\n",
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super().__init__()\n",
        "        self.stem = Stem16()\n",
        "        self.stage1 = LevitStage(256, 256, 4, 4, downsample=False)\n",
        "        self.stage2 = LevitStage(256, 384, 6, 4, downsample=True)\n",
        "        self.conv1x1 = nn.Sequential(nn.Conv2d(384, 512, 1), nn.BatchNorm2d(512), nn.ReLU(True))\n",
        "        self.head = NormLinear(512, num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(512, num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        H = W = int(x.shape[1] ** 0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "        x = self.conv1x1(x)\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        return self.head(x)\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        x = self.stem(x)\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        H = W = int(x.shape[1] ** 0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "        x = self.conv1x1(x)\n",
        "        return torch.mean(x, dim=(2, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "2fa173b2-3f1c-4f0c-966a-ca5e0f4c8745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gNpMsNYAzLDF",
        "outputId": "2d020715-2e91-4172-cda1-ac3fdfd25e80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.22\n",
            "Params size (MB): 33.32\n",
            "Estimated Total Size (MB): 1444.80\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "5c06b17c-f7a6-4357-f647-b1a61902d50c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.22\n",
            "Params size (MB): 33.32\n",
            "Estimated Total Size (MB): 1444.80\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.22\n",
            "Params size (MB): 33.32\n",
            "Estimated Total Size (MB): 1444.80\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LUiqsuSdOgj0"
      },
      "outputs": [],
      "source": [
        "class BSDALayer(nn.Module):\n",
        "    def __init__(self, feature_dim, bsda_lambda=0.8) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.bsda_lambda = bsda_lambda\n",
        "\n",
        "        self.logvar = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "        )\n",
        "\n",
        "        self.d = nn.Dropout(p=self.bsda_lambda)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "    def modified_indicator_function(self, x):\n",
        "        return torch.where(x >= 0, torch.sign(x), -torch.sign(x))\n",
        "\n",
        "    def calc_a_tilde(self, a, m, multi=1):\n",
        "        a = a.repeat(multi, 1)\n",
        "        return a + self.d(m) * self.modified_indicator_function(a)\n",
        "\n",
        "    def reparameterize(self, mu, logvar, multi=1):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        std = std.repeat(multi, 1)\n",
        "        eps = torch.randn_like(std, device=std.device)\n",
        "        mu = mu.repeat(multi, 1)\n",
        "        return eps * std + mu\n",
        "\n",
        "    def forward(self, a, multi=1):\n",
        "        \"\"\"\n",
        "            a: (batch_size, feature_dim)\n",
        "            m: (batch_size, feature_dim)\n",
        "            mu: (batch_size, feature_dim)\n",
        "            logvar: (batch_size, feature_dim)\n",
        "        \"\"\"\n",
        "        x = self.encoder(a)\n",
        "\n",
        "        logvar = self.logvar(x)\n",
        "        mu = torch.zeros_like(logvar, device=logvar.device)\n",
        "\n",
        "        m = self.reparameterize(mu, logvar, multi)\n",
        "        a_hat = self.decoder(m)\n",
        "\n",
        "        return m, mu, logvar, a_hat\n",
        "\n",
        "    def calc_kl_loss(self, mu, logvar):\n",
        "\n",
        "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        return kl_loss\n",
        "\n",
        "    def calc_recon_loss(self, a, a_hat, multi=1):\n",
        "        recon_loss = torch.mean((a.repeat(multi, 1) - a_hat) ** 2) * 0.5\n",
        "        return recon_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "94d6e9ff-e37c-4533-da8c-fcc26160eeb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mAsRwMpISMIh"
      },
      "outputs": [],
      "source": [
        "# Augmentation\n",
        "aug_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.75),\n",
        "    transforms.RandomVerticalFlip(p=0.75),\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fnlxaQSs7NsL"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "#train_data = Subset(dataset, load_train_idx)\n",
        "#val_data = Subset(dataset, load_val_idx)\n",
        "#test_data = Subset(dataset, load_test_idx)\n",
        "\n",
        "dataset_train = datasets.ImageFolder(root=train_dir, transform=aug_transform)\n",
        "dataset_eval = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "\n",
        "train_data = Subset(dataset_train, load_train_idx)\n",
        "val_data = Subset(dataset_eval, load_val_idx)\n",
        "test_data = Subset(dataset_eval, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "ad7ae30b-eb5c-44f3-a833-cafbf754bfe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch,\n",
        "          use_bsda=False, bsda_layer=None, multi=10, bsda_alpha=0.5,\n",
        "          kl_weight=8e-4, recon_weight=1.0, use_ori=True, num_epochs=30):\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    ratio = min(bsda_alpha * (epoch / (num_epochs // 2)), bsda_alpha) if use_bsda else 0\n",
        "\n",
        "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        features = model.extract_features(inputs)\n",
        "        y_hat = model.head(features)\n",
        "\n",
        "        if use_bsda:\n",
        "            m, mu, logvar, a_hat = bsda_layer(features, multi=multi)\n",
        "            a_tilde = bsda_layer.calc_a_tilde(features, m, multi=multi)\n",
        "            y_hat_tilde = model.head(a_tilde)\n",
        "\n",
        "            loss_task = criterion(y_hat, labels)\n",
        "            loss_task_tilde = criterion(y_hat_tilde, labels.repeat(multi,))\n",
        "            loss_kl = bsda_layer.calc_kl_loss(mu, logvar)\n",
        "            loss_recon = bsda_layer.calc_recon_loss(features, a_hat, multi)\n",
        "            loss_bsda = kl_weight * loss_kl + recon_weight * loss_recon\n",
        "            loss = loss_task_tilde + loss_bsda\n",
        "            if use_ori:\n",
        "                loss = loss * ratio + loss_task\n",
        "        else:\n",
        "            loss = criterion(y_hat, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(y_hat, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Train Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100*correct/total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "d21d3f92-ded0-442a-abd8-6627a9d188d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 2188/2188 [02:54<00:00, 12.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6638, Accuracy: 76.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7758, Validation Accuracy: 83.50%\n",
            "Balanced Accuracy: 0.8298\n",
            "New best model saved with Validation loss 0.7758 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 2188/2188 [02:53<00:00, 12.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4246, Accuracy: 87.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3898, Validation Accuracy: 90.10%\n",
            "Balanced Accuracy: 0.8951\n",
            "New best model saved with Validation loss 0.3898 at best_model.pth\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 2188/2188 [02:55<00:00, 12.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3475, Accuracy: 91.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3765, Validation Accuracy: 87.69%\n",
            "Balanced Accuracy: 0.8711\n",
            "New best model saved with Validation loss 0.3765 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 2188/2188 [02:55<00:00, 12.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3204, Accuracy: 93.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5608, Validation Accuracy: 80.25%\n",
            "Balanced Accuracy: 0.7929\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 2188/2188 [02:56<00:00, 12.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3074, Accuracy: 94.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3682, Validation Accuracy: 86.83%\n",
            "Balanced Accuracy: 0.8617\n",
            "New best model saved with Validation loss 0.3682 at best_model.pth\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 2188/2188 [02:55<00:00, 12.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2967, Accuracy: 95.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3420, Validation Accuracy: 87.06%\n",
            "Balanced Accuracy: 0.8730\n",
            "New best model saved with Validation loss 0.3420 at best_model.pth\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 2188/2188 [02:55<00:00, 12.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2886, Accuracy: 96.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1460, Validation Accuracy: 95.20%\n",
            "Balanced Accuracy: 0.9502\n",
            "New best model saved with Validation loss 0.1460 at best_model.pth\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 2188/2188 [02:56<00:00, 12.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2843, Accuracy: 97.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1375, Validation Accuracy: 95.55%\n",
            "Balanced Accuracy: 0.9552\n",
            "New best model saved with Validation loss 0.1375 at best_model.pth\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 2188/2188 [02:59<00:00, 12.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2872, Accuracy: 97.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1020, Validation Accuracy: 96.66%\n",
            "Balanced Accuracy: 0.9665\n",
            "New best model saved with Validation loss 0.1020 at best_model.pth\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 2188/2188 [03:00<00:00, 12.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2889, Accuracy: 98.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3390, Validation Accuracy: 87.53%\n",
            "Balanced Accuracy: 0.8683\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 2188/2188 [03:00<00:00, 12.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2965, Accuracy: 98.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2023, Validation Accuracy: 92.68%\n",
            "Balanced Accuracy: 0.9223\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 2188/2188 [03:00<00:00, 12.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3011, Accuracy: 98.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3433, Validation Accuracy: 88.84%\n",
            "Balanced Accuracy: 0.8780\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 2188/2188 [02:59<00:00, 12.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3054, Accuracy: 98.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1621, Validation Accuracy: 94.39%\n",
            "Balanced Accuracy: 0.9413\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 2188/2188 [02:58<00:00, 12.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3188, Accuracy: 98.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0457, Validation Accuracy: 98.53%\n",
            "Balanced Accuracy: 0.9846\n",
            "New best model saved with Validation loss 0.0457 at best_model.pth\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 2188/2188 [03:03<00:00, 11.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3235, Accuracy: 98.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1725, Validation Accuracy: 94.18%\n",
            "Balanced Accuracy: 0.9385\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 2188/2188 [03:00<00:00, 12.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3314, Accuracy: 99.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1379, Validation Accuracy: 95.85%\n",
            "Balanced Accuracy: 0.9581\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 2188/2188 [02:53<00:00, 12.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3266, Accuracy: 99.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0778, Validation Accuracy: 97.41%\n",
            "Balanced Accuracy: 0.9730\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 2188/2188 [02:54<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3180, Accuracy: 99.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0328, Validation Accuracy: 98.95%\n",
            "Balanced Accuracy: 0.9890\n",
            "New best model saved with Validation loss 0.0328 at best_model.pth\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 2188/2188 [02:56<00:00, 12.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3081, Accuracy: 99.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1146, Validation Accuracy: 96.47%\n",
            "Balanced Accuracy: 0.9623\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3019, Accuracy: 99.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1260, Validation Accuracy: 76.27%\n",
            "Balanced Accuracy: 0.7348\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 2188/2188 [02:55<00:00, 12.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2988, Accuracy: 99.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0442, Validation Accuracy: 98.67%\n",
            "Balanced Accuracy: 0.9867\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 2188/2188 [02:53<00:00, 12.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2928, Accuracy: 99.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2237, Validation Accuracy: 93.87%\n",
            "Balanced Accuracy: 0.9346\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 2188/2188 [02:54<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2907, Accuracy: 99.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0603, Validation Accuracy: 98.17%\n",
            "Balanced Accuracy: 0.9827\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2870, Accuracy: 99.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1357, Validation Accuracy: 96.07%\n",
            "Balanced Accuracy: 0.9587\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 2188/2188 [02:54<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2812, Accuracy: 99.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0307, Validation Accuracy: 99.11%\n",
            "Balanced Accuracy: 0.9914\n",
            "New best model saved with Validation loss 0.0307 at best_model.pth\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 2188/2188 [02:54<00:00, 12.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2755, Accuracy: 99.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1585, Validation Accuracy: 95.41%\n",
            "Balanced Accuracy: 0.9503\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 2188/2188 [02:55<00:00, 12.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2781, Accuracy: 99.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0702, Validation Accuracy: 98.17%\n",
            "Balanced Accuracy: 0.9837\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 2188/2188 [02:55<00:00, 12.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2695, Accuracy: 99.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1150, Validation Accuracy: 96.69%\n",
            "Balanced Accuracy: 0.9654\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 2188/2188 [02:54<00:00, 12.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2719, Accuracy: 99.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0410, Validation Accuracy: 98.64%\n",
            "Balanced Accuracy: 0.9861\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 2188/2188 [02:54<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2658, Accuracy: 99.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0306, Validation Accuracy: 99.19%\n",
            "Balanced Accuracy: 0.9912\n",
            "New best model saved with Validation loss 0.0306 at best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "bsda_layer = BSDALayer(feature_dim=512, bsda_lambda=0.8).to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch,\n",
        "          use_bsda=True,\n",
        "          bsda_layer=bsda_layer,\n",
        "          multi=10,\n",
        "          bsda_alpha=0.5,\n",
        "          kl_weight=8e-4,\n",
        "          recon_weight=1.0,\n",
        "          use_ori=True,\n",
        "          num_epochs=num_epochs)\n",
        "\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCGf9fvf2-qk",
        "outputId": "bea95f2c-2d77-40ea-f612-61662c6ace54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "c279b5da-26d9-4751-f052-3320b2153e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:22<00:00, 20.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0367, Test Accuracy: 99.09%\n",
            "Balanced Accuracy: 0.9900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "f22b9189-22c0-4227-c0db-2dd8b1d42f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 10.03 ms\n",
            "Standard Deviation: 0.41 ms\n",
            "Maximum Time: 14.77 ms\n",
            "Minimum Time: 9.56 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "e37c4584-5a6f-4053-991e-773c71e2c7ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul        14.36%       3.922ms        42.34%      11.567ms     240.970us       0.000us         0.00%       5.043ms     105.066us            48  \n",
            "                                           aten::linear         0.70%     192.348us        23.00%       6.283ms     190.394us       0.000us         0.00%       3.605ms     109.251us            33  \n",
            "                                               aten::mm         4.53%       1.238ms        19.95%       5.449ms     170.286us       3.594ms        43.45%       3.594ms     112.298us            32  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.351ms        16.33%       1.351ms     168.884us             8  \n",
            "                                              aten::bmm         2.06%     564.025us         2.61%     712.644us      44.540us       1.131ms        13.68%       1.131ms      70.714us            16  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     986.398us        11.93%     986.398us     123.300us             8  \n",
            "                                       aten::batch_norm         0.89%     243.049us        30.06%       8.213ms     216.132us       0.000us         0.00%     847.454us      22.301us            38  \n",
            "                           aten::_batch_norm_impl_index        13.11%       3.582ms        29.17%       7.970ms     209.736us       0.000us         0.00%     847.454us      22.301us            38  \n",
            "                                            aten::copy_         3.23%     882.698us         7.83%       2.139ms      26.402us     785.149us         9.49%     785.149us       9.693us            81  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     769.149us         9.30%     769.149us      96.144us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 27.318ms\n",
            "Self CUDA time total: 8.271ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    val_losses.append(epoch_loss)\n",
        "    val_accuracies.append(accuracy)\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubbBuFrU-GRd",
        "outputId": "d1e930d5-8c15-437c-c5c3-a7a5cc9040b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test: 100%|██████████| 469/469 [00:23<00:00, 20.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0284, Test Accuracy: 99.19%\n",
            "Overall - F1: 0.9917, Recall: 0.9916, Precision: 0.9917\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9984, Recall: 0.9981, Precision: 0.9987\n",
            "Class 1 - F1: 0.9984, Recall: 1.0000, Precision: 0.9969\n",
            "Class 2 - F1: 0.9865, Recall: 0.9919, Precision: 0.9811\n",
            "Class 3 - F1: 0.9986, Recall: 0.9977, Precision: 0.9994\n",
            "Class 4 - F1: 0.9888, Recall: 0.9910, Precision: 0.9866\n",
            "Class 5 - F1: 0.9951, Recall: 0.9961, Precision: 0.9941\n",
            "Class 6 - F1: 0.9886, Recall: 0.9916, Precision: 0.9856\n",
            "Class 7 - F1: 0.9796, Recall: 0.9668, Precision: 0.9928\n",
            "Class 8 - F1: 0.9909, Recall: 0.9916, Precision: 0.9902\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "3qaLb5c--H0Q",
        "outputId": "d893478b-0d2a-4afc-af68-466398308df8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29ACr21nOjBW",
        "outputId": "3b7fbad3-f819-4e65-a074-62d6997ddf44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model weights saved to HoViT_44_default_baseline_bsda.pth\n"
          ]
        }
      ],
      "source": [
        "save_path = \"HoViT_44_default_baseline_bsda.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model weights saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCHdGKmbuw9W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2NMYNeV0Ly5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}