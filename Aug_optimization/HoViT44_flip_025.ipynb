{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "84cde6d5-1be0-4730-f09b-b3f09d05cd39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=9b10132ed7d391d50c9b2a3e087b73ed5d070b702ae22dd6e4970a775de23ac1\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "8f334781-6cbd-446d-8612-1eed58d1efb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-23 07:23:12--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.45.92, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-03-23 07:23:12--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  24.8MB/s    in 11m 48s \n",
            "\n",
            "2025-03-23 07:35:00 (15.8 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "7fe01210-6f75-4c23-e3c8-cfce5cb1abdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "eb03c21a-83ae-4901-b22d-15319577fd7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "0441a19d-fd39-47cd-9c32-bbab78c44898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "7f17abd2-d57e-4688-9a06-81753c00ddc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation\n",
        "aug_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.25),\n",
        "    transforms.RandomVerticalFlip(p=0.25),\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "zja84HaiVhoh"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "#train_data = Subset(dataset, load_train_idx)\n",
        "#val_data = Subset(dataset, load_val_idx)\n",
        "#test_data = Subset(dataset, load_test_idx)\n",
        "\n",
        "dataset_train = datasets.ImageFolder(root=train_dir, transform=aug_transform)\n",
        "dataset_eval = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "\n",
        "train_data = Subset(dataset_train, load_train_idx)\n",
        "val_data = Subset(dataset_eval, load_val_idx)\n",
        "test_data = Subset(dataset_eval, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "418ab340-7b76-477c-c840-da87a7236db0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "db2e0ca3-5c5e-42c9-8153-5232ef7018e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6857, Train Accuracy: 75.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3595, Validation Accuracy: 87.32%\n",
            "Balanced Accuracy: 0.8706\n",
            "New best model saved with Validation loss 0.3595 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3505, Train Accuracy: 87.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3511, Validation Accuracy: 87.84%\n",
            "Balanced Accuracy: 0.8690\n",
            "New best model saved with Validation loss 0.3511 at best_model.pth\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2421, Train Accuracy: 91.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3952, Validation Accuracy: 86.89%\n",
            "Balanced Accuracy: 0.8575\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1829, Train Accuracy: 93.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4908, Validation Accuracy: 83.51%\n",
            "Balanced Accuracy: 0.8388\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1477, Train Accuracy: 95.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3180, Validation Accuracy: 89.93%\n",
            "Balanced Accuracy: 0.8909\n",
            "New best model saved with Validation loss 0.3180 at best_model.pth\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1166, Train Accuracy: 96.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7582, Validation Accuracy: 81.35%\n",
            "Balanced Accuracy: 0.8070\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0929, Train Accuracy: 96.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1535, Validation Accuracy: 94.85%\n",
            "Balanced Accuracy: 0.9453\n",
            "New best model saved with Validation loss 0.1535 at best_model.pth\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0738, Train Accuracy: 97.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1899, Validation Accuracy: 93.96%\n",
            "Balanced Accuracy: 0.9416\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0641, Train Accuracy: 97.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1544, Validation Accuracy: 95.11%\n",
            "Balanced Accuracy: 0.9508\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0539, Train Accuracy: 98.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7337, Validation Accuracy: 83.41%\n",
            "Balanced Accuracy: 0.8230\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0454, Train Accuracy: 98.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1035, Validation Accuracy: 96.65%\n",
            "Balanced Accuracy: 0.9644\n",
            "New best model saved with Validation loss 0.1035 at best_model.pth\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0390, Train Accuracy: 98.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1915, Validation Accuracy: 94.35%\n",
            "Balanced Accuracy: 0.9368\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0353, Train Accuracy: 98.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.8466, Validation Accuracy: 63.51%\n",
            "Balanced Accuracy: 0.6063\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:48<00:00, 13.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0306, Train Accuracy: 98.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0534, Validation Accuracy: 98.08%\n",
            "Balanced Accuracy: 0.9811\n",
            "New best model saved with Validation loss 0.0534 at best_model.pth\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:47<00:00, 13.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0286, Train Accuracy: 99.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5563, Validation Accuracy: 87.86%\n",
            "Balanced Accuracy: 0.8625\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0264, Train Accuracy: 99.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3270, Validation Accuracy: 91.65%\n",
            "Balanced Accuracy: 0.9094\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0222, Train Accuracy: 99.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1001, Validation Accuracy: 97.03%\n",
            "Balanced Accuracy: 0.9723\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0225, Train Accuracy: 99.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0870, Validation Accuracy: 97.21%\n",
            "Balanced Accuracy: 0.9735\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0165, Train Accuracy: 99.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4403, Validation Accuracy: 89.23%\n",
            "Balanced Accuracy: 0.8816\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0191, Train Accuracy: 99.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3780, Validation Accuracy: 92.26%\n",
            "Balanced Accuracy: 0.9176\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:47<00:00, 13.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0184, Train Accuracy: 99.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1677, Validation Accuracy: 94.73%\n",
            "Balanced Accuracy: 0.9414\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0167, Train Accuracy: 99.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6930, Validation Accuracy: 85.75%\n",
            "Balanced Accuracy: 0.8432\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0144, Train Accuracy: 99.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0336, Validation Accuracy: 99.06%\n",
            "Balanced Accuracy: 0.9900\n",
            "New best model saved with Validation loss 0.0336 at best_model.pth\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0155, Train Accuracy: 99.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6554, Validation Accuracy: 89.21%\n",
            "Balanced Accuracy: 0.8892\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0134, Train Accuracy: 99.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4690, Validation Accuracy: 91.07%\n",
            "Balanced Accuracy: 0.9047\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0135, Train Accuracy: 99.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0484, Validation Accuracy: 98.59%\n",
            "Balanced Accuracy: 0.9849\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0139, Train Accuracy: 99.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0314, Validation Accuracy: 99.03%\n",
            "Balanced Accuracy: 0.9903\n",
            "New best model saved with Validation loss 0.0314 at best_model.pth\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0105, Train Accuracy: 99.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3582, Validation Accuracy: 92.93%\n",
            "Balanced Accuracy: 0.9215\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0108, Train Accuracy: 99.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0391, Validation Accuracy: 98.81%\n",
            "Balanced Accuracy: 0.9877\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0100, Train Accuracy: 99.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4528, Validation Accuracy: 89.83%\n",
            "Balanced Accuracy: 0.9048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wDDP-iS8z1Q",
        "outputId": "319310fc-b525-41d4-fe88-c5a3961a5626"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "d72036a3-be1b-4003-d69c-04d6edc24083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:22<00:00, 20.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0320, Test Accuracy: 98.99%\n",
            "Balanced Accuracy: 0.9899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "0a19139b-abfa-4141-8d52-09a0cff0b8e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 10.29 ms\n",
            "Standard Deviation: 0.53 ms\n",
            "Maximum Time: 18.00 ms\n",
            "Minimum Time: 9.71 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "b8a7b61f-c7f1-4b89-b8a6-11975b6025cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         6.92%       1.233ms        31.91%       5.689ms     118.512us       0.000us         0.00%       5.076ms     105.743us            48  \n",
            "                                           aten::linear         1.27%     226.262us        18.87%       3.363ms      98.924us       0.000us         0.00%       3.634ms     106.889us            34  \n",
            "                                               aten::mm         6.32%       1.126ms        14.15%       2.522ms      78.809us       3.610ms        43.07%       3.610ms     112.825us            32  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.358ms        16.20%       1.358ms     169.777us             8  \n",
            "                                              aten::bmm         2.66%     473.990us         3.40%     606.283us      37.893us       1.137ms        13.56%       1.137ms      71.038us            16  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     988.963us        11.80%     988.963us     123.620us             8  \n",
            "                                       aten::batch_norm         1.28%     228.195us        30.61%       5.457ms     139.912us       0.000us         0.00%     868.739us      22.275us            39  \n",
            "                           aten::_batch_norm_impl_index         6.51%       1.161ms        29.33%       5.228ms     134.061us       0.000us         0.00%     868.739us      22.275us            39  \n",
            "                                            aten::copy_         4.85%     865.553us        11.37%       2.026ms      24.710us     821.060us         9.79%     821.060us      10.013us            82  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     772.771us         9.22%     772.771us      96.596us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 17.829ms\n",
            "Self CUDA time total: 8.383ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4UchJcz1N6K",
        "outputId": "f382140c-0937-4e6c-9991-5503e215acb5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:24<00:00, 19.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0320, Test Accuracy: 98.99%\n",
            "Overall - F1: 0.9897, Recall: 0.9899, Precision: 0.9895\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9978, Recall: 0.9981, Precision: 0.9974\n",
            "Class 1 - F1: 0.9987, Recall: 0.9994, Precision: 0.9981\n",
            "Class 2 - F1: 0.9861, Recall: 0.9832, Precision: 0.9889\n",
            "Class 3 - F1: 0.9951, Recall: 0.9983, Precision: 0.9920\n",
            "Class 4 - F1: 0.9877, Recall: 0.9925, Precision: 0.9829\n",
            "Class 5 - F1: 0.9946, Recall: 0.9931, Precision: 0.9960\n",
            "Class 6 - F1: 0.9821, Recall: 0.9787, Precision: 0.9855\n",
            "Class 7 - F1: 0.9803, Recall: 0.9853, Precision: 0.9754\n",
            "Class 8 - F1: 0.9850, Recall: 0.9809, Precision: 0.9892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "ZLcoSxfe1Qbt",
        "outputId": "01cac1ef-1967-45f1-a060-3a8368c6566f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MOLSL09JxKdp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}