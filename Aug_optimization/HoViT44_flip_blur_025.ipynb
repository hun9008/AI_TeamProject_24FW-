{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "7b121014-21cb-4469-b3d0-e670722a63b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=a9cad925356e13599af0f5fb1f050cfec31f86d50d348e317bb518bb0ab593ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "ddda8a3e-d97e-4a68-b84f-04cbfa3bd920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-21 01:16:02--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.45.92, 188.185.48.194, 188.185.43.25, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.45.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-03-21 01:16:02--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  17.0MB/s    in 11m 18s \n",
            "\n",
            "2025-03-21 01:27:20 (16.5 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "0644b5cd-8be0-4561-bafe-c6efb9eb5196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "007bd172-25ec-461e-f061-b69f7a0fd797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "607631cc-cdd6-469b-b249-99bf887b4a58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "c2d3b87b-8e58-4a11-c3fd-2bf3a108209a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.25),\n",
        "    transforms.RandomVerticalFlip(p=0.25),\n",
        "    transforms.RandomApply(\n",
        "        [transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0))],\n",
        "        p=0.25\n",
        "    ),\n",
        "    #transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.25),\n",
        "])"
      ],
      "metadata": {
        "id": "zja84HaiVhoh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "train_data = Subset(dataset, load_train_idx)\n",
        "val_data = Subset(dataset, load_val_idx)\n",
        "test_data = Subset(dataset, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "2d02a3d7-94b9-44ed-da6f-18563262a9ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "5da398f1-f1e7-41a6-cacb-d3d566628880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:04<00:00, 11.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.7347, Train Accuracy: 73.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3891, Validation Accuracy: 86.26%\n",
            "Balanced Accuracy: 0.8613\n",
            "New best model saved with Validation loss 0.3891 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:02<00:00, 11.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4000, Train Accuracy: 85.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2992, Validation Accuracy: 89.31%\n",
            "Balanced Accuracy: 0.8888\n",
            "New best model saved with Validation loss 0.2992 at best_model.pth\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:03<00:00, 11.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2632, Train Accuracy: 90.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2131, Validation Accuracy: 92.43%\n",
            "Balanced Accuracy: 0.9216\n",
            "New best model saved with Validation loss 0.2131 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:02<00:00, 11.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2024, Train Accuracy: 92.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2325, Validation Accuracy: 91.59%\n",
            "Balanced Accuracy: 0.9156\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:03<00:00, 11.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1657, Train Accuracy: 94.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2671, Validation Accuracy: 90.65%\n",
            "Balanced Accuracy: 0.9064\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:03<00:00, 11.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1339, Train Accuracy: 95.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5875, Validation Accuracy: 81.23%\n",
            "Balanced Accuracy: 0.8014\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:03<00:00, 11.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1126, Train Accuracy: 96.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1419, Validation Accuracy: 95.12%\n",
            "Balanced Accuracy: 0.9508\n",
            "New best model saved with Validation loss 0.1419 at best_model.pth\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:03<00:00, 11.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0923, Train Accuracy: 96.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:28<00:00, 16.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2232, Validation Accuracy: 92.46%\n",
            "Balanced Accuracy: 0.9188\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:05<00:00, 11.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0761, Train Accuracy: 97.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:28<00:00, 16.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0895, Validation Accuracy: 96.98%\n",
            "Balanced Accuracy: 0.9709\n",
            "New best model saved with Validation loss 0.0895 at best_model.pth\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:04<00:00, 11.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0636, Train Accuracy: 97.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0856, Validation Accuracy: 97.14%\n",
            "Balanced Accuracy: 0.9712\n",
            "New best model saved with Validation loss 0.0856 at best_model.pth\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:03<00:00, 11.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0548, Train Accuracy: 98.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0739, Validation Accuracy: 97.45%\n",
            "Balanced Accuracy: 0.9751\n",
            "New best model saved with Validation loss 0.0739 at best_model.pth\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:03<00:00, 11.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0484, Train Accuracy: 98.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0712, Validation Accuracy: 97.75%\n",
            "Balanced Accuracy: 0.9778\n",
            "New best model saved with Validation loss 0.0712 at best_model.pth\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:04<00:00, 11.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0418, Train Accuracy: 98.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0450, Validation Accuracy: 98.53%\n",
            "Balanced Accuracy: 0.9848\n",
            "New best model saved with Validation loss 0.0450 at best_model.pth\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:02<00:00, 11.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0366, Train Accuracy: 98.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1031, Validation Accuracy: 97.11%\n",
            "Balanced Accuracy: 0.9701\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:03<00:00, 11.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0350, Train Accuracy: 98.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:28<00:00, 16.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1691, Validation Accuracy: 94.63%\n",
            "Balanced Accuracy: 0.9411\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:03<00:00, 11.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0287, Train Accuracy: 99.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1987, Validation Accuracy: 93.50%\n",
            "Balanced Accuracy: 0.9267\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:03<00:00, 11.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0271, Train Accuracy: 99.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0903, Validation Accuracy: 97.28%\n",
            "Balanced Accuracy: 0.9733\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:03<00:00, 11.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0244, Train Accuracy: 99.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:28<00:00, 16.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0453, Validation Accuracy: 98.53%\n",
            "Balanced Accuracy: 0.9848\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:03<00:00, 11.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0238, Train Accuracy: 99.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:28<00:00, 16.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0936, Validation Accuracy: 97.24%\n",
            "Balanced Accuracy: 0.9696\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:03<00:00, 11.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0214, Train Accuracy: 99.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:28<00:00, 16.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0423, Validation Accuracy: 98.58%\n",
            "Balanced Accuracy: 0.9858\n",
            "New best model saved with Validation loss 0.0423 at best_model.pth\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:03<00:00, 11.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0207, Train Accuracy: 99.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:28<00:00, 16.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0646, Validation Accuracy: 98.01%\n",
            "Balanced Accuracy: 0.9794\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:04<00:00, 11.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0210, Train Accuracy: 99.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:28<00:00, 16.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5401, Validation Accuracy: 86.01%\n",
            "Balanced Accuracy: 0.8529\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:03<00:00, 11.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0167, Train Accuracy: 99.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1393, Validation Accuracy: 96.02%\n",
            "Balanced Accuracy: 0.9577\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:05<00:00, 11.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0171, Train Accuracy: 99.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:28<00:00, 16.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0358, Validation Accuracy: 98.87%\n",
            "Balanced Accuracy: 0.9889\n",
            "New best model saved with Validation loss 0.0358 at best_model.pth\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:05<00:00, 11.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0150, Train Accuracy: 99.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:28<00:00, 16.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0352, Validation Accuracy: 98.93%\n",
            "Balanced Accuracy: 0.9890\n",
            "New best model saved with Validation loss 0.0352 at best_model.pth\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:06<00:00, 11.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0161, Train Accuracy: 99.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:28<00:00, 16.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0770, Validation Accuracy: 98.07%\n",
            "Balanced Accuracy: 0.9800\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:04<00:00, 11.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0140, Train Accuracy: 99.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0341, Validation Accuracy: 98.99%\n",
            "Balanced Accuracy: 0.9895\n",
            "New best model saved with Validation loss 0.0341 at best_model.pth\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:04<00:00, 11.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0135, Train Accuracy: 99.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:28<00:00, 16.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1792, Validation Accuracy: 95.79%\n",
            "Balanced Accuracy: 0.9552\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:04<00:00, 11.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0128, Train Accuracy: 99.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:27<00:00, 16.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0539, Validation Accuracy: 98.43%\n",
            "Balanced Accuracy: 0.9847\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [03:06<00:00, 11.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0121, Train Accuracy: 99.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:28<00:00, 16.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0544, Validation Accuracy: 98.38%\n",
            "Balanced Accuracy: 0.9832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wDDP-iS8z1Q",
        "outputId": "ccec1c35-2fe1-4219-fd5b-725f334c4049"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "62ea36d7-81f0-43dc-f3fd-04e42a26a10a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:30<00:00, 15.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0432, Test Accuracy: 98.78%\n",
            "Balanced Accuracy: 0.9875\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "6c08c360-b1c5-4b45-e03f-be072d880058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 12.57 ms\n",
            "Standard Deviation: 0.43 ms\n",
            "Maximum Time: 15.65 ms\n",
            "Minimum Time: 11.98 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "8d7f3749-4c95-472a-fddd-85a902f77bfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         2.44%     351.544us        26.86%       3.870ms      80.627us       0.000us         0.00%       5.061ms     105.428us            48  \n",
            "                                           aten::linear         1.20%     173.510us        16.74%       2.412ms      70.934us       0.000us         0.00%       3.626ms     106.658us            34  \n",
            "                                               aten::mm         7.82%       1.127ms        11.54%       1.663ms      51.974us       3.603ms        43.33%       3.603ms     112.585us            32  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.356ms        16.31%       1.356ms     169.504us             8  \n",
            "                                              aten::bmm         3.37%     485.917us         4.34%     624.850us      39.053us       1.135ms        13.65%       1.135ms      70.944us            16  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     989.215us        11.90%     989.215us     123.652us             8  \n",
            "                                       aten::batch_norm         1.67%     240.815us        29.60%       4.265ms     109.359us       0.000us         0.00%     869.408us      22.293us            39  \n",
            "                           aten::_batch_norm_impl_index         2.20%     317.529us        27.93%       4.024ms     103.184us       0.000us         0.00%     869.408us      22.293us            39  \n",
            "                                            aten::copy_         5.71%     822.133us        13.44%       1.937ms      23.624us     799.874us         9.62%     799.874us       9.755us            82  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     770.656us         9.27%     770.656us      96.332us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 14.409ms\n",
            "Self CUDA time total: 8.315ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4UchJcz1N6K",
        "outputId": "1d6f37fe-1984-45d1-90bf-44877c1d3fca"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:29<00:00, 15.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0459, Test Accuracy: 98.66%\n",
            "Overall - F1: 0.9865, Recall: 0.9863, Precision: 0.9868\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9987, Recall: 1.0000, Precision: 0.9974\n",
            "Class 1 - F1: 0.9997, Recall: 1.0000, Precision: 0.9994\n",
            "Class 2 - F1: 0.9795, Recall: 0.9803, Precision: 0.9786\n",
            "Class 3 - F1: 0.9974, Recall: 0.9965, Precision: 0.9983\n",
            "Class 4 - F1: 0.9825, Recall: 0.9910, Precision: 0.9742\n",
            "Class 5 - F1: 0.9909, Recall: 0.9966, Precision: 0.9854\n",
            "Class 6 - F1: 0.9832, Recall: 0.9764, Precision: 0.9900\n",
            "Class 7 - F1: 0.9657, Recall: 0.9528, Precision: 0.9790\n",
            "Class 8 - F1: 0.9807, Recall: 0.9828, Precision: 0.9787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "ZLcoSxfe1Qbt",
        "outputId": "248c5053-8c41-4f32-db8b-7f96f68e677d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbSpMMWGk3bf",
        "outputId": "9a28dd19-4414-44ca-f31e-2504c3649bc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-21 04:08:44--  https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.45.92, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 800276929 (763M) [application/octet-stream]\n",
            "Saving to: ‘CRC-VAL-HE-7K.zip’\n",
            "\n",
            "CRC-VAL-HE-7K.zip   100%[===================>] 763.20M  17.1MB/s    in 4m 24s  \n",
            "\n",
            "2025-03-21 04:13:09 (2.89 MB/s) - ‘CRC-VAL-HE-7K.zip’ saved [800276929/800276929]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O CRC-VAL-HE-7K.zip https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
        "!unzip -qq CRC-VAL-HE-7K.zip -d val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "rldaXFNXpT4r"
      },
      "outputs": [],
      "source": [
        "test_7k_dir = './val/CRC-VAL-HE-7K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "6oLIYyRG9dVi"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Belqw8QytnZL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "test7k_dataset = datasets.ImageFolder(root=test_7k_dir, transform=test_transform)\n",
        "test7k_dataloader = DataLoader(test7k_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2y3cywDpjUQ",
        "outputId": "92d34e9c-9e2c-4ab4-d2a9-ca324ab73e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 225/225 [00:11<00:00, 19.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.6036, Test Accuracy: 90.52%\n",
            "Overall - F1: 0.8607, Recall: 0.8746, Precision: 0.8801\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9461, Recall: 0.9111, Precision: 0.9839\n",
            "Class 1 - F1: 0.9485, Recall: 1.0000, Precision: 0.9020\n",
            "Class 2 - F1: 0.7746, Recall: 0.9735, Precision: 0.6433\n",
            "Class 3 - F1: 0.9587, Recall: 0.9874, Precision: 0.9315\n",
            "Class 4 - F1: 0.9645, Recall: 0.9459, Precision: 0.9839\n",
            "Class 5 - F1: 0.7685, Recall: 0.8328, Precision: 0.7135\n",
            "Class 6 - F1: 0.9327, Recall: 0.9069, Precision: 0.9600\n",
            "Class 7 - F1: 0.5017, Recall: 0.3539, Precision: 0.8613\n",
            "Class 8 - F1: 0.9506, Recall: 0.9603, Precision: 0.9412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test7k_dataloader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "p4pYjMPUpy2m",
        "outputId": "97550460-8dae-4454-b5c3-18a940901f13"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MOLSL09JxKdp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}