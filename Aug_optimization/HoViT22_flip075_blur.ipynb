{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "46fbbc7f-c391-427e-ac4d-c840d0cf73ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=0a55f90ccfb19e3581e66ce8716f4bae255042454c5f379bb4770427ac08c6cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "224a8f1d-6fa8-4823-eaca-db7a2080b988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-02 05:50:02--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.45.92, 188.185.43.25, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.45.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-04-02 05:50:03--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  10.6MB/s    in 21m 48s \n",
            "\n",
            "2025-04-02 06:11:51 (8.52 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=2, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=2, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "ef749692-6f11-4ef3-8fcd-48a4de6945b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "b13c9afb-0777-46b7-8899-d7c708865e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 4,909,234\n",
            "Trainable params: 4,909,234\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.82\n",
            "Params size (MB): 19.64\n",
            "Estimated Total Size (MB): 936.72\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "bdd7ebb9-ffc1-43fa-8125-d477a7855078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.82\n",
            "Params size (MB): 19.64\n",
            "Estimated Total Size (MB): 936.72\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.82\n",
            "Params size (MB): 19.64\n",
            "Estimated Total Size (MB): 936.72\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "5bd54b70-5f53-492d-f271-83acb3916185"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_XOsreNaIoSQ"
      },
      "outputs": [],
      "source": [
        "from skimage.color import rgb2hed, hed2rgb\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zja84HaiVhoh"
      },
      "outputs": [],
      "source": [
        "# Augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.75),\n",
        "    transforms.RandomVerticalFlip(p=0.75),\n",
        "    transforms.GaussianBlur(kernel_size=3, sigma=(0.5, 0.5)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YDaTgqOuPUej"
      },
      "outputs": [],
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "train_dataset_full = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "test_dataset_full = datasets.ImageFolder(root=train_dir, transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "train_data = Subset(train_dataset_full, load_train_idx)\n",
        "val_data = Subset(test_dataset_full, load_val_idx)\n",
        "test_data = Subset(test_dataset_full, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "5d0f0966-f355-4d60-e452-a4d928846c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "64e9d704-c823-4612-bdd6-37fa5303345f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:59<00:00,  7.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5110, Train Accuracy: 81.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6125, Validation Accuracy: 78.48%\n",
            "Balanced Accuracy: 0.7927\n",
            "New best model saved with Validation loss 0.6125 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:57<00:00,  7.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2375, Train Accuracy: 91.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2757, Validation Accuracy: 90.11%\n",
            "Balanced Accuracy: 0.9051\n",
            "New best model saved with Validation loss 0.2757 at best_model.pth\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:56<00:00,  7.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1725, Train Accuracy: 94.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1719, Validation Accuracy: 93.93%\n",
            "Balanced Accuracy: 0.9352\n",
            "New best model saved with Validation loss 0.1719 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:57<00:00,  7.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1343, Train Accuracy: 95.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1991, Validation Accuracy: 93.08%\n",
            "Balanced Accuracy: 0.9263\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1096, Train Accuracy: 96.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0955, Validation Accuracy: 96.88%\n",
            "Balanced Accuracy: 0.9675\n",
            "New best model saved with Validation loss 0.0955 at best_model.pth\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:57<00:00,  7.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0884, Train Accuracy: 97.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4066, Validation Accuracy: 88.61%\n",
            "Balanced Accuracy: 0.8753\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0744, Train Accuracy: 97.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1317, Validation Accuracy: 95.41%\n",
            "Balanced Accuracy: 0.9507\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0626, Train Accuracy: 97.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1140, Validation Accuracy: 95.91%\n",
            "Balanced Accuracy: 0.9565\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:57<00:00,  7.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0549, Train Accuracy: 98.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6980, Validation Accuracy: 82.40%\n",
            "Balanced Accuracy: 0.8098\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0464, Train Accuracy: 98.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1774, Validation Accuracy: 94.94%\n",
            "Balanced Accuracy: 0.9522\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0423, Train Accuracy: 98.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0955, Validation Accuracy: 96.97%\n",
            "Balanced Accuracy: 0.9685\n",
            "New best model saved with Validation loss 0.0955 at best_model.pth\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0358, Train Accuracy: 98.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1644, Validation Accuracy: 94.82%\n",
            "Balanced Accuracy: 0.9425\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:57<00:00,  7.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0336, Train Accuracy: 98.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0819, Validation Accuracy: 97.41%\n",
            "Balanced Accuracy: 0.9737\n",
            "New best model saved with Validation loss 0.0819 at best_model.pth\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:57<00:00,  7.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0298, Train Accuracy: 98.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1714, Validation Accuracy: 94.94%\n",
            "Balanced Accuracy: 0.9494\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0266, Train Accuracy: 99.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3376, Validation Accuracy: 91.62%\n",
            "Balanced Accuracy: 0.9091\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0256, Train Accuracy: 99.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0590, Validation Accuracy: 98.17%\n",
            "Balanced Accuracy: 0.9812\n",
            "New best model saved with Validation loss 0.0590 at best_model.pth\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0238, Train Accuracy: 99.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0520, Validation Accuracy: 98.45%\n",
            "Balanced Accuracy: 0.9836\n",
            "New best model saved with Validation loss 0.0520 at best_model.pth\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:59<00:00,  7.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0215, Train Accuracy: 99.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3226, Validation Accuracy: 92.05%\n",
            "Balanced Accuracy: 0.9155\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0191, Train Accuracy: 99.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1683, Validation Accuracy: 95.37%\n",
            "Balanced Accuracy: 0.9510\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0191, Train Accuracy: 99.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1182, Validation Accuracy: 96.81%\n",
            "Balanced Accuracy: 0.9645\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:59<00:00,  7.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0182, Train Accuracy: 99.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1572, Validation Accuracy: 95.83%\n",
            "Balanced Accuracy: 0.9555\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:00<00:00,  7.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0159, Train Accuracy: 99.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0460, Validation Accuracy: 98.69%\n",
            "Balanced Accuracy: 0.9860\n",
            "New best model saved with Validation loss 0.0460 at best_model.pth\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0156, Train Accuracy: 99.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.7835, Validation Accuracy: 74.12%\n",
            "Balanced Accuracy: 0.7213\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0157, Train Accuracy: 99.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0411, Validation Accuracy: 98.83%\n",
            "Balanced Accuracy: 0.9878\n",
            "New best model saved with Validation loss 0.0411 at best_model.pth\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:57<00:00,  7.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0150, Train Accuracy: 99.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0436, Validation Accuracy: 98.67%\n",
            "Balanced Accuracy: 0.9864\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0125, Train Accuracy: 99.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0534, Validation Accuracy: 98.63%\n",
            "Balanced Accuracy: 0.9862\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0125, Train Accuracy: 99.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1231, Validation Accuracy: 96.51%\n",
            "Balanced Accuracy: 0.9667\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0111, Train Accuracy: 99.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1095, Validation Accuracy: 96.75%\n",
            "Balanced Accuracy: 0.9658\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0130, Train Accuracy: 99.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0434, Validation Accuracy: 98.63%\n",
            "Balanced Accuracy: 0.9860\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [04:58<00:00,  7.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0110, Train Accuracy: 99.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 23.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0679, Validation Accuracy: 97.96%\n",
            "Balanced Accuracy: 0.9793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aeS-ct5VYqE",
        "outputId": "364c28c6-a2ba-434d-defa-c3d195599db8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"HoViT22_flip075_blur.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "6d2ed862-3ab2-4f71-e4a6-c0b1cc4c58b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:21<00:00, 21.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0444, Test Accuracy: 98.78%\n",
            "Balanced Accuracy: 0.9874\n",
            "New best model saved with Test loss 0.0444 at best_model.pth\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, 1, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "8923764d-e85c-4762-faf8-8e43833adac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 6.78 ms\n",
            "Standard Deviation: 2.59 ms\n",
            "Maximum Time: 58.78 ms\n",
            "Minimum Time: 5.83 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "d7a17701-22d3-4d1a-afff-f4192fcc27d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         9.01%       1.516ms        25.77%       4.337ms     180.703us       0.000us         0.00%       2.535ms     105.630us            24  \n",
            "                                           aten::linear         0.58%      98.393us        13.36%       2.248ms     124.870us       0.000us         0.00%       1.827ms     101.497us            18  \n",
            "                                               aten::mm         3.48%     585.299us        10.47%       1.762ms     110.123us       1.803ms        37.99%       1.803ms     112.682us            16  \n",
            "                                           aten::conv2d         0.92%     154.256us        31.53%       5.306ms     884.404us       0.000us         0.00%     723.230us     120.538us             6  \n",
            "                                      aten::convolution         0.32%      53.548us        30.62%       5.152ms     858.695us       0.000us         0.00%     723.230us     120.538us             6  \n",
            "                                     aten::_convolution        22.03%       3.708ms        30.30%       5.099ms     849.771us       0.000us         0.00%     723.230us     120.538us             6  \n",
            "                                aten::cudnn_convolution         6.19%       1.041ms         7.92%       1.332ms     222.012us     708.510us        14.93%     708.510us     118.085us             6  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     679.327us        14.31%     679.327us     169.832us             4  \n",
            "                                              aten::bmm         1.61%     271.099us         2.02%     339.950us      42.494us     567.998us        11.97%     567.998us      71.000us             8  \n",
            "                                       aten::batch_norm         0.83%     139.060us        25.59%       4.307ms     187.262us       0.000us         0.00%     549.211us      23.879us            23  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 16.828ms\n",
            "Self CUDA time total: 4.746ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ],
      "metadata": {
        "id": "lcYP95GeycR1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56a99f47-c8b1-4c68-ab26-52833bdb9bb6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:21<00:00, 21.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0444, Test Accuracy: 98.78%\n",
            "Overall - F1: 0.9877, Recall: 0.9874, Precision: 0.9881\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9978, Recall: 0.9974, Precision: 0.9981\n",
            "Class 1 - F1: 0.9984, Recall: 0.9968, Precision: 1.0000\n",
            "Class 2 - F1: 0.9810, Recall: 0.9873, Precision: 0.9748\n",
            "Class 3 - F1: 0.9977, Recall: 0.9971, Precision: 0.9983\n",
            "Class 4 - F1: 0.9864, Recall: 0.9805, Precision: 0.9924\n",
            "Class 5 - F1: 0.9882, Recall: 0.9867, Precision: 0.9896\n",
            "Class 6 - F1: 0.9863, Recall: 0.9856, Precision: 0.9871\n",
            "Class 7 - F1: 0.9667, Recall: 0.9636, Precision: 0.9698\n",
            "Class 8 - F1: 0.9870, Recall: 0.9916, Precision: 0.9825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "FyLRPcP1Lbfs",
        "outputId": "ff3fbaa1-a762-4cfd-8e25-61446cc32107"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G5i6ftANLhqk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}