{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "8d91dcf5-0b89-475f-dd9f-d41673b27ed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=02642291201138d3dd2fe972bdc4d38df70f35cdac7e6eace51ba945b5bf7133\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "63157291-e8ba-4cb6-9839-4b09b25b639b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-26 22:42:23--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.48.194, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-03-26 22:42:24--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  11.3MB/s    in 16m 21s \n",
            "\n",
            "2025-03-26 22:58:45 (11.4 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "b62efad1-36a1-410d-a7ca-e7e70b8a8d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "f25d83c7-7206-4438-c22d-a4a9f61955e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "60c1146b-2c19-4907-d7a0-56ca02e4400d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "c1e390b5-46e4-43f3-942e-2b29413053fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.color import rgb2hed, hed2rgb\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "id": "_XOsreNaIoSQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.75),\n",
        "    transforms.RandomVerticalFlip(p=0.75),\n",
        "    transforms.GaussianBlur(kernel_size=3, sigma=(0.5, 0.5)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "zja84HaiVhoh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "YDaTgqOuPUej"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "train_dataset_full = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "test_dataset_full = datasets.ImageFolder(root=train_dir, transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "train_data = Subset(train_dataset_full, load_train_idx)\n",
        "val_data = Subset(test_dataset_full, load_val_idx)\n",
        "test_data = Subset(test_dataset_full, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "3bb07c97-6eee-4ea0-d0a7-11c266c83c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "c17317a7-565f-48a2-c70d-73a6952db866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:35<00:00,  6.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6883, Train Accuracy: 75.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4043, Validation Accuracy: 86.05%\n",
            "Balanced Accuracy: 0.8570\n",
            "New best model saved with Validation loss 0.4043 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:34<00:00,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3643, Train Accuracy: 87.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2699, Validation Accuracy: 90.84%\n",
            "Balanced Accuracy: 0.9053\n",
            "New best model saved with Validation loss 0.2699 at best_model.pth\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:33<00:00,  6.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2502, Train Accuracy: 91.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1957, Validation Accuracy: 93.17%\n",
            "Balanced Accuracy: 0.9299\n",
            "New best model saved with Validation loss 0.1957 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:33<00:00,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1942, Train Accuracy: 93.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6241, Validation Accuracy: 79.93%\n",
            "Balanced Accuracy: 0.7866\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:34<00:00,  6.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1532, Train Accuracy: 94.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2410, Validation Accuracy: 91.98%\n",
            "Balanced Accuracy: 0.9176\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:34<00:00,  6.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1247, Train Accuracy: 95.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7892, Validation Accuracy: 79.76%\n",
            "Balanced Accuracy: 0.7839\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:35<00:00,  6.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1001, Train Accuracy: 96.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2795, Validation Accuracy: 91.59%\n",
            "Balanced Accuracy: 0.9076\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:35<00:00,  6.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0806, Train Accuracy: 97.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6175, Validation Accuracy: 84.61%\n",
            "Balanced Accuracy: 0.8324\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:35<00:00,  6.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0688, Train Accuracy: 97.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1669, Validation Accuracy: 94.42%\n",
            "Balanced Accuracy: 0.9420\n",
            "New best model saved with Validation loss 0.1669 at best_model.pth\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:36<00:00,  6.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0556, Train Accuracy: 98.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2573, Validation Accuracy: 92.10%\n",
            "Balanced Accuracy: 0.9179\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:34<00:00,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0478, Train Accuracy: 98.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7292, Validation Accuracy: 82.23%\n",
            "Balanced Accuracy: 0.8008\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:33<00:00,  6.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0438, Train Accuracy: 98.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1652, Validation Accuracy: 94.57%\n",
            "Balanced Accuracy: 0.9401\n",
            "New best model saved with Validation loss 0.1652 at best_model.pth\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:33<00:00,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0369, Train Accuracy: 98.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0682, Validation Accuracy: 97.79%\n",
            "Balanced Accuracy: 0.9768\n",
            "New best model saved with Validation loss 0.0682 at best_model.pth\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:34<00:00,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0335, Train Accuracy: 98.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1288, Validation Accuracy: 95.89%\n",
            "Balanced Accuracy: 0.9565\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:33<00:00,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0313, Train Accuracy: 98.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0704, Validation Accuracy: 97.89%\n",
            "Balanced Accuracy: 0.9783\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:33<00:00,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0256, Train Accuracy: 99.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9805, Validation Accuracy: 80.27%\n",
            "Balanced Accuracy: 0.7868\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:33<00:00,  6.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0253, Train Accuracy: 99.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1536, Validation Accuracy: 95.34%\n",
            "Balanced Accuracy: 0.9517\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:34<00:00,  6.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0217, Train Accuracy: 99.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2581, Validation Accuracy: 92.98%\n",
            "Balanced Accuracy: 0.9233\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:34<00:00,  6.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0207, Train Accuracy: 99.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0610, Validation Accuracy: 98.27%\n",
            "Balanced Accuracy: 0.9814\n",
            "New best model saved with Validation loss 0.0610 at best_model.pth\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:33<00:00,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0188, Train Accuracy: 99.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0619, Validation Accuracy: 98.15%\n",
            "Balanced Accuracy: 0.9816\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:35<00:00,  6.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0184, Train Accuracy: 99.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0615, Validation Accuracy: 98.36%\n",
            "Balanced Accuracy: 0.9835\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:35<00:00,  6.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0183, Train Accuracy: 99.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1736, Validation Accuracy: 95.21%\n",
            "Balanced Accuracy: 0.9472\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:34<00:00,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0153, Train Accuracy: 99.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 20.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0807, Validation Accuracy: 97.47%\n",
            "Balanced Accuracy: 0.9750\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:33<00:00,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0157, Train Accuracy: 99.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0362, Validation Accuracy: 99.01%\n",
            "Balanced Accuracy: 0.9898\n",
            "New best model saved with Validation loss 0.0362 at best_model.pth\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:34<00:00,  6.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0148, Train Accuracy: 99.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0523, Validation Accuracy: 98.41%\n",
            "Balanced Accuracy: 0.9831\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:35<00:00,  6.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0122, Train Accuracy: 99.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0980, Validation Accuracy: 97.63%\n",
            "Balanced Accuracy: 0.9742\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:33<00:00,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0146, Train Accuracy: 99.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4017, Validation Accuracy: 92.27%\n",
            "Balanced Accuracy: 0.9159\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:34<00:00,  6.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0120, Train Accuracy: 99.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0600, Validation Accuracy: 98.37%\n",
            "Balanced Accuracy: 0.9825\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:34<00:00,  6.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0105, Train Accuracy: 99.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0299, Validation Accuracy: 99.19%\n",
            "Balanced Accuracy: 0.9920\n",
            "New best model saved with Validation loss 0.0299 at best_model.pth\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:34<00:00,  6.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0123, Train Accuracy: 99.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 20.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0509, Validation Accuracy: 98.77%\n",
            "Balanced Accuracy: 0.9873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aeS-ct5VYqE",
        "outputId": "b0eca090-1a5d-45b9-9fe3-f76f918014ef"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "10ceb07e-ef7b-4fcc-b52f-186f12fe9db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:23<00:00, 20.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0314, Test Accuracy: 99.06%\n",
            "Balanced Accuracy: 0.9905\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "50e8279e-2702-4bb9-996a-aa7d9cb06c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 10.56 ms\n",
            "Standard Deviation: 0.58 ms\n",
            "Maximum Time: 13.43 ms\n",
            "Minimum Time: 10.00 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "0ad5b8b3-fba9-4300-9088-4b732112c6a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul        12.86%       3.431ms        36.51%       9.745ms     203.029us       0.000us         0.00%       5.081ms     105.848us            48  \n",
            "                                           aten::linear         0.74%     198.085us        19.18%       5.120ms     150.582us       0.000us         0.00%       3.641ms     107.083us            34  \n",
            "                                               aten::mm         4.17%       1.112ms        16.14%       4.308ms     134.638us       3.617ms        43.33%       3.617ms     113.029us            32  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.361ms        16.31%       1.361ms     170.148us             8  \n",
            "                                              aten::bmm         1.80%     481.120us         2.35%     627.357us      39.210us       1.139ms        13.65%       1.139ms      71.188us            16  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     992.483us        11.89%     992.483us     124.060us             8  \n",
            "                                       aten::batch_norm         1.01%     270.644us        31.04%       8.285ms     212.443us       0.000us         0.00%     863.996us      22.154us            39  \n",
            "                           aten::_batch_norm_impl_index        14.35%       3.830ms        30.03%       8.015ms     205.504us       0.000us         0.00%     863.996us      22.154us            39  \n",
            "                                            aten::copy_         3.43%     916.372us         7.71%       2.059ms      25.111us     807.548us         9.67%     807.548us       9.848us            82  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     774.466us         9.28%     774.466us      96.808us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 26.691ms\n",
            "Self CUDA time total: 8.347ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbSpMMWGk3bf",
        "outputId": "71d7c0d2-6303-4e52-a5ee-230ff74aed9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-27 02:02:48--  https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.45.92, 188.185.43.25, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 800276929 (763M) [application/octet-stream]\n",
            "Saving to: ‘CRC-VAL-HE-7K.zip’\n",
            "\n",
            "CRC-VAL-HE-7K.zip   100%[===================>] 763.20M  18.0MB/s    in 68s     \n",
            "\n",
            "2025-03-27 02:03:57 (11.3 MB/s) - ‘CRC-VAL-HE-7K.zip’ saved [800276929/800276929]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O CRC-VAL-HE-7K.zip https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
        "!unzip -qq CRC-VAL-HE-7K.zip -d val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "rldaXFNXpT4r"
      },
      "outputs": [],
      "source": [
        "test_7k_dir = './val/CRC-VAL-HE-7K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "6oLIYyRG9dVi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Belqw8QytnZL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "test7k_dataset = datasets.ImageFolder(root=test_7k_dir, transform=test_transform)\n",
        "test7k_dataloader = DataLoader(test7k_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2y3cywDpjUQ",
        "outputId": "f2e77e1e-8262-4453-985c-54ece80df03c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 225/225 [00:11<00:00, 19.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.8867, Test Accuracy: 92.03%\n",
            "Overall - F1: 0.8903, Recall: 0.8974, Precision: 0.8978\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9627, Recall: 0.9454, Precision: 0.9806\n",
            "Class 1 - F1: 0.9517, Recall: 1.0000, Precision: 0.9078\n",
            "Class 2 - F1: 0.7922, Recall: 0.9617, Precision: 0.6736\n",
            "Class 3 - F1: 0.9812, Recall: 0.9874, Precision: 0.9751\n",
            "Class 4 - F1: 0.9576, Recall: 0.9285, Precision: 0.9887\n",
            "Class 5 - F1: 0.8175, Recall: 0.8057, Precision: 0.8296\n",
            "Class 6 - F1: 0.9108, Recall: 0.9298, Precision: 0.8925\n",
            "Class 7 - F1: 0.6860, Recall: 0.5606, Precision: 0.8839\n",
            "Class 8 - F1: 0.9532, Recall: 0.9578, Precision: 0.9486\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test7k_dataloader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "p4pYjMPUpy2m",
        "outputId": "233de790-a5c4-48aa-a7aa-e80e8161529e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}