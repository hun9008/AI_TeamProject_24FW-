{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "f835cbce-8367-458e-e23f-f2d32798cf7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=545f258c90aeed1a29ee4f173782710713c4471b79cb1f04123686cb1e9de3af\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n",
            "--2025-04-03 04:52:44--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.43.25, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-04-03 04:52:45--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  17.9MB/s    in 10m 46s \n",
            "\n",
            "2025-04-03 05:03:31 (17.3 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo\n",
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super().__init__()\n",
        "        self.stem = Stem16()\n",
        "        self.stage1 = LevitStage(256, 256, 4, 2, downsample=False)\n",
        "        self.stage2 = LevitStage(256, 384, 6, 2, downsample=True)\n",
        "        self.conv1x1 = nn.Sequential(nn.Conv2d(384, 512, 1), nn.BatchNorm2d(512), nn.ReLU(True))\n",
        "        self.head = NormLinear(512, num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(512, num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        H = W = int(x.shape[1] ** 0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "        x = self.conv1x1(x)\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        return self.head(x)\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        x = self.stem(x)\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        H = W = int(x.shape[1] ** 0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "        x = self.conv1x1(x)\n",
        "        return torch.mean(x, dim=(2, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "f77a5c33-23da-4788-92cf-c644db076325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gNpMsNYAzLDF",
        "outputId": "fceb0140-8a67-4230-94a2-0d77edce6a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 4,909,234\n",
            "Trainable params: 4,909,234\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.68\n",
            "Params size (MB): 19.61\n",
            "Estimated Total Size (MB): 936.56\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "aeebc344-079e-48fb-b872-86b8d1e7f977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.68\n",
            "Params size (MB): 19.61\n",
            "Estimated Total Size (MB): 936.56\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.68\n",
            "Params size (MB): 19.61\n",
            "Estimated Total Size (MB): 936.56\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "LUiqsuSdOgj0"
      },
      "outputs": [],
      "source": [
        "class BSDALayer(nn.Module):\n",
        "    def __init__(self, feature_dim, bsda_lambda=0.8) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.bsda_lambda = bsda_lambda\n",
        "\n",
        "        self.logvar = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "        )\n",
        "\n",
        "        self.d = nn.Dropout(p=self.bsda_lambda)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "    def modified_indicator_function(self, x):\n",
        "        return torch.where(x >= 0, torch.sign(x), -torch.sign(x))\n",
        "\n",
        "    def calc_a_tilde(self, a, m, multi=1):\n",
        "        a = a.repeat(multi, 1)\n",
        "        return a + self.d(m) * self.modified_indicator_function(a)\n",
        "\n",
        "    def reparameterize(self, mu, logvar, multi=1):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        std = std.repeat(multi, 1)\n",
        "        eps = torch.randn_like(std, device=std.device)\n",
        "        mu = mu.repeat(multi, 1)\n",
        "        return eps * std + mu\n",
        "\n",
        "    def forward(self, a, multi=1):\n",
        "        \"\"\"\n",
        "            a: (batch_size, feature_dim)\n",
        "            m: (batch_size, feature_dim)\n",
        "            mu: (batch_size, feature_dim)\n",
        "            logvar: (batch_size, feature_dim)\n",
        "        \"\"\"\n",
        "        x = self.encoder(a)\n",
        "\n",
        "        logvar = self.logvar(x)\n",
        "        mu = torch.zeros_like(logvar, device=logvar.device)\n",
        "\n",
        "        m = self.reparameterize(mu, logvar, multi)\n",
        "        a_hat = self.decoder(m)\n",
        "\n",
        "        return m, mu, logvar, a_hat\n",
        "\n",
        "    def calc_kl_loss(self, mu, logvar):\n",
        "\n",
        "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        return kl_loss\n",
        "\n",
        "    def calc_recon_loss(self, a, a_hat, multi=1):\n",
        "        recon_loss = torch.mean((a.repeat(multi, 1) - a_hat) ** 2) * 0.5\n",
        "        return recon_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "1a88b276-3e65-44ba-a002-410f7b99fe0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def elastic_transform(image, alpha, sigma):\n",
        "    \"\"\"탄성 변형 적용\"\"\"\n",
        "\n",
        "    if isinstance(image, torch.Tensor):\n",
        "        image_np = image.permute(1, 2, 0).numpy()\n",
        "    else:\n",
        "        image_np = np.array(image)\n",
        "\n",
        "    shape = image_np.shape[:2]\n",
        "\n",
        "    ksize = 2 * int(sigma) + 1\n",
        "\n",
        "    dx = cv2.GaussianBlur((np.random.rand(*shape) * 2 - 1), (ksize, ksize), sigma) * alpha\n",
        "    dy = cv2.GaussianBlur((np.random.rand(*shape) * 2 - 1), (ksize, ksize), sigma) * alpha\n",
        "    x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
        "\n",
        "    indices = np.stack((y + dy, x + dx), axis=-1).astype(np.float32)\n",
        "    distorted_image = cv2.remap(image_np, indices, None, cv2.INTER_LINEAR)\n",
        "\n",
        "    return distorted_image"
      ],
      "metadata": {
        "id": "2qQFL1y8fp5K"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "mAsRwMpISMIh"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "aug_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.75),\n",
        "    transforms.RandomVerticalFlip(p=0.75),\n",
        "    transforms.Lambda(lambda x: elastic_transform(x, alpha=10, sigma=4)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "fnlxaQSs7NsL"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "dataset_train = datasets.ImageFolder(root=train_dir, transform=aug_transform)\n",
        "dataset_eval = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "\n",
        "train_data = Subset(dataset_train, load_train_idx)\n",
        "val_data = Subset(dataset_eval, load_val_idx)\n",
        "test_data = Subset(dataset_eval, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "ef732dea-8d2d-4ca9-e570-0f7b97b89dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch,\n",
        "          use_bsda=False, bsda_layer=None, multi=10, bsda_alpha=0.5,\n",
        "          kl_weight=8e-4, recon_weight=1.0, use_ori=True, num_epochs=30):\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    ratio = min(bsda_alpha * (epoch / (num_epochs // 2)), bsda_alpha) if use_bsda else 0\n",
        "\n",
        "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        features = model.extract_features(inputs)\n",
        "        y_hat = model.head(features)\n",
        "\n",
        "        if use_bsda:\n",
        "            m, mu, logvar, a_hat = bsda_layer(features, multi=multi)\n",
        "            a_tilde = bsda_layer.calc_a_tilde(features, m, multi=multi)\n",
        "            y_hat_tilde = model.head(a_tilde)\n",
        "\n",
        "            loss_task = criterion(y_hat, labels)\n",
        "            loss_task_tilde = criterion(y_hat_tilde, labels.repeat(multi,))\n",
        "            loss_kl = bsda_layer.calc_kl_loss(mu, logvar)\n",
        "            loss_recon = bsda_layer.calc_recon_loss(features, a_hat, multi)\n",
        "            loss_bsda = kl_weight * loss_kl + recon_weight * loss_recon\n",
        "            loss = loss_task_tilde + loss_bsda\n",
        "            if use_ori:\n",
        "                loss = loss * ratio + loss_task\n",
        "        else:\n",
        "            loss = criterion(y_hat, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(y_hat, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Train Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100*correct/total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "2b6749c7-c15c-40af-a9d4-7a633da67a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 2188/2188 [05:46<00:00,  6.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5058, Accuracy: 82.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1301, Validation Accuracy: 61.08%\n",
            "Balanced Accuracy: 0.6186\n",
            "New best model saved with Validation loss 1.1301 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 2188/2188 [05:48<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3072, Accuracy: 91.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6001, Validation Accuracy: 78.09%\n",
            "Balanced Accuracy: 0.7952\n",
            "New best model saved with Validation loss 0.6001 at best_model.pth\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 2188/2188 [05:49<00:00,  6.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2763, Accuracy: 93.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2984, Validation Accuracy: 90.43%\n",
            "Balanced Accuracy: 0.9098\n",
            "New best model saved with Validation loss 0.2984 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 2188/2188 [05:47<00:00,  6.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2639, Accuracy: 95.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2690, Validation Accuracy: 90.91%\n",
            "Balanced Accuracy: 0.9133\n",
            "New best model saved with Validation loss 0.2690 at best_model.pth\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 2188/2188 [05:48<00:00,  6.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2622, Accuracy: 96.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3775, Validation Accuracy: 86.32%\n",
            "Balanced Accuracy: 0.8538\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 2188/2188 [05:48<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2604, Accuracy: 96.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1955, Validation Accuracy: 93.61%\n",
            "Balanced Accuracy: 0.9378\n",
            "New best model saved with Validation loss 0.1955 at best_model.pth\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 2188/2188 [05:47<00:00,  6.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2620, Accuracy: 97.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1580, Validation Accuracy: 94.66%\n",
            "Balanced Accuracy: 0.9484\n",
            "New best model saved with Validation loss 0.1580 at best_model.pth\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 2188/2188 [05:47<00:00,  6.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2656, Accuracy: 97.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5172, Validation Accuracy: 82.37%\n",
            "Balanced Accuracy: 0.8050\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 2188/2188 [05:49<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2742, Accuracy: 97.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2083, Validation Accuracy: 92.37%\n",
            "Balanced Accuracy: 0.9164\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 2188/2188 [05:50<00:00,  6.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2764, Accuracy: 98.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0930, Validation Accuracy: 96.89%\n",
            "Balanced Accuracy: 0.9686\n",
            "New best model saved with Validation loss 0.0930 at best_model.pth\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 2188/2188 [05:50<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2865, Accuracy: 98.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0981, Validation Accuracy: 96.55%\n",
            "Balanced Accuracy: 0.9639\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 2188/2188 [05:52<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2943, Accuracy: 98.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:22<00:00, 21.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2785, Validation Accuracy: 91.23%\n",
            "Balanced Accuracy: 0.9050\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 2188/2188 [05:51<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3049, Accuracy: 98.73%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0574, Validation Accuracy: 98.14%\n",
            "Balanced Accuracy: 0.9812\n",
            "New best model saved with Validation loss 0.0574 at best_model.pth\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 2188/2188 [05:48<00:00,  6.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3137, Accuracy: 98.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1022, Validation Accuracy: 96.57%\n",
            "Balanced Accuracy: 0.9641\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 2188/2188 [05:48<00:00,  6.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3231, Accuracy: 98.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0652, Validation Accuracy: 97.99%\n",
            "Balanced Accuracy: 0.9794\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 2188/2188 [05:49<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3330, Accuracy: 99.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0907, Validation Accuracy: 97.32%\n",
            "Balanced Accuracy: 0.9708\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 2188/2188 [05:49<00:00,  6.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3265, Accuracy: 99.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0598, Validation Accuracy: 98.11%\n",
            "Balanced Accuracy: 0.9800\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 2188/2188 [06:21<00:00,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3209, Accuracy: 99.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1078, Validation Accuracy: 96.50%\n",
            "Balanced Accuracy: 0.9624\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 2188/2188 [05:44<00:00,  6.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3087, Accuracy: 99.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0531, Validation Accuracy: 98.33%\n",
            "Balanced Accuracy: 0.9826\n",
            "New best model saved with Validation loss 0.0531 at best_model.pth\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 2188/2188 [05:45<00:00,  6.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3040, Accuracy: 99.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0484, Validation Accuracy: 98.54%\n",
            "Balanced Accuracy: 0.9857\n",
            "New best model saved with Validation loss 0.0484 at best_model.pth\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 2188/2188 [05:45<00:00,  6.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3044, Accuracy: 99.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1508, Validation Accuracy: 95.63%\n",
            "Balanced Accuracy: 0.9540\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 2188/2188 [05:45<00:00,  6.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2969, Accuracy: 99.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0372, Validation Accuracy: 98.87%\n",
            "Balanced Accuracy: 0.9881\n",
            "New best model saved with Validation loss 0.0372 at best_model.pth\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 2188/2188 [05:45<00:00,  6.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2932, Accuracy: 99.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0607, Validation Accuracy: 98.21%\n",
            "Balanced Accuracy: 0.9816\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 2188/2188 [05:46<00:00,  6.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2911, Accuracy: 99.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3323, Validation Accuracy: 91.10%\n",
            "Balanced Accuracy: 0.9007\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 2188/2188 [05:46<00:00,  6.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2840, Accuracy: 99.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1173, Validation Accuracy: 96.65%\n",
            "Balanced Accuracy: 0.9642\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 2188/2188 [05:44<00:00,  6.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2822, Accuracy: 99.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0546, Validation Accuracy: 98.38%\n",
            "Balanced Accuracy: 0.9824\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 2188/2188 [05:45<00:00,  6.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2774, Accuracy: 99.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0271, Validation Accuracy: 80.83%\n",
            "Balanced Accuracy: 0.8018\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 2188/2188 [05:45<00:00,  6.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2768, Accuracy: 99.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0362, Validation Accuracy: 98.90%\n",
            "Balanced Accuracy: 0.9889\n",
            "New best model saved with Validation loss 0.0362 at best_model.pth\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 2188/2188 [05:44<00:00,  6.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2740, Accuracy: 99.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0540, Validation Accuracy: 98.57%\n",
            "Balanced Accuracy: 0.9850\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 2188/2188 [05:45<00:00,  6.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2718, Accuracy: 99.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0362, Validation Accuracy: 98.93%\n",
            "Balanced Accuracy: 0.9890\n",
            "New best model saved with Validation loss 0.0362 at best_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "bsda_layer = BSDALayer(feature_dim=512, bsda_lambda=0.8).to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch,\n",
        "          use_bsda=True,\n",
        "          bsda_layer=bsda_layer,\n",
        "          multi=10,\n",
        "          bsda_alpha=0.5,\n",
        "          kl_weight=8e-4,\n",
        "          recon_weight=1.0,\n",
        "          use_ori=True,\n",
        "          num_epochs=num_epochs)\n",
        "\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCGf9fvf2-qk",
        "outputId": "e94f2e75-1e83-4c7c-be9d-6176aaad6c47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "39361016-517f-4078-b525-d8a04eb0afa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:21<00:00, 21.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0488, Test Accuracy: 98.59%\n",
            "Balanced Accuracy: 0.9855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "e12b3aba-c753-486f-f224-5e76d83cee39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 7.33 ms\n",
            "Standard Deviation: 0.66 ms\n",
            "Maximum Time: 11.37 ms\n",
            "Minimum Time: 6.86 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "55bdea1d-22d1-49ac-ae9c-9e4166c24eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         2.29%     197.970us        24.28%       2.100ms      87.505us       0.000us         0.00%       2.541ms     105.861us            24  \n",
            "                                           aten::linear         0.94%      81.488us        14.94%       1.292ms      76.029us       0.000us         0.00%       1.821ms     107.091us            17  \n",
            "                                               aten::mm         7.10%     614.625us        10.48%     906.446us      56.653us       1.808ms        38.29%       1.808ms     113.018us            16  \n",
            "                                           aten::conv2d         0.50%      43.453us        16.50%       1.428ms     237.963us       0.000us         0.00%     722.175us     120.363us             6  \n",
            "                                      aten::convolution         0.55%      47.301us        16.00%       1.384ms     230.720us       0.000us         0.00%     722.175us     120.363us             6  \n",
            "                                     aten::_convolution         0.87%      74.886us        15.46%       1.337ms     222.837us       0.000us         0.00%     722.175us     120.363us             6  \n",
            "                                aten::cudnn_convolution        11.23%     971.754us        13.98%       1.210ms     201.587us     707.679us        14.98%     707.679us     117.947us             6  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     679.457us        14.39%     679.457us     169.864us             4  \n",
            "                                              aten::bmm         3.34%     289.332us         4.35%     375.947us      46.993us     568.160us        12.03%     568.160us      71.020us             8  \n",
            "                                       aten::batch_norm         1.40%     120.829us        29.16%       2.522ms     114.657us       0.000us         0.00%     543.394us      24.700us            22  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 8.651ms\n",
            "Self CUDA time total: 4.723ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    val_losses.append(epoch_loss)\n",
        "    val_accuracies.append(accuracy)\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubbBuFrU-GRd",
        "outputId": "e8d38b90-b1be-49e0-fac9-bd089f29bd4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:21<00:00, 21.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0488, Test Accuracy: 98.59%\n",
            "Overall - F1: 0.9858, Recall: 0.9855, Precision: 0.9863\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9971, Recall: 0.9955, Precision: 0.9987\n",
            "Class 1 - F1: 1.0000, Recall: 1.0000, Precision: 1.0000\n",
            "Class 2 - F1: 0.9827, Recall: 0.9855, Precision: 0.9799\n",
            "Class 3 - F1: 0.9986, Recall: 0.9977, Precision: 0.9994\n",
            "Class 4 - F1: 0.9876, Recall: 0.9865, Precision: 0.9887\n",
            "Class 5 - F1: 0.9812, Recall: 0.9916, Precision: 0.9711\n",
            "Class 6 - F1: 0.9837, Recall: 0.9871, Precision: 0.9804\n",
            "Class 7 - F1: 0.9558, Recall: 0.9387, Precision: 0.9735\n",
            "Class 8 - F1: 0.9858, Recall: 0.9870, Precision: 0.9847\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "3qaLb5c--H0Q",
        "outputId": "fe546d50-3742-4614-803e-20a95d3bd359"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "QCHdGKmbuw9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac4d7ed-6d39-4fae-c5d5-5ec02f0f17cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved to HoViT22_flip_bsda_elastic.pth\n"
          ]
        }
      ],
      "source": [
        "save_path = \"HoViT22_flip_bsda_elastic.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model weights saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "K2NMYNeV0Ly5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}