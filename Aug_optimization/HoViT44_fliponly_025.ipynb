{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "1169da0a-5e01-407b-b005-5b35d519b683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=d592dd00fe3f1121ce08674d548b6397e447622c1a4b62b6dfc6f39d52623811\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxTtKfkN46C",
        "outputId": "f10f46e0-0e59-4ad1-c1e5-ba5dd4a0695f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-20 06:51:50--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.45.92, 188.185.43.25, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-03-20 06:51:51--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  21.2MB/s    in 10m 13s \n",
            "\n",
            "2025-03-20 07:02:04 (18.2 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n",
            "dataset setup complete!\n"
          ]
        }
      ],
      "source": [
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train\n",
        "\n",
        "print(\"dataset setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super(LevitDistilled, self).__init__()\n",
        "\n",
        "        self.stem = Stem16()\n",
        "\n",
        "        self.stage1 = LevitStage(dim=256, out_dim=256, num_heads=4, num_blocks=4, downsample=False) # block 수 적용\n",
        "        self.stage2 = LevitStage(dim=256, out_dim=384, num_heads=6, num_blocks=4, downsample=True)\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(384, 512, kernel_size=1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.head = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(in_features=512, out_features=num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "\n",
        "        H = W = int(x.shape[1]**0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "\n",
        "        x = self.conv1x1(x)\n",
        "\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        out = self.head(x)\n",
        "        out_dist = self.head_dist(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "b50ff56a-6685-4f03-b74f-ace255529811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNpMsNYAzLDF",
        "outputId": "902bf91a-fe59-4b7e-f7c0-fd78c916350e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 8,335,026\n",
            "Trainable params: 8,335,026\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "943b28a4-0897-4fe1-e9ea-7611afcad9ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   --\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─2.attn.attention_biases                                               ├─784\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─3.attn.attention_biases                                               ├─784\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-11                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-12                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.2.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.2.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.2.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.2.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.2.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.2.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.2.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.2.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.2.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.2.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.2.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.2.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.3.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.3.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.3.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.3.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.3.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.3.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.3.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.3.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.3.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.3.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.3.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.3.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-13                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-14                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─2.attn.attention_biases                                               ├─294\n",
            "│    │    └─2.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─2.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─2.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─2.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─2.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─2.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─2.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─2.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─2.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─2.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─2.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─3.attn.attention_biases                                               ├─294\n",
            "│    │    └─3.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─3.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─3.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─3.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─3.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─3.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─3.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─3.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─3.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─3.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─3.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-15                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-16                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-17                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-18                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "├─NormLinear: 1-6                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-18                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-19                                    [32, 512]                 --\n",
            "│    └─Linear: 2-20                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 8,339,338\n",
            "Trainable params: 8,339,338\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 28.27\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 1392.35\n",
            "Params size (MB): 33.34\n",
            "Estimated Total Size (MB): 1444.96\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "aff79f49-b155-4fc1-e654-03a730f85264"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir     = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.25),\n",
        "    transforms.RandomVerticalFlip(p=0.25),\n",
        "    #transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.25),\n",
        "])"
      ],
      "metadata": {
        "id": "zja84HaiVhoh"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Qe6c884rPvE7"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "train_data = Subset(dataset, load_train_idx)\n",
        "val_data = Subset(dataset, load_val_idx)\n",
        "test_data = Subset(dataset, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "722a6c5b-bf9d-4ce3-eb14-84f701c720c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "4d8e4545-19e1-483b-fc5c-8d86653d2867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:43<00:00, 13.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6857, Train Accuracy: 75.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3630, Validation Accuracy: 86.98%\n",
            "Balanced Accuracy: 0.8668\n",
            "New best model saved with Validation loss 0.3630 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:43<00:00, 13.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3508, Train Accuracy: 87.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5146, Validation Accuracy: 83.18%\n",
            "Balanced Accuracy: 0.8146\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:43<00:00, 13.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2430, Train Accuracy: 91.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3477, Validation Accuracy: 88.35%\n",
            "Balanced Accuracy: 0.8728\n",
            "New best model saved with Validation loss 0.3477 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:43<00:00, 13.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1846, Train Accuracy: 93.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2032, Validation Accuracy: 92.75%\n",
            "Balanced Accuracy: 0.9199\n",
            "New best model saved with Validation loss 0.2032 at best_model.pth\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1457, Train Accuracy: 95.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2131, Validation Accuracy: 93.28%\n",
            "Balanced Accuracy: 0.9294\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1177, Train Accuracy: 95.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1661, Validation Accuracy: 94.23%\n",
            "Balanced Accuracy: 0.9408\n",
            "New best model saved with Validation loss 0.1661 at best_model.pth\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0916, Train Accuracy: 96.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1336, Validation Accuracy: 95.59%\n",
            "Balanced Accuracy: 0.9531\n",
            "New best model saved with Validation loss 0.1336 at best_model.pth\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0758, Train Accuracy: 97.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9708, Validation Accuracy: 74.31%\n",
            "Balanced Accuracy: 0.7452\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:43<00:00, 13.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0625, Train Accuracy: 97.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4527, Validation Accuracy: 87.35%\n",
            "Balanced Accuracy: 0.8638\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:43<00:00, 13.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0514, Train Accuracy: 98.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0790, Validation Accuracy: 97.61%\n",
            "Balanced Accuracy: 0.9752\n",
            "New best model saved with Validation loss 0.0790 at best_model.pth\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:43<00:00, 13.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0459, Train Accuracy: 98.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2613, Validation Accuracy: 92.13%\n",
            "Balanced Accuracy: 0.9197\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:43<00:00, 13.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0397, Train Accuracy: 98.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5226, Validation Accuracy: 87.07%\n",
            "Balanced Accuracy: 0.8561\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:43<00:00, 13.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0344, Train Accuracy: 98.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0834, Validation Accuracy: 97.52%\n",
            "Balanced Accuracy: 0.9730\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:43<00:00, 13.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0314, Train Accuracy: 98.94%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0560, Validation Accuracy: 98.19%\n",
            "Balanced Accuracy: 0.9803\n",
            "New best model saved with Validation loss 0.0560 at best_model.pth\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:43<00:00, 13.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0290, Train Accuracy: 99.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0969, Validation Accuracy: 97.07%\n",
            "Balanced Accuracy: 0.9678\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:43<00:00, 13.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0252, Train Accuracy: 99.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0472, Validation Accuracy: 98.59%\n",
            "Balanced Accuracy: 0.9860\n",
            "New best model saved with Validation loss 0.0472 at best_model.pth\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:43<00:00, 13.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0244, Train Accuracy: 99.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0543, Validation Accuracy: 98.38%\n",
            "Balanced Accuracy: 0.9829\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0196, Train Accuracy: 99.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0295, Validation Accuracy: 99.11%\n",
            "Balanced Accuracy: 0.9911\n",
            "New best model saved with Validation loss 0.0295 at best_model.pth\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0195, Train Accuracy: 99.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1260, Validation Accuracy: 96.39%\n",
            "Balanced Accuracy: 0.9606\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0170, Train Accuracy: 99.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1493, Validation Accuracy: 95.93%\n",
            "Balanced Accuracy: 0.9550\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0184, Train Accuracy: 99.39%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3764, Validation Accuracy: 91.28%\n",
            "Balanced Accuracy: 0.9027\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0165, Train Accuracy: 99.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0267, Validation Accuracy: 99.14%\n",
            "Balanced Accuracy: 0.9910\n",
            "New best model saved with Validation loss 0.0267 at best_model.pth\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0148, Train Accuracy: 99.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1903, Validation Accuracy: 94.89%\n",
            "Balanced Accuracy: 0.9484\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0146, Train Accuracy: 99.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0511, Validation Accuracy: 98.50%\n",
            "Balanced Accuracy: 0.9862\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0134, Train Accuracy: 99.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1050, Validation Accuracy: 96.92%\n",
            "Balanced Accuracy: 0.9677\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0130, Train Accuracy: 99.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0520, Validation Accuracy: 98.43%\n",
            "Balanced Accuracy: 0.9847\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:47<00:00, 13.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0133, Train Accuracy: 99.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1871, Validation Accuracy: 95.53%\n",
            "Balanced Accuracy: 0.9540\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:46<00:00, 13.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0119, Train Accuracy: 99.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:24<00:00, 19.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1041, Validation Accuracy: 97.19%\n",
            "Balanced Accuracy: 0.9697\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:44<00:00, 13.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0112, Train Accuracy: 99.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0553, Validation Accuracy: 98.42%\n",
            "Balanced Accuracy: 0.9844\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [02:45<00:00, 13.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0107, Train Accuracy: 99.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:23<00:00, 19.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0194, Validation Accuracy: 99.44%\n",
            "Balanced Accuracy: 0.9946\n",
            "New best model saved with Validation loss 0.0194 at best_model.pth\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "e90354cd-26f3-438e-cf48-c7fdf5d2fa1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:24<00:00, 19.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0256, Test Accuracy: 99.30%\n",
            "Balanced Accuracy: 0.9930\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "e55c1ce9-f3ea-49e0-8ae5-3a4d436bf2f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 10.19 ms\n",
            "Standard Deviation: 0.48 ms\n",
            "Maximum Time: 13.08 ms\n",
            "Minimum Time: 9.57 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "b62571b6-f637-4d69-84bc-23da3dfdcc9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         7.06%       1.267ms        31.32%       5.621ms     117.100us       0.000us         0.00%       5.050ms     105.199us            48  \n",
            "                                           aten::linear         1.04%     187.199us        17.83%       3.201ms      94.137us       0.000us         0.00%       3.617ms     106.395us            34  \n",
            "                                               aten::mm         6.49%       1.164ms        13.56%       2.433ms      76.021us       3.594ms        43.20%       3.594ms     112.299us            32  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us       1.352ms        16.25%       1.352ms     168.940us             8  \n",
            "                                              aten::bmm         2.71%     485.658us         3.47%     623.310us      38.957us       1.131ms        13.60%       1.131ms      70.716us            16  \n",
            "                                ampere_sgemm_128x128_nn         0.00%       0.000us         0.00%       0.000us       0.000us     986.658us        11.86%     986.658us     123.332us             8  \n",
            "                                       aten::batch_norm         1.36%     244.513us        31.46%       5.646ms     144.773us       0.000us         0.00%     885.787us      22.712us            39  \n",
            "                           aten::_batch_norm_impl_index         7.26%       1.303ms        30.10%       5.402ms     138.503us       0.000us         0.00%     885.787us      22.712us            39  \n",
            "                                            aten::copy_         4.73%     848.692us        11.38%       2.042ms      24.897us     816.124us         9.81%     816.124us       9.953us            82  \n",
            "                                 ampere_sgemm_128x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us     769.344us         9.25%     769.344us      96.168us             8  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 17.946ms\n",
            "Self CUDA time total: 8.318ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device) # move tensors to device\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc2tPigjv6Is"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"HoViT44_withAug_7Ktest.pth\")\n",
        "#model.load_state_dict(torch.load(\"HoViT44_withAug_7Ktest.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbSpMMWGk3bf",
        "outputId": "58efbff7-2973-4856-aa07-51a16e1ea160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-20 09:47:09--  https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.48.194, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 800276929 (763M) [application/octet-stream]\n",
            "Saving to: ‘CRC-VAL-HE-7K.zip’\n",
            "\n",
            "CRC-VAL-HE-7K.zip   100%[===================>] 763.20M  16.1MB/s    in 48s     \n",
            "\n",
            "2025-03-20 09:47:58 (15.8 MB/s) - ‘CRC-VAL-HE-7K.zip’ saved [800276929/800276929]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O CRC-VAL-HE-7K.zip https://zenodo.org/records/1214456/files/CRC-VAL-HE-7K.zip\n",
        "!unzip -qq CRC-VAL-HE-7K.zip -d val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "rldaXFNXpT4r"
      },
      "outputs": [],
      "source": [
        "test_7k_dir = './val/CRC-VAL-HE-7K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "6oLIYyRG9dVi"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "Belqw8QytnZL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "test7k_dataset = datasets.ImageFolder(root=test_7k_dir, transform=test_transform)\n",
        "test7k_dataloader = DataLoader(test7k_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2y3cywDpjUQ",
        "outputId": "b9d41c7e-a554-4559-afda-04c3f93dc849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 225/225 [00:11<00:00, 19.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.5468, Test Accuracy: 92.44%\n",
            "Overall - F1: 0.8974, Recall: 0.9011, Precision: 0.9047\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9472, Recall: 0.9111, Precision: 0.9862\n",
            "Class 1 - F1: 0.9544, Recall: 1.0000, Precision: 0.9127\n",
            "Class 2 - F1: 0.8601, Recall: 0.9705, Precision: 0.7723\n",
            "Class 3 - F1: 0.9834, Recall: 0.9795, Precision: 0.9873\n",
            "Class 4 - F1: 0.9580, Recall: 0.9700, Precision: 0.9463\n",
            "Class 5 - F1: 0.7977, Recall: 0.8091, Precision: 0.7865\n",
            "Class 6 - F1: 0.9401, Recall: 0.9312, Precision: 0.9491\n",
            "Class 7 - F1: 0.6744, Recall: 0.5534, Precision: 0.8630\n",
            "Class 8 - F1: 0.9616, Recall: 0.9854, Precision: 0.9389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test7k_dataloader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "p4pYjMPUpy2m",
        "outputId": "b4075242-3193-4da5-f12f-50c8b9d44283"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABTMAAAGkCAYAAADt4rEnAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAc31JREFUeJzt3XdUFFcDxuEXUMCKCCrYNYqIDXvvotix91hjib3HFksssXeNHXuvUaMxJmo0JsZE7MYWS6yIYBeQ5fsDXV0B26fgyO85Z0/C7J3hXi935s67M7NW4eHh4QIAAAAAAACAj5x1bFcAAAAAAAAAAN4EYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAA8IkpU6aMunXrZv45Y8aMmjRpUqzV530hzES09u/fLxsbG1WtWtVi+YULF2RlZWV+JUmSRDly5FDHjh115swZi7K+vr5KlixZDNYaUWnRooVFnzk5Ocnb21tHjhyJVLZdu3aysbHR6tWro9zW2bNn1bJlS6VNm1Z2dnbKlCmTGjVqpIMHD5rLWFlZacOGDeafQ0ND1ahRI6VJk0bHjh177+3Dq73Y//Hjx1eqVKnk5eWl+fPny2QymctlzJjR4u/k2evbb7+VFHns29raKkuWLBo+fLjCw8Njq3mIRosWLeTj4yNJCg4OVo4cOdS2bdtI5fr06aNMmTLp3r178vX1lZWVlbJnzx6p3OrVq2VlZaWMGTN+4JrjTT0b2+3bt4/0XseOHWVlZaUWLVpIijyRfSaq4/Tdu3c1YMAAubu7y97eXi4uLqpQoYLWrVvHWI9lH6LPHz58qH79+umzzz6Tvb29UqRIodKlS2vjxo0fqBV42bN+fXa8fWbDhg2ysrIy/xwWFqaJEycqV65csre3l6OjoypXrqx9+/ZZrPdsX25lZSVra2u5urqqQYMGunTpkkW5MmXKRPl7Jalq1aqysrLSkCFD3l9D8Ub8/f3VoUMHpU+fXnZ2dnJxcVGlSpU0YsSIKOdpL7527dr1xv2P2PG6PhwyZIh27dolKysrBQUFRVr/5SDq2Xq///67Rbng4GA5OTmZ/y7w4Vy+fFmtWrVS6tSpZWtrqwwZMqhr164KCAiI7ap90ggzEa158+apc+fO2rNnj65evRrp/Z9++knXrl3T4cOHNXLkSJ08eVJ58uTRzp07Y6G2eB1vb29du3ZN165d086dOxUvXjxVq1bNoszDhw+1YsUK9enTR/Pnz4+0jYMHDyp//vw6ffq0Zs2apRMnTmj9+vVyd3dXz549o/y9Dx8+VI0aNfTnn39q7969ypkz5wdpH17tWf9fuHBBP/zwg8qWLauuXbuqWrVqevLkibncsGHDzH8nz16dO3e22NazsX/mzBkNHTpUI0aMiPLvBR8POzs7LVq0SL6+vtq+fbt5+e+//66JEyfK19dXSZIkkSQlSpRIN2/e1P79+y22MW/ePKVPnz5G643XS5cunVasWKFHjx6Zlz1+/FjLli17p/4KCgpSsWLFtGjRIvXr109///239uzZowYNGqhPnz66c+fO+6w+3sH77vP27dtr3bp1mjp1qk6dOqVt27apbt26nITFMHt7e40ePVqBgYFRvh8eHq6GDRtq2LBh6tq1q06ePKldu3YpXbp0KlOmjMWHyJKUNGlSXbt2TVeuXNHatWv1zz//qF69epG2my5dOvn6+losu3Llinbu3ClXV9f31Ty8hTp16ujQoUNauHChTp8+rU2bNqlMmTLKlSuXxfysfv36FvP7a9euqVixYpLevP8R817sr0mTJpn76tmrV69eb73NdOnSacGCBRbL1q9fr8SJE7+vaiMa58+fV4ECBXTmzBktX75cZ8+e1XfffaedO3eqaNGiun379gf73aGhoR9s20ZAmIko3b9/XytXrlSHDh1UtWrVSJMcSXJycpKLi4syZ86smjVr6qefflLhwoXVunVrhYWFxXyl8UrPPtl1cXGRp6envvrqK12+fFn+/v7mMqtXr5aHh4e++uor7dmzR5cvXza/Fx4erhYtWihr1qz69ddfVbVqVX322Wfy9PTU4MGDo7yCIygoSF5eXrp69ar27t2rTJkyxUhbEdmz/k+TJo3y5cun/v37a+PGjfrhhx8sxneSJEnMfyfPXokSJbLY1rOxnyFDBjVp0kTFixfX33//HcMtwtvKnz+/BgwYoNatWysoKEiPHz9Wy5Yt1blzZ5UuXdpcLl68eGrcuLFFQP3ff/9p165daty4cWxUHa+QL18+pUuXTuvWrTMvW7dundKnT6+8efO+9fb69++vCxcu6I8//lDz5s3l4eEhNzc3ffHFF/Lz8+PE6CPwvvt806ZN6t+/v6pUqaKMGTMqf/786ty5s1q1avU+q43XqFChglxcXDRq1Kgo31+1apXWrFmjRYsWqU2bNsqUKZPy5Mmj2bNnq0aNGmrTpo0ePHhgLm9lZSUXFxe5urqqWLFiat26tQ4cOKC7d+9abLdatWq6deuWxdWdCxcuVMWKFZUyZcoP01hEKygoSL/++qtGjx6tsmXLKkOGDCpUqJD69eunGjVqWMzPEiRIYDG/d3Fxka2traQ373/EvBf7y8HBwdxXz17vcpxt3rx5pA+55s+fr+bNm7/PqiMKHTt2lK2trX788UeVLl1a6dOnV+XKlfXTTz/pypUrGjBggPr376/ChQtHWjdPnjwaNmyY+ee5c+cqe/bssre3l7u7u2bMmGF+79kdcitXrlTp0qVlb2+vpUuXKiAgwHwHZMKECZUrVy4tX748Rtoe2wgzEaVVq1bJ3d1d2bJlU9OmTTV//vzX3lpmbW2trl276uLFi/rrr79iqKZ4F/fv39eSJUuUJUsWOTk5mZfPmzdPTZs2lYODgypXrmwRcvn5+en48ePq2bOnrK0j7zpevk3x+vXr5oBk9+7dcnFx+SBtwbsrV66c8uTJY3FC/LYOHjyov/76K8oDND4+AwYMkIuLi7p06aKBAwfKyspKI0eOjFSuVatWWrVqlR4+fCgp4pZFb29vpUqVKqarjDfQqlUriysy5s+fr5YtW771dkwmk1asWKEmTZooderUkd5PnDix4sWL93/VFe/H++pzKeLEeuvWrbp37977qh7egY2NjUaOHKmpU6fqv//+i/T+smXL5ObmpurVq0d6r2fPngoICNCOHTui3PbNmze1fv162djYyMbGxuI9W1tbNWnSxOLvydfXlzA7liROnFiJEyfWhg0bFBwc/F62+ar+x6chf/78ypgxo9auXStJunTpkvbs2aNmzZrFcs0+bbdv39b27dv15ZdfKkGCBBbvubi4qEmTJlq5cqWaNGmiAwcO6Ny5c+b3jx8/riNHjpgvFFi6dKm+/vprjRgxQidPntTIkSM1aNAgLVy40GK7X331lfnq/EqVKunx48fKnz+/tmzZomPHjqlt27Zq1qyZDhw48OH/AWIZYSai9CzUkiJuT71z545279792vXc3d0lRXxygI/L5s2bzROkJEmSaNOmTVq5cqU5mDxz5ox+//13NWjQQJLUtGlTLViwwBxiP3se6rM+fp2uXbsqJCREO3bs4LmpHzF3d3eL8dq3b1/z38mz16+//mqxTrFixZQ4cWLZ2tqqYMGCql+/vj7//PMYrjneRbx48bRo0SKtXr1aU6dO1aJFi2Rvbx+pXN68eZU5c2atWbNG4eHhnNh+5Jo2baq9e/fq4sWLunjxovbt22c+hr+NW7duKTAw8I3384g976vPJWn27Nn67bff5OTkpIIFC6p79+6RnsGImFGrVi3zHS8vO336dJTPM5ZkXn769Gnzsjt37ihx4sRKlCiRUqVKpV9++UUdO3aMdLeF9PwDrAcPHmjPnj26c+dOpEcRIWbEixdPvr6+WrhwoZIlS6bixYurf//+UT7n/lXepv/xaWjVqpX5rhpfX19VqVJFKVKkiOVafdrOnDmj8PDwV+6bAwMDlSJFCuXJk0fLli0zv7d06VIVLlxYWbJkkSQNHjxY48ePV+3atZUpUybVrl1b3bt316xZsyy22a1bN3MZV1dXpUmTRr169ZKnp6cyZ86szp07y9vbW6tWrfpwDf9IEGYikn/++UcHDhxQo0aNJEUcVBs0aKB58+a9dt1nwdeLDyvHx6Fs2bLy8/OTn5+fDhw4oEqVKqly5cq6ePGipIirOipVqiRnZ2dJUpUqVXTnzh39/PPPkvTWX/pQrVo187M18fEKDw+3GK+9e/c2/508exUoUMBinZUrV8rPz0+HDx/WqlWrtHHjRn311VcxXXW8Iw8PD9WpU0deXl6R+vZFz6782r17tx48eKAqVarEYC3xNlKkSGF+JMyCBQtUtWpV8778bfDlPsbxvvpckkqVKqXz589r586dqlu3ro4fP66SJUvqm2++ec+1xpsYPXq0Fi5cqJMnT0Z6723GaJIkSeTn56eDBw9q/Pjxypcvn0aMGBFl2Tx58ihr1qxas2aN5s+fr2bNmnEVdiyqU6eOrl69qk2bNsnb21u7du1Svnz5onzsV3Tepv/xaWjatKn279+v8+fP8yF0DHuTfXOTJk3MYWZ4eLiWL1+uJk2aSJIePHigc+fOqXXr1hYXlAwfPtziak5JkebuYWFh+uabb5QrVy4lT55ciRMn1vbt2+PEF35xlEIk8+bN05MnTyxuMQsPD5ednZ2mTZv2ynWfTbx4NuLHJ1GiROZPfqSIZ3I4ODhozpw5Gjp0qBYuXKjr169bTF7DwsI0f/58lS9fXm5ubpKkU6dOvdEzuZo1a6YaNWqoVatWCg8PV48ePd5/o/B/O3nypMV4dXZ2tvg7iUq6dOnMZbJnz65z585p0KBBGjJkSJRX+eHjEy9evNeeqDZp0kR9+vTRkCFDOLE1gFatWqlTp06SpOnTp0d6P2nSpFF+eU9QUJAcHBwkRQRkyZIl06lTpz5sZfFevI8+fyZ+/PgqWbKkSpYsqb59+2r48OEaNmyY+vbta34GH2JGqVKlVKlSJfXr18/8zfSS5ObmFmXAKT2ffz+bq0kRj396+VjdoUMHLV68OMpttGrVStOnT9eJEyfixO2JHzt7e3t5eXnJy8tLgwYNUps2bTR48GCLv4lXedv+x8cladKkkiKusH35Dreo9uFSxDPtq1WrptatW+vx48eqXLkyjw/5wLJkySIrKyudPHlStWrVivT+yZMn5ejoqBQpUqhRo0bq27ev/v77bz169EiXL1823xF5//59SdKcOXMiPbrr5UdDvHx19dixYzV58mRNmjRJuXLlUqJEidStWzeFhIS8z6Z+lLgyExaePHmiRYsWafz48RZXZh0+fFipU6d+5cNkTSaTpkyZokyZMr3TA+gRs6ysrGRtba1Hjx6Zn5V16NAhi35fvny51q1bp6CgIHl6esrDw0Pjx4+XyWSKtL2goKBIy5o3by5fX1/16dNH48aNi4FW4W38/PPPOnr0qOrUqfN/bcfGxkZPnjyJEwfNuCR58uSqUaOGdu/ezaf7BuDt7a2QkBCFhoaqUqVKkd7Pli1blF/U9ffff5sDEGtrazVs2FBLly7V1atXI5W9f/++njx58v4rj3fyPvo8Oh4eHnry5IkeP3783uqLN/ftt9/q+++/1/79+83LGjZsqDNnzuj777+PVH78+PFycnKSl5dXtNv86quvtHLlymi/sK9x48Y6evSocubMKQ8Pj/+/EXivPDw8LL7g6W29rv/xccmaNausra0jfQ/F+fPndefOnWj34a1atdKuXbv0+eef83zUGPBsvztjxgyLL1+SIr4/YunSpWrQoIGsrKyUNm1alS5dWkuXLtXSpUvl5eVl/pK1VKlSKXXq1Dp//ryyZMli8XrdRWL79u1TzZo11bRpU+XJk0eZM2e2eOTIp4zLLGBh8+bNCgwMVOvWrSN94lOnTh3NmzdP3t7ekqSAgABdv35dDx8+1LFjxzRp0iQdOHBAW7ZsYef5EQoODtb169clSYGBgZo2bZru37+v6tWra9KkSapatary5MljsY6Hh4e6d++upUuXqmPHjlqwYIEqVKigkiVLasCAAXJ3d9f9+/f1/fff68cff4zyuarNmjWTtbW1mjdvrvDwcPXu3TtG2gtLz/o/LCxMN27c0LZt2zRq1ChVq1bN4nmX9+7dM/+dPJMwYULzJ8TS87H/5MkTHT16VJMnT1bZsmUtyuDjcOfOHfn5+Vkse/FLv17H19dXM2bMeKt1EDtsbGzMV2dFdQzu0KGDpk2bpi5duqhNmzays7PTli1btHz5cotwZMSIEdq1a5cKFy6sESNGqECBAoofP75+/fVXjRo1Sn/++SfPQf5IvK8+L1OmjBo1aqQCBQrIyclJJ06cUP/+/dmvx6JcuXKpSZMmmjJlinlZw4YNtXr1ajVv3lxjx45V+fLldffuXU2fPl2bNm3S6tWrX/k8xHTp0qlWrVr6+uuvtXnz5kjvOzo66tq1a4ofP/4HaRPeTEBAgOrVq6dWrVopd+7cSpIkiQ4ePKgxY8aoZs2a77zd1/U/Pi5JkiRRmzZt1LNnT8WLF0+5cuXS5cuX1bdvXxUpUkTFihWLcj1vb2/5+/uz745B06ZNU7FixVSpUiUNHz5cmTJl0vHjx9W7d2+lSZPG4vEOTZo00eDBgxUSEqKJEydabGfo0KHq0qWLHBwc5O3treDgYB08eFCBgYGvvMPx2SNCfvvtNzk6OmrChAm6ceNGnPhQijATFubNm6cKFSpEeel6nTp1NGbMGN29e1eSVKFCBUkRQUeGDBlUtmxZzZ49+7W3qCJ2bNu2Ta6urpIiDpDu7u5avXq1smfPri1btlg8kPgZa2tr1apVS/PmzVPHjh1VqFAhHTx4UCNGjNAXX3yhW7duydXVVcWKFdOkSZOi/d1NmjSRtbW1mjVrJpPJpL59+36oZiIaz/o/Xrx4cnR0VJ48eTRlyhQ1b97c4tvpv/76a3399dcW67Zr107fffed+ednY9/Gxkaurq6qUqUKz2H6SO3atSvSlfKtW7d+4/UTJEgQ6dsZ8fF61clL5syZtWfPHg0YMEAVKlRQSEiI+Tjw7ENKKeKK3N9//13ffvuthg8frosXL8rR0VG5cuXS2LFjo5wfIPa8jz6vVKmSFi5cqP79++vhw4dKnTq1qlWrFulYgJg1bNgwrVy50vyzlZWVVq1apUmTJmnixIn68ssvZW9vr6JFi2rXrl0qXrz4a7fZvXt3FS1aVAcOHFChQoUivc8HFbEvceLEKly4sCZOnKhz584pNDRU6dKl0xdffKH+/fv/X9t+Xf/j4zJ58mR9++236tu3ry5evCgXFxd5eXlpxIgR0X4/hZWV1Ts/PxnvJmvWrDp48KAGDx6s+vXr6/bt23JxcZGPj48GDx6s5MmTm8vWrVtXnTp1ko2NjXx8fCy206ZNGyVMmFBjx45V7969lShRIuXKlUvdunV75e8fOHCgzp8/r0qVKilhwoRq27atfHx8onzMzKfGKpynvQMAAAAAAAAwAJ6ZCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZuKdBQcHa8iQIQoODo7tqiAG0N9xC/0dt9DfcQv9HbfQ33EL/R230N9xC/0dt9Dfr2YVHh4eHtuVgDHdvXtXDg4OunPnjpImTRrb1cEHRn/HLfR33EJ/xy30d9xCf8ct9HfcQn/HLfR33EJ/vxpXZgIAAAAAAAAwBMJMAAAAAAAAAIYQL7Yr8CkwmUy6evWqkiRJIisrq9iuToy5e/euxX/xaaO/4xb6O26hv+MW+jtuob/jFvo7bqG/4xb6O26Jq/0dHh6ue/fuKXXq1LK2jv76S56Z+R78999/SpcuXWxXAwAAAAAAADC0y5cvK23atNG+z5WZ70GSJEkkSQu/36+EiRLHcm0QI8JNsV0DxKBEyZLEdhUQgx7cuhXbVUBMimcb2zVADErpmjy2q4AYdPNG3LqaJa7L75YqtquAGPTXyf9iuwqIQfETJortKiCGPHxwX4298plztugQZr4Hz24tT5gosRImJvSIEwgz45REjOs4JfzR49iuAmJSPLvYrgFiUOIkfBtoXHL/ATegxSVJ+LbfOCVhIubncYltIsLMuOZ1j3DkC4AAAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMmG1evUgtaxaXTwk3dW9ZU/8c94u27JMnoVo2d7Ja1yolnxJu6tTYWwf377Ios3T2RFUtlNHi1a5euQ/bCLyxzasXqaVPSfmUdFf3VrX0z/HD0ZaN6O8pal27jHxKuqtTkyo6uH+3RZmlcyapauHMFq929St86GbgDa1fOk8NyuWTV660al+vkk4e+fuV5Vf7fqemlYrIK3c61S2dR9NGDlRw8GOLMv43rml4rw6qXthNXrnTqUX1Ujp11O8DtgJvavPaZWpZt4J8ynmq+xcN9M+JI9GWffIkVMsWzFDr+pXkU85TnZrX0sHff7UoExYWpsVzpqhVPS/VKpdXretX0nLfmQoPD//QTcEb2LxmsVr6lJJPqezq3qr26/fn86aqdZ2y8imVXZ2aVo20P5ekWzeva+zgHmpYMb9qlfbQl00q68zJ6P+OEHNW+c5RtaK5VDRLKn1evbyOHfrrleWXzZ2h2qULqFgWF1UplEPjh/RT8GPL/fnbbhMxZ/OqhWpZo7h8irupe4s3mJ/PmazWPiXlU/zp/Py3XdGWX+U7Q1ULZtDs8UPff8XxTubNnql8OdyU1jmpKpUtob8P/vnK8neCgtSnRxflyJJBaZySqLBnDu3Y/oP5/Xw53JQiiV2kV58eXT50U/AGNq9ZrJa1SsuntIe6t67zZsfvumXlU9pDnZpVi/74PaSHGlYqoFqlc+jLJlV05uTRD9kMvKGNKxaoqXdBVSmQUZ0bV9Gpo4eiLfskNFSLv5ugz6sUUZUCGdWubnn9uffn/2ubn5pPPsxs0aKFrKysIr3Onj2rPXv2qHr16kqdOrWsrKy0YcOG2K5urNmz43vNmTRcjdt01ZRFW5Qpq4cGdflcQbdvRVl+0cxx2rZ+mdr3GqqZK39S5dpNNKJPO53755hFuQyZ3bR46wHza8ycNTHRHLzGnh2bNWfySDVu3UVTFn6vTFmya1DX5tH393fjtW3DcrXvOVgzV/yoyrUba0Tf9jr3z3GLchH9/Yf5NWb2qphoDl7j563rNX3U12resZfmrN+pz9xzqFfr+goM8I+y/I7v12r2+OFq3qm3Fm3dp74jJunnrRs0Z8IIc5l7d4LUqVFV2cSPpzFzVmjRlr3q2Heokjg4xFSzEI09O3/QnGmj1bjll5oyb40yZXHXoB5tFRQYEGX5RbOnaNvGVWrfvb9mLv5elX0aaET/Ljp3+oS5zJqlc7V1wwq17z5Q3y3drJYdemjt0nn6fs2SmGoWomHen7fpoikLNylTVncN6tbiFfvzCU/3519r5vLtqlyrsUZ81cFif37v7h31bltf8eLF09CJ8zVz+Xa16dJfiZMwvmPbj5vWacI3A9S2W18t3bpbbh451alZbd2+FfX+/If1qzX126H6oltfrfnlDw0aO1U/fr9e00cPe+dtIubs+fGF+fnizcqUNbsGdW72mvn5UrXv/eL8vG2k+bkknT5+WNvWL1WmrNk/dDPwhtavXa2v+/VRr68GaOfeP5QjZy7Vr1VN/v43oywfEhKiujWr6PLFi5q/eLn2/31UE6bNlGvqNOYyP+7ap2NnL5pfazZtlSTVrFUnRtqE6O35aYvmTBmpxq07a4rvxojjd/eWCrodzXxt1kRt27BC7XsM1sxl21S5ViON+OrLyMfvdg0UL158DZ0wTzOXb1ObLv2UOEnSmGoWorFr20bNGjtETdv31MyV25U5m4f6tW+kwICo9+cLpo3WljWL1bHfCM3bsFvV6n2uId1b6+wLwfTbbvNT88mHmZLk7e2ta9euWbwyZcqkBw8eKE+ePJo+fXpsVzHWrV82V94+DeVVvb7SZ86qTl+NkL19Av34fdRh1C8/rFf9Fh1VsHhZuaZJr6p1m6lAsbJat3SuRTlrGxsld05pfjkkSx4TzcFrrF8+T941G8irer2n/T38aX+vjrL8Lz9sUP3mHZ73d52mKlC0jNYti6K/nVKYX/T3x2HVgu9UrX5TVanTWBmzZFPPoeNkb59AW9cui7L88UMHlDNfIXlVryPXtOlVsERZla9WW6deuJpz2ZwpSuGSWv1GTVX23Pnkmi6DCpYoqzTpM8VUsxCN9St85V29nryq1lb6TFnUqfdg2dvb68fN66Is/8v2TarfrK0KFi0t1zTpVLVWQxUoWkrrVviay5w85qfCJcqpULHSSuWaRiXKVlLeQsX1D5/0x7r1y+dH7M+r1VX6TFnVqe/T/fnmqD88/GXb0/15sWf78yZP9+fzzGXWLJ6lFKlc1X3QGGXLkUcuqdMpX+GSck2bIaaahWgsmTNdtRo1V40GTZXZzV39R02UvX1CbVwZ9QcLR/46oDwFCqtyrXpKnS6DipYup0o16+jY4b/feZuIOeb5eY36Sp/ZTZ36jYwY35uimZ9vXfd0fl5OrmlfmJ8vmWNR7tHDBxr7dVd17j+aDyk+It9Nm6ymLVqpcbPmyuaeXeMmT1eCBAm1bNHCKMsvW+yroMDbWrRijQoXLab0GTKqeIlSypkrt7mMc4oUSpXKxfz6cdtWZcycWcVKlIqpZiEa65fPl3eNF47ffb6RvV0C/bg5mvOxbRtUv3l7FSxWJuL4XbuJChQro3XLXzh+L3l6/B44muP3R2btolmqXKeJvH0aKsNn2dR10BjZJUig7RuWR1n+p81r1KhNFxUuWV6uaTOoeoPmKlSinNYs+u6dt/mpiRNhpp2dnVxcXCxeNjY2qly5soYPH65atWrFdhVjVWhoiM6eOibPgsXNy6ytreVZsLhOHY36VtTQkBDFt7WzWGZrZ68Thy1vhbh6+YKaVSmkVj4lNXZQV928fuX9NwBvxdzfhaLq76gvSw8NCVF8u5f6295eJw4ftFh29fIFNataRK1qldbYr7vR3x+B0JAQnT5+WPmLlTYvs7a2Vv5ipXT80MEo18mRt5BOHz9svhX96uUL+n33Typc+vljA/b9vF3uOT31dZdWqlk0u1r7lNX3qxZ/2MbgtUJDQ3T29Al5FihiXmZtbS3PAkV1KppbE0NDoxjfdnY68UJ4nT2npw7/9buuXLogSTp/5pROHPlbBYqUfO9twJsLDQ3R2X+OybNgMfOyiP15sVfvz6M8fj/fH/zx605lyZ5LI/t3UuPKBdX58+ratmHFh2kE3lhoSIhOHfVToRKW+/NCJUvr6F8Holwnd/5COnnUz3zb+H8XL2jfLztUoqzXO28TMSNivnZUnoVKmJdZW1vLs1CJ6OfnUe7PI8/XZo4ZpILFyylv4RLCxyEkJESHD/2t0mWeP5LL2tpapcqU08EDv0e5zratm1WgUBH17dFFHpnTqWShvJo4drTCwsKi/R1rVixX46YRdy4i9jw/fr98PlZMp469zfHbTicOP38syB+/7lQW95wRx+8qhSKO3xs5fse20NAQnT55RPlemDdbW1srX+GSFv1nsU5IiGxf6m87e3sdO3Tgnbf5qYkX2xUwouDgYAUHB5t/vnv3bizW5v93NyhQprAwJUvubLE8WfIUunzxXJTr5CtSShuWzVXOvIXkmjaDDv+5T/t/2aYwk8lcJltOT3X/epzSZsis27duatncyerTtr5mLN+uhIkSf9A2IXrR97fzK/q7pDYsm6+cni/293bL/s7hqe5fj1Xa9Jl0O8Bfy+ZOUZ92DTRj2Tb6OxbdCbytsLAwOTqlsFju6JRSl86fjXIdr+p1dCcwQJ0aV1N4eLjCnjxRjYYt1Kx9d3OZa5cvauNyX9Vr2V5N23fTqaN+mjK8v+LHjy/vWg0/aJsQvbt3gqIZ3066fPF8lOvkK1RCG1b4Kmee/HJNk16H//pd+3f/pDDT85Ohek2/0MMHD9SuSVVZW9vIZArT5227qmzF6h+0PXi1aPfnjs66fCGa/i5SUhuWz1dOz4JP9+e/af8uy/359auXtHXdUtVq1FoNmnfQ6ZNHNGviMMWLH18VqnJrYmwJuh2gsLAwOaVIabHcyTmlLpw9E+U6lWvVU1BggFrX8Tbvz+s0baVWnXu+8zYRM145X7vwivn50rnKmbdwtPPz3T9u0tlTxzRp4aYPWn+8ndsBtxQWFqYUKVNZLE+ZMqXOnvknynUu/vuv9u7epTr1G2n52o06f/6c+nbvoidPQtW738BI5bdu3qQ7d4LUqGmzD9IGvLnn49vJYnnE+Vg0x+/CJbVhxfyI8+806XX44G/av+tHi/na9auXtXX9MtVq2Orp8fuoZk34RvHi2apC1doftE2I3p3A2zJFeT6WQpf/jfp8rECxMlq7eJZy5S+i1Oky6tAfv2rvzq0yhZneeZufmjgRZm7evFmJEz8PUypXrqzVq6O+fPtNjBo1SkOHxu0HZbfrOVhTRnyl9vXLS1ZWck2TQRWq19OOF25LL1CsrPn/M2XNrmw5PdWyRgn9+tMWVarZIDaqjXfUrsfXmjKyv9o38Hra3+lVoVpd7XjhNogCxcqY/z9T1uzKlsNTLWuW0K87t6hSDfrbSA79sU9LZ01S98GjlT13fl259K+mjhighdPHq3nHiBNgU7hJ2XJ6qm2PiMmym0du/XvmpDauWEiYaTDtuvbTlDFfq32TahHjO3U6VahSSzu2PL8t/deft2nXjs3qPXisMmTKovNnTmn2lFFK7pxSFSr7xF7l8dbadR+kKaP6q33DitHuz8NN4cqSPaead+glSfosWw5dPHdaP6xfTphpMAf3/6oF0yboqxHjldMzvy5fOK9xQ/ppzqQx+qJbn9iuHt6zdj2HRMzP65WLcn7uf/2qZo8fquHTlsjWzj6Wa4v/l8lkknOKlJowdYZsbGyUJ28+Xb96RdMmT4wyzFy6aIHKe1WSi2vqWKgt/l/tug/UlG8HWB6/q9bRjhceKxNuClcW95eO3+dP64cNywgzDebLvsM0cWgvta5ZUrKyUuq0GVWxZkNt504ZszgRZpYtW1YzZ840/5woUaL/a3v9+vVTjx49zD/fvXtX6dKl+7+2GZuSJnOUtY1NpIeJB932j5T0P+Pg6KRB4+YoJPix7t4JklOKVFow7Vu5pE4f7e9JnMRBadJn0rX/LrzP6uMtRd/ft+SY/BX9PXaWQoKDdfdOYER/Tx/9mv5OGtHfly++1/rj7Tg4JpeNjU2kL/sJDLip5M4po1xn3uRRqlijvqrVi/jk/rNsHnr88KHGfd1TzTp0l7W1tZxSpFLGz9ws1suQ2U17tm/+MA3BG0nqkCya8R0gRyfnKNdxcEyuQaOmRYzvu0Fyck6pBTMnyCV1WnOZ+TPGqV6TNipdoYokKeNnbrp5/apWL55DmBmLot2fB9569fF7zMv78zEW+3NH5xRKnzGrxXrpMmbRb7u2v/9G4I0lS+4kGxsbBbz0ZSABt27KOUXU+/OZY0eqSu0GqtXoc0lS1uw59PjRQw3v202tu/R6p20iZrxyvvaO8/Ozp44q6PYtdWlW1byOKSxMxw79oe9XL9SGfWdkY2Pz4RqFaCV3cpaNjY38b96wWH7z5k2lfOlqzWdSubgqfvx4Fn2WNZu7bt64rpCQENna2pqXX750UXt++Vm+S1d+mAbgrTwf35Zf9hMxvqObrzlp0OjvLI/fM8bKJc3zHMLROYXSZ8pisV66jJ/pt184fscmB8fkso7yfMxfjtGcjyVL7qyhk30j9udBgXJK6aK5k0bINW36d97mpyZOPDMzUaJEypIli/nl6ur6f23Pzs5OSZMmtXgZWfz4tsrinlN+f/5mXmYymeR38De558r3ynVt7ezlnNJFYWFP9Nsv21SktFe0ZR89fKBrVy5GG6AgZkTb33/+JvdceV+5rq2d3Qv9vV1FSlWItmxEf1+iv2NZfFtbueXIo7/27zEvM5lM+nv/r8qRt0CU6wQ/fiQra8vDg/XTiXJ4eLgkKWe+Qrr00i0M/104p1RpjPvBzqcgfnxbZXHzkN9fz5+vZTKZ5PfX73LP4fnKdW3t7OScIlXE+N79o4qUfP7crqj/JqxleuHWRcS8+PFtlSVbVPvz/W+3P9+1zWJ/7pE7v65csrzN7crlf5XChat5YlN8W1u55/LUn/t2m5eZTCb9uXePcuUvFOU6jx8/lPXLY9f6+f78XbaJmBExX8slvz/3mZdFjO99bzc///kHFSldUZKUp2BxTV/+o6Yu+cH8ypo9t8p4+2jqkh8IMmORra2t8uTNpz27fzEvM5lM+nX3LypQqEiU6xQqUlT/nj9vcSw+d/aMUrm4WgSZkrR8ySI5p0gpL+8qH6YBeCvm4/fBKM6/c77N+dg2FSn5wvE7V8QdVS+6conjd2yLH99Wbtlz69Afe83LTCaTDv2xVx558r9yXVs7ezmnclXYkyfa+9MWFS1T6f/e5qciTlyZider1biNJgztqazZc8kth6c2rpinx48eyqtaPUnS+ME95JQylVp07CtJOnXskAL8byizm4cCbl7XsjmTZDKZVKdZO/M2504eocIlyyulSxoF3LqppbMnytraRqUr1oiVNuK5Wo1aa8KwXhH97ZFHG1cs0OPHD+VVra4kafyQnnJKkUotOkbcgnbqmJ8C/K8/7++5k6Po75Ev9PcNLZ0z6Wl/80y92Fa/ZXuN6ttZ7jk95Z47n9YsnKVHjx6qcu1GkqQRfToqRSoXte05SJJUrGwlrVowU1k9cskjdz79d+lfzZ88SsXKVjSf6NRr3l4dG1XR4u8mqmzlmjp55JC+X7VYvYaNj7V2IkKthi00YUQ/ZXXPKbfsubRx1SI9fvRIXlUjvuxu/DdfySlFSrVoH3GHwanjhxVw66YyZ3FXwK0bWjZ/ukymcNVp3Nq8zULFy2rloohvyMyQKYvOnT6p9SsXyqsKtyzFtlqNWmnCN72f789XPt2fV326Px/aU04pXNTiy96Snu3PbyizW3YF+N94uj8PV52mbc3b9GnYSr2+qKeVvjNUsnwVnT5xRNs2rFDnr0bEShvxXNMvOmpwjw7Knjuvcnrm17J5M/Xo0QPVqN9EkvR1t3ZK4ZJanb8aLEkqVcFbS+fMULYcuZUzb35dvvCvZo4boVIVvM3789dtE7Hn+fw8t9xy5NHG5fMj5ufVn83Pu0eM704vzM9vXldmtxwK8L+uZbMnRszXPo+YryVMlFgZs2Sz+B32CRIqqYNjpOWIee07dVXndq3lmTe/8uUvoFkzpurhwwdq1CziyuqObVvJxTW1Bg0dLklq2aat5s2eqf59euiLdl/q3LmzmjxujNp06GixXZPJpOVLFqlB46aKF4/T/4+F+fjtnktuOXJr4wpfPX786Pn52NBeEedjz47fx58ev7M+O35PkSn85eN3S/VqW9/y+L1xpTp/NTxW2ojn6nzeTmMGdpWbRx5ly+Wp9Uvm6PGjh6rkE/F4rtH9O8s5lYtadx0gSTp55G/dunlNWdxz6taNa1o0c7xMJpMatOz4xtv81MXpvdn9+/d19uzzK4v+/fdf+fn5KXny5EqfPvrbZz9Fpbyq607gbS2ZPVGBAf7K7JZdwyYvNN/G4n/jiqysn3/rXWhIsBZ/N07Xr1xSggSJVKBYWfUcOlGJkziYywTcvKYxA7vo7p0gOTgmV448BTRh/no5ODpF+v2IWaW8qulO0LP+vhXR35N8X+jvqxZXYUX09wRdv/qsv8uo55AJSpzk+VXJATeva8ygrhH9nexpf89bS39/BMpVqaWg2wGaP2W0bvvfVJbsOTV27krzVbM3r/0n6xfGd7MOPWRlZaV5k0bK/8Z1JUvupGJlK6pN9wHmMtlz59XwaQs1e8JwLZo+Xi5p06tT/+HyqlE3xtsHS6XKV44Y33OnKvD2LWXO4q5h42fJ8emXSPjfuPbS+A7R4jmTdf3qf0qQIKEKFCmlnoNGW4zv9t0HaMmcKZoxfpjuBN5WcueUqlyjvhq17BDj7YMl8/58zqSI/XnW7Bo2cYH5NjX/69dkZfXS/nzWi/vz0uo5eLxFf7t55NbA0TPlO3Osls+fqlSu6dS220CV9a4Z4+2DpYo1aivw9i19N36kAvxvys0jl6YuXmv+Ap/rV/6z6O/WXXrLyspKM8YOl//1a0rm5KxSFbzVsc/AN94mYk+pitV1JyhAS2ZNeDo/99CwKYuez9euX7Uc38HP5ueXI/bnxcuq57BJFvNzfLxq1amngFv+Gj1imG7euK6cufNo5brvzbeZ/3f5skV/p0mbTqvWb9agr3qrdNECck2dWl906KQuPXpZbHf3Lzv13+VLatKseYy2B69WqkJV3QkM0JK5kyLGd1YPDZs4/4X52kvnY8HPjt+XI47fRUur5+BxkY/f386Q78xxWr5g2tPj9wCVrcTxO7aV8a6poMAALZwxRoG3/PVZthwaOXOZeX9+8/oVi/4OCXks32mjde2/S0qQMKEKlSivviOnKnFShzfe5qfOKvzZPYOfqBYtWigoKEgbNmyI9N6uXbtUtmzZSMubN28uX1/fN/4dd+/elYODg1b/fFQJEyf5P2oLwwjn1sq4JHEyxnVcct/f//WF8OmIZxfbNUAMcknDB2xxyfXrd2K7CohBhdxdYrsKiEEHjl2O7SogBtn+n997AuN4cP+efIq56c6dO698pOMnf2Xmq0LJMmXK6BPPcgEAAAAAAIBPRpz4AiAAAAAAAAAAxkeYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCHEi+0KfFJCHkrB5MNxQbwkyWK7CohBTkntYrsKiEH3b4bHdhUQk6xtYrsGiEE21laxXQXEpHD253HJiSt3Y7sKiEnx4sd2DRCDwtmfxxlv2tckbwAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIH32YaWVlpQ0bNrz3sohs87plalnPSz7l86p724b658SRaMs+eRKqZQtmqHUDb/mUz6tOLWrp4B+/WpR5+PCBZk8ZpRZ1K6hW+Xzq2aGJTp88+qGbgTe0aYWvPq9cWNUKZVaXptV06uihaMs+CQ3VklkT1aJaMVUrlFnt61fQn/t+sShz9K/f9XWX5mrklU+VPNPot5+3fegm4C0sXzBbFQvmVL6MKdSoSlkdPXQw2rItaldRTtekkV4dmtY1l4nq/ZyuSTV/xuSYaA5eg/153LJ59SK1rFlcPiXc1L1lTf1z3C/ask+ehGrZ3MlqXauUfEq4qVNjbx3cv8uizNLZE1W1UEaLV7t65T5sI/DGVvjOUeXCuVQoc0o1rVZORw/9FW3Z1nWryjONQ6RXp2b1zGUC/G9qULcO8sqXTUU+c9GXTWrr4vlzMdEUvAHGd9yyfuk8NSiXT16506p9/Uo6eeTvV5ZfvfA7NfUuIq886VS3TB5NGzVQwcGPLcr437im4b07qHphN3nlSacW1Uvp1FG/D9gKvKnNqxaqZY3i8inupu4t3mB8z5ms1j4l5VP86fj+bVe05Vf5zlDVghk0e/zQ919xvJNNKxaoWeVCqlowkzo3qfr68+/vJqh51aKqWjCT2teLfP79ttv81LxVmNmiRQtZWVnJyspKtra2ypIli4YNG6YnT558qPrp2rVrqly58nsvC0t7dv6gOdPGqHGLLzVl7mplypJNg3q2U1BgQJTlF82Zom2bVqt9t/6auXiTKtdsoBH9u+rc6ZPmMlNGf61Df+5Xr4HfavrC9cpXsJgGdG+jW/43YqpZiMau7Rs1e/xQNWnXQ9OXb1NmNw8N+LKJgm7firK87/Qx2rpmib7s+43mrPtFVes207AebXT21DFzmcePHiqzm4c69RsRU83AG/ph41qNGdJfHXp+pdXbf1U2j1xq16i2Am75R1l+8rwl2nX4jPm1YdcfsrGxUaXqtcxlXnx/1+Ez+mbiDFlZWcmrao2Yahaiwf48btmz43vNmTRcjdt01ZRFW5Qpq4cGdfk82v35opnjtG39MrXvNVQzV/6kyrWbaESfdjr3zzGLchkyu2nx1gPm15g5a2KiOXiN7RvXavzQ/mrXo6+Wb9sjN4+c+rJJLd2OZn8+Yc5i/XTotPm15uffZWNjI69qPpKk8PBwdW/VWFcuXdDE+cu0Yvuvck2TTu0b1tSjhw9isGWICuM7bvl563pN//ZrNe/YS3PW7dRn2XKoV5v6CgyIenzv+H6tZo8fruYde2vRln3qO3ySft66QXMmPJ+L37sTpE6NqsomXjyNmbNCi7bsVce+Q5XEwSGmmoVo7PnxhfG9eLMyZc2uQZ2bvWZ8L1X73i+O77aRxrcknT5+WNvWL1WmrNk/dDPwhnZt26hZ44aqabsemrFiuzJn81D/Do0VGBDN+fe00dqyZok6fjVcc9fvUtV6zTS0e2udfeFigrfd5qfmra/M9Pb21rVr13TmzBn17NlTQ4YM0dixYyOVCwkJeS8VdHFxkZ2d3XsvC0vrVy6Ud/W68qpaS+kzZVGnXoNlb2+vH7esi7L8L9u/V/1mX6hg0VJyTZ1OVWs1VIGiJbVuha8kKTj4sfbt3qGWHXoqp2cBpU6bQU1adZRrmvTaumFFDLYMUVm3eI68azdWJZ8GyvCZm7oM/FZ29gm0PZq+2bllrRq27qxCJcvLNW0GVa/fXAVLlNPaRbPMZQqWKKcWnfqqeDk+UPjYLJo1TXWbNFethk31WTZ3fT1mkuwTJND65YujLO/gmFzOKVOZX/t3/yz7BAlVsbqPucyL7zunTKVftm1RoeKllC5DphhqFaLD/jxuWb9srrx9Gsqren2lz5xVnb4aIXv7BPrx+1VRlv/lh/Wq36KjChYvK9c06VW1bjMVKFZW65bOtShnbWOj5M4pzS+HZMljojl4jcVzpqt24+byadBUn7m5a+C3k2SfIKE2rHiz/fnve36x2J9fOn9OR/7+U/1HTVBOz/zKmCWrBnw7UY8fP9IPGwi4YhvjO25Z5fudqtVrqip1GitjlmzqOXSc7O0TaOvaZVGWP37ogHLmKySv6nXkmja9CpYoq/JVa+vU0edXcy6bO0UpXFOr36ipyp47n1zTZlDBEmWVJj3ztdhmHt816it9Zjd16jcyYnxvimZ8b133dHyXk2vaF8b3kjkW5R49fKCxX3dV5/6jlTgJofXHYu3i2apcu7Eq+TRUhs/c1HXg6Kfn38ujLP/TlrVq1Mby/LtQiXJa88L599tu81Pz1mGmnZ2dXFxclCFDBnXo0EEVKlTQpk2b1KJFC/n4+GjEiBFKnTq1smXLJkm6fPmy6tevr2TJkil58uSqWbOmLly4YLHN+fPnK0eOHLKzs5Orq6s6depkfu/FW8dDQkLUqVMnubq6yt7eXhkyZNCoUaOiLCtJR48eVbly5ZQgQQI5OTmpbdu2un//vvn9Z3UeN26cXF1d5eTkpI4dOyo0NPRt/1kMLTQ0RGdPn5Bn/qLmZdbW1vIsUESnjh+Odp34tpbBsa2tvU48PXiGhYXJFBYm25fK2NnZ6cSRuHPp88coNDREZ04eUb7CJc3LrK2tlbdwCZ04EvWtaqEhwbK1e7kv7XX80IEPWlf8/0JDQnTiiJ+KlCxrXmZtba0iJcvo8F9v1n/rli9W5Zp1lDBhoijfv+V/U3t2blftRs3eS53x7tifxy2hoSE6e+qYPAsWNy+ztraWZ8HiFiezFuuERNHfdvY6cfhPi2VXL19QsyqF1MqnpMYO6qqb16+8/wbgrYSGhOjkET8VLlnGvMza2lqFS5TRkb/+jH7FF2xYsViVatZWgqf785CQYEmyuBjA2tpatrZ2OnTg9/dXebw1xnfcEhoSotPHDyt/sdLmZdbW1spftJSO+0X9aKAceQvp9PHD5lvRr16+oN/3/KTCpSqYy+z7ebvcc3rq666tVLNYdrWuVVbfr4r6ww/EnIjxfVSehUqYl1lbW8uzUInox3doiOLbRTW+Lf8+Zo4ZpILFyylv4RLCx+HZ+XfeIi+dfxcpqZPRnn9HvT8/7nfgnbf5qfm/n5mZIEEC81WYO3fu1D///KMdO3Zo8+bNCg0NVaVKlZQkSRL9+uuv2rdvnxInTixvb2/zOjNnzlTHjh3Vtm1bHT16VJs2bVKWLFmi/F1TpkzRpk2btGrVKv3zzz9aunSpMmbMGGXZBw8eqFKlSnJ0dNSff/6p1atX66effrIISiXpl19+0blz5/TLL79o4cKF8vX1la+v7yvbHBwcrLt371q8jOzunSCZwsKULLmTxfJkjk7RXqKcr1BxbVi5UFcuX5TJZNKhP3/T/j0/6fbT2yASJkwk95yeWrHwOwXcuqmwsDD9vP17nTp+2FwGseNu4O2I/nZytlju6JRCgdHcppa/aBmtXTxbVy6el8lk0l/792jfz1t1+9bNmKgy/g+BtwMUFhYmpxQpLJY7pUipWzdff4vw0UMHdebUCdVp8nm0ZTatWqaEiROrQhVuMY9t7M/jlrtBgU/723J/nix5imhvS8xXpJQ2LJurK5f+jejvP37V/l+2WdymnC2np7p/PU7DJi9Ux77Ddf3qZfVpW18PH9yPcpuIGeb9uXNKi+VOKVK80SMfjh76S2dPnVCtRs3NyzJmcZNrmnSaMmqo7gYFKjQkRAumT9SNa1d06+b1994GvDnGd9xyJ/C2wsLC5OhkOV9zdE4Z7Xzbq3odtezcV52aVFO5nK5q5FVQnoWKq1n77uYy1y5f1MblvkqbIbPGzl2pmg1basqI/tq2njsrYlP049v51eN7aVTj+/nfx+4fN+nsqWNq0bHPB60/3s6z8+9I49vJOdrHxBQoVlrrLM6/d0ecf/vffOdtfmriveuK4eHh2rlzp7Zv367OnTvL399fiRIl0ty5c2VraytJWrJkiUwmk+bOnSsrKytJ0oIFC5QsWTLt2rVLFStW1PDhw9WzZ0917drVvO2CBQtG+TsvXbqkrFmzqkSJErKyslKGDBmird+yZcv0+PFjLVq0SIkSRXz6PG3aNFWvXl2jR49WqlSpJEmOjo6aNm2abGxs5O7urqpVq2rnzp364osvot32qFGjNHRo3H6Qbrsu/TRlzGC1b1pNsrKSa+p0qlDFRzu2rDeX6TVwlCaNGqTPa5WVtY2NsrhlV6nyVXT29IlYrDneRYc+wzRpWG+1qVVasrJS6rQZVLFGA23fuDK2q4YPbN2yxcqaPYdy5S0QbZn1yxerWu36srO3j8Ga4X1hfx63tOs5WFNGfKX29ctH9HeaDKpQvZ52vHDbaoFiz6/kzpQ1u7Ll9FTLGiX0609bVKlmg9ioNt6DDcsXPd2f5zcvix8/vsbPXawhPTurVI6MsrGxUeGSZVS8nJcUHh6LtcW7YHzHLYf+2Kelsyep+9ejlT13fl259K+mjhyghTPGq/mXPSVJpnCTsuXwVNseAyVJbh659e+Zk9q4YqG8azWMzerjLbXrOSRifNcrF+X49r9+VbPHD9XwaUtka8ec3Og69PlGE4f1UmufUs/Pv2s20PYNnH8/89Zh5ubNm5U4cWKFhobKZDKpcePGGjJkiDp27KhcuXKZg0xJOnz4sM6ePaskSZJYbOPx48c6d+6cbt68qatXr6p8+fJv9LtbtGghLy8vZcuWTd7e3qpWrZoqVqwYZdmTJ08qT5485iBTkooXLy6TyaR//vnHHGbmyJFDNjY25jKurq46evTV39Dar18/9ejRw/zz3bt3lS5dujdqw8coqUMyWdvYKOi25ZdDBAUGyPGlq/eecXBMrkGjpiokOFh37wbJyTmlFnw3QS6p05rLuKZJr9HTFurxo4d6+OCBkjun0LeDe8rFNW2U20TMSOqYPKK/X7pKKzDAX47OKaJcJ1lyJw2ZNF8hwY91NyhQTildNG/ySLmkSR8TVcb/wTG5k2xsbBTgb/kJXYD/TTmnTPXKdR8+fKAfNq5Vx979oy3z1++/6d9zZzR2lu/7qC7+T+zP45akyRyf9rfl/jzotn+kT+qfcXB00qBxcyL253eC5JQilRZM+1YuqaPfnydO4qA06TPp2n8X3mf18ZbM+/OXrtIK8PeXc4pX788fPXyg7ZvWqUOvyPtzj9x5tWrHXt27e0ehoaFK7uSsptXKySN33vdaf7wdxnfc4uCYXDY2NpGuygu8dVPJX7oa+5l5U0apYo36qlYv4jE/n2Xz0ONHDzXu655q1r67rK2t5ZQilTJmcbNYL8Nnbtrz4+YP0xC8kejH9613Ht9nTx1V0O1b6tKsqnkdU1iYjh36Q9+vXqgN+85Y5B6IOc/OvyON74BbSv6K8++hkxZYnn9PGiHXp+ff77LNT81b32ZetmxZ+fn56cyZM3r06JEWLlxoDgxfDA4l6f79+8qfP7/8/PwsXqdPn1bjxo2VIEGCt/rd+fLl07///qtvvvlGjx49Uv369VW3bt23bYKF+PHjW/xsZWUlk8n0ynXs7OyUNGlSi5eRxY9vqyxuHvL76/mzkUwmk/z++kPuOfK8cl1bOzs5p0ilsLAn+m33DhUpUS5SGfsECZXcOYXu3bujvw/ss3h2H2Je/Pi2ypo9tw4d2GteZjKZ5Hdgrzxy53/FmhHP6XBO5aqwJ0+0d+dWFS0T9YcJ+HjEt7WVR25P/bF3l3mZyWTSH3t3K0/+Qq9c98fvNygkJFjV60R/pca65YvkkTuv3HPkel9Vxv+B/XncEj++rbK455Tfn7+Zl5lMJvkd/E3uufK9cl1bO3s5p3SJ6O9ftqlIaa9oyz56+EDXrlyM9oQaMSO+ra2y5/bUgb27zctMJpMO7N2t3PmjvqvpmWf786q1o9+fJ0nqoOROzrp4/pxOHD6kMpWqvLe64+0xvuOW+La2csuRR3/t32NeZjKZ9PfvvyqHZ9R3xwQ/eiQra8vTeWvriLAq/OmV1TnzFtKlf89alPnvwjmlSm3cC3E+BRHjO5f8/txnXmYymeT35763G98//6AipSPOx/IULK7py3/U1CU/mF9Zs+dWGW8fTV3yA0FmLHp2/u33x0vn33/sVfa3Pf8uW+n/3uan4q2vzEyUKFG0z7R8Wb58+bRy5UqlTJky2sAvY8aM2rlzp8qWfbMToqRJk6pBgwZq0KCB6tatK29vb92+fVvJk1t+C1/27Nnl6+urBw8emEPWffv2ydra2vzlRHiuVoPmmjCyv7K655Bb9lzauHqxHj96JK8qtSRJ44f3k5NzSrV4+gyWU8ePKODWDWXO6q4A/5taNn+6TKZw1WncyrzNv/7Yq3CFK226TLp25ZLmzRintOkzmbeJ2FO72RcaN6i73DxyK1vOvFq/dI4eP3qkik9vLxozsIucU7qqVZd+kqRTR//WrZvX9Vm2HLp187qWfDde4SaT6rf40rzNRw8f6Oqlf80/X79ySedOHVMSB0eldE0Tsw2Ehc/bddKAru2VI09e5fQsoCVzZujRw4fyadhUktSvc1uldEmt7gOGWKy3btkilfOuGun5i8/cv3dXP36/Qb0Gj/jQTcBbYH8et9Rq3EYThvZU1uy55JbDUxtXzNPjRw/lVa2eJGn84B5ySplKLTr2lSSdOnZIAf43lNnNQwE3r2vZnEkymUyq06ydeZtzJ49Q4ZLlldIljQJu3dTS2RNlbW2j0hV5Lm5sa/ZFRw3q3kEeufMqZ978Wjpnhh49eqCaDSL25wO7tFNKV1d16TfEYr0NKxarbKWqSpY88rdW//j9ejk6Ocs1TVqdOXVCY77+SmW9q6pY6Te7cwofDuM7bqnfor1GfdVZ7jk95Z47n9YsnKVHjx6qcu1GkqQRfTsqRUoXte05SJJUrGwlrfKdqazZc8kjTz79d/FfzZ8ySsXKVjQHV/VatFfHRlW0+LuJKlu5pk4eOaTvVy1Wr2HjY62diPB8fOeWW4482rh8fsT4rv5sfHeXUwoXtej0wvi+eV2Z3XIowP+6ls2eGDG+P48Y3wkTJVbGLJY5h32ChErq4BhpOWJenWZtNXZQN2XNkUfuOfNq3ZI5evzooSr5RDzuYcyALnJK6aLWXSPuoDh55G8F3Lyuz9wjzr8Xzxwv00vn36/b5qfunZ+Z+SaaNGmisWPHqmbNmho2bJjSpk2rixcvat26derTp4/Spk2rIUOGqH379kqZMqUqV66se/fuad++fercuXOk7U2YMEGurq7KmzevrK2ttXr1arm4uChZsmRR/u7BgwerefPmGjJkiPz9/dW5c2c1a9bMfIs5nitVvrLuBN3WknnTFHj7ljJncdewcbPk+PShxP43rpmfeypFfLv14jlTdP3af0qQIKEKFCmlnoO+VeIkz0Prhw/uy3fWJN3yv64kSRxUvIyXPv+iq+LFix/p9yNmlalUU3cCb2vRzHEKvOWvzNlyaMSMJebbGvyvXZW11fNPekOCg7Vw+hhd+++SEiRMqIIlyqnP8ClKnNTBXOb08cPq80U988+zxkc8V9arej31+mZSzDQMUapcs44CA25p2piRuuV/Q+45cum7ZWvlnCLiKoxrV/6T9Uuf7P979oz+PrBfs1dsiHa7P2xYq/DwcFWp9f9dIY/3i/153FLKq7ruBN7WktkTFRjgr8xu2TVs8sLn+/MbV2Rl/VJ/fzdO169cUoIEiVSgWFn1HDpRiZM8358H3LymMQO76O6dIDk4JleOPAU0Yf56OThG/cEGYk6lmnUUeDtAM8dF7M+z5cilGUvWyenZ/vzqf5Gu1Lpw9owOHdivmcvXR7VJ3bp5Q+OHDlDArZtKkdJF1eo2VNtufHnEx4DxHbeUq1JLQbcDNH/qaN32v6ks2XNq7JyV5qtmb179T9YvHL+bdeghKysrzZs8Uv43ritZcicVK1tRbboNMJfJniuvhk9dqNkThmvRjPFySZtenfoNl1d15m6xrVTF6roTFKAlsyY8Hd8eGjZl0fPxff2qrF44HwsNfja+L0fM14qXVc9hkyzGNz5eZbxr6k5ggBbNGPvC+fdSc3/fvH7F4vgdGhIs3+mjzeffhUqUV98Rluffr9vmp84qPPzNn+7dokULBQUFacOGDW/83vXr19W3b19t3bpV9+7dU5o0aVS+fHmNGzfOfLXmrFmzNHHiRJ0/f17Ozs6qW7eupkyZElFBKyutX79ePj4+mjNnjmbMmKEzZyKe91CwYEGNHTtWefPmjVRWko4ePaquXbtq//79SpgwoerUqaMJEyYoceLE0da5W7du8vPz065du970n0V3796Vg4ODVm/7QwkTJX7j9WBc8ZIki+0qIAalSZXk9YXwybh49nJsVwExyS7R68vgk5EmjWNsVwEx6MqVwNiuAmJQ4qTsz+OS+/cexnYVEIPi2/IBelzx4P491SqeTXfu3HnlIx3fKsxE1Agz4x7CzLiFMDNuIcyMYwgz4xTCzLiFMDNuIcyMWwgz4xbCzLjjTcPMt/4CIAAAAAAAAACIDYSZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGEK82K7Ap8QmsYPiJU4S29VADHhyJyC2q4AYdPHhg9iuAmKSFZ/zxSlPQmK7BohBoU9MsV0FxCArG5vYrgJiUPGszrFdBcSg7b+djO0qICbZJYvtGiCmWL1ZMc7YAAAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMyVZWVlpw4YNkqQLFy7IyspKfn5+sVqn2LBpha8+r1xY1QplVpem1XTq6KFoyz4JDdWSWRPVoloxVSuUWe3rV9Cf+36xKHP0r9/1dZfmauSVT5U80+i3n7d96CbgDR07fFBDv+qkZrXLq2rp3Nr/68+vXefIoT/VpU191ayQX20aV9WOHzZGKrN5/Qq1bOAtH68C6t6+sf45efRDVB/vYPPaJWpZu6x8yuRU9zZ19c+Jw9GWffIkVMvmT1PruuXlUyanOn1eXQd/32NRpmXtsqpazC3Sa8a4IR+4JXgTm9cuVcu65eVTLo+6f9FA/5w4Em3ZJ09CtWzBdLWuX1E+5fKoU3MfHfz9V4syYWFhWjxnslrVq6Ba5TzVun5FLfedofDw8A/dFLwBxnfcsmrhHNUonlvF3VzUomYFHff765Xll82bqTplC6qEm6uqFsmhCcP6K/jxY/P7f/+xT91bNVTlgtlVMIOjdm3f8qGbgLfw/SpftahWVDWLZlG3z6vrn2Ovnp8vmz1JrWoUV82iWdSxYUUd/M1yfr5l9SJ92cBLdUplV51S2dWjRc1Ic3jEnhkzpuuzzBmVKKG9ihYtrAMHDkRbdqGvr+LZWFm8EiW0tyjTqmWLSGWqVPb+0M3AG9q8bpla1qsgn/Ke6t72TeZrM9S6QSX5lPdUpxa1dPAPy/naw4cPNHvKKLWoW161yudVzw6NdZrzsY/GphUL1My7kKoWyKTOjau+Pm/5boKaVymqqgUyqX3dCvpzb+R99dts81MT62FmixYtZGVlJSsrK8WPH1+ZMmVSnz599PiFSRY+vF3bN2r2+KFq0q6Hpi/fpsxuHhrwZRMF3b4VZXnf6WO0dc0Sfdn3G81Z94uq1m2mYT3a6OypY+Yyjx89VGY3D3XqNyKmmoE39PjRI2XKkk0duvV/o/LXr/2nIV91VO68hTR17mrVrNtUU8YO0V8H9pnL7Pl5m+ZMH6vGzdtrypyVyvRZNg3q1V5BgQEfqhl4Q3t+2qI5U0apcatOmrJggzJlcdeg7q0VdDvqvlk0a5K2bVih9j0GaebSrars00gjvuqoc/+cMJeZNG+tFn+/z/waPnmBJKlEucox0iZEb8/OrZozbbQat+yoKfPWKlOWbBrU44tox+Ki2ZO1beMqte8+QDMXb1ZlnwYa0b+zzp1+3t9rls7V1g0r1L77QH23dItaduiptUvn6fs1S2KqWYgG4ztu+fH7dZo0fKDadO2rxZt3KWv2nOrcrI5u3/KPsvy2Das1ffRQfdG1j1bt/EODxkzVju/Xa8aYb8xlHj18KLfsOdXnm7Ex1Qy8od0/btKcCd+ocdtumrp0qzK7eWhQp2bRzs8XzRyrH9YtUYc+3+i71TtVpU5TDe/1hc69MD93TuWqlp37acqSrZq8eIvyFCymb3q01sVz/8RUsxCNVStXqlfPHho0aLD+PPi38uTOoyqVK+nmzZvRrpM0aVL9d+Wa+XX+34uRylSq5G1RZumy5R+yGXhDe3b+EDFfa/GlpsxdE3H87tk2+vnanCnatmmV2nfrr5mLv1flmg00on8Xi/nalNGDdOjP39Rr4GhNX7hB+QoW04DurXXL/0ZMNQvR2LVto2aNHaqm7XtoxsrtypzNQ/3bN1ZgQDR5y7TR2rJmiTr2G665G3apar1mGtq9tc6+EE6/7TY/NbEeZkqSt7e3rl27pvPnz2vixImaNWuWBg8eHNvVilPWLZ4j79qNVcmngTJ85qYuA7+VnX0Cbd+wIsryO7esVcPWnVWoZHm5ps2g6vWbq2CJclq7aJa5TMES5dSiU18V5+Tno1OgSEl93qazipUq/0blt25cLRfXNGrTsZfSZ8ys6rUbqURpL21YvdhcZv2qRfKuVkdeVXyUPuNn6tRzkOztE+jHrRs+UCvwptavWCDvGvXlVa2O0mfKok59hsnezl4/bl4TZflftm9U/ebtVbBYGbmmSa+qtRurQLHSWrd8vrmMg2NyJXdKYX79uW+XXNOkV668hWKqWYjG+hUL5V29nryq1o7o795DZG9vrx83r4uy/C/bN6l+s7YqWLS0XNOkU9VajVSgaCmtW+FrLnPy2CEVLlFOhYqVUSrXNCpRtpLyFirO1dcfAcZ33LJs7gz5NPxcNeo3UWY3d/UbOUH2CRJq06qoP1g48tcB5c5fWN4+9ZQ6XXoVKVVOFWvU0fHDz6/mLF7WSx16D1RZ72ox1Qy8ofVL5si7ViNVrNFA6TO7qVP/UbKzt9ePG1dGWf7nLWtVv1UnFSxRTq5pM6hqvc9VoHg5rVsy21ymcCkvFSxRTmnSZ1LaDJnVvGNf2SdMGKeu5vlYTZw0QW3afKEWLVvKw8NDM2Z+p4QJE2rBgvnRrmNlZSUXFxfzK1WqVJHK2NnZWZRxdHT8kM3AG1q/0tdyvtZrcMR8bcsbzNdSp1PVWg0t5mvBwY+1b/cOtezQSzk9Cyh12gxq0qqTXNOk19ZozukRc9Yumq3KdRqrkk9DZfjMTV0HjZZdggTaviHqDxd+2rxWjdq8kLc0aK5CJcppzQt5y9tu81PzUYSZz3aw6dKlk4+PjypUqKAdO3ZIkkwmk0aNGqVMmTIpQYIEypMnj9assZygHz9+XNWqVVPSpEmVJEkSlSxZUufOnZMk/fnnn/Ly8pKzs7McHBxUunRp/f333zHexo9ZaGiIzpw8onyFS5qXWVtbK2/hEjpxJOpbl0JDgmVrZ2exzM7OXscPRX8rBIzr1PHD8sxfxGJZvoLFdOp4xK0QoaGhOnv6pEUZa2treeYvrFPHo7/dER9eaGiIzv5zXJ4FipmXWVtby7NgMZ065hf1OiEhim9rOb5tbe2j3x+EhuiX7RvlVa2OrKys3lvd8fZCQ0N09vRxeRYoal5mbW0tzwJFdeq4X7TrxH9pf25rZ9nf2XPm1eG/fteVS/9Kks6fOaUTR/5WgSIlhdjD+I5bQkNCdOqonwqVKGNeZm1trUIlSuvo339GuU7u/IV06pif+Vb0/y5d0G+/7FDxsl4xUWX8H0JDQ3T21FF5FiphXmZtbS3PQiV16mj049XW1vI2Yzs7ex33i/rvIywsTLu3b9TjR4+UPXe+91d5vLWQkBD9/ddfKl++gnmZtbW1ypevoN/37492vfv37ytzpgzKmCGdavnU1PHjxyOV2b17l1xdUsojezZ1/LKDAgK4ayq2RczXTkQ+d3rdfC3S8dtOJ45GZBthYWEyhYXJ1tbWooydnb1OHCH/iE3P8pa8RV7OW0rq5OHo8pYo+tv+ed7yLtv81MSL7Qq87NixY/rtt9+UIUMGSdKoUaO0ZMkSfffdd8qaNav27Nmjpk2bKkWKFCpdurSuXLmiUqVKqUyZMvr555+VNGlS7du3T0+ePJEk3bt3T82bN9fUqVMVHh6u8ePHq0qVKjpz5oySJEnyTnUMDg5WcHCw+ee7d+/+/w2PRXcDb8sUFqZkTs4Wyx2dUujyhXNRrpO/aBmtXTxbufIVlmu6jDr0x17t+3mrTGGmmKgyYljg7QAlc3SyWJYsuZMePriv4ODHun/vbsTf0MtlHJ10+Wn4gdhxNygwom+SW47vZMmddfni+SjXyVe4hDasWKCcngXlmia9Dh/cr/27f1SYKSzK8r/v+Un3799ThSq133v98Xbu3gl62t+Rx+vli1GPxXyFSmjDCl/lzFMgor//2q/9u3dY9He9pl/o4YP7atekqqytbWQyhenztt1UtmL1D9oevBrjO24JCgxQWFiYkjunsFie3DmFLpw7E+U63j71FBR4W23qVlZ4eLjCnjxRnaYt1bJTz5ioMv4Pd4Mi5ueOTpb9nczJWZcvnI1ynXxFSmv90jnKma+wXNNmkN+Bvfrt5x8UZrKcn/975qR6tvRRSEiwEiRIpEHj5ih9ZrcP1ha83q1btxQWFqaUL11ZmTJVKp3651SU67hly6a5c+crV+7cunPnjiaMH6eSJYrpyNHjSps2raSIW8xr1aqtjJky6fy5cxo4sL+qVq2sffv2y8bG5oO3C1F7Pl976fjt6BT98btQCW1Y6aucefI/na/9rv17fjIfvxMmTCT3nJ5asfA7pcv4mZI5Omn3T1t06rifXNOk/+BtQvSe5S0v788dnZx1+d+o9+cFipXWusWzlTt/kad5y6/at/N53vIu2/zUfBRh5ubNm5U4cWI9efJEwcHBsra21rRp0xQcHKyRI0fqp59+UtGiEVeZZM6cWXv37tWsWbNUunRpTZ8+XQ4ODlqxYoXix48vSXJze34wLleunMXvmj17tpIlS6bdu3erWrV3u51m1KhRGjp06Du29tPQoc8wTRrWW21qlZasrJQ6bQZVrNFA26O57QWAcbTrNlBTvh2g9o28JSsruaZJrwpVa2vH5rVRlv/x+zUqUKSUnFJEvrUJH792Xftrypiv1b5J1Yj+Tp1OFarU0o4XbnP69ecftGvHZvUePFYZMmXV+TMnNXvKKCV3TqkKlX1ir/J4a4zvuOWv/Xu1YPoE9f1mnHLmza/LF/7V+KFfae7ksWrTtXdsVw/vWfveQzX5mz5qV6dMxPhOm0EVatTXjk2W8/O0GT/TtOXb9OD+Pe39aavGD+6uMXNWE2gaTNGiRc3nyJJUrFgx5cyRXbNnz9KwYRHPxW3QsKH5/Vy5cilX7txyy/qZdu3apfLl3+xxU/g4tOvSL2K+1rRatPO1XgO/1aRRA/V5rTKytrFRFjcPlSpfRWdfeK4mjKFD3280cWgvta5Z6nneUrOBtm8gb3nmowgzy5Ytq5kzZ+rBgweaOHGi4sWLpzp16uj48eN6+PChvLwsb4UJCQlR3rx5JUl+fn4qWbKkOch82Y0bNzRw4EDt2rVLN2/eVFhYmB4+fKhLly69c3379eunHj16mH++e/eu0qVL987bi21JHZPL2sZGQS89KDYwwF+OL336/0yy5E4aMmm+QoIf625QoJxSumje5JFy4VOfT5JjcqdID6MOuh2ghIkSy87OXtbWNhF/Qy+XCQyQ40ufOCJmJU3mGNE3L31ZQNDtW3JMHvX4dnBMrkGjZyokOFh37wbKyTmVFswYJ5c0kfdzN69dkd/B39R/5LQPUn+8naQOyZ72d+Tx6ugU9Vh0cEyuQaOmPe3vIDk5p9SCmePlkjqtucz8GeNUr0kbla5QVZKU8TM33bx+VasXzybMjEWM77glmaOTbGxsIn3Zz+1b/nJKkTLKdb4bP0JVatWXT6PPJUlZ3HPo0cMHGtmvu1p17ilr64/iiVOIQtJkEfPzwADL/g4KuBXp6txnHByd9PWEeRHz8zuBckrhogVTR8klTQaLcvHj2yp1ukySpKzZc+vMicPauHy+Og/49sM0Bq/l7OwsGxsb3bxh+UUtN2/ckEsqlzfaRvz48eXpmVfnzkZ/VVbmzJnl7Oysc2fPEmbGoufztZeO34FvOV/7boLFfM01TXqNnrZIjx891MMHD5TcOYW+HdxDLq5po9wmYsazvOXl/XngK/bnyZI7aejkBZZ5y6QRck2b/p23+an5KGYwiRIlUpYsWZQnTx7Nnz9ff/zxh+bNm6f79+9LkrZs2SI/Pz/z68SJE+bnZiZIkOCV227evLn8/Pw0efJk/fbbb/Lz85OTk5NCQkLeub52dnZKmjSpxcvI4se3VdbsuXXowF7zMpPJJL8De+WRO/8r17W1s5dzKleFPXmivTu3qmiZih+6uogF7jnyyO+vPyyWHTq4X+45ckuKmDxlcctuUcZkMsnv7z/kniNPjNYVluLHt1WWbDnk99fz5y2ZTCb5Hdwv95yer1zX1s5OzilcFBb2RL/t2q4iJSNPendsWSsHRycVKlbmPdcc7yJ+fFtlccshv79+Ny8zmUzy++t3uefwfOW6Ef2dKqK/d++w6O/gx49k9VLoYW1jI5OJR4vEJsZ33BLf1lbuuTz1577d5mUmk0l/7tujXPkKRrnO40ePIgWWz24tDQ8P/3CVxf8tfnxbZXHPpcN/7jMvM5lM8vtzr9xzvcH8PGXE/Hzfzq0qUvrVz0g1mUwKDQl+ZRl8WLa2tsqXP79+/nmneZnJZNLPP+9UkReuvnyVsLAwHTt2VC6urtGW+e+//xQQECDXV5TBhxcxX/N4D/O1H1WkRLlIZewTJFRy5xS6d++O/j6wT0VKRi6DmPMsb/H746W85Y+9yp7nLfKWn7aqaJlK//c2PxUfxZWZL7K2tlb//v3Vo0cPnT59WnZ2drp06ZJKly4dZfncuXNr4cKFCg0NjfLqzH379mnGjBmqUqWKJOny5cu6dStufFX926jd7AuNG9Rdbh65lS1nXq1fOkePHz1SxZoNJEljBnaRc0pXterST5J06ujfunXzuj7LlkO3bl7Xku/GK9xkUv0WX5q3+ejhA1194XmJ169c0rlTx5TEwVEpXdPEbANh4dHDh7p65fnVydevXdG5M6eUJKmDUqZyle/syQrwv6GeA0ZKkqrUrKfN65dr/swJ8qpSS4f//kO/7vpRQ759frVOrfqfa8Kogcrq7iE391zauGaJHj96JC+u2op1tRq21IThfZXVPafcPHJr48qFevz4kbyq1ZEkjR/WW04pUqlFh16SIr7wKcD/ujJnza4A/xtaNm+qTOEm1WnyhcV2TSaTdmxZp/KVfWQT76M7nMRZtRo214QR/SL6O3subVy1KGIsVq0lSRr/Td+I/m4fcYfBqeOHFXDrhjJnya6AWze0bP50mUwm1Wnc2rzNQsXLauWiWUqRylUZMmXVudMntH6lr7x4jmKsY3zHLY3bfKmhPb9U9tx5lSNPPi2fP1OPHj5Q9XpNJEmDu7dXChdXdeo7WJJUsoK3ls2doWw5ciuHZwH9d/G8vhs/UiUreJtDzYcP7uvyhefztauXL+qf40flkCxZlFfsIubUavqFJgzuoazZc8stp6c2Lpun4EeP5FWjviRp3Nfd5JTCRS07fyVJOnX0UMT4dvNQgP91LZ01UeHh4arbvIN5mwumfqsCxcsopUsaPXxwX7u2bdTRv/brm2lLYqWNeK57tx5q2bK58ucvoIKFCmnK5El68OCBWrRoKUlq0fxzpU6TRiNHjpIkffPNMBUuXERZsmRRUFCQxo8bq4sXL6p16zaSIr4caNiwoapdu45cXFx07tw59fuqj7JkyaKKlSrFWjsRoVaDFpow8oX52uqn87UqT+drw7+Sk3PKl+ZrN5U5q3vE8Xv+dJlM4Rbztb/+2KtwhSttuky6duWS5s0Yq7TpM5m3idhT5/O2Gjuwm7J65JF7rrxat2SOHj96qEo+EY+CGNO/i5xSuah11/6SpJNH/lbAzev6zD2Hbt24rsUzx8tkMql+yy/feJufuo9ydlqvXj317t1bs2bNUq9evdS9e3eZTCaVKFFCd+7c0b59+5Q0aVI1b95cnTp10tSpU9WwYUP169dPDg4O+v3331WoUCFly5ZNWbNm1eLFi1WgQAHdvXtXvXv3fu3VnHFRmUo1dSfwthbNHKfAW/7KnC2HRsxYYn6grP+1q7K2ev7JfkhwsBZOH6Nr/11SgoQJVbBEOfUZPkWJkzqYy5w+flh9vqhn/nnW+IjnjHpVr6de30yKmYYhSmf+Oa5+3Z4f+OZOHytJKu9dQz36DdftAH/537xuft/FNa2GfDtdc6aN1ca1S+WcIpW69B6i/IWKm8uUKuetO0GBWjJ/hgJv31LmLNk0bOxMOb70RSSIeaUqVNWdoNtaMmeKAm/7K3PW7Bo2YZ75EQD+N65ZXHUXGhKsxbMn6frVy0qQIKEKFC2tnl+PVeIklleh+/35m/xvXFXFanVjtD14tVLlq0SMxblTno7F7Bo2fvar+3vOlOf9XaSUeg4abdHf7bsP1JI5kzVj/DDdCbyt5M4pVblGfTV6YUKF2MH4jlsqVq+toIBbmjVhpAL8b8rNI5emLFpjvs38+tX/LPq7VedesrKy0sxxI+R//ZqSOTmpZHlvfdl7kLnMySN+at/w+Zd5TfxmgCSpat1GGjJ+Rgy1DFEpXbGG7gbe1uLvxiswwF+Z3Tw0bOri5/Pz61dkbWVlLh8a8liLZozV9SuXIsZ3iXLq9c0kJU7yfH5+J/CWxn/dXbdv3VSixEmUKWt2fTNtifIVKRXj7YOl+g0ayP+Wv4YM+VrXr19XHk9Pbdm6TamefinQpcuXLK60DgwMVPt2X+j69etydHRUvnz59eve3+Th4SEp4irso0eOaPGihQoKClLq1Knl5VVRQ4d9Izs7uyjrgJhTqnzliOP3vKlP52vuGjZuluXx2+rF43eIFs+ZrOvX/ot2vvbwwT35zpqkW/7XlSSJg4qXqajPv+iqePGifiQfYk4Z75q6ExigRTPGPs9bZi41789vXr8Sab7mO220OW8pVKK8+o60zFtet81PnVV4LN9j0qJFCwUFBWnDhg0Wy7/99ltNmDBB//77r+bOnauZM2fq/PnzSpYsmfLly6f+/furVKmIg+6RI0fUu3dv7d27VzY2NvL09JSvr68yZ86sQ4cOqW3btjp27JjSpUunkSNHqlevXurWrZu6desmSbKystL69evl4+OjCxcuKFOmTDp06JA8PT3fqA13796Vg4OD1u09pUSJ3+0b0mEsT+4EvL4QPh3x7WO7BohJ0XyrMz5R1nyba1ySMk3cmOAjgv+t+7FdBcSgip48FzAu2f7bydiuAmJQfIdksV0FxJAH9++pVrFsunPnzisf6RjrYeangDAz7iHMjGMIM+MWwsy4hTAzTiHMjFsIM+MWwsy4hTAzbiHMjDveNMz8KL4ACAAAAAAAAABehzATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAhEGYCAAAAAAAAMATCTAAAAAAAAACGQJgJAAAAAAAAwBAIMwEAAAAAAAAYAmEmAAAAAAAAAEMgzAQAAAAAAABgCISZAAAAAAAAAAyBMBMAAAAAAACAIRBmAgAAAAAAADAEwkwAAAAAAAAAhkCYCQAAAAAAAMAQCDMBAAAAAAAAGAJhJgAAAAAAAABDIMwEAAAAAAAAYAiEmQAAAAAAAAAMgTATAAAAAAAAgCEQZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABhCvNiuwKcgPDxckvTwwf1YrgliShh9HbfEfxLbNUBMMoXFdg0Qk6xtYrsGiEH379nFdhUQgx7efxDbVUAMunv3bmxXATGIc++4JZ4N87W44tnYfpazRYcw8z24d++eJKlppQKxXBMAAAAAAADAuO7duycHB4do37cKf13cidcymUy6evWqkiRJIisrq9iuToy5e/eu0qVLp8uXLytp0qSxXR18YPR33EJ/xy30d9xCf8ct9HfcQn/HLfR33EJ/xy1xtb/Dw8N17949pU6dWtbW0T8Zkysz3wNra2ulTZs2tqsRa5ImTRqnBldcR3/HLfR33EJ/xy30d9xCf8ct9HfcQn/HLfR33BIX+/tVV2Q+wxcAAQAAAAAAADAEwkwAAAAAAAAAhkCYiXdmZ2enwYMHy86ObwaNC+jvuIX+jlvo77iF/o5b6O+4hf6OW+jvuIX+jlvo71fjC4AAAAAAAAAAGAJXZgIAAAAAAAAwBMJMAAAAAAAAAIZAmAkAAAAAAADAEAgzAQAAAAAAABgCYSYAAAAAAAAAQyDMBAAAAAAAAGAIhJkAAAAAAAAADIEwEwAAAAAAAIAh/A+OuLH3WcDcRwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MOLSL09JxKdp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}