{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "39738ece-e8d4-4bc5-a8bb-4a26dacfddf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=7e5fed199a8ea184d3e48a4d1bf8b21801a95e99d3725f1312724c91b34c5f36\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n",
            "--2025-04-03 01:31:23--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.48.194, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-04-03 01:31:24--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  16.4MB/s    in 11m 28s \n",
            "\n",
            "2025-04-03 01:42:52 (16.2 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo\n",
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super().__init__()\n",
        "        self.stem = Stem16()\n",
        "        self.stage1 = LevitStage(256, 256, 4, 2, downsample=False)\n",
        "        self.stage2 = LevitStage(256, 384, 6, 2, downsample=True)\n",
        "        self.conv1x1 = nn.Sequential(nn.Conv2d(384, 512, 1), nn.BatchNorm2d(512), nn.ReLU(True))\n",
        "        self.head = NormLinear(512, num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(512, num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        H = W = int(x.shape[1] ** 0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "        x = self.conv1x1(x)\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        return self.head(x)\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        x = self.stem(x)\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        H = W = int(x.shape[1] ** 0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "        x = self.conv1x1(x)\n",
        "        return torch.mean(x, dim=(2, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "5fc97119-cd7d-402a-fa04-fedad3d9dcbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gNpMsNYAzLDF",
        "outputId": "2667ecfe-4073-4cda-c4fd-7dc5cd458708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 4,909,234\n",
            "Trainable params: 4,909,234\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.68\n",
            "Params size (MB): 19.61\n",
            "Estimated Total Size (MB): 936.56\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "450ec0b5-a1f5-41df-8a18-b9120007bd19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.68\n",
            "Params size (MB): 19.61\n",
            "Estimated Total Size (MB): 936.56\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.68\n",
            "Params size (MB): 19.61\n",
            "Estimated Total Size (MB): 936.56\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LUiqsuSdOgj0"
      },
      "outputs": [],
      "source": [
        "class BSDALayer(nn.Module):\n",
        "    def __init__(self, feature_dim, bsda_lambda=0.8) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.bsda_lambda = bsda_lambda\n",
        "\n",
        "        self.logvar = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "        )\n",
        "\n",
        "        self.d = nn.Dropout(p=self.bsda_lambda)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "\n",
        "            nn.Linear(self.feature_dim, self.feature_dim),\n",
        "            nn.BatchNorm1d(self.feature_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "    def modified_indicator_function(self, x):\n",
        "        return torch.where(x >= 0, torch.sign(x), -torch.sign(x))\n",
        "\n",
        "    def calc_a_tilde(self, a, m, multi=1):\n",
        "        a = a.repeat(multi, 1)\n",
        "        return a + self.d(m) * self.modified_indicator_function(a)\n",
        "\n",
        "    def reparameterize(self, mu, logvar, multi=1):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        std = std.repeat(multi, 1)\n",
        "        eps = torch.randn_like(std, device=std.device)\n",
        "        mu = mu.repeat(multi, 1)\n",
        "        return eps * std + mu\n",
        "\n",
        "    def forward(self, a, multi=1):\n",
        "        \"\"\"\n",
        "            a: (batch_size, feature_dim)\n",
        "            m: (batch_size, feature_dim)\n",
        "            mu: (batch_size, feature_dim)\n",
        "            logvar: (batch_size, feature_dim)\n",
        "        \"\"\"\n",
        "        x = self.encoder(a)\n",
        "\n",
        "        logvar = self.logvar(x)\n",
        "        mu = torch.zeros_like(logvar, device=logvar.device)\n",
        "\n",
        "        m = self.reparameterize(mu, logvar, multi)\n",
        "        a_hat = self.decoder(m)\n",
        "\n",
        "        return m, mu, logvar, a_hat\n",
        "\n",
        "    def calc_kl_loss(self, mu, logvar):\n",
        "\n",
        "        kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        return kl_loss\n",
        "\n",
        "    def calc_recon_loss(self, a, a_hat, multi=1):\n",
        "        recon_loss = torch.mean((a.repeat(multi, 1) - a_hat) ** 2) * 0.5\n",
        "        return recon_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "c696924a-ac6b-477a-bae9-5c01f4f593ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mAsRwMpISMIh"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fnlxaQSs7NsL"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "dataset_train = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "dataset_eval = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "\n",
        "train_data = Subset(dataset_train, load_train_idx)\n",
        "val_data = Subset(dataset_eval, load_val_idx)\n",
        "test_data = Subset(dataset_eval, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "4c5f703f-2809-422e-88fd-ff72b977b45c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch,\n",
        "          use_bsda=False, bsda_layer=None, multi=10, bsda_alpha=0.5,\n",
        "          kl_weight=8e-4, recon_weight=1.0, use_ori=True, num_epochs=30):\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    ratio = min(bsda_alpha * (epoch / (num_epochs // 2)), bsda_alpha) if use_bsda else 0\n",
        "\n",
        "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        features = model.extract_features(inputs)\n",
        "        y_hat = model.head(features)\n",
        "\n",
        "        if use_bsda:\n",
        "            m, mu, logvar, a_hat = bsda_layer(features, multi=multi)\n",
        "            a_tilde = bsda_layer.calc_a_tilde(features, m, multi=multi)\n",
        "            y_hat_tilde = model.head(a_tilde)\n",
        "\n",
        "            loss_task = criterion(y_hat, labels)\n",
        "            loss_task_tilde = criterion(y_hat_tilde, labels.repeat(multi,))\n",
        "            loss_kl = bsda_layer.calc_kl_loss(mu, logvar)\n",
        "            loss_recon = bsda_layer.calc_recon_loss(features, a_hat, multi)\n",
        "            loss_bsda = kl_weight * loss_kl + recon_weight * loss_recon\n",
        "            loss = loss_task_tilde + loss_bsda\n",
        "            if use_ori:\n",
        "                loss = loss * ratio + loss_task\n",
        "        else:\n",
        "            loss = criterion(y_hat, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(y_hat, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Train Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100*correct/total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "13a24bad-cffa-48f0-8cf3-5438fab5fa9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 2188/2188 [02:22<00:00, 15.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5038, Accuracy: 82.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8426, Validation Accuracy: 71.57%\n",
            "Balanced Accuracy: 0.6870\n",
            "New best model saved with Validation loss 0.8426 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 2188/2188 [02:17<00:00, 15.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2851, Accuracy: 92.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3275, Validation Accuracy: 90.88%\n",
            "Balanced Accuracy: 0.9139\n",
            "New best model saved with Validation loss 0.3275 at best_model.pth\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 2188/2188 [02:19<00:00, 15.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2471, Accuracy: 94.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3031, Validation Accuracy: 90.88%\n",
            "Balanced Accuracy: 0.9027\n",
            "New best model saved with Validation loss 0.3031 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 2188/2188 [02:19<00:00, 15.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2355, Accuracy: 95.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1941, Validation Accuracy: 93.72%\n",
            "Balanced Accuracy: 0.9346\n",
            "New best model saved with Validation loss 0.1941 at best_model.pth\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 2188/2188 [02:19<00:00, 15.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2349, Accuracy: 96.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.3763, Validation Accuracy: 87.85%\n",
            "Balanced Accuracy: 0.8598\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 2188/2188 [02:19<00:00, 15.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2318, Accuracy: 97.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 2.4389, Validation Accuracy: 46.63%\n",
            "Balanced Accuracy: 0.4676\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 2188/2188 [02:19<00:00, 15.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2346, Accuracy: 98.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.5266, Validation Accuracy: 58.48%\n",
            "Balanced Accuracy: 0.5709\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 2188/2188 [02:19<00:00, 15.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2419, Accuracy: 98.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.0452, Validation Accuracy: 71.45%\n",
            "Balanced Accuracy: 0.7181\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 2188/2188 [02:19<00:00, 15.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2468, Accuracy: 98.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.7956, Validation Accuracy: 55.21%\n",
            "Balanced Accuracy: 0.5519\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 2188/2188 [02:19<00:00, 15.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2554, Accuracy: 98.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6142, Validation Accuracy: 82.79%\n",
            "Balanced Accuracy: 0.8070\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 2188/2188 [02:20<00:00, 15.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2666, Accuracy: 98.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.8414, Validation Accuracy: 78.34%\n",
            "Balanced Accuracy: 0.7845\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 2188/2188 [02:20<00:00, 15.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2705, Accuracy: 98.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1718, Validation Accuracy: 94.65%\n",
            "Balanced Accuracy: 0.9432\n",
            "New best model saved with Validation loss 0.1718 at best_model.pth\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 2188/2188 [02:20<00:00, 15.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2777, Accuracy: 99.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.9325, Validation Accuracy: 75.28%\n",
            "Balanced Accuracy: 0.7426\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 2188/2188 [02:19<00:00, 15.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2912, Accuracy: 99.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4558, Validation Accuracy: 88.07%\n",
            "Balanced Accuracy: 0.8714\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 2188/2188 [02:19<00:00, 15.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2985, Accuracy: 99.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2207, Validation Accuracy: 93.33%\n",
            "Balanced Accuracy: 0.9293\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 2188/2188 [02:18<00:00, 15.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3092, Accuracy: 99.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0812, Validation Accuracy: 97.75%\n",
            "Balanced Accuracy: 0.9755\n",
            "New best model saved with Validation loss 0.0812 at best_model.pth\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 2188/2188 [02:19<00:00, 15.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3042, Accuracy: 99.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.1669, Validation Accuracy: 76.99%\n",
            "Balanced Accuracy: 0.7525\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 2188/2188 [02:18<00:00, 15.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2955, Accuracy: 99.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4771, Validation Accuracy: 89.94%\n",
            "Balanced Accuracy: 0.8924\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 2188/2188 [02:19<00:00, 15.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2877, Accuracy: 99.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 1.4683, Validation Accuracy: 69.50%\n",
            "Balanced Accuracy: 0.6655\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 2188/2188 [02:19<00:00, 15.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2892, Accuracy: 99.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0516, Validation Accuracy: 98.49%\n",
            "Balanced Accuracy: 0.9853\n",
            "New best model saved with Validation loss 0.0516 at best_model.pth\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 2188/2188 [02:19<00:00, 15.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2772, Accuracy: 99.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0447, Validation Accuracy: 98.73%\n",
            "Balanced Accuracy: 0.9877\n",
            "New best model saved with Validation loss 0.0447 at best_model.pth\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 2188/2188 [02:19<00:00, 15.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2778, Accuracy: 99.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2656, Validation Accuracy: 93.76%\n",
            "Balanced Accuracy: 0.9325\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 2188/2188 [02:19<00:00, 15.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2799, Accuracy: 99.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5232, Validation Accuracy: 87.87%\n",
            "Balanced Accuracy: 0.8668\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 2188/2188 [02:19<00:00, 15.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2663, Accuracy: 99.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0458, Validation Accuracy: 98.69%\n",
            "Balanced Accuracy: 0.9870\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 2188/2188 [02:19<00:00, 15.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2692, Accuracy: 99.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0865, Validation Accuracy: 97.61%\n",
            "Balanced Accuracy: 0.9749\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 2188/2188 [02:19<00:00, 15.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2659, Accuracy: 99.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0440, Validation Accuracy: 98.98%\n",
            "Balanced Accuracy: 0.9893\n",
            "New best model saved with Validation loss 0.0440 at best_model.pth\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 2188/2188 [02:18<00:00, 15.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2621, Accuracy: 99.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0555, Validation Accuracy: 98.51%\n",
            "Balanced Accuracy: 0.9842\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 2188/2188 [02:19<00:00, 15.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2641, Accuracy: 99.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.6192, Validation Accuracy: 88.33%\n",
            "Balanced Accuracy: 0.8751\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 2188/2188 [02:19<00:00, 15.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2588, Accuracy: 99.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4849, Validation Accuracy: 89.19%\n",
            "Balanced Accuracy: 0.8866\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 2188/2188 [02:19<00:00, 15.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2512, Accuracy: 99.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:20<00:00, 22.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0771, Validation Accuracy: 98.27%\n",
            "Balanced Accuracy: 0.9821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "bsda_layer = BSDALayer(feature_dim=512, bsda_lambda=0.8).to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch,\n",
        "          use_bsda=True,\n",
        "          bsda_layer=bsda_layer,\n",
        "          multi=10,\n",
        "          bsda_alpha=0.5,\n",
        "          kl_weight=8e-4,\n",
        "          recon_weight=1.0,\n",
        "          use_ori=True,\n",
        "          num_epochs=num_epochs)\n",
        "\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCGf9fvf2-qk",
        "outputId": "aedf1f21-0793-4029-d494-25f0317d337b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "c25e5e1e-8470-4883-8149-6e3c0d5fa66e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:20<00:00, 22.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0585, Test Accuracy: 98.59%\n",
            "Balanced Accuracy: 0.9853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "a3c3b82c-a420-42f2-919d-6b878cca18f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 5.98 ms\n",
            "Standard Deviation: 0.35 ms\n",
            "Maximum Time: 9.13 ms\n",
            "Minimum Time: 5.64 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "9a4a8aa5-7ccd-4008-ae12-155eabdaa672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         9.22%       1.128ms        32.23%       3.941ms     164.209us       0.000us         0.00%       2.544ms     106.012us            24  \n",
            "                                           aten::linear         0.76%      92.620us        18.18%       2.223ms     130.764us       0.000us         0.00%       1.826ms     107.431us            17  \n",
            "                                               aten::mm         4.58%     559.495us        14.79%       1.808ms     112.985us       1.814ms        38.56%       1.814ms     113.367us            16  \n",
            "                                           aten::conv2d         1.56%     191.061us        15.20%       1.858ms     309.740us       0.000us         0.00%     725.599us     120.933us             6  \n",
            "                                      aten::convolution         0.43%      52.840us        13.64%       1.667ms     277.896us       0.000us         0.00%     725.599us     120.933us             6  \n",
            "                                     aten::_convolution         1.96%     239.324us        13.21%       1.615ms     269.090us       0.000us         0.00%     725.599us     120.933us             6  \n",
            "                                aten::cudnn_convolution         8.66%       1.059ms        10.69%       1.307ms     217.866us     710.623us        15.11%     710.623us     118.437us             6  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     681.629us        14.49%     681.629us     170.407us             4  \n",
            "                                              aten::bmm         2.11%     258.351us         2.67%     326.207us      40.776us     569.661us        12.11%     569.661us      71.208us             8  \n",
            "                                       aten::batch_norm         1.01%     123.548us        30.74%       3.758ms     170.821us       0.000us         0.00%     533.953us      24.271us            22  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 12.226ms\n",
            "Self CUDA time total: 4.704ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    val_losses.append(epoch_loss)\n",
        "    val_accuracies.append(accuracy)\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubbBuFrU-GRd",
        "outputId": "8835c38e-4732-4b71-b522-d11f630c79ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:21<00:00, 21.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0585, Test Accuracy: 98.59%\n",
            "Overall - F1: 0.9855, Recall: 0.9853, Precision: 0.9857\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9978, Recall: 0.9974, Precision: 0.9981\n",
            "Class 1 - F1: 0.9984, Recall: 0.9994, Precision: 0.9975\n",
            "Class 2 - F1: 0.9736, Recall: 0.9820, Precision: 0.9653\n",
            "Class 3 - F1: 0.9983, Recall: 0.9971, Precision: 0.9994\n",
            "Class 4 - F1: 0.9794, Recall: 0.9805, Precision: 0.9783\n",
            "Class 5 - F1: 0.9916, Recall: 0.9877, Precision: 0.9955\n",
            "Class 6 - F1: 0.9785, Recall: 0.9681, Precision: 0.9891\n",
            "Class 7 - F1: 0.9666, Recall: 0.9706, Precision: 0.9627\n",
            "Class 8 - F1: 0.9851, Recall: 0.9851, Precision: 0.9851\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "3qaLb5c--H0Q",
        "outputId": "e24985f9-77d3-42ee-a032-eac99823d880"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29ACr21nOjBW",
        "outputId": "ed9ba756-0291-42c3-94ce-b8f645cc4ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved to HoViT22_bsda.pth\n"
          ]
        }
      ],
      "source": [
        "save_path = \"HoViT22_bsda.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model weights saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "QCHdGKmbuw9W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2NMYNeV0Ly5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}