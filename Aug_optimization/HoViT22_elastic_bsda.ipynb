{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYpt3QcVCl83",
        "outputId": "424159cc-5af1-4e80-b209-e53805954442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=b893745c1ae26a7437fdc0fc1ea31ef41f09d7c7a4bae3dc1d304b978ac0ad1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, torchinfo\n",
            "Successfully installed torchinfo-1.8.0 wget-3.2\n",
            "--2025-04-06 02:23:30--  https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.45.92, 188.185.48.194, 188.185.43.25, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.45.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 MOVED PERMANENTLY\n",
            "Location: /records/1214456/files/NCT-CRC-HE-100K.zip [following]\n",
            "--2025-04-06 02:23:31--  https://zenodo.org/records/1214456/files/NCT-CRC-HE-100K.zip\n",
            "Reusing existing connection to zenodo.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11690284003 (11G) [application/octet-stream]\n",
            "Saving to: ‘NCT-CRC-HE-100K.zip’\n",
            "\n",
            "NCT-CRC-HE-100K.zip 100%[===================>]  10.89G  24.3MB/s    in 7m 44s  \n",
            "\n",
            "2025-04-06 02:31:15 (24.0 MB/s) - ‘NCT-CRC-HE-100K.zip’ saved [11690284003/11690284003]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install wget torchinfo\n",
        "!wget -O NCT-CRC-HE-100K.zip https://zenodo.org/record/1214456/files/NCT-CRC-HE-100K.zip\n",
        "!unzip -qq NCT-CRC-HE-100K.zip -d train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Wa8mdzSwvzMe"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import itertools\n",
        "from torchinfo import summary\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4FLtpbS_Vrd7"
      },
      "outputs": [],
      "source": [
        "class ConvNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
        "        super(ConvNorm, self).__init__()\n",
        "        self.linear = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size,\n",
        "            stride=stride, padding=padding, bias=False\n",
        "        )\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.bn(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zhaJu1oZyp0D"
      },
      "outputs": [],
      "source": [
        "class Stem16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Stem16, self).__init__()\n",
        "        self.conv1 = ConvNorm(3, 32)\n",
        "        self.act1 = nn.Hardswish()\n",
        "        self.conv2 = ConvNorm(32, 64)\n",
        "        self.act2 = nn.Hardswish()\n",
        "        self.conv3 = ConvNorm(64, 128)\n",
        "        self.act3 = nn.Hardswish()\n",
        "        self.conv4 = ConvNorm(128, 256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.conv1(x))\n",
        "        x = self.act2(self.conv2(x))\n",
        "        x = self.act3(self.conv3(x))\n",
        "        x = self.conv4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W1Xh6-wOyskM"
      },
      "outputs": [],
      "source": [
        "class LinearNorm(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(LinearNorm, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if x.dim() == 3:\n",
        "            B, N, C = x.shape\n",
        "            x = x.reshape(B * N, C)\n",
        "            x = self.bn(self.linear(x))\n",
        "            x = x.reshape(B, N, -1)\n",
        "        else:\n",
        "            x = self.bn(self.linear(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wHeuFDCPyuLf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, attn_ratio=2):\n",
        "        super(Attention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        inner_dim = head_dim * num_heads * 3\n",
        "        self.qkv = LinearNorm(dim, inner_dim)\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Hardswish(),\n",
        "            LinearNorm(dim, dim)\n",
        "        )\n",
        "\n",
        "        self.attention_biases = None\n",
        "        self.attention_bias_idxs = None\n",
        "\n",
        "    def compute_attention_bias(self, resolution):\n",
        "\n",
        "        points = list(itertools.product(range(resolution), range(resolution)))\n",
        "        N = len(points)\n",
        "\n",
        "        attention_offsets = {}\n",
        "        idxs = []\n",
        "\n",
        "        # if N = 196, then resolution = 14\n",
        "        for p1 in points:\n",
        "            for p2 in points:\n",
        "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
        "                if offset not in attention_offsets:\n",
        "                    attention_offsets[offset] = len(attention_offsets)\n",
        "                idxs.append(attention_offsets[offset])\n",
        "\n",
        "        num_offsets = len(attention_offsets)\n",
        "\n",
        "        # 각 attention head에 대해 num_offsets 만큼의 학습 가능한 Bias를 생성\n",
        "        self.attention_biases = nn.Parameter(torch.zeros(self.num_heads, num_offsets).to(next(self.parameters()).device))\n",
        "        self.attention_bias_idxs = torch.LongTensor(idxs).view(N, N).to(next(self.parameters()).device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        resolution = int(N ** 0.5)\n",
        "\n",
        "        if self.attention_biases is None or self.attention_bias_idxs.shape[0] != N:\n",
        "            self.compute_attention_bias(resolution)\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        qkv = qkv.view(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        # qkv: (3, B, num_heads, N, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2] # q, k, v: (B, num_heads, N, head_dim)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale # attn: (B, num_heads, N, N)\n",
        "        attn_bias = self.attention_biases[:, self.attention_bias_idxs].unsqueeze(0) # attn_bias: (1, num_heads, N, N)\n",
        "        attn = attn + attn_bias\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.proj(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xvyY-FeUywyR"
      },
      "outputs": [],
      "source": [
        "class LevitMlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, out_features):\n",
        "        super(LevitMlp, self).__init__()\n",
        "        self.ln1 = LinearNorm(in_features, hidden_features)\n",
        "        self.act = nn.Hardswish()\n",
        "        self.drop = nn.Dropout(p=0.5, inplace=False)#dropout 적용\n",
        "        self.ln2 = LinearNorm(hidden_features, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.ln2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ubl233osyyHQ"
      },
      "outputs": [],
      "source": [
        "class LevitBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=2):\n",
        "        super(LevitBlock, self).__init__()\n",
        "        self.attn = Attention(dim, num_heads)\n",
        "        self.drop_path1 = nn.Identity()\n",
        "        self.mlp = LevitMlp(dim, dim * mlp_ratio, dim)\n",
        "        self.drop_path2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path1(self.attn(x))\n",
        "        x = x + self.drop_path2(self.mlp(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cjBHkWJYyzfc"
      },
      "outputs": [],
      "source": [
        "class CNNDownsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CNNDownsample, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "        self.act = nn.Hardswish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape # (B, N, C)  N=H*W (16 * 16 = 196)\n",
        "        H = int(np.sqrt(N))\n",
        "        x = x.view(B, H, H, C).permute(0, 3, 1, 2)\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "        x = x.permute(0, 2, 3, 1).view(B, -1, self.out_channels)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jNpOjwVVy1Im"
      },
      "outputs": [],
      "source": [
        "class LevitStage(nn.Module):\n",
        "    def __init__(self, dim, out_dim, num_heads, num_blocks, downsample=True):\n",
        "        super(LevitStage, self).__init__()\n",
        "        self.downsample = CNNDownsample(dim, out_dim) if downsample else nn.Identity()\n",
        "        self.blocks = nn.Sequential(*[LevitBlock(out_dim, num_heads) for _ in range(num_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample(x)\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FyFtflRsy2QE"
      },
      "outputs": [],
      "source": [
        "class ConvLevitStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, kernel_size, stride, padding):\n",
        "        super(ConvLevitStage, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            *[nn.Conv2d(in_channels if i == 0 else out_channels, out_channels, kernel_size, stride, padding)\n",
        "              for i in range(num_blocks)],\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yKzCWv-Ny3j9"
      },
      "outputs": [],
      "source": [
        "class NormLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, dropout_prob=0.5):#drop_out_0.5 적용\n",
        "        super(NormLinear, self).__init__()\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=dropout_prob, inplace=False)\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "nS7iQ8-453Ru"
      },
      "outputs": [],
      "source": [
        "class LevitDistilled(nn.Module):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super().__init__()\n",
        "        self.stem = Stem16()\n",
        "        self.stage1 = LevitStage(256, 256, 4, 2, downsample=False)\n",
        "        self.stage2 = LevitStage(256, 384, 6, 2, downsample=True)\n",
        "        self.conv1x1 = nn.Sequential(nn.Conv2d(384, 512, 1), nn.BatchNorm2d(512), nn.ReLU(True))\n",
        "        self.head = NormLinear(512, num_classes, dropout_prob=0.0)\n",
        "        self.head_dist = NormLinear(512, num_classes, dropout_prob=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.view(B, C, -1).transpose(1, 2)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        H = W = int(x.shape[1] ** 0.5)\n",
        "        x = x.transpose(1, 2).view(B, 384, H, W)\n",
        "        x = self.conv1x1(x)\n",
        "        x = torch.mean(x, dim=(2, 3))\n",
        "        return self.head(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lbCq25bWzJSQ",
        "outputId": "e0113128-f5c7-4f17-9725-8345645bfdc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LevitDistilled(\n",
            "  (stem): Stem16(\n",
            "    (conv1): ConvNorm(\n",
            "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act1): Hardswish()\n",
            "    (conv2): ConvNorm(\n",
            "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act2): Hardswish()\n",
            "    (conv3): ConvNorm(\n",
            "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (act3): Hardswish()\n",
            "    (conv4): ConvNorm(\n",
            "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (stage1): LevitStage(\n",
            "    (downsample): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
            "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
            "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
            "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): LevitStage(\n",
            "    (downsample): CNNDownsample(\n",
            "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (act): Hardswish()\n",
            "    )\n",
            "    (blocks): Sequential(\n",
            "      (0): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): LevitBlock(\n",
            "        (attn): Attention(\n",
            "          (qkv): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
            "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (proj): Sequential(\n",
            "            (0): Hardswish()\n",
            "            (1): LinearNorm(\n",
            "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
            "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (drop_path1): Identity()\n",
            "        (mlp): LevitMlp(\n",
            "          (ln1): LinearNorm(\n",
            "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
            "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (act): Hardswish()\n",
            "          (drop): Dropout(p=0.5, inplace=False)\n",
            "          (ln2): LinearNorm(\n",
            "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
            "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv1x1): Sequential(\n",
            "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (head): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            "  (head_dist): NormLinear(\n",
            "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (drop): Dropout(p=0.0, inplace=False)\n",
            "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = LevitDistilled(num_classes=9)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gNpMsNYAzLDF",
        "outputId": "7d17c5ca-944a-4f04-ea9b-9a60d2c03cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            527,872\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            527,872\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,024\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,024\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "=========================================================================================================\n",
            "Total params: 4,909,234\n",
            "Trainable params: 4,909,234\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.68\n",
            "Params size (MB): 19.61\n",
            "Estimated Total Size (MB): 936.56\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qDELjYy2zP90",
        "outputId": "27c0a3d8-efd8-4deb-912c-75022f524049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.68\n",
            "Params size (MB): 19.61\n",
            "Estimated Total Size (MB): 936.56\n",
            "=========================================================================================================\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "LevitDistilled                                          [32, 9]                   5,641\n",
            "├─Stem16: 1-1                                           [32, 256, 14, 14]         --\n",
            "│    └─conv1.linear.weight                                                        ├─864\n",
            "│    └─conv1.bn.weight                                                            ├─32\n",
            "│    └─conv1.bn.bias                                                              ├─32\n",
            "│    └─conv2.linear.weight                                                        ├─18,432\n",
            "│    └─conv2.bn.weight                                                            ├─64\n",
            "│    └─conv2.bn.bias                                                              ├─64\n",
            "│    └─conv3.linear.weight                                                        ├─73,728\n",
            "│    └─conv3.bn.weight                                                            ├─128\n",
            "│    └─conv3.bn.bias                                                              ├─128\n",
            "│    └─conv4.linear.weight                                                        ├─294,912\n",
            "│    └─conv4.bn.weight                                                            ├─256\n",
            "│    └─conv4.bn.bias                                                              └─256\n",
            "│    └─ConvNorm: 2-1                                    [32, 32, 112, 112]        --\n",
            "│    │    └─linear.weight                                                         ├─864\n",
            "│    │    └─bn.weight                                                             ├─32\n",
            "│    │    └─bn.bias                                                               └─32\n",
            "│    │    └─Conv2d: 3-1                                 [32, 32, 112, 112]        864\n",
            "│    │    │    └─weight                                                           └─864\n",
            "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]        64\n",
            "│    │    │    └─weight                                                           ├─32\n",
            "│    │    │    └─bias                                                             └─32\n",
            "│    └─Hardswish: 2-2                                   [32, 32, 112, 112]        --\n",
            "│    └─ConvNorm: 2-3                                    [32, 64, 56, 56]          --\n",
            "│    │    └─linear.weight                                                         ├─18,432\n",
            "│    │    └─bn.weight                                                             ├─64\n",
            "│    │    └─bn.bias                                                               └─64\n",
            "│    │    └─Conv2d: 3-3                                 [32, 64, 56, 56]          18,432\n",
            "│    │    │    └─weight                                                           └─18,432\n",
            "│    │    └─BatchNorm2d: 3-4                            [32, 64, 56, 56]          128\n",
            "│    │    │    └─weight                                                           ├─64\n",
            "│    │    │    └─bias                                                             └─64\n",
            "│    └─Hardswish: 2-4                                   [32, 64, 56, 56]          --\n",
            "│    └─ConvNorm: 2-5                                    [32, 128, 28, 28]         --\n",
            "│    │    └─linear.weight                                                         ├─73,728\n",
            "│    │    └─bn.weight                                                             ├─128\n",
            "│    │    └─bn.bias                                                               └─128\n",
            "│    │    └─Conv2d: 3-5                                 [32, 128, 28, 28]         73,728\n",
            "│    │    │    └─weight                                                           └─73,728\n",
            "│    │    └─BatchNorm2d: 3-6                            [32, 128, 28, 28]         256\n",
            "│    │    │    └─weight                                                           ├─128\n",
            "│    │    │    └─bias                                                             └─128\n",
            "│    └─Hardswish: 2-6                                   [32, 128, 28, 28]         --\n",
            "│    └─ConvNorm: 2-7                                    [32, 256, 14, 14]         --\n",
            "│    │    └─linear.weight                                                         ├─294,912\n",
            "│    │    └─bn.weight                                                             ├─256\n",
            "│    │    └─bn.bias                                                               └─256\n",
            "│    │    └─Conv2d: 3-7                                 [32, 256, 14, 14]         294,912\n",
            "│    │    │    └─weight                                                           └─294,912\n",
            "│    │    └─BatchNorm2d: 3-8                            [32, 256, 14, 14]         512\n",
            "│    │    │    └─weight                                                           ├─256\n",
            "│    │    │    └─bias                                                             └─256\n",
            "├─LevitStage: 1-2                                       [32, 196, 256]            --\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─256\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─784\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─196,608\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─768\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─768\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─65,536\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─256\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─256\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─512\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─512\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─131,072\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─256\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─256\n",
            "│    └─Identity: 2-8                                    [32, 196, 256]            --\n",
            "│    └─Sequential: 2-9                                  [32, 196, 256]            --\n",
            "│    │    └─0.attn.attention_biases                                               ├─784\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─256\n",
            "│    │    └─1.attn.attention_biases                                               ├─784\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─196,608\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─768\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─768\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─65,536\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─256\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─256\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─512\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─512\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─131,072\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─256\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─256\n",
            "│    │    └─LevitBlock: 3-9                             [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "│    │    └─LevitBlock: 3-10                            [32, 196, 256]            528,656\n",
            "│    │    │    └─attn.attention_biases                                            ├─784\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─196,608\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─768\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─768\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─65,536\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─256\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─256\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─512\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─512\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─131,072\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─256\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─256\n",
            "├─LevitStage: 1-3                                       [32, 49, 384]             --\n",
            "│    └─downsample.conv.weight                                                     ├─884,736\n",
            "│    └─downsample.conv.bias                                                       ├─384\n",
            "│    └─blocks.0.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.0.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.0.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.0.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.0.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.0.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.0.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.0.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.0.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.0.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.0.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.0.mlp.ln2.bn.bias                                                   ├─384\n",
            "│    └─blocks.1.attn.attention_biases                                             ├─294\n",
            "│    └─blocks.1.attn.qkv.linear.weight                                            ├─442,368\n",
            "│    └─blocks.1.attn.qkv.bn.weight                                                ├─1,152\n",
            "│    └─blocks.1.attn.qkv.bn.bias                                                  ├─1,152\n",
            "│    └─blocks.1.attn.proj.1.linear.weight                                         ├─147,456\n",
            "│    └─blocks.1.attn.proj.1.bn.weight                                             ├─384\n",
            "│    └─blocks.1.attn.proj.1.bn.bias                                               ├─384\n",
            "│    └─blocks.1.mlp.ln1.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln1.bn.weight                                                 ├─768\n",
            "│    └─blocks.1.mlp.ln1.bn.bias                                                   ├─768\n",
            "│    └─blocks.1.mlp.ln2.linear.weight                                             ├─294,912\n",
            "│    └─blocks.1.mlp.ln2.bn.weight                                                 ├─384\n",
            "│    └─blocks.1.mlp.ln2.bn.bias                                                   └─384\n",
            "│    └─CNNDownsample: 2-10                              [32, 49, 384]             --\n",
            "│    │    └─conv.weight                                                           ├─884,736\n",
            "│    │    └─conv.bias                                                             └─384\n",
            "│    │    └─Conv2d: 3-11                                [32, 384, 7, 7]           885,120\n",
            "│    │    │    └─weight                                                           ├─884,736\n",
            "│    │    │    └─bias                                                             └─384\n",
            "│    │    └─Hardswish: 3-12                             [32, 384, 7, 7]           --\n",
            "│    └─Sequential: 2-11                                 [32, 49, 384]             --\n",
            "│    │    └─0.attn.attention_biases                                               ├─294\n",
            "│    │    └─0.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─0.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─0.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─0.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─0.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─0.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─0.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─0.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─0.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─0.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─0.mlp.ln2.bn.bias                                                     ├─384\n",
            "│    │    └─1.attn.attention_biases                                               ├─294\n",
            "│    │    └─1.attn.qkv.linear.weight                                              ├─442,368\n",
            "│    │    └─1.attn.qkv.bn.weight                                                  ├─1,152\n",
            "│    │    └─1.attn.qkv.bn.bias                                                    ├─1,152\n",
            "│    │    └─1.attn.proj.1.linear.weight                                           ├─147,456\n",
            "│    │    └─1.attn.proj.1.bn.weight                                               ├─384\n",
            "│    │    └─1.attn.proj.1.bn.bias                                                 ├─384\n",
            "│    │    └─1.mlp.ln1.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln1.bn.weight                                                   ├─768\n",
            "│    │    └─1.mlp.ln1.bn.bias                                                     ├─768\n",
            "│    │    └─1.mlp.ln2.linear.weight                                               ├─294,912\n",
            "│    │    └─1.mlp.ln2.bn.weight                                                   ├─384\n",
            "│    │    └─1.mlp.ln2.bn.bias                                                     └─384\n",
            "│    │    └─LevitBlock: 3-13                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "│    │    └─LevitBlock: 3-14                            [32, 49, 384]             1,185,318\n",
            "│    │    │    └─attn.attention_biases                                            ├─294\n",
            "│    │    │    └─attn.qkv.linear.weight                                           ├─442,368\n",
            "│    │    │    └─attn.qkv.bn.weight                                               ├─1,152\n",
            "│    │    │    └─attn.qkv.bn.bias                                                 ├─1,152\n",
            "│    │    │    └─attn.proj.1.linear.weight                                        ├─147,456\n",
            "│    │    │    └─attn.proj.1.bn.weight                                            ├─384\n",
            "│    │    │    └─attn.proj.1.bn.bias                                              ├─384\n",
            "│    │    │    └─mlp.ln1.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln1.bn.weight                                                ├─768\n",
            "│    │    │    └─mlp.ln1.bn.bias                                                  ├─768\n",
            "│    │    │    └─mlp.ln2.linear.weight                                            ├─294,912\n",
            "│    │    │    └─mlp.ln2.bn.weight                                                ├─384\n",
            "│    │    │    └─mlp.ln2.bn.bias                                                  └─384\n",
            "├─Sequential: 1-4                                       [32, 512, 7, 7]           --\n",
            "│    └─0.weight                                                                   ├─196,608\n",
            "│    └─0.bias                                                                     ├─512\n",
            "│    └─1.weight                                                                   ├─512\n",
            "│    └─1.bias                                                                     └─512\n",
            "│    └─Conv2d: 2-12                                     [32, 512, 7, 7]           197,120\n",
            "│    │    └─weight                                                                ├─196,608\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─BatchNorm2d: 2-13                                [32, 512, 7, 7]           1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─ReLU: 2-14                                       [32, 512, 7, 7]           --\n",
            "├─NormLinear: 1-5                                       [32, 9]                   --\n",
            "│    └─bn.weight                                                                  ├─512\n",
            "│    └─bn.bias                                                                    ├─512\n",
            "│    └─linear.weight                                                              ├─4,608\n",
            "│    └─linear.bias                                                                └─9\n",
            "│    └─BatchNorm1d: 2-15                                [32, 512]                 1,024\n",
            "│    │    └─weight                                                                ├─512\n",
            "│    │    └─bias                                                                  └─512\n",
            "│    └─Dropout: 2-16                                    [32, 512]                 --\n",
            "│    └─Linear: 2-17                                     [32, 9]                   4,617\n",
            "│    │    └─weight                                                                ├─4,608\n",
            "│    │    └─bias                                                                  └─9\n",
            "=========================================================================================================\n",
            "Total params: 4,911,390\n",
            "Trainable params: 4,911,390\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 17.93\n",
            "=========================================================================================================\n",
            "Input size (MB): 19.27\n",
            "Forward/backward pass size (MB): 897.68\n",
            "Params size (MB): 19.61\n",
            "Estimated Total Size (MB): 936.56\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(summary(model, input_size=(32, 3, 224, 224), verbose=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XJWJO0JTIMT",
        "outputId": "70d666ad-3637-4c0c-9046-25edf6ebec50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LevitDistilled(\n",
              "  (stem): Stem16(\n",
              "    (conv1): ConvNorm(\n",
              "      (linear): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act1): Hardswish()\n",
              "    (conv2): ConvNorm(\n",
              "      (linear): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act2): Hardswish()\n",
              "    (conv3): ConvNorm(\n",
              "      (linear): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (act3): Hardswish()\n",
              "    (conv4): ConvNorm(\n",
              "      (linear): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1): LevitStage(\n",
              "    (downsample): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=False)\n",
              "              (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=256, out_features=512, bias=False)\n",
              "            (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=512, out_features=256, bias=False)\n",
              "            (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): LevitStage(\n",
              "    (downsample): CNNDownsample(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act): Hardswish()\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): LevitBlock(\n",
              "        (attn): Attention(\n",
              "          (qkv): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=1152, bias=False)\n",
              "            (bn): BatchNorm1d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (proj): Sequential(\n",
              "            (0): Hardswish()\n",
              "            (1): LinearNorm(\n",
              "              (linear): Linear(in_features=384, out_features=384, bias=False)\n",
              "              (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (drop_path1): Identity()\n",
              "        (mlp): LevitMlp(\n",
              "          (ln1): LinearNorm(\n",
              "            (linear): Linear(in_features=384, out_features=768, bias=False)\n",
              "            (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (act): Hardswish()\n",
              "          (drop): Dropout(p=0.5, inplace=False)\n",
              "          (ln2): LinearNorm(\n",
              "            (linear): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv1x1): Sequential(\n",
              "    (0): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (head): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              "  (head_dist): NormLinear(\n",
              "    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (linear): Linear(in_features=512, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # CUDA 연산 시 동일한 결과 보장\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티-GPU 환경에서 동일한 결과 보장\n",
        "    torch.backends.cudnn.deterministic = True  # CuDNN 연산을 deterministic하게 설정\n",
        "    torch.backends.cudnn.benchmark = False  # 연산 속도를 희생하고 일관된 연산을 수행\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):  # Conv 레이어 초기화\n",
        "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.Linear):  # Linear 레이어 초기화\n",
        "        init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):  # BatchNorm 초기화\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "set_seed(42)  # 랜덤 시드 고정\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "p5GDxFHzR-y7"
      },
      "outputs": [],
      "source": [
        "train_dir = './train/NCT-CRC-HE-100K'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def elastic_transform(image, alpha, sigma):\n",
        "    \"\"\"탄성 변형 적용\"\"\"\n",
        "\n",
        "    if isinstance(image, torch.Tensor):\n",
        "        image_np = image.permute(1, 2, 0).numpy()\n",
        "    else:\n",
        "        image_np = np.array(image)\n",
        "\n",
        "    shape = image_np.shape[:2]\n",
        "\n",
        "    ksize = 2 * int(sigma) + 1\n",
        "\n",
        "    dx = cv2.GaussianBlur((np.random.rand(*shape) * 2 - 1), (ksize, ksize), sigma) * alpha\n",
        "    dy = cv2.GaussianBlur((np.random.rand(*shape) * 2 - 1), (ksize, ksize), sigma) * alpha\n",
        "    x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
        "\n",
        "    indices = np.stack((y + dy, x + dx), axis=-1).astype(np.float32)\n",
        "    distorted_image = cv2.remap(image_np, indices, None, cv2.INTER_LINEAR)\n",
        "\n",
        "    return distorted_image"
      ],
      "metadata": {
        "id": "mhwEbFOP9QUW"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "mAsRwMpISMIh"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "fnlxaQSs7NsL"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.ImageFolder(root=train_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "N0BkxEAYTMvj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/default_index_dict.json\", \"r\") as f:\n",
        "    index_dict = json.load(f)\n",
        "load_train_idx = index_dict[\"train_idx\"]\n",
        "load_val_idx = index_dict[\"val_idx\"]\n",
        "load_test_idx = index_dict[\"test_idx\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "aug_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.75),\n",
        "    transforms.RandomVerticalFlip(p=0.75),\n",
        "    transforms.Lambda(lambda x: elastic_transform(x, alpha=10, sigma=4)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "g6huRbGQ9Tb5"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "rEIH5EZxTN6n"
      },
      "outputs": [],
      "source": [
        "dataset_train = datasets.ImageFolder(root=train_dir, transform=aug_transform)\n",
        "dataset_eval = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "\n",
        "train_data = Subset(dataset_train, load_train_idx)\n",
        "val_data = Subset(dataset_eval, load_val_idx)\n",
        "test_data = Subset(dataset_eval, load_test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8inM-bBnztEN",
        "outputId": "127068a8-5092-4820-c368-23b5e7d46563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 70000\n",
            "Validation set size: 15000\n",
            "Test set size: 15000\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "4TSObUGwcYxd"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lr=learning_rate, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "1No-7jzGgzrV"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "Yf0ZPGLtz_gB"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "rbdjXJ520Btp"
      },
      "outputs": [],
      "source": [
        "# Global variable to track the best validation loss\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device, epoch, phase=\"Validation\", save_path=\"best_model.pth\"):\n",
        "    global best_val_loss  # Reference global best validation loss\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(tqdm(data_loader, desc=f\"{phase}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Save all labels and predictions for balanced accuracy\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
        "    val_accuracies.append(accuracy)\n",
        "    val_losses.append(epoch_loss)\n",
        "    # Check if this is the best model so far (lowest validation loss)\n",
        "    if epoch_loss < best_val_loss:\n",
        "        best_val_loss = epoch_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"New best model saved with {phase} loss {epoch_loss:.4f} at {save_path}\")\n",
        "\n",
        "    #return epoch_loss, accuracy, balanced_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "GfBjePI-0DkY"
      },
      "outputs": [],
      "source": [
        "def measure_inference_time(model, data_loader, device):\n",
        "    model.eval()\n",
        "    times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            start_time = torch.cuda.Event(enable_timing=True)\n",
        "            end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "            start_time.record()\n",
        "            _ = model(inputs)  # inference 수행\n",
        "            end_time.record()\n",
        "\n",
        "            # 시간 측정\n",
        "            torch.cuda.synchronize()  # CUDA에서 모든 커널이 완료될 때까지 대기\n",
        "            elapsed_time = start_time.elapsed_time(end_time)  # 밀리초 단위로 반환\n",
        "            times.append(elapsed_time)\n",
        "\n",
        "    # 통계량 계산\n",
        "    times_np = np.array(times)\n",
        "    total_inferences = len(times_np)\n",
        "    avg_time = np.mean(times_np)\n",
        "    std_dev = np.std(times_np)\n",
        "    max_time = np.max(times_np)\n",
        "    min_time = np.min(times_np)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Inference Time Measurement Results:\")\n",
        "    print(f\"Total Inferences: {total_inferences}\")\n",
        "    print(f\"Average Time: {avg_time:.2f} ms\")\n",
        "    print(f\"Standard Deviation: {std_dev:.2f} ms\")\n",
        "    print(f\"Maximum Time: {max_time:.2f} ms\")\n",
        "    print(f\"Minimum Time: {min_time:.2f} ms\")\n",
        "\n",
        "    return times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXsiOTOO0GGK",
        "outputId": "70a8a6f0-0c7c-45a3-821b-40b7d4c359b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0210, Train Accuracy: 99.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1034, Validation Accuracy: 97.49%\n",
            "Balanced Accuracy: 0.9738\n",
            "New best model saved with Validation loss 0.1034 at best_model.pth\n",
            "\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0155, Train Accuracy: 99.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1941, Validation Accuracy: 95.86%\n",
            "Balanced Accuracy: 0.9564\n",
            "\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0134, Train Accuracy: 99.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0471, Validation Accuracy: 98.77%\n",
            "Balanced Accuracy: 0.9879\n",
            "New best model saved with Validation loss 0.0471 at best_model.pth\n",
            "\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0137, Train Accuracy: 99.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0357, Validation Accuracy: 98.93%\n",
            "Balanced Accuracy: 0.9895\n",
            "New best model saved with Validation loss 0.0357 at best_model.pth\n",
            "\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0109, Train Accuracy: 99.66%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1696, Validation Accuracy: 95.97%\n",
            "Balanced Accuracy: 0.9578\n",
            "\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0106, Train Accuracy: 99.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0706, Validation Accuracy: 98.17%\n",
            "Balanced Accuracy: 0.9811\n",
            "\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0113, Train Accuracy: 99.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4918, Validation Accuracy: 89.51%\n",
            "Balanced Accuracy: 0.9005\n",
            "\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0098, Train Accuracy: 99.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0590, Validation Accuracy: 98.33%\n",
            "Balanced Accuracy: 0.9820\n",
            "\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0097, Train Accuracy: 99.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1901, Validation Accuracy: 95.27%\n",
            "Balanced Accuracy: 0.9547\n",
            "\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0107, Train Accuracy: 99.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1137, Validation Accuracy: 97.20%\n",
            "Balanced Accuracy: 0.9705\n",
            "\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0078, Train Accuracy: 99.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0592, Validation Accuracy: 98.45%\n",
            "Balanced Accuracy: 0.9844\n",
            "\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0092, Train Accuracy: 99.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0754, Validation Accuracy: 98.09%\n",
            "Balanced Accuracy: 0.9807\n",
            "\n",
            "Epoch 13/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0092, Train Accuracy: 99.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0394, Validation Accuracy: 98.93%\n",
            "Balanced Accuracy: 0.9893\n",
            "\n",
            "Epoch 14/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:33<00:00,  6.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0062, Train Accuracy: 99.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0346, Validation Accuracy: 99.08%\n",
            "Balanced Accuracy: 0.9908\n",
            "New best model saved with Validation loss 0.0346 at best_model.pth\n",
            "\n",
            "Epoch 15/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0082, Train Accuracy: 99.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0445, Validation Accuracy: 98.80%\n",
            "Balanced Accuracy: 0.9879\n",
            "\n",
            "Epoch 16/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0071, Train Accuracy: 99.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1043, Validation Accuracy: 97.32%\n",
            "Balanced Accuracy: 0.9705\n",
            "\n",
            "Epoch 17/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0088, Train Accuracy: 99.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0396, Validation Accuracy: 98.94%\n",
            "Balanced Accuracy: 0.9890\n",
            "\n",
            "Epoch 18/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0067, Train Accuracy: 99.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1184, Validation Accuracy: 97.11%\n",
            "Balanced Accuracy: 0.9712\n",
            "\n",
            "Epoch 19/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0063, Train Accuracy: 99.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.5978, Validation Accuracy: 87.81%\n",
            "Balanced Accuracy: 0.8690\n",
            "\n",
            "Epoch 20/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0061, Train Accuracy: 99.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0586, Validation Accuracy: 98.51%\n",
            "Balanced Accuracy: 0.9846\n",
            "\n",
            "Epoch 21/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0067, Train Accuracy: 99.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0317, Validation Accuracy: 99.15%\n",
            "Balanced Accuracy: 0.9915\n",
            "New best model saved with Validation loss 0.0317 at best_model.pth\n",
            "\n",
            "Epoch 22/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0071, Train Accuracy: 99.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0540, Validation Accuracy: 98.53%\n",
            "Balanced Accuracy: 0.9858\n",
            "\n",
            "Epoch 23/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0070, Train Accuracy: 99.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0673, Validation Accuracy: 98.22%\n",
            "Balanced Accuracy: 0.9817\n",
            "\n",
            "Epoch 24/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0059, Train Accuracy: 99.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0322, Validation Accuracy: 99.07%\n",
            "Balanced Accuracy: 0.9906\n",
            "\n",
            "Epoch 25/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:32<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0059, Train Accuracy: 99.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0395, Validation Accuracy: 98.96%\n",
            "Balanced Accuracy: 0.9893\n",
            "\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:30<00:00,  6.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0059, Train Accuracy: 99.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4776, Validation Accuracy: 90.01%\n",
            "Balanced Accuracy: 0.8892\n",
            "\n",
            "Epoch 27/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0050, Train Accuracy: 99.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0527, Validation Accuracy: 98.67%\n",
            "Balanced Accuracy: 0.9862\n",
            "\n",
            "Epoch 28/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0061, Train Accuracy: 99.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 21.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0718, Validation Accuracy: 98.14%\n",
            "Balanced Accuracy: 0.9820\n",
            "\n",
            "Epoch 29/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0059, Train Accuracy: 99.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0445, Validation Accuracy: 98.90%\n",
            "Balanced Accuracy: 0.9888\n",
            "\n",
            "Epoch 30/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2188/2188 [05:31<00:00,  6.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0058, Train Accuracy: 99.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 469/469 [00:21<00:00, 22.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.0529, Validation Accuracy: 98.73%\n",
            "Balanced Accuracy: 0.9874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    evaluate(model, val_loader, criterion, device, epoch, phase=\"Validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCGf9fvf2-qk",
        "outputId": "906910fe-50d6-4254-f8c9-341c4587f6b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"best_model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq3Yxnau6V3e",
        "outputId": "37f34e9f-35a5-4ece-9774-3bb6b0748eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:21<00:00, 21.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0299, Test Accuracy: 99.20%\n",
            "Balanced Accuracy: 0.9920\n",
            "New best model saved with Test loss 0.0299 at best_model.pth\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Test Evaluation\")\n",
        "evaluate(model,test_loader, criterion, device, epoch, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlazeL-a0WTt",
        "outputId": "7b71741a-bd02-41c5-aa86-9471782de800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time Measurement Results:\n",
            "Total Inferences: 469\n",
            "Average Time: 7.33 ms\n",
            "Standard Deviation: 0.36 ms\n",
            "Maximum Time: 11.64 ms\n",
            "Minimum Time: 6.95 ms\n"
          ]
        }
      ],
      "source": [
        "times = measure_inference_time(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77rmtOz0XuA",
        "outputId": "7574def3-5888-4014-a90a-84d14e01ec5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::matmul         2.30%     201.173us        23.12%       2.022ms      84.269us       0.000us         0.00%       2.535ms     105.645us            24  \n",
            "                                           aten::linear         1.19%     104.194us        14.07%       1.231ms      72.397us       0.000us         0.00%       1.818ms     106.948us            17  \n",
            "                                               aten::mm         6.49%     567.901us         9.50%     831.419us      51.964us       1.806ms        38.41%       1.806ms     112.874us            16  \n",
            "                                           aten::conv2d         0.57%      49.773us        17.26%       1.510ms     251.691us       0.000us         0.00%     723.835us     120.639us             6  \n",
            "                                      aten::convolution         0.63%      55.229us        16.69%       1.460ms     243.396us       0.000us         0.00%     723.835us     120.639us             6  \n",
            "                                     aten::_convolution         1.26%     109.842us        16.06%       1.405ms     234.191us       0.000us         0.00%     723.835us     120.639us             6  \n",
            "                                aten::cudnn_convolution        11.51%       1.007ms        14.16%       1.239ms     206.517us     709.307us        15.09%     709.307us     118.218us             6  \n",
            "                                 ampere_sgemm_32x128_tn         0.00%       0.000us         0.00%       0.000us       0.000us     679.840us        14.46%     679.840us     169.960us             4  \n",
            "                                              aten::bmm         3.12%     273.241us         3.91%     342.469us      42.809us     568.383us        12.09%     568.383us      71.048us             8  \n",
            "                                       aten::batch_norm         2.24%     195.892us        29.83%       2.610ms     118.618us       0.000us         0.00%     534.584us      24.299us            22  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 8.749ms\n",
            "Self CUDA time total: 4.702ms\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch import profiler\n",
        "\n",
        "dummy_input = torch.randn(32, 3, 224, 224).cuda()\n",
        "\n",
        "# Profiling inference\n",
        "with profiler.profile(\n",
        "    activities=[\n",
        "       profiler.ProfilerActivity.CPU,\n",
        "        profiler.ProfilerActivity.CUDA,  # Include if using GPU\n",
        "    ],\n",
        "    on_trace_ready=profiler.tensorboard_trace_handler(\"./logs\"),  # Optional logging\n",
        "    record_shapes=True,\n",
        "    with_stack=True\n",
        ") as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\" if torch.cuda.is_available() else \"cpu_time_total\", row_limit=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "jXvKsupvZYjZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, roc_curve, auc\n",
        "\n",
        "def score_evaluate(model, data_loader, criterion, device, phase=\"Validation\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=f\"{phase}\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    overall_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "    overall_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "    recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "    precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "    class_labels = sorted(set(all_labels))\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {accuracy:.2f}%\")\n",
        "    val_losses.append(epoch_loss)\n",
        "    val_accuracies.append(accuracy)\n",
        "\n",
        "    print(f\"Overall - F1: {overall_f1:.4f}, Recall: {overall_recall:.4f}, Precision: {overall_precision:.4f}\")\n",
        "    print(\"Per-Class Metrics:\")\n",
        "    for i, label in enumerate(class_labels):\n",
        "        print(f\"Class {label} - F1: {f1_per_class[i]:.4f}, Recall: {recall_per_class[i]:.4f}, Precision: {precision_per_class[i]:.4f}\")\n",
        "\n",
        "    return overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "oe9DO2tS-BpI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def roc_auc(model, data_loader, device, num_classes):\n",
        "\n",
        "    y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(data_loader, desc=\"ROC AUC\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_scores.extend(outputs.cpu().numpy())\n",
        "\n",
        "    all_labels = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "    print(f\"Binarized all_labels shape: {all_labels.shape}\")\n",
        "    print(f\"All_scores shape: {np.array(all_scores).shape}\")\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(all_labels.ravel(), np.array(all_scores).ravel())\n",
        "    roc_auc_value = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_value:0.4f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Overall ROC AUC: {roc_auc_value:.4f}\")\n",
        "\n",
        "    return fpr, tpr, roc_auc_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubbBuFrU-GRd",
        "outputId": "fa10944c-1962-4e13-9b2b-6d67fa96a65c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: 100%|██████████| 469/469 [00:21<00:00, 21.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0299, Test Accuracy: 99.20%\n",
            "Overall - F1: 0.9919, Recall: 0.9920, Precision: 0.9918\n",
            "Per-Class Metrics:\n",
            "Class 0 - F1: 0.9984, Recall: 1.0000, Precision: 0.9968\n",
            "Class 1 - F1: 1.0000, Recall: 1.0000, Precision: 1.0000\n",
            "Class 2 - F1: 0.9890, Recall: 0.9890, Precision: 0.9890\n",
            "Class 3 - F1: 0.9986, Recall: 0.9983, Precision: 0.9988\n",
            "Class 4 - F1: 0.9914, Recall: 0.9910, Precision: 0.9917\n",
            "Class 5 - F1: 0.9894, Recall: 0.9901, Precision: 0.9887\n",
            "Class 6 - F1: 0.9898, Recall: 0.9932, Precision: 0.9864\n",
            "Class 7 - F1: 0.9773, Recall: 0.9745, Precision: 0.9801\n",
            "Class 8 - F1: 0.9935, Recall: 0.9921, Precision: 0.9949\n"
          ]
        }
      ],
      "source": [
        "overall_f1, overall_recall, overall_precision, f1_per_class, recall_per_class, precision_per_class = score_evaluate(model, test_loader, criterion, device, phase=\"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "3qaLb5c--H0Q",
        "outputId": "caf20205-b35e-496c-9ddc-86fd7a8c5a38"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x = [\"ADI\", \"BACK\", \"DEB\", \"LYM\", \"MUC\", \"MUS\", \"NORM\", 'STR', \"TUM\"]\n",
        "y = [\"F1\", \"Precision\", \"Recall\"]\n",
        "\n",
        "f1_score_list = []\n",
        "precision_score_list = []\n",
        "recall_score_list = []\n",
        "\n",
        "for i, class_name in enumerate(x):\n",
        "    f1_score_list.append(f1_per_class[i])\n",
        "    precision_score_list.append(precision_per_class[i])\n",
        "    recall_score_list.append(recall_per_class[i])\n",
        "\n",
        "x.append(\"Overall\")\n",
        "f1_score_list.append(overall_f1)\n",
        "precision_score_list.append(overall_precision)\n",
        "recall_score_list.append(overall_recall)\n",
        "\n",
        "score_list = [f1_score_list, precision_score_list, recall_score_list]\n",
        "score_list = np.array(score_list)\n",
        "plt.figure(figsize=(20, 12))\n",
        "score_cm = plt.matshow(score_list, cmap=plt.cm.Blues, alpha=0.3)\n",
        "plt.xticks(range(len(x)), x)\n",
        "plt.yticks(range(len(y)), y)\n",
        "for i in range(len(y)):\n",
        "    for j in range(len(x)):\n",
        "        # 행렬의 각각의 수치를 각 칸의 중앙에 넣어준다\n",
        "        plt.text(x=j, y=i,\n",
        "                     s=\"{:.2f}\".format(score_list[i, j]),\n",
        "                     va='center',\n",
        "                     ha='center',\n",
        "                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "QCHdGKmbuw9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8e501a4-4117-4d16-899a-f8be749a3ad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved to HoViT22_bsda_elastic.pth\n"
          ]
        }
      ],
      "source": [
        "save_path = \"HoViT22_bsda_elastic.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model weights saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2NMYNeV0Ly5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}